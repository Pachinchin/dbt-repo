2022-01-05 08:51:08.011330 (MainThread): Running with dbt=1.0.1
2022-01-05 08:51:08.120177 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-05 08:51:08.136975 (MainThread): Tracking: tracking
2022-01-05 08:51:08.146317 (Thread-12): 08:51:08  Partial parse save file not found. Starting full parse.
2022-01-05 08:51:08.146870 (Thread-12): 08:51:08  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9045bf70>]}
2022-01-05 08:51:08.148317 (MainThread): 08:51:08  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7da4ee1be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9045bf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d903c2430>]}
2022-01-05 08:51:08.148595 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-05 08:51:08.148841 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-05 08:51:08.148974 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-05 08:51:08.177208 (Thread-12): 08:51:08  Parsing macros/catalog.sql
2022-01-05 08:51:08.190330 (Thread-12): 08:51:08  Parsing macros/adapters.sql
2022-01-05 08:51:08.218041 (Thread-12): 08:51:08  Parsing macros/relations.sql
2022-01-05 08:51:08.218589 (Thread-12): 08:51:08  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 08:51:08.219192 (Thread-12): 08:51:08  Parsing macros/catalog.sql
2022-01-05 08:51:08.221235 (Thread-12): 08:51:08  Parsing macros/adapters.sql
2022-01-05 08:51:08.242320 (Thread-12): 08:51:08  Parsing macros/relations.sql
2022-01-05 08:51:08.243557 (Thread-12): 08:51:08  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 08:51:08.245127 (Thread-12): 08:51:08  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-05 08:51:08.246577 (Thread-12): 08:51:08  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-05 08:51:08.248079 (Thread-12): 08:51:08  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-05 08:51:08.250469 (Thread-12): 08:51:08  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-05 08:51:08.251790 (Thread-12): 08:51:08  Parsing macros/generic_test_sql/not_null.sql
2022-01-05 08:51:08.252341 (Thread-12): 08:51:08  Parsing macros/generic_test_sql/relationships.sql
2022-01-05 08:51:08.253171 (Thread-12): 08:51:08  Parsing macros/generic_test_sql/unique.sql
2022-01-05 08:51:08.253896 (Thread-12): 08:51:08  Parsing macros/materializations/configs.sql
2022-01-05 08:51:08.256180 (Thread-12): 08:51:08  Parsing macros/materializations/hooks.sql
2022-01-05 08:51:08.260026 (Thread-12): 08:51:08  Parsing macros/materializations/snapshots/strategies.sql
2022-01-05 08:51:08.276370 (Thread-12): 08:51:08  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-05 08:51:08.278102 (Thread-12): 08:51:08  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-05 08:51:08.289092 (Thread-12): 08:51:08  Parsing macros/materializations/snapshots/helpers.sql
2022-01-05 08:51:08.299645 (Thread-12): 08:51:08  Parsing macros/materializations/seeds/seed.sql
2022-01-05 08:51:08.305575 (Thread-12): 08:51:08  Parsing macros/materializations/seeds/helpers.sql
2022-01-05 08:51:08.321519 (Thread-12): 08:51:08  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-05 08:51:08.323757 (Thread-12): 08:51:08  Parsing macros/materializations/models/view/view.sql
2022-01-05 08:51:08.330394 (Thread-12): 08:51:08  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-05 08:51:08.332952 (Thread-12): 08:51:08  Parsing macros/materializations/models/view/helpers.sql
2022-01-05 08:51:08.334258 (Thread-12): 08:51:08  Parsing macros/materializations/models/table/table.sql
2022-01-05 08:51:08.341177 (Thread-12): 08:51:08  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-05 08:51:08.344053 (Thread-12): 08:51:08  Parsing macros/materializations/models/incremental/merge.sql
2022-01-05 08:51:08.354876 (Thread-12): 08:51:08  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-05 08:51:08.369575 (Thread-12): 08:51:08  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-05 08:51:08.373951 (Thread-12): 08:51:08  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-05 08:51:08.384028 (Thread-12): 08:51:08  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-05 08:51:08.384949 (Thread-13): handling status request
2022-01-05 08:51:08.386552 (Thread-12): 08:51:08  Parsing macros/materializations/tests/test.sql
2022-01-05 08:51:08.386843 (Thread-13): 08:51:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9042ebe0>]}
2022-01-05 08:51:08.391133 (Thread-12): 08:51:08  Parsing macros/materializations/tests/where_subquery.sql
2022-01-05 08:51:08.391683 (Thread-13): sending response (<Response 185 bytes [200 OK]>) to 10.0.46.191
2022-01-05 08:51:08.393552 (Thread-12): 08:51:08  Parsing macros/materializations/tests/helpers.sql
2022-01-05 08:51:08.395827 (Thread-12): 08:51:08  Parsing macros/etc/statement.sql
2022-01-05 08:51:08.400347 (Thread-12): 08:51:08  Parsing macros/etc/datetime.sql
2022-01-05 08:51:08.408395 (Thread-12): 08:51:08  Parsing macros/adapters/indexes.sql
2022-01-05 08:51:08.411105 (Thread-12): 08:51:08  Parsing macros/adapters/persist_docs.sql
2022-01-05 08:51:08.415428 (Thread-12): 08:51:08  Parsing macros/adapters/freshness.sql
2022-01-05 08:51:08.418304 (Thread-12): 08:51:08  Parsing macros/adapters/relation.sql
2022-01-05 08:51:08.427537 (Thread-12): 08:51:08  Parsing macros/adapters/metadata.sql
2022-01-05 08:51:08.434440 (Thread-12): 08:51:08  Parsing macros/adapters/columns.sql
2022-01-05 08:51:08.444094 (Thread-12): 08:51:08  Parsing macros/adapters/schema.sql
2022-01-05 08:51:08.446260 (Thread-12): 08:51:08  Parsing tests/generic/builtin.sql
2022-01-05 08:51:08.563263 (Thread-14): handling status request
2022-01-05 08:51:08.583890 (Thread-14): 08:51:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d903a28e0>]}
2022-01-05 08:51:08.589446 (Thread-14): sending response (<Response 185 bytes [200 OK]>) to 10.0.40.203
2022-01-05 08:51:08.647813 (Thread-12): 08:51:08  1699: static parser successfully parsed example/my_second_dbt_model.sql
2022-01-05 08:51:08.659991 (Thread-12): 08:51:08  1699: static parser successfully parsed example/my_first_dbt_model.sql
2022-01-05 08:51:08.742064 (Thread-12): 08:51:08  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900f4520>]}
2022-01-05 08:51:09.755583 (Thread-15): handling status request
2022-01-05 08:51:09.755916 (Thread-15): 08:51:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d90108c40>]}
2022-01-05 08:51:09.756769 (Thread-15): sending response (<Response 15479 bytes [200 OK]>) to 10.0.46.191
2022-01-05 08:51:09.990366 (Thread-16): handling status request
2022-01-05 08:51:09.990688 (Thread-16): 08:51:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d904437c0>]}
2022-01-05 08:51:09.991516 (Thread-16): sending response (<Response 15479 bytes [200 OK]>) to 10.0.41.88
2022-01-05 08:51:59.578565 (Thread-17): handling status request
2022-01-05 08:51:59.580516 (Thread-17): 08:51:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900f45e0>]}
2022-01-05 08:51:59.581332 (Thread-17): sending response (<Response 15479 bytes [200 OK]>) to 10.0.28.79
2022-01-05 08:52:01.823634 (Thread-18): 08:52:01  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 08:52:01.823819 (Thread-18): 08:52:01  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 08:52:01.828713 (Thread-18): 08:52:01  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9006bb80>]}
2022-01-05 08:52:02.470383 (Thread-19): handling status request
2022-01-05 08:52:02.470708 (Thread-19): 08:52:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900812b0>]}
2022-01-05 08:52:02.471163 (Thread-19): sending response (<Response 1241 bytes [200 OK]>) to 10.0.8.202
2022-01-05 08:52:02.486184 (Thread-20): handling status request
2022-01-05 08:52:02.486451 (Thread-20): 08:52:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d90062be0>]}
2022-01-05 08:52:02.486868 (Thread-20): sending response (<Response 1241 bytes [200 OK]>) to 10.0.8.202
2022-01-05 08:52:19.316700 (Thread-21): handling status request
2022-01-05 08:52:19.317027 (Thread-21): 08:52:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d90062dc0>]}
2022-01-05 08:52:19.317502 (Thread-21): sending response (<Response 1241 bytes [200 OK]>) to 10.0.23.251
2022-01-05 08:52:19.347521 (Thread-22): handling status request
2022-01-05 08:52:19.347755 (Thread-22): 08:52:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d90062a60>]}
2022-01-05 08:52:19.348148 (Thread-22): sending response (<Response 1241 bytes [200 OK]>) to 10.0.43.0
2022-01-05 08:52:19.386192 (Thread-23): handling status request
2022-01-05 08:52:19.386409 (Thread-23): 08:52:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900622e0>]}
2022-01-05 08:52:19.386790 (Thread-23): sending response (<Response 1241 bytes [200 OK]>) to 10.0.28.79
2022-01-05 08:52:19.396619 (Thread-24): handling ps request
2022-01-05 08:52:19.396829 (Thread-24): 08:52:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9040c1c0>]}
2022-01-05 08:52:19.397167 (Thread-24): sending response (<Response 105 bytes [200 OK]>) to 10.0.9.20
2022-01-05 08:52:20.122437 (Thread-25): handling status request
2022-01-05 08:52:20.122798 (Thread-25): 08:52:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9045b340>]}
2022-01-05 08:52:20.123265 (Thread-25): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 08:52:20.129072 (Thread-26): handling list request
2022-01-05 08:52:20.129284 (Thread-26): 08:52:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d90441d60>]}
2022-01-05 08:52:20.157288 (Thread-26): 08:52:20  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900eee20>]}
2022-01-05 08:52:20.157639 (Thread-26): 08:52:20  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 08:52:20.161548 (Thread-26): 08:52:20  The selection criterion '+1641370237724/__unsaved/Statement' does not match any nodes
2022-01-05 08:52:20.161741 (Thread-26): 08:52:20  The selection criterion '1.sql+' does not match any nodes
2022-01-05 08:52:20.161842 (Thread-26): 08:52:20  No nodes selected!
2022-01-05 08:52:20.163275 (Thread-26): sending response (<Response 2348 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:02:37.322806 (Thread-27): handling status request
2022-01-05 09:02:37.324268 (Thread-27): 09:02:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900621c0>]}
2022-01-05 09:02:37.324725 (Thread-27): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:02:37.336332 (Thread-28): handling list request
2022-01-05 09:02:37.336559 (Thread-28): 09:02:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9006d880>]}
2022-01-05 09:02:37.364380 (Thread-28): 09:02:37  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9006df70>]}
2022-01-05 09:02:37.364642 (Thread-28): 09:02:37  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:02:37.372442 (Thread-28): sending response (<Response 5008 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:03:12.543069 (Thread-29): handling status request
2022-01-05 09:03:12.544560 (Thread-29): 09:03:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9006b8e0>]}
2022-01-05 09:03:12.545041 (Thread-29): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:03:12.555852 (Thread-30): handling list request
2022-01-05 09:03:12.556058 (Thread-30): 09:03:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9006df40>]}
2022-01-05 09:03:12.585449 (Thread-30): 09:03:12  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1c6f40>]}
2022-01-05 09:03:12.585700 (Thread-30): 09:03:12  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:03:12.589315 (Thread-30): sending response (<Response 5008 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:03:14.157262 (Thread-31): handling status request
2022-01-05 09:03:14.157613 (Thread-31): 09:03:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1cca30>]}
2022-01-05 09:03:14.158055 (Thread-31): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:03:14.163783 (Thread-32): handling list request
2022-01-05 09:03:14.163987 (Thread-32): 09:03:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1cccd0>]}
2022-01-05 09:03:14.192632 (Thread-32): 09:03:14  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1cca60>]}
2022-01-05 09:03:14.192877 (Thread-32): 09:03:14  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:03:14.196089 (Thread-32): sending response (<Response 5008 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:03:16.843650 (Thread-33): handling status request
2022-01-05 09:03:16.843979 (Thread-33): 09:03:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1d6550>]}
2022-01-05 09:03:16.844436 (Thread-33): sending response (<Response 1241 bytes [200 OK]>) to 10.0.41.88
2022-01-05 09:03:17.249854 (Thread-34): handling run_sql request
2022-01-05 09:03:17.250176 (Thread-34): 09:03:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1d61c0>]}
2022-01-05 09:03:19.341231 (Thread-34): sending response (<Response 138 bytes [200 OK]>) to 10.0.3.189
2022-01-05 09:03:19.366656 (MainThread): 09:03:19  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '58794d9e-e72f-42cc-a6ba-525420adedff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c0ab1bc70>]}
2022-01-05 09:03:19.367186 (MainThread): 09:03:19  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:03:19.367743 (Thread-1): 09:03:19  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:03:19.367876 (Thread-1): 09:03:19  Began compiling node rpc.my_new_project.request
2022-01-05 09:03:19.367966 (Thread-1): 09:03:19  Compiling rpc.my_new_project.request
2022-01-05 09:03:19.369986 (Thread-1): 09:03:19  finished collecting timing info
2022-01-05 09:03:19.370114 (Thread-1): 09:03:19  Began executing node rpc.my_new_project.request
2022-01-05 09:03:19.370209 (Thread-1): 09:03:19  Using redshift connection "rpc.my_new_project.request"
2022-01-05 09:03:19.370283 (Thread-1): 09:03:19  On rpc.my_new_project.request: -- Use the `ref` function to select from other models

select *
from "analytics"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:03:19.370358 (Thread-1): 09:03:19  Opening a new connection, currently in state init
2022-01-05 09:03:19.370436 (Thread-1): 09:03:19  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:03:19.385650 (Thread-1): 09:03:19  Postgres adapter: Got an error when attempting to open a postgres connection: 'FATAL:  database "analytics" does not exist
'
2022-01-05 09:03:19.385790 (Thread-1): 09:03:19  Postgres adapter: Error running SQL: -- Use the `ref` function to select from other models

select *
from "analytics"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:03:19.385867 (Thread-1): 09:03:19  Postgres adapter: Rolling back transaction.
2022-01-05 09:03:19.385961 (Thread-1): 09:03:19  finished collecting timing info
2022-01-05 09:03:19.386068 (Thread-1): 09:03:19  On rpc.my_new_project.request: No close available on handle
2022-01-05 09:03:19.386130 (Thread-1): Got an exception: Database Error
  FATAL:  database "analytics" does not exist
  
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 121, in open
    handle = psycopg2.connect(
  File "/usr/local/lib/python3.8/dist-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: FATAL:  database "analytics" does not exist


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 73, in add_query
    cursor = connection.handle.cursor()
  File "/usr/local/lib/python3.8/dist-packages/dbt/contracts/connection.py", line 83, in handle
    self._handle.resolve(self)
  File "/usr/local/lib/python3.8/dist-packages/dbt/contracts/connection.py", line 106, in resolve
    return self.opener(connection)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 143, in open
    raise dbt.exceptions.FailedToConnectException(str(e))
dbt.exceptions.FailedToConnectException: Database Error
  FATAL:  database "analytics" does not exist
2022-01-05 09:03:19.387286 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'FailedToConnectException', 'message': 'Database Error in rpc request (from remote system)\n  FATAL:  database "analytics" does not exist\n  ', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "analytics"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'FailedToConnectException', 'message': 'Database Error in rpc request (from remote system)\n  FATAL:  database "analytics" does not exist\n  ', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "analytics"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 09:03:19.708666 (Thread-35): handling poll request
2022-01-05 09:03:19.709078 (Thread-35): 09:03:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1d6610>]}
2022-01-05 09:03:19.737619 (Thread-35): sending response (<Response 10666 bytes [200 OK]>) to 10.0.8.124
2022-01-05 09:04:11.409852 (MainThread): Running with dbt=1.0.1
2022-01-05 09:04:11.512021 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-05 09:04:11.519046 (MainThread): Tracking: tracking
2022-01-05 09:04:11.539288 (MainThread): 09:04:11  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f501bf4cc40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4889a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee488cd0>]}
2022-01-05 09:04:11.539672 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-05 09:04:11.539911 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-05 09:04:11.540043 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-05 09:04:11.549989 (Thread-12): 09:04:11  Unable to do partial parsing because profile has changed
2022-01-05 09:04:11.550312 (Thread-12): 09:04:11  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee488bb0>]}
2022-01-05 09:04:11.591674 (Thread-12): 09:04:11  Parsing macros/catalog.sql
2022-01-05 09:04:11.604631 (Thread-12): 09:04:11  Parsing macros/adapters.sql
2022-01-05 09:04:11.632278 (Thread-12): 09:04:11  Parsing macros/relations.sql
2022-01-05 09:04:11.633008 (Thread-12): 09:04:11  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 09:04:11.633670 (Thread-12): 09:04:11  Parsing macros/catalog.sql
2022-01-05 09:04:11.635756 (Thread-12): 09:04:11  Parsing macros/adapters.sql
2022-01-05 09:04:11.656938 (Thread-12): 09:04:11  Parsing macros/relations.sql
2022-01-05 09:04:11.658228 (Thread-12): 09:04:11  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 09:04:11.659842 (Thread-12): 09:04:11  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-05 09:04:11.661346 (Thread-12): 09:04:11  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-05 09:04:11.662876 (Thread-12): 09:04:11  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-05 09:04:11.665320 (Thread-12): 09:04:11  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-05 09:04:11.666705 (Thread-12): 09:04:11  Parsing macros/generic_test_sql/not_null.sql
2022-01-05 09:04:11.667273 (Thread-12): 09:04:11  Parsing macros/generic_test_sql/relationships.sql
2022-01-05 09:04:11.668130 (Thread-12): 09:04:11  Parsing macros/generic_test_sql/unique.sql
2022-01-05 09:04:11.668873 (Thread-12): 09:04:11  Parsing macros/materializations/configs.sql
2022-01-05 09:04:11.671125 (Thread-12): 09:04:11  Parsing macros/materializations/hooks.sql
2022-01-05 09:04:11.674988 (Thread-12): 09:04:11  Parsing macros/materializations/snapshots/strategies.sql
2022-01-05 09:04:11.691247 (Thread-12): 09:04:11  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-05 09:04:11.693018 (Thread-12): 09:04:11  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-05 09:04:11.704072 (Thread-12): 09:04:11  Parsing macros/materializations/snapshots/helpers.sql
2022-01-05 09:04:11.714904 (Thread-12): 09:04:11  Parsing macros/materializations/seeds/seed.sql
2022-01-05 09:04:11.720799 (Thread-12): 09:04:11  Parsing macros/materializations/seeds/helpers.sql
2022-01-05 09:04:11.736629 (Thread-12): 09:04:11  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-05 09:04:11.738975 (Thread-12): 09:04:11  Parsing macros/materializations/models/view/view.sql
2022-01-05 09:04:11.745673 (Thread-12): 09:04:11  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-05 09:04:11.748277 (Thread-12): 09:04:11  Parsing macros/materializations/models/view/helpers.sql
2022-01-05 09:04:11.749619 (Thread-12): 09:04:11  Parsing macros/materializations/models/table/table.sql
2022-01-05 09:04:11.756688 (Thread-12): 09:04:11  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-05 09:04:11.759484 (Thread-12): 09:04:11  Parsing macros/materializations/models/incremental/merge.sql
2022-01-05 09:04:11.770604 (Thread-12): 09:04:11  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-05 09:04:11.785628 (Thread-12): 09:04:11  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-05 09:04:11.790144 (Thread-12): 09:04:11  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-05 09:04:11.800038 (Thread-12): 09:04:11  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-05 09:04:11.801725 (Thread-12): 09:04:11  Parsing macros/materializations/tests/test.sql
2022-01-05 09:04:11.806220 (Thread-12): 09:04:11  Parsing macros/materializations/tests/where_subquery.sql
2022-01-05 09:04:11.808034 (Thread-12): 09:04:11  Parsing macros/materializations/tests/helpers.sql
2022-01-05 09:04:11.809814 (Thread-12): 09:04:11  Parsing macros/etc/statement.sql
2022-01-05 09:04:11.814144 (Thread-12): 09:04:11  Parsing macros/etc/datetime.sql
2022-01-05 09:04:11.822725 (Thread-12): 09:04:11  Parsing macros/adapters/indexes.sql
2022-01-05 09:04:11.825672 (Thread-12): 09:04:11  Parsing macros/adapters/persist_docs.sql
2022-01-05 09:04:11.830083 (Thread-12): 09:04:11  Parsing macros/adapters/freshness.sql
2022-01-05 09:04:11.833006 (Thread-12): 09:04:11  Parsing macros/adapters/relation.sql
2022-01-05 09:04:11.842797 (Thread-12): 09:04:11  Parsing macros/adapters/metadata.sql
2022-01-05 09:04:11.849992 (Thread-12): 09:04:11  Parsing macros/adapters/columns.sql
2022-01-05 09:04:11.859752 (Thread-12): 09:04:11  Parsing macros/adapters/schema.sql
2022-01-05 09:04:11.862089 (Thread-12): 09:04:11  Parsing tests/generic/builtin.sql
2022-01-05 09:04:12.056049 (Thread-12): 09:04:12  1699: static parser successfully parsed example/my_second_dbt_model.sql
2022-01-05 09:04:12.071674 (Thread-12): 09:04:12  1699: static parser successfully parsed example/my_first_dbt_model.sql
2022-01-05 09:04:12.160181 (Thread-12): 09:04:12  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fed458220>]}
2022-01-05 09:04:13.915456 (Thread-13): handling status request
2022-01-05 09:04:13.915832 (Thread-13): 09:04:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4d0d30>]}
2022-01-05 09:04:13.916831 (Thread-13): sending response (<Response 15522 bytes [200 OK]>) to 10.0.1.185
2022-01-05 09:04:13.991280 (Thread-14): handling status request
2022-01-05 09:04:13.991676 (Thread-14): 09:04:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4ec670>]}
2022-01-05 09:04:13.992889 (Thread-14): sending response (<Response 15522 bytes [200 OK]>) to 10.0.9.20
2022-01-05 09:04:13.994304 (Thread-15): handling ps request
2022-01-05 09:04:13.994676 (Thread-15): 09:04:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee534340>]}
2022-01-05 09:04:13.995094 (Thread-15): sending response (<Response 105 bytes [200 OK]>) to 10.0.23.251
2022-01-05 09:04:14.000271 (Thread-16): handling status request
2022-01-05 09:04:14.000547 (Thread-16): 09:04:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1b74f0>]}
2022-01-05 09:04:14.001420 (Thread-16): sending response (<Response 15522 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:04:22.189781 (Thread-17): handling status request
2022-01-05 09:04:22.191647 (Thread-17): 09:04:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1b7bb0>]}
2022-01-05 09:04:22.192590 (Thread-17): sending response (<Response 15522 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:04:22.523700 (Thread-18): handling run_sql request
2022-01-05 09:04:22.524068 (Thread-18): 09:04:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1b7970>]}
2022-01-05 09:04:24.664280 (Thread-18): sending response (<Response 138 bytes [200 OK]>) to 10.0.22.146
2022-01-05 09:04:24.690177 (MainThread): 09:04:24  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '89d1a01a-870b-4d87-81f6-72548cd1c1b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbee73e610>]}
2022-01-05 09:04:24.690780 (MainThread): 09:04:24  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:04:24.691387 (Thread-1): 09:04:24  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:04:24.691519 (Thread-1): 09:04:24  Began compiling node rpc.my_new_project.request
2022-01-05 09:04:24.691618 (Thread-1): 09:04:24  Compiling rpc.my_new_project.request
2022-01-05 09:04:24.693739 (Thread-1): 09:04:24  finished collecting timing info
2022-01-05 09:04:24.693885 (Thread-1): 09:04:24  Began executing node rpc.my_new_project.request
2022-01-05 09:04:24.693988 (Thread-1): 09:04:24  Using redshift connection "rpc.my_new_project.request"
2022-01-05 09:04:24.694065 (Thread-1): 09:04:24  On rpc.my_new_project.request: -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:04:24.694144 (Thread-1): 09:04:24  Opening a new connection, currently in state init
2022-01-05 09:04:24.694225 (Thread-1): 09:04:24  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:04:24.713806 (Thread-1): 09:04:24  Postgres adapter: Postgres error: Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".

2022-01-05 09:04:24.714045 (Thread-1): 09:04:24  finished collecting timing info
2022-01-05 09:04:24.714202 (Thread-1): 09:04:24  On rpc.my_new_project.request: Close
2022-01-05 09:04:24.714535 (Thread-1): Got an exception: Database Error
  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InternalError_: Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".
2022-01-05 09:04:24.715633 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "dev"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "dev"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 09:04:25.015250 (Thread-19): handling poll request
2022-01-05 09:04:25.015713 (Thread-19): 09:04:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1b7100>]}
2022-01-05 09:04:25.016611 (Thread-19): sending response (<Response 9862 bytes [200 OK]>) to 10.0.18.33
2022-01-05 09:04:54.409698 (Thread-20): handling status request
2022-01-05 09:04:54.411835 (Thread-20): 09:04:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1bcb50>]}
2022-01-05 09:04:54.412898 (Thread-20): sending response (<Response 15522 bytes [200 OK]>) to 10.0.43.0
2022-01-05 09:04:54.781767 (Thread-21): handling run_sql request
2022-01-05 09:04:54.782138 (Thread-21): 09:04:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1bc520>]}
2022-01-05 09:04:56.916885 (Thread-21): sending response (<Response 138 bytes [200 OK]>) to 10.0.18.33
2022-01-05 09:04:56.946111 (MainThread): 09:04:56  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '324af820-22ff-48a5-98c8-39e0f6b53e87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe96c63d700>]}
2022-01-05 09:04:56.946707 (MainThread): 09:04:56  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:04:56.947327 (Thread-1): 09:04:56  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:04:56.947462 (Thread-1): 09:04:56  Began compiling node rpc.my_new_project.request
2022-01-05 09:04:56.947557 (Thread-1): 09:04:56  Compiling rpc.my_new_project.request
2022-01-05 09:04:56.949641 (Thread-1): 09:04:56  finished collecting timing info
2022-01-05 09:04:56.949774 (Thread-1): 09:04:56  Began executing node rpc.my_new_project.request
2022-01-05 09:04:56.949875 (Thread-1): 09:04:56  Using redshift connection "rpc.my_new_project.request"
2022-01-05 09:04:56.949950 (Thread-1): 09:04:56  On rpc.my_new_project.request: /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:04:56.950028 (Thread-1): 09:04:56  Opening a new connection, currently in state init
2022-01-05 09:04:56.950107 (Thread-1): 09:04:56  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:04:56.969208 (Thread-1): 09:04:56  SQL status: SELECT in 0.02 seconds
2022-01-05 09:04:56.970292 (Thread-1): 09:04:56  finished collecting timing info
2022-01-05 09:04:56.970446 (Thread-1): 09:04:56  On rpc.my_new_project.request: Close
2022-01-05 09:04:57.242792 (Thread-22): handling poll request
2022-01-05 09:04:57.243226 (Thread-22): 09:04:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1cb3d0>]}
2022-01-05 09:04:57.244488 (Thread-22): sending response (<Response 9360 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:05:06.113750 (Thread-23): handling status request
2022-01-05 09:05:06.114136 (Thread-23): 09:05:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1cb820>]}
2022-01-05 09:05:06.115081 (Thread-23): sending response (<Response 15522 bytes [200 OK]>) to 10.0.8.124
2022-01-05 09:05:06.451010 (Thread-24): handling run_sql request
2022-01-05 09:05:06.451395 (Thread-24): 09:05:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fed4244c0>]}
2022-01-05 09:05:08.580355 (Thread-24): sending response (<Response 138 bytes [200 OK]>) to 10.0.3.45
2022-01-05 09:05:08.606974 (MainThread): 09:05:08  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3af1ed36-2cb4-40ad-bc65-29c40b3ce858', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa05a4b2790>]}
2022-01-05 09:05:08.607592 (MainThread): 09:05:08  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:05:08.608220 (Thread-1): 09:05:08  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:05:08.608356 (Thread-1): 09:05:08  Began compiling node rpc.my_new_project.request
2022-01-05 09:05:08.608450 (Thread-1): 09:05:08  Compiling rpc.my_new_project.request
2022-01-05 09:05:08.610677 (Thread-1): 09:05:08  finished collecting timing info
2022-01-05 09:05:08.610814 (Thread-1): 09:05:08  Began executing node rpc.my_new_project.request
2022-01-05 09:05:08.610918 (Thread-1): 09:05:08  Using redshift connection "rpc.my_new_project.request"
2022-01-05 09:05:08.610998 (Thread-1): 09:05:08  On rpc.my_new_project.request: -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:05:08.611078 (Thread-1): 09:05:08  Opening a new connection, currently in state init
2022-01-05 09:05:08.611160 (Thread-1): 09:05:08  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:05:08.629183 (Thread-1): 09:05:08  Postgres adapter: Postgres error: Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".

2022-01-05 09:05:08.629421 (Thread-1): 09:05:08  finished collecting timing info
2022-01-05 09:05:08.629558 (Thread-1): 09:05:08  On rpc.my_new_project.request: Close
2022-01-05 09:05:08.629857 (Thread-1): Got an exception: Database Error
  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InternalError_: Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".
2022-01-05 09:05:08.630962 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "dev"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "dev"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 09:05:08.979242 (Thread-25): handling poll request
2022-01-05 09:05:08.980012 (Thread-25): 09:05:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fed4248e0>]}
2022-01-05 09:05:08.980844 (Thread-25): sending response (<Response 9862 bytes [200 OK]>) to 10.0.8.124
2022-01-05 09:06:13.735816 (Thread-26): handling ps request
2022-01-05 09:06:13.736229 (Thread-26): 09:06:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4c4100>]}
2022-01-05 09:06:13.736947 (Thread-26): sending response (<Response 1640 bytes [200 OK]>) to 10.0.19.22
2022-01-05 09:06:13.755989 (Thread-27): handling status request
2022-01-05 09:06:13.756354 (Thread-27): 09:06:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4c43a0>]}
2022-01-05 09:06:13.757345 (Thread-27): sending response (<Response 15522 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:06:13.821135 (Thread-28): handling status request
2022-01-05 09:06:13.821499 (Thread-28): 09:06:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4c4130>]}
2022-01-05 09:06:13.822340 (Thread-28): sending response (<Response 15522 bytes [200 OK]>) to 10.0.43.0
2022-01-05 09:06:13.863141 (Thread-29): handling status request
2022-01-05 09:06:13.863551 (Thread-29): 09:06:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec185640>]}
2022-01-05 09:06:13.864426 (Thread-29): sending response (<Response 15522 bytes [200 OK]>) to 10.0.3.45
2022-01-05 09:06:14.953143 (Thread-30): handling status request
2022-01-05 09:06:14.953763 (Thread-30): 09:06:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1853d0>]}
2022-01-05 09:06:14.954734 (Thread-30): sending response (<Response 15500 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:14.955270 (Thread-31): handling status request
2022-01-05 09:06:14.956322 (Thread-32): handling status request
2022-01-05 09:06:14.956786 (Thread-31): 09:06:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec185fd0>]}
2022-01-05 09:06:14.957117 (Thread-32): 09:06:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4c44f0>]}
2022-01-05 09:06:14.958001 (Thread-31): sending response (<Response 15500 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:14.958908 (Thread-32): sending response (<Response 15500 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:14.962866 (Thread-33): handling list request
2022-01-05 09:06:14.963121 (Thread-33): 09:06:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1851f0>]}
2022-01-05 09:06:14.967226 (Thread-34): handling list request
2022-01-05 09:06:15.017078 (Thread-35): sending response (<Response 214 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:16.371885 (Thread-36): handling status request
2022-01-05 09:06:16.372264 (Thread-36): 09:06:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fed41c580>]}
2022-01-05 09:06:16.396600 (Thread-36): sending response (<Response 15500 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:16.402751 (Thread-37): handling list request
2022-01-05 09:06:16.403061 (Thread-37): 09:06:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1ce250>]}
2022-01-05 09:06:16.433529 (Thread-37): 09:06:16  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0e87f0>]}
2022-01-05 09:06:16.433897 (Thread-37): 09:06:16  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:06:16.436616 (Thread-37): sending response (<Response 5006 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:21.670744 (Thread-38): handling status request
2022-01-05 09:06:21.671124 (Thread-38): 09:06:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0e8f40>]}
2022-01-05 09:06:21.671998 (Thread-38): sending response (<Response 15500 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:21.677522 (Thread-39): handling list request
2022-01-05 09:06:21.677822 (Thread-39): 09:06:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec15f250>]}
2022-01-05 09:06:21.705736 (Thread-39): 09:06:21  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0e80d0>]}
2022-01-05 09:06:21.706132 (Thread-39): 09:06:21  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:06:21.706989 (Thread-39): 09:06:21  The selection criterion '+1641370237724/__unsaved/Statement' does not match any nodes
2022-01-05 09:06:21.707205 (Thread-39): 09:06:21  The selection criterion '1.sql+' does not match any nodes
2022-01-05 09:06:21.707317 (Thread-39): 09:06:21  No nodes selected!
2022-01-05 09:06:21.708960 (Thread-39): sending response (<Response 2343 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:23.571235 (Thread-40): handling status request
2022-01-05 09:06:23.571625 (Thread-40): 09:06:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec15fc70>]}
2022-01-05 09:06:23.572502 (Thread-40): sending response (<Response 15522 bytes [200 OK]>) to 10.0.40.203
2022-01-05 09:06:23.925543 (Thread-41): handling run_sql request
2022-01-05 09:06:23.925910 (Thread-41): 09:06:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec15fee0>]}
2022-01-05 09:06:26.097478 (Thread-41): sending response (<Response 138 bytes [200 OK]>) to 10.0.22.146
2022-01-05 09:06:26.123748 (MainThread): 09:06:26  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a7aa97a1-f89b-4a75-9529-d7fcbab33bbf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752814a970>]}
2022-01-05 09:06:26.124341 (MainThread): 09:06:26  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:06:26.124964 (Thread-1): 09:06:26  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:06:26.125092 (Thread-1): 09:06:26  Began compiling node rpc.my_new_project.request
2022-01-05 09:06:26.125184 (Thread-1): 09:06:26  Compiling rpc.my_new_project.request
2022-01-05 09:06:26.127816 (Thread-1): 09:06:26  finished collecting timing info
2022-01-05 09:06:26.127948 (Thread-1): 09:06:26  Began executing node rpc.my_new_project.request
2022-01-05 09:06:26.128049 (Thread-1): 09:06:26  Using redshift connection "rpc.my_new_project.request"
2022-01-05 09:06:26.128125 (Thread-1): 09:06:26  On rpc.my_new_project.request: 

  select 0 as number  union all 



  select 1 as number  union all 



  select 2 as number  union all 



  select 3 as number  union all 



  select 4 as number  union all 



  select 5 as number  union all 



  select 6 as number  union all 



  select 7 as number  union all 



  select 8 as number  union all 



  select 9 as number 


limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:06:26.128205 (Thread-1): 09:06:26  Opening a new connection, currently in state init
2022-01-05 09:06:26.128286 (Thread-1): 09:06:26  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:06:26.147532 (Thread-1): 09:06:26  SQL status: SELECT in 0.02 seconds
2022-01-05 09:06:26.148790 (Thread-1): 09:06:26  finished collecting timing info
2022-01-05 09:06:26.148961 (Thread-1): 09:06:26  On rpc.my_new_project.request: Close
2022-01-05 09:06:26.504522 (Thread-42): handling poll request
2022-01-05 09:06:26.504980 (Thread-42): 09:06:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec10d3a0>]}
2022-01-05 09:06:26.506218 (Thread-42): sending response (<Response 8387 bytes [200 OK]>) to 10.0.41.88
2022-01-05 09:13:02.276770 (Thread-43): handling status request
2022-01-05 09:13:02.278899 (Thread-43): 09:13:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec10d550>]}
2022-01-05 09:13:02.279948 (Thread-43): sending response (<Response 15522 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:13:02.703429 (Thread-44): handling compile_sql request
2022-01-05 09:13:02.703827 (Thread-44): 09:13:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec10d940>]}
2022-01-05 09:13:04.869826 (Thread-44): sending response (<Response 138 bytes [200 OK]>) to 10.0.19.22
2022-01-05 09:13:04.899073 (MainThread): 09:13:04  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1a6ba891-5ee6-436c-af81-f6ab818da749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ba0fa1f10>]}
2022-01-05 09:13:04.899729 (MainThread): 09:13:04  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:13:04.900396 (Thread-1): 09:13:04  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:13:04.900571 (Thread-1): 09:13:04  Began compiling node rpc.my_new_project.request
2022-01-05 09:13:04.900669 (Thread-1): 09:13:04  Compiling rpc.my_new_project.request
2022-01-05 09:13:04.902031 (Thread-1): 09:13:04  finished collecting timing info
2022-01-05 09:13:04.902163 (Thread-1): 09:13:04  Began executing node rpc.my_new_project.request
2022-01-05 09:13:04.902271 (Thread-1): 09:13:04  finished collecting timing info
2022-01-05 09:13:05.221887 (Thread-45): handling poll request
2022-01-05 09:13:05.222340 (Thread-45): 09:13:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec10d490>]}
2022-01-05 09:13:05.223397 (Thread-45): sending response (<Response 7164 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:18:22.647626 (Thread-46): handling status request
2022-01-05 09:18:22.649759 (Thread-46): 09:18:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1c4970>]}
2022-01-05 09:18:22.650800 (Thread-46): sending response (<Response 15522 bytes [200 OK]>) to 10.0.23.251
2022-01-05 09:18:22.888748 (Thread-47): handling status request
2022-01-05 09:18:22.889117 (Thread-47): 09:18:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fed442700>]}
2022-01-05 09:18:22.889993 (Thread-47): sending response (<Response 15522 bytes [200 OK]>) to 10.0.9.20
2022-01-05 09:18:22.991082 (Thread-48): handling cli_args request
2022-01-05 09:18:22.991456 (Thread-48): 09:18:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1106d0>]}
2022-01-05 09:18:25.164595 (Thread-48): sending response (<Response 138 bytes [200 OK]>) to 10.0.41.88
2022-01-05 09:18:25.262928 (MainThread): 09:18:25  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 09:18:25.263373 (MainThread): 09:18:25  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 09:18:25.269715 (MainThread): 09:18:25  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0ffdc471-2794-4ba4-a05d-6e70a316dfc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd62777a60>]}
2022-01-05 09:18:25.304676 (MainThread): 09:18:25  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0ffdc471-2794-4ba4-a05d-6e70a316dfc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd627d7a00>]}
2022-01-05 09:18:25.305019 (MainThread): 09:18:25  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:18:25.306193 (MainThread): 09:18:25  
2022-01-05 09:18:25.306547 (MainThread): 09:18:25  Acquiring new redshift connection "master"
2022-01-05 09:18:25.307511 (ThreadPoolExecutor-0_0): 09:18:25  Acquiring new redshift connection "list_dev"
2022-01-05 09:18:25.318203 (ThreadPoolExecutor-0_0): 09:18:25  Using redshift connection "list_dev"
2022-01-05 09:18:25.318333 (ThreadPoolExecutor-0_0): 09:18:25  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-05 09:18:25.318424 (ThreadPoolExecutor-0_0): 09:18:25  Opening a new connection, currently in state init
2022-01-05 09:18:25.318511 (ThreadPoolExecutor-0_0): 09:18:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:25.337776 (ThreadPoolExecutor-0_0): 09:18:25  SQL status: SELECT in 0.02 seconds
2022-01-05 09:18:25.339009 (ThreadPoolExecutor-0_0): 09:18:25  On list_dev: Close
2022-01-05 09:18:25.339871 (ThreadPoolExecutor-0_0): 09:18:25  Acquiring new redshift connection "create_dev_dbt_nobodozie"
2022-01-05 09:18:25.340133 (ThreadPoolExecutor-0_0): 09:18:25  Acquiring new redshift connection "create_dev_dbt_nobodozie"
2022-01-05 09:18:25.340305 (ThreadPoolExecutor-0_0): 09:18:25  Creating schema "_ReferenceKey(database='dev', schema='dbt_nobodozie', identifier=None)"
2022-01-05 09:18:25.346396 (ThreadPoolExecutor-0_0): 09:18:25  Using redshift connection "create_dev_dbt_nobodozie"
2022-01-05 09:18:25.346507 (ThreadPoolExecutor-0_0): 09:18:25  On create_dev_dbt_nobodozie: BEGIN
2022-01-05 09:18:25.346591 (ThreadPoolExecutor-0_0): 09:18:25  Opening a new connection, currently in state closed
2022-01-05 09:18:25.346672 (ThreadPoolExecutor-0_0): 09:18:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:25.367572 (ThreadPoolExecutor-0_0): 09:18:25  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:25.367750 (ThreadPoolExecutor-0_0): 09:18:25  Using redshift connection "create_dev_dbt_nobodozie"
2022-01-05 09:18:25.367836 (ThreadPoolExecutor-0_0): 09:18:25  On create_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "create_dev_dbt_nobodozie"} */
create schema if not exists "dbt_nobodozie"
2022-01-05 09:18:25.369985 (ThreadPoolExecutor-0_0): 09:18:25  SQL status: CREATE SCHEMA in 0.0 seconds
2022-01-05 09:18:25.370819 (ThreadPoolExecutor-0_0): 09:18:25  On create_dev_dbt_nobodozie: COMMIT
2022-01-05 09:18:25.370926 (ThreadPoolExecutor-0_0): 09:18:25  Using redshift connection "create_dev_dbt_nobodozie"
2022-01-05 09:18:25.371003 (ThreadPoolExecutor-0_0): 09:18:25  On create_dev_dbt_nobodozie: COMMIT
2022-01-05 09:18:25.427178 (ThreadPoolExecutor-0_0): 09:18:25  SQL status: COMMIT in 0.06 seconds
2022-01-05 09:18:25.427396 (ThreadPoolExecutor-0_0): 09:18:25  On create_dev_dbt_nobodozie: Close
2022-01-05 09:18:25.428905 (ThreadPoolExecutor-1_0): 09:18:25  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:25.436213 (ThreadPoolExecutor-1_0): 09:18:25  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:25.436381 (ThreadPoolExecutor-1_0): 09:18:25  On list_dev_dbt_nobodozie: BEGIN
2022-01-05 09:18:25.436510 (ThreadPoolExecutor-1_0): 09:18:25  Opening a new connection, currently in state closed
2022-01-05 09:18:25.436599 (ThreadPoolExecutor-1_0): 09:18:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:25.456921 (ThreadPoolExecutor-1_0): 09:18:25  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:25.457092 (ThreadPoolExecutor-1_0): 09:18:25  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:25.457177 (ThreadPoolExecutor-1_0): 09:18:25  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-05 09:18:25.467943 (ThreadPoolExecutor-1_0): 09:18:25  SQL status: SELECT in 0.01 seconds
2022-01-05 09:18:25.469178 (ThreadPoolExecutor-1_0): 09:18:25  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-05 09:18:25.470906 (ThreadPoolExecutor-1_0): 09:18:25  On list_dev_dbt_nobodozie: Close
2022-01-05 09:18:25.475191 (MainThread): 09:18:25  Using redshift connection "master"
2022-01-05 09:18:25.475320 (MainThread): 09:18:25  On master: BEGIN
2022-01-05 09:18:25.475409 (MainThread): 09:18:25  Opening a new connection, currently in state init
2022-01-05 09:18:25.475492 (MainThread): 09:18:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:25.498583 (MainThread): 09:18:25  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:25.498752 (MainThread): 09:18:25  Using redshift connection "master"
2022-01-05 09:18:25.498835 (MainThread): 09:18:25  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-05 09:18:25.517349 (MainThread): 09:18:25  SQL status: SELECT in 0.02 seconds
2022-01-05 09:18:25.518479 (MainThread): 09:18:25  On master: ROLLBACK
2022-01-05 09:18:25.520307 (MainThread): 09:18:25  Using redshift connection "master"
2022-01-05 09:18:25.520418 (MainThread): 09:18:25  On master: BEGIN
2022-01-05 09:18:25.523663 (MainThread): 09:18:25  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:25.523780 (MainThread): 09:18:25  On master: COMMIT
2022-01-05 09:18:25.523855 (MainThread): 09:18:25  Using redshift connection "master"
2022-01-05 09:18:25.523926 (MainThread): 09:18:25  On master: COMMIT
2022-01-05 09:18:25.525547 (MainThread): 09:18:25  SQL status: COMMIT in 0.0 seconds
2022-01-05 09:18:25.525699 (MainThread): 09:18:25  On master: Close
2022-01-05 09:18:25.526232 (MainThread): 09:18:25  Concurrency: 4 threads (target='default')
2022-01-05 09:18:25.526354 (MainThread): 09:18:25  
2022-01-05 09:18:25.528953 (Thread-1): 09:18:25  Began running node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:25.529254 (Thread-1): 09:18:25  1 of 2 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-05 09:18:25.529539 (Thread-1): 09:18:25  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:25.529635 (Thread-1): 09:18:25  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:25.529728 (Thread-1): 09:18:25  Compiling model.my_new_project.my_first_dbt_model
2022-01-05 09:18:25.532149 (Thread-1): 09:18:25  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:25.565934 (Thread-1): 09:18:25  finished collecting timing info
2022-01-05 09:18:25.566166 (Thread-1): 09:18:25  Began executing node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:25.581588 (Thread-49): handling poll request
2022-01-05 09:18:25.581983 (Thread-49): 09:18:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0b90d0>]}
2022-01-05 09:18:25.583329 (Thread-49): sending response (<Response 24818 bytes [200 OK]>) to 10.0.43.175
2022-01-05 09:18:25.599705 (Thread-1): 09:18:25  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:25.641364 (Thread-1): 09:18:25  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:25.641542 (Thread-1): 09:18:25  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:25.641635 (Thread-1): 09:18:25  Opening a new connection, currently in state closed
2022-01-05 09:18:25.641720 (Thread-1): 09:18:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:25.660944 (Thread-1): 09:18:25  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:25.661123 (Thread-1): 09:18:25  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:25.661209 (Thread-1): 09:18:25  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-05 09:18:26.162640 (Thread-1): 09:18:26  SQL status: SELECT in 0.5 seconds
2022-01-05 09:18:26.168886 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.169025 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-05 09:18:26.171582 (Thread-1): 09:18:26  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 09:18:26.182098 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:26.182245 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.182325 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:26.223482 (Thread-1): 09:18:26  SQL status: COMMIT in 0.04 seconds
2022-01-05 09:18:26.223827 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.223920 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:26.225886 (Thread-1): 09:18:26  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:26.230573 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.230682 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-05 09:18:26.232557 (Thread-1): 09:18:26  SQL status: DROP TABLE in 0.0 seconds
2022-01-05 09:18:26.233295 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:26.233396 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.233472 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:26.237263 (Thread-1): 09:18:26  SQL status: COMMIT in 0.0 seconds
2022-01-05 09:18:26.237369 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.237441 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:26.239204 (Thread-1): 09:18:26  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:26.239682 (Thread-1): 09:18:26  finished collecting timing info
2022-01-05 09:18:26.239836 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-05 09:18:26.241470 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: Close
2022-01-05 09:18:26.241995 (Thread-1): 09:18:26  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ffdc471-2794-4ba4-a05d-6e70a316dfc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd60691f70>]}
2022-01-05 09:18:26.242348 (Thread-1): 09:18:26  1 of 2 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.71s]
2022-01-05 09:18:26.242464 (Thread-1): 09:18:26  Finished running node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:26.243359 (Thread-3): 09:18:26  Began running node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:26.243577 (Thread-3): 09:18:26  2 of 2 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-05 09:18:26.243836 (Thread-3): 09:18:26  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.243923 (Thread-3): 09:18:26  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:26.244011 (Thread-3): 09:18:26  Compiling model.my_new_project.my_second_dbt_model
2022-01-05 09:18:26.246404 (Thread-3): 09:18:26  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.259815 (Thread-3): 09:18:26  finished collecting timing info
2022-01-05 09:18:26.259973 (Thread-3): 09:18:26  Began executing node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:26.276594 (Thread-3): 09:18:26  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.289891 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.290043 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:26.290136 (Thread-3): 09:18:26  Opening a new connection, currently in state init
2022-01-05 09:18:26.290223 (Thread-3): 09:18:26  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:26.307730 (Thread-3): 09:18:26  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:26.307898 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.307983 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-05 09:18:26.312746 (Thread-3): 09:18:26  SQL status: CREATE VIEW in 0.0 seconds
2022-01-05 09:18:26.315068 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.315188 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-05 09:18:26.317162 (Thread-3): 09:18:26  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 09:18:26.318262 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:26.318362 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.318436 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:26.346717 (Thread-3): 09:18:26  SQL status: COMMIT in 0.03 seconds
2022-01-05 09:18:26.347044 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.347134 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:26.349041 (Thread-3): 09:18:26  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:26.351775 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.351878 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-05 09:18:26.353615 (Thread-3): 09:18:26  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 09:18:26.354346 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:26.354444 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.354519 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:26.377998 (Thread-3): 09:18:26  SQL status: COMMIT in 0.02 seconds
2022-01-05 09:18:26.378154 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.378233 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:26.380065 (Thread-3): 09:18:26  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:26.380623 (Thread-3): 09:18:26  finished collecting timing info
2022-01-05 09:18:26.380772 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-05 09:18:26.382359 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: Close
2022-01-05 09:18:26.382877 (Thread-3): 09:18:26  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ffdc471-2794-4ba4-a05d-6e70a316dfc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd6060df70>]}
2022-01-05 09:18:26.383239 (Thread-3): 09:18:26  2 of 2 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.14s]
2022-01-05 09:18:26.383353 (Thread-3): 09:18:26  Finished running node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:26.384785 (MainThread): 09:18:26  Acquiring new redshift connection "master"
2022-01-05 09:18:26.384945 (MainThread): 09:18:26  Using redshift connection "master"
2022-01-05 09:18:26.385026 (MainThread): 09:18:26  On master: BEGIN
2022-01-05 09:18:26.385104 (MainThread): 09:18:26  Opening a new connection, currently in state closed
2022-01-05 09:18:26.385184 (MainThread): 09:18:26  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:26.407190 (MainThread): 09:18:26  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:26.407382 (MainThread): 09:18:26  On master: COMMIT
2022-01-05 09:18:26.407463 (MainThread): 09:18:26  Using redshift connection "master"
2022-01-05 09:18:26.407539 (MainThread): 09:18:26  On master: COMMIT
2022-01-05 09:18:26.409081 (MainThread): 09:18:26  SQL status: COMMIT in 0.0 seconds
2022-01-05 09:18:26.409215 (MainThread): 09:18:26  On master: Close
2022-01-05 09:18:26.409732 (MainThread): 09:18:26  
2022-01-05 09:18:26.409856 (MainThread): 09:18:26  Finished running 1 table model, 1 view model in 1.10s.
2022-01-05 09:18:26.409942 (MainThread): 09:18:26  Connection 'master' was properly closed.
2022-01-05 09:18:26.410010 (MainThread): 09:18:26  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-05 09:18:26.410075 (MainThread): 09:18:26  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-05 09:18:26.449477 (MainThread): 09:18:26  
2022-01-05 09:18:26.449709 (MainThread): 09:18:26  Completed successfully
2022-01-05 09:18:26.449809 (MainThread): 09:18:26  
2022-01-05 09:18:26.449898 (MainThread): 09:18:26  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2022-01-05 09:18:26.919047 (Thread-50): handling poll request
2022-01-05 09:18:26.919431 (Thread-50): 09:18:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0a1ca0>]}
2022-01-05 09:18:26.921227 (Thread-50): sending response (<Response 43307 bytes [200 OK]>) to 10.0.35.228
2022-01-05 09:18:27.567455 (Thread-51): handling status request
2022-01-05 09:18:27.567831 (Thread-51): 09:18:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0d2250>]}
2022-01-05 09:18:27.568763 (Thread-51): sending response (<Response 15522 bytes [200 OK]>) to 10.0.8.124
2022-01-05 09:18:27.603137 (Thread-52): handling status request
2022-01-05 09:18:27.603511 (Thread-52): 09:18:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0d2af0>]}
2022-01-05 09:18:27.604306 (Thread-52): sending response (<Response 15522 bytes [200 OK]>) to 10.0.31.49
2022-01-05 09:18:37.291148 (Thread-53): handling status request
2022-01-05 09:18:37.291535 (Thread-53): 09:18:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0d2d60>]}
2022-01-05 09:18:37.292333 (Thread-53): sending response (<Response 15522 bytes [200 OK]>) to 10.0.31.49
2022-01-05 09:18:37.579995 (Thread-54): handling status request
2022-01-05 09:18:37.580401 (Thread-54): 09:18:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0d2fd0>]}
2022-01-05 09:18:37.581277 (Thread-54): sending response (<Response 15522 bytes [200 OK]>) to 10.0.46.191
2022-01-05 09:18:37.608557 (Thread-55): handling cli_args request
2022-01-05 09:18:37.608936 (Thread-55): 09:18:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec055280>]}
2022-01-05 09:18:39.756760 (Thread-55): sending response (<Response 138 bytes [200 OK]>) to 10.0.8.202
2022-01-05 09:18:39.846940 (MainThread): 09:18:39  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 09:18:39.847414 (MainThread): 09:18:39  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 09:18:39.853523 (MainThread): 09:18:39  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'caf0dcfa-b066-47c3-bd15-7998fbb6cdfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39b80d6a90>]}
2022-01-05 09:18:39.883275 (MainThread): 09:18:39  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'caf0dcfa-b066-47c3-bd15-7998fbb6cdfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39b8136a30>]}
2022-01-05 09:18:39.883614 (MainThread): 09:18:39  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:18:39.884782 (MainThread): 09:18:39  
2022-01-05 09:18:39.885129 (MainThread): 09:18:39  Acquiring new redshift connection "master"
2022-01-05 09:18:39.886087 (ThreadPoolExecutor-0_0): 09:18:39  Acquiring new redshift connection "list_dev"
2022-01-05 09:18:39.896644 (ThreadPoolExecutor-0_0): 09:18:39  Using redshift connection "list_dev"
2022-01-05 09:18:39.896778 (ThreadPoolExecutor-0_0): 09:18:39  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-05 09:18:39.896869 (ThreadPoolExecutor-0_0): 09:18:39  Opening a new connection, currently in state init
2022-01-05 09:18:39.896956 (ThreadPoolExecutor-0_0): 09:18:39  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:39.918688 (ThreadPoolExecutor-0_0): 09:18:39  SQL status: SELECT in 0.02 seconds
2022-01-05 09:18:39.919919 (ThreadPoolExecutor-0_0): 09:18:39  On list_dev: Close
2022-01-05 09:18:39.921204 (ThreadPoolExecutor-1_0): 09:18:39  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:39.927731 (ThreadPoolExecutor-1_0): 09:18:39  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:39.927843 (ThreadPoolExecutor-1_0): 09:18:39  On list_dev_dbt_nobodozie: BEGIN
2022-01-05 09:18:39.927930 (ThreadPoolExecutor-1_0): 09:18:39  Opening a new connection, currently in state closed
2022-01-05 09:18:39.928011 (ThreadPoolExecutor-1_0): 09:18:39  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:39.950427 (ThreadPoolExecutor-1_0): 09:18:39  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:39.950602 (ThreadPoolExecutor-1_0): 09:18:39  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:39.950684 (ThreadPoolExecutor-1_0): 09:18:39  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-05 09:18:39.961819 (ThreadPoolExecutor-1_0): 09:18:39  SQL status: SELECT in 0.01 seconds
2022-01-05 09:18:39.963223 (ThreadPoolExecutor-1_0): 09:18:39  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-05 09:18:39.965011 (ThreadPoolExecutor-1_0): 09:18:39  On list_dev_dbt_nobodozie: Close
2022-01-05 09:18:39.969952 (MainThread): 09:18:39  Using redshift connection "master"
2022-01-05 09:18:39.970087 (MainThread): 09:18:39  On master: BEGIN
2022-01-05 09:18:39.970175 (MainThread): 09:18:39  Opening a new connection, currently in state init
2022-01-05 09:18:39.970259 (MainThread): 09:18:39  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:40.116326 (Thread-56): handling poll request
2022-01-05 09:18:40.116822 (Thread-56): 09:18:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec055640>]}
2022-01-05 09:18:40.117878 (Thread-56): sending response (<Response 9949 bytes [200 OK]>) to 10.0.23.251
2022-01-05 09:18:40.510973 (MainThread): 09:18:40  SQL status: BEGIN in 0.54 seconds
2022-01-05 09:18:40.511152 (MainThread): 09:18:40  Using redshift connection "master"
2022-01-05 09:18:40.511238 (MainThread): 09:18:40  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-05 09:18:40.539720 (MainThread): 09:18:40  SQL status: SELECT in 0.03 seconds
2022-01-05 09:18:40.541032 (MainThread): 09:18:40  On master: ROLLBACK
2022-01-05 09:18:40.542921 (MainThread): 09:18:40  Using redshift connection "master"
2022-01-05 09:18:40.543039 (MainThread): 09:18:40  On master: BEGIN
2022-01-05 09:18:40.546333 (MainThread): 09:18:40  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:40.546462 (MainThread): 09:18:40  On master: COMMIT
2022-01-05 09:18:40.546542 (MainThread): 09:18:40  Using redshift connection "master"
2022-01-05 09:18:40.546617 (MainThread): 09:18:40  On master: COMMIT
2022-01-05 09:18:40.548215 (MainThread): 09:18:40  SQL status: COMMIT in 0.0 seconds
2022-01-05 09:18:40.548343 (MainThread): 09:18:40  On master: Close
2022-01-05 09:18:40.548919 (MainThread): 09:18:40  Concurrency: 4 threads (target='default')
2022-01-05 09:18:40.549081 (MainThread): 09:18:40  
2022-01-05 09:18:40.551527 (Thread-1): 09:18:40  Began running node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:40.552061 (Thread-1): 09:18:40  1 of 2 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-05 09:18:40.552372 (Thread-1): 09:18:40  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.552520 (Thread-1): 09:18:40  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:40.552621 (Thread-1): 09:18:40  Compiling model.my_new_project.my_first_dbt_model
2022-01-05 09:18:40.555098 (Thread-1): 09:18:40  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.571373 (Thread-1): 09:18:40  finished collecting timing info
2022-01-05 09:18:40.571586 (Thread-1): 09:18:40  Began executing node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:40.608485 (Thread-1): 09:18:40  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.624558 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.624730 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:40.624830 (Thread-1): 09:18:40  Opening a new connection, currently in state closed
2022-01-05 09:18:40.624916 (Thread-1): 09:18:40  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:40.642447 (Thread-1): 09:18:40  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:40.642629 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.642714 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-05 09:18:40.689110 (Thread-1): 09:18:40  SQL status: SELECT in 0.05 seconds
2022-01-05 09:18:40.695566 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.695710 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-05 09:18:40.698156 (Thread-1): 09:18:40  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 09:18:40.700158 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.700267 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-05 09:18:40.702591 (Thread-1): 09:18:40  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 09:18:40.713224 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:40.713363 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.713442 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:40.746959 (Thread-1): 09:18:40  SQL status: COMMIT in 0.03 seconds
2022-01-05 09:18:40.747310 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.747404 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:40.749450 (Thread-1): 09:18:40  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:40.753989 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.754096 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-05 09:18:40.758877 (Thread-1): 09:18:40  SQL status: DROP TABLE in 0.0 seconds
2022-01-05 09:18:40.759610 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:40.759711 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.759787 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:40.785211 (Thread-1): 09:18:40  SQL status: COMMIT in 0.03 seconds
2022-01-05 09:18:40.785378 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.785461 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:40.787424 (Thread-1): 09:18:40  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:40.787973 (Thread-1): 09:18:40  finished collecting timing info
2022-01-05 09:18:40.788116 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-05 09:18:40.789786 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: Close
2022-01-05 09:18:40.790335 (Thread-1): 09:18:40  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'caf0dcfa-b066-47c3-bd15-7998fbb6cdfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39b7029370>]}
2022-01-05 09:18:40.790719 (Thread-1): 09:18:40  1 of 2 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.24s]
2022-01-05 09:18:40.790856 (Thread-1): 09:18:40  Finished running node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:40.791754 (Thread-3): 09:18:40  Began running node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:40.792029 (Thread-3): 09:18:40  2 of 2 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-05 09:18:40.792321 (Thread-3): 09:18:40  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:40.792416 (Thread-3): 09:18:40  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:40.792538 (Thread-3): 09:18:40  Compiling model.my_new_project.my_second_dbt_model
2022-01-05 09:18:40.795042 (Thread-3): 09:18:40  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:40.810254 (Thread-3): 09:18:40  finished collecting timing info
2022-01-05 09:18:40.810455 (Thread-3): 09:18:40  Began executing node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:40.827545 (Thread-3): 09:18:40  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:40.843252 (Thread-3): 09:18:40  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:40.843423 (Thread-3): 09:18:40  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:40.843519 (Thread-3): 09:18:40  Opening a new connection, currently in state init
2022-01-05 09:18:40.843605 (Thread-3): 09:18:40  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:41.285691 (Thread-3): 09:18:41  SQL status: BEGIN in 0.44 seconds
2022-01-05 09:18:41.285875 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.285961 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-05 09:18:41.290681 (Thread-3): 09:18:41  SQL status: CREATE VIEW in 0.0 seconds
2022-01-05 09:18:41.292998 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.293127 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-05 09:18:41.295243 (Thread-3): 09:18:41  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 09:18:41.296386 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:41.296525 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.296605 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:41.324686 (Thread-3): 09:18:41  SQL status: COMMIT in 0.03 seconds
2022-01-05 09:18:41.325018 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.325109 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:41.327081 (Thread-3): 09:18:41  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:41.328653 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.328759 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-05 09:18:41.330536 (Thread-3): 09:18:41  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 09:18:41.331290 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:41.331390 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.331464 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:41.356932 (Thread-3): 09:18:41  SQL status: COMMIT in 0.03 seconds
2022-01-05 09:18:41.357099 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.357179 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:41.359241 (Thread-3): 09:18:41  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:41.359789 (Thread-3): 09:18:41  finished collecting timing info
2022-01-05 09:18:41.359933 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-05 09:18:41.361515 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: Close
2022-01-05 09:18:41.362047 (Thread-3): 09:18:41  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'caf0dcfa-b066-47c3-bd15-7998fbb6cdfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3997fa6070>]}
2022-01-05 09:18:41.362403 (Thread-3): 09:18:41  2 of 2 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.57s]
2022-01-05 09:18:41.362521 (Thread-3): 09:18:41  Finished running node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:41.364021 (MainThread): 09:18:41  Acquiring new redshift connection "master"
2022-01-05 09:18:41.364179 (MainThread): 09:18:41  Using redshift connection "master"
2022-01-05 09:18:41.364261 (MainThread): 09:18:41  On master: BEGIN
2022-01-05 09:18:41.364345 (MainThread): 09:18:41  Opening a new connection, currently in state closed
2022-01-05 09:18:41.364428 (MainThread): 09:18:41  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:41.388057 (MainThread): 09:18:41  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:41.388246 (MainThread): 09:18:41  On master: COMMIT
2022-01-05 09:18:41.388332 (MainThread): 09:18:41  Using redshift connection "master"
2022-01-05 09:18:41.388411 (MainThread): 09:18:41  On master: COMMIT
2022-01-05 09:18:41.390025 (MainThread): 09:18:41  SQL status: COMMIT in 0.0 seconds
2022-01-05 09:18:41.390170 (MainThread): 09:18:41  On master: Close
2022-01-05 09:18:41.390711 (MainThread): 09:18:41  
2022-01-05 09:18:41.390840 (MainThread): 09:18:41  Finished running 1 table model, 1 view model in 1.51s.
2022-01-05 09:18:41.390926 (MainThread): 09:18:41  Connection 'master' was properly closed.
2022-01-05 09:18:41.390997 (MainThread): 09:18:41  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-05 09:18:41.391062 (MainThread): 09:18:41  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-05 09:18:41.451709 (MainThread): 09:18:41  
2022-01-05 09:18:41.451936 (MainThread): 09:18:41  Completed successfully
2022-01-05 09:18:41.452035 (MainThread): 09:18:41  
2022-01-05 09:18:41.452123 (MainThread): 09:18:41  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2022-01-05 09:18:41.457290 (Thread-57): handling poll request
2022-01-05 09:18:41.457615 (Thread-57): 09:18:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec11c3a0>]}
2022-01-05 09:18:41.459158 (Thread-57): sending response (<Response 48497 bytes [200 OK]>) to 10.0.43.175
2022-01-05 09:18:42.836873 (Thread-58): handling poll request
2022-01-05 09:18:42.837274 (Thread-58): 09:18:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec11c940>]}
2022-01-05 09:18:42.838212 (Thread-58): sending response (<Response 6210 bytes [200 OK]>) to 10.0.9.20
2022-01-05 09:18:43.445916 (Thread-59): handling status request
2022-01-05 09:18:43.446332 (Thread-59): 09:18:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec07f580>]}
2022-01-05 09:18:43.447356 (Thread-59): sending response (<Response 15522 bytes [200 OK]>) to 10.0.40.203
2022-01-05 09:18:43.552650 (Thread-60): handling status request
2022-01-05 09:18:43.553053 (Thread-60): 09:18:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec07f970>]}
2022-01-05 09:18:43.553961 (Thread-60): sending response (<Response 15522 bytes [200 OK]>) to 10.0.18.33
2022-01-05 16:18:58.393119 (MainThread): Running with dbt=1.0.1
2022-01-05 16:18:58.494275 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-05 16:18:58.501451 (MainThread): Tracking: tracking
2022-01-05 16:18:58.521656 (MainThread): 16:18:58  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cdfb33c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0071a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0071d90>]}
2022-01-05 16:18:58.522055 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-05 16:18:58.522291 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-05 16:18:58.522425 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-05 16:18:58.566695 (Thread-12): 16:18:58  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 16:18:58.566930 (Thread-12): 16:18:58  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 16:18:58.573259 (Thread-12): 16:18:58  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fdf2e0>]}
2022-01-05 16:19:01.218865 (Thread-13): handling ps request
2022-01-05 16:19:01.219288 (Thread-13): 16:19:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd00d75b0>]}
2022-01-05 16:19:01.219847 (Thread-13): sending response (<Response 105 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:19:01.222694 (Thread-14): handling status request
2022-01-05 16:19:01.222956 (Thread-14): 16:19:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd00d7250>]}
2022-01-05 16:19:01.223385 (Thread-14): sending response (<Response 1241 bytes [200 OK]>) to 10.0.42.119
2022-01-05 16:19:01.307931 (Thread-15): handling status request
2022-01-05 16:19:01.308307 (Thread-15): 16:19:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd00d7070>]}
2022-01-05 16:19:01.308796 (Thread-15): sending response (<Response 1241 bytes [200 OK]>) to 10.0.38.111
2022-01-05 16:19:01.517449 (Thread-16): handling status request
2022-01-05 16:19:01.517826 (Thread-16): 16:19:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0119b20>]}
2022-01-05 16:19:01.518282 (Thread-16): sending response (<Response 1241 bytes [200 OK]>) to 10.0.46.191
2022-01-05 16:19:02.605573 (Thread-17): handling status request
2022-01-05 16:19:02.605950 (Thread-17): 16:19:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0071f40>]}
2022-01-05 16:19:02.606440 (Thread-17): sending response (<Response 1219 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:19:02.612856 (Thread-18): handling list request
2022-01-05 16:19:02.613183 (Thread-18): 16:19:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0071ac0>]}
2022-01-05 16:19:02.646100 (Thread-18): 16:19:02  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd00d7850>]}
2022-01-05 16:19:02.646497 (Thread-18): 16:19:02  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:19:02.649596 (Thread-18): 16:19:02  The selection criterion '+1641399542329/__unsaved/Statement' does not match any nodes
2022-01-05 16:19:02.649839 (Thread-18): 16:19:02  The selection criterion '1.sql+' does not match any nodes
2022-01-05 16:19:02.649956 (Thread-18): 16:19:02  No nodes selected!
2022-01-05 16:19:02.651784 (Thread-18): sending response (<Response 2343 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:19:35.647741 (Thread-19): handling status request
2022-01-05 16:19:35.648121 (Thread-19): 16:19:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fdf7c0>]}
2022-01-05 16:19:35.648644 (Thread-19): sending response (<Response 1241 bytes [200 OK]>) to 10.0.30.3
2022-01-05 16:19:35.666335 (Thread-20): handling status request
2022-01-05 16:19:35.666677 (Thread-20): 16:19:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fe81c0>]}
2022-01-05 16:19:35.667130 (Thread-20): sending response (<Response 1241 bytes [200 OK]>) to 10.0.19.216
2022-01-05 16:19:35.677318 (Thread-21): handling ps request
2022-01-05 16:19:35.677623 (Thread-21): 16:19:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fe8220>]}
2022-01-05 16:19:35.678125 (Thread-21): sending response (<Response 393 bytes [200 OK]>) to 10.0.42.85
2022-01-05 16:19:35.694513 (Thread-22): handling status request
2022-01-05 16:19:35.694872 (Thread-22): 16:19:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fe83d0>]}
2022-01-05 16:19:35.695325 (Thread-22): sending response (<Response 1241 bytes [200 OK]>) to 10.0.38.111
2022-01-05 16:19:36.553649 (Thread-23): handling status request
2022-01-05 16:19:36.554048 (Thread-23): 16:19:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fe88b0>]}
2022-01-05 16:19:36.554504 (Thread-23): sending response (<Response 1219 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:19:36.560954 (Thread-24): handling list request
2022-01-05 16:19:36.561286 (Thread-24): 16:19:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fe8b80>]}
2022-01-05 16:19:36.591181 (Thread-24): 16:19:36  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0071cd0>]}
2022-01-05 16:19:36.591719 (Thread-24): 16:19:36  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:19:36.595207 (Thread-24): 16:19:36  The selection criterion '+1641399576289/__unsaved/Statement' does not match any nodes
2022-01-05 16:19:36.595550 (Thread-24): 16:19:36  The selection criterion '1.sql+' does not match any nodes
2022-01-05 16:19:36.595730 (Thread-24): 16:19:36  No nodes selected!
2022-01-05 16:19:36.598319 (Thread-24): sending response (<Response 2343 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:20:08.480526 (Thread-25): handling status request
2022-01-05 16:20:08.480909 (Thread-25): 16:20:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb61c0>]}
2022-01-05 16:20:08.481362 (Thread-25): sending response (<Response 1219 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:20:08.495496 (Thread-26): handling list request
2022-01-05 16:20:08.495851 (Thread-26): 16:20:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb66d0>]}
2022-01-05 16:20:08.528099 (Thread-26): 16:20:08  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb8040>]}
2022-01-05 16:20:08.528507 (Thread-26): 16:20:08  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:20:08.532627 (Thread-26): 16:20:08  The selection criterion '+1641399576289/__unsaved/Statement' does not match any nodes
2022-01-05 16:20:08.532846 (Thread-26): 16:20:08  The selection criterion '1.sql+' does not match any nodes
2022-01-05 16:20:08.532962 (Thread-26): 16:20:08  No nodes selected!
2022-01-05 16:20:08.534640 (Thread-26): sending response (<Response 2343 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:20:13.521856 (Thread-27): handling status request
2022-01-05 16:20:13.522235 (Thread-27): 16:20:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb6f40>]}
2022-01-05 16:20:13.522717 (Thread-27): sending response (<Response 1241 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:20:13.969781 (Thread-28): handling run_sql request
2022-01-05 16:20:13.970165 (Thread-28): 16:20:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb8850>]}
2022-01-05 16:20:16.178208 (Thread-28): sending response (<Response 138 bytes [200 OK]>) to 10.0.19.216
2022-01-05 16:20:16.204513 (MainThread): 16:20:16  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2b6730dd-1335-4de8-b990-36a56e7cdccc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956d50aeb0>]}
2022-01-05 16:20:16.205166 (MainThread): 16:20:16  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:20:16.205816 (Thread-1): 16:20:16  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:20:16.205952 (Thread-1): 16:20:16  Began compiling node rpc.my_new_project.request
2022-01-05 16:20:16.206044 (Thread-1): 16:20:16  Compiling rpc.my_new_project.request
2022-01-05 16:20:16.207452 (Thread-1): 16:20:16  finished collecting timing info
2022-01-05 16:20:16.207592 (Thread-1): 16:20:16  Began executing node rpc.my_new_project.request
2022-01-05 16:20:16.207701 (Thread-1): 16:20:16  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:20:16.207788 (Thread-1): 16:20:16  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:20:16.207871 (Thread-1): 16:20:16  Opening a new connection, currently in state init
2022-01-05 16:20:16.207957 (Thread-1): 16:20:16  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:20:16.227781 (Thread-1): 16:20:16  Postgres adapter: Postgres error: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^

2022-01-05 16:20:16.228023 (Thread-1): 16:20:16  finished collecting timing info
2022-01-05 16:20:16.228174 (Thread-1): 16:20:16  On rpc.my_new_project.request: Close
2022-01-05 16:20:16.228526 (Thread-1): Got an exception: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
2022-01-05 16:20:16.229676 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 16:20:16.542413 (Thread-29): handling poll request
2022-01-05 16:20:16.542899 (Thread-29): 16:20:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0740be0>]}
2022-01-05 16:20:16.543773 (Thread-29): sending response (<Response 15966 bytes [200 OK]>) to 10.0.46.191
2022-01-05 16:27:27.433511 (Thread-30): 16:27:27  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-01-05 16:27:27.436013 (Thread-30): 16:27:27  Partial parsing: added file: my_new_project://models/dim_customers.sql
2022-01-05 16:27:27.447705 (Thread-30): 16:27:27  1699: static parser successfully parsed dim_customers.sql
2022-01-05 16:27:27.522204 (Thread-30): 16:27:27  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb06b57c0>]}
2022-01-05 16:27:28.015977 (Thread-31): handling status request
2022-01-05 16:27:28.016348 (Thread-31): 16:27:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd00d7b80>]}
2022-01-05 16:27:28.016881 (Thread-31): sending response (<Response 1550 bytes [200 OK]>) to 10.0.32.47
2022-01-05 16:27:28.080616 (Thread-32): handling status request
2022-01-05 16:27:28.080992 (Thread-32): 16:27:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb8d30>]}
2022-01-05 16:27:28.081472 (Thread-32): sending response (<Response 1550 bytes [200 OK]>) to 10.0.32.47
2022-01-05 16:27:49.104245 (Thread-33): handling status request
2022-01-05 16:27:49.104668 (Thread-33): 16:27:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0100b50>]}
2022-01-05 16:27:49.105150 (Thread-33): sending response (<Response 1550 bytes [200 OK]>) to 10.0.10.137
2022-01-05 16:27:49.493307 (Thread-34): handling run_sql request
2022-01-05 16:27:49.493676 (Thread-34): 16:27:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb07548b0>]}
2022-01-05 16:27:51.661758 (Thread-34): sending response (<Response 138 bytes [200 OK]>) to 10.0.32.67
2022-01-05 16:27:51.687151 (MainThread): 16:27:51  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1f0a8b83-a905-4338-b9f4-9aede296d085', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f027f8a3160>]}
2022-01-05 16:27:51.687783 (MainThread): 16:27:51  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:27:51.688437 (Thread-1): 16:27:51  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:27:51.688614 (Thread-1): 16:27:51  Began compiling node rpc.my_new_project.request
2022-01-05 16:27:51.688717 (Thread-1): 16:27:51  Compiling rpc.my_new_project.request
2022-01-05 16:27:51.690111 (Thread-1): 16:27:51  finished collecting timing info
2022-01-05 16:27:51.690255 (Thread-1): 16:27:51  Began executing node rpc.my_new_project.request
2022-01-05 16:27:51.690375 (Thread-1): 16:27:51  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:27:51.690462 (Thread-1): 16:27:51  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:27:51.690553 (Thread-1): 16:27:51  Opening a new connection, currently in state init
2022-01-05 16:27:51.690641 (Thread-1): 16:27:51  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:27:51.709561 (Thread-1): 16:27:51  Postgres adapter: Postgres error: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^

2022-01-05 16:27:51.709799 (Thread-1): 16:27:51  finished collecting timing info
2022-01-05 16:27:51.709959 (Thread-1): 16:27:51  On rpc.my_new_project.request: Close
2022-01-05 16:27:51.710231 (Thread-1): Got an exception: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
2022-01-05 16:27:51.711336 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 16:27:52.059880 (Thread-35): handling poll request
2022-01-05 16:27:52.060336 (Thread-35): 16:27:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb06b1490>]}
2022-01-05 16:27:52.061229 (Thread-35): sending response (<Response 15951 bytes [200 OK]>) to 10.0.38.111
2022-01-05 16:30:42.878891 (MainThread): Running with dbt=1.0.1
2022-01-05 16:30:42.976404 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-05 16:30:42.983115 (MainThread): Tracking: tracking
2022-01-05 16:30:43.003156 (MainThread): 16:30:43  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bf2b0bb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7be404f520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7be404f280>]}
2022-01-05 16:30:43.003512 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-05 16:30:43.003821 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-05 16:30:43.003957 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-05 16:30:43.018552 (Thread-12): 16:30:43  Unable to do partial parsing because profile has changed
2022-01-05 16:30:43.018843 (Thread-12): 16:30:43  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7be404fd00>]}
2022-01-05 16:30:43.055555 (Thread-12): 16:30:43  Parsing macros/catalog.sql
2022-01-05 16:30:43.068110 (Thread-12): 16:30:43  Parsing macros/adapters.sql
2022-01-05 16:30:43.095307 (Thread-12): 16:30:43  Parsing macros/relations.sql
2022-01-05 16:30:43.095891 (Thread-12): 16:30:43  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 16:30:43.096521 (Thread-12): 16:30:43  Parsing macros/catalog.sql
2022-01-05 16:30:43.098590 (Thread-12): 16:30:43  Parsing macros/adapters.sql
2022-01-05 16:30:43.119563 (Thread-12): 16:30:43  Parsing macros/relations.sql
2022-01-05 16:30:43.120863 (Thread-12): 16:30:43  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 16:30:43.122444 (Thread-12): 16:30:43  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-05 16:30:43.123904 (Thread-12): 16:30:43  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-05 16:30:43.125429 (Thread-12): 16:30:43  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-05 16:30:43.127813 (Thread-12): 16:30:43  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-05 16:30:43.129169 (Thread-12): 16:30:43  Parsing macros/generic_test_sql/not_null.sql
2022-01-05 16:30:43.129739 (Thread-12): 16:30:43  Parsing macros/generic_test_sql/relationships.sql
2022-01-05 16:30:43.130613 (Thread-12): 16:30:43  Parsing macros/generic_test_sql/unique.sql
2022-01-05 16:30:43.131339 (Thread-12): 16:30:43  Parsing macros/materializations/configs.sql
2022-01-05 16:30:43.133657 (Thread-12): 16:30:43  Parsing macros/materializations/hooks.sql
2022-01-05 16:30:43.137487 (Thread-12): 16:30:43  Parsing macros/materializations/snapshots/strategies.sql
2022-01-05 16:30:43.153319 (Thread-12): 16:30:43  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-05 16:30:43.154894 (Thread-12): 16:30:43  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-05 16:30:43.165571 (Thread-12): 16:30:43  Parsing macros/materializations/snapshots/helpers.sql
2022-01-05 16:30:43.176088 (Thread-12): 16:30:43  Parsing macros/materializations/seeds/seed.sql
2022-01-05 16:30:43.181729 (Thread-12): 16:30:43  Parsing macros/materializations/seeds/helpers.sql
2022-01-05 16:30:43.196895 (Thread-12): 16:30:43  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-05 16:30:43.199103 (Thread-12): 16:30:43  Parsing macros/materializations/models/view/view.sql
2022-01-05 16:30:43.205581 (Thread-12): 16:30:43  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-05 16:30:43.208160 (Thread-12): 16:30:43  Parsing macros/materializations/models/view/helpers.sql
2022-01-05 16:30:43.209445 (Thread-12): 16:30:43  Parsing macros/materializations/models/table/table.sql
2022-01-05 16:30:43.216297 (Thread-12): 16:30:43  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-05 16:30:43.219061 (Thread-12): 16:30:43  Parsing macros/materializations/models/incremental/merge.sql
2022-01-05 16:30:43.229668 (Thread-12): 16:30:43  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-05 16:30:43.244218 (Thread-12): 16:30:43  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-05 16:30:43.248474 (Thread-12): 16:30:43  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-05 16:30:43.257913 (Thread-12): 16:30:43  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-05 16:30:43.259393 (Thread-12): 16:30:43  Parsing macros/materializations/tests/test.sql
2022-01-05 16:30:43.263580 (Thread-12): 16:30:43  Parsing macros/materializations/tests/where_subquery.sql
2022-01-05 16:30:43.265308 (Thread-12): 16:30:43  Parsing macros/materializations/tests/helpers.sql
2022-01-05 16:30:43.266981 (Thread-12): 16:30:43  Parsing macros/etc/statement.sql
2022-01-05 16:30:43.271230 (Thread-12): 16:30:43  Parsing macros/etc/datetime.sql
2022-01-05 16:30:43.279336 (Thread-12): 16:30:43  Parsing macros/adapters/indexes.sql
2022-01-05 16:30:43.281928 (Thread-12): 16:30:43  Parsing macros/adapters/persist_docs.sql
2022-01-05 16:30:43.286130 (Thread-12): 16:30:43  Parsing macros/adapters/freshness.sql
2022-01-05 16:30:43.288969 (Thread-12): 16:30:43  Parsing macros/adapters/relation.sql
2022-01-05 16:30:43.298016 (Thread-12): 16:30:43  Parsing macros/adapters/metadata.sql
2022-01-05 16:30:43.304840 (Thread-12): 16:30:43  Parsing macros/adapters/columns.sql
2022-01-05 16:30:43.314256 (Thread-12): 16:30:43  Parsing macros/adapters/schema.sql
2022-01-05 16:30:43.316415 (Thread-12): 16:30:43  Parsing tests/generic/builtin.sql
2022-01-05 16:30:43.505433 (Thread-12): 16:30:43  1699: static parser successfully parsed dim_customers.sql
2022-01-05 16:30:43.517300 (Thread-12): 16:30:43  1699: static parser successfully parsed example/my_second_dbt_model.sql
2022-01-05 16:30:43.519507 (Thread-12): 16:30:43  1699: static parser successfully parsed example/my_first_dbt_model.sql
2022-01-05 16:30:43.611272 (Thread-12): 16:30:43  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc7ba0d0>]}
2022-01-05 16:30:44.812352 (Thread-13): handling status request
2022-01-05 16:30:44.812725 (Thread-13): 16:30:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc183970>]}
2022-01-05 16:30:44.813673 (Thread-13): sending response (<Response 15820 bytes [200 OK]>) to 10.0.30.3
2022-01-05 16:30:44.847893 (Thread-14): handling status request
2022-01-05 16:30:44.848502 (Thread-14): 16:30:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc183460>]}
2022-01-05 16:30:44.849342 (Thread-14): sending response (<Response 15820 bytes [200 OK]>) to 10.0.46.191
2022-01-05 16:30:44.860788 (Thread-15): handling ps request
2022-01-05 16:30:44.876475 (Thread-15): 16:30:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc183850>]}
2022-01-05 16:30:44.876938 (Thread-15): sending response (<Response 105 bytes [200 OK]>) to 10.0.5.1
2022-01-05 16:30:44.976647 (Thread-16): handling status request
2022-01-05 16:30:44.977031 (Thread-16): 16:30:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7be40b4e20>]}
2022-01-05 16:30:44.977865 (Thread-16): sending response (<Response 15820 bytes [200 OK]>) to 10.0.20.28
2022-01-05 16:31:12.937901 (Thread-17): handling status request
2022-01-05 16:31:12.939374 (Thread-17): 16:31:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc183f10>]}
2022-01-05 16:31:12.940283 (Thread-17): sending response (<Response 15820 bytes [200 OK]>) to 10.0.6.188
2022-01-05 16:31:13.297265 (Thread-18): handling run_sql request
2022-01-05 16:31:13.297618 (Thread-18): 16:31:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7be40885e0>]}
2022-01-05 16:31:15.373069 (Thread-18): sending response (<Response 138 bytes [200 OK]>) to 10.0.32.47
2022-01-05 16:31:15.397039 (MainThread): 16:31:15  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8f1d7668-1c99-48ae-8386-4f145f2c2b67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6151640e80>]}
2022-01-05 16:31:15.397583 (MainThread): 16:31:15  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:31:15.398163 (Thread-1): 16:31:15  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:31:15.398293 (Thread-1): 16:31:15  Began compiling node rpc.my_new_project.request
2022-01-05 16:31:15.398383 (Thread-1): 16:31:15  Compiling rpc.my_new_project.request
2022-01-05 16:31:15.399580 (Thread-1): 16:31:15  finished collecting timing info
2022-01-05 16:31:15.399708 (Thread-1): 16:31:15  Began executing node rpc.my_new_project.request
2022-01-05 16:31:15.399809 (Thread-1): 16:31:15  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:31:15.399888 (Thread-1): 16:31:15  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:31:15.399967 (Thread-1): 16:31:15  Opening a new connection, currently in state init
2022-01-05 16:31:15.400047 (Thread-1): 16:31:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:31:15.411891 (Thread-1): 16:31:15  Postgres adapter: Got an error when attempting to open a postgres connection: 'FATAL:  database "Serverless/dev" does not exist
'
2022-01-05 16:31:15.412031 (Thread-1): 16:31:15  Postgres adapter: Error running SQL: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:31:15.412105 (Thread-1): 16:31:15  Postgres adapter: Rolling back transaction.
2022-01-05 16:31:15.412201 (Thread-1): 16:31:15  finished collecting timing info
2022-01-05 16:31:15.412319 (Thread-1): 16:31:15  On rpc.my_new_project.request: No close available on handle
2022-01-05 16:31:15.412383 (Thread-1): Got an exception: Database Error
  FATAL:  database "Serverless/dev" does not exist
  
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 121, in open
    handle = psycopg2.connect(
  File "/usr/local/lib/python3.8/dist-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: FATAL:  database "Serverless/dev" does not exist


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 73, in add_query
    cursor = connection.handle.cursor()
  File "/usr/local/lib/python3.8/dist-packages/dbt/contracts/connection.py", line 83, in handle
    self._handle.resolve(self)
  File "/usr/local/lib/python3.8/dist-packages/dbt/contracts/connection.py", line 106, in resolve
    return self.opener(connection)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 143, in open
    raise dbt.exceptions.FailedToConnectException(str(e))
dbt.exceptions.FailedToConnectException: Database Error
  FATAL:  database "Serverless/dev" does not exist
2022-01-05 16:31:15.413610 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'FailedToConnectException', 'message': 'Database Error in rpc request (from remote system)\n  FATAL:  database "Serverless/dev" does not exist\n  ', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'FailedToConnectException', 'message': 'Database Error in rpc request (from remote system)\n  FATAL:  database "Serverless/dev" does not exist\n  ', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 16:31:15.717223 (Thread-19): handling poll request
2022-01-05 16:31:15.717656 (Thread-19): 16:31:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc183460>]}
2022-01-05 16:31:15.718527 (Thread-19): sending response (<Response 17444 bytes [200 OK]>) to 10.0.42.85
2022-01-05 16:39:15.648211 (MainThread): Running with dbt=1.0.1
2022-01-05 16:39:15.739482 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-05 16:39:15.745897 (MainThread): Tracking: tracking
2022-01-05 16:39:15.765400 (MainThread): 16:39:15  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0af913fcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae46471c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4647250>]}
2022-01-05 16:39:15.765818 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-05 16:39:15.766128 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-05 16:39:15.766375 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-05 16:39:15.783436 (Thread-12): 16:39:15  Unable to do partial parsing because profile has changed
2022-01-05 16:39:15.783721 (Thread-12): 16:39:15  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4647f40>]}
2022-01-05 16:39:15.812470 (Thread-12): 16:39:15  Parsing macros/catalog.sql
2022-01-05 16:39:15.824739 (Thread-12): 16:39:15  Parsing macros/adapters.sql
2022-01-05 16:39:15.851320 (Thread-12): 16:39:15  Parsing macros/relations.sql
2022-01-05 16:39:15.851874 (Thread-12): 16:39:15  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 16:39:15.852476 (Thread-12): 16:39:15  Parsing macros/catalog.sql
2022-01-05 16:39:15.854502 (Thread-12): 16:39:15  Parsing macros/adapters.sql
2022-01-05 16:39:15.875090 (Thread-12): 16:39:15  Parsing macros/relations.sql
2022-01-05 16:39:15.876314 (Thread-12): 16:39:15  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 16:39:15.877872 (Thread-12): 16:39:15  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-05 16:39:15.879272 (Thread-12): 16:39:15  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-05 16:39:15.880838 (Thread-12): 16:39:15  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-05 16:39:15.883157 (Thread-12): 16:39:15  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-05 16:39:15.884458 (Thread-12): 16:39:15  Parsing macros/generic_test_sql/not_null.sql
2022-01-05 16:39:15.885006 (Thread-12): 16:39:15  Parsing macros/generic_test_sql/relationships.sql
2022-01-05 16:39:15.885848 (Thread-12): 16:39:15  Parsing macros/generic_test_sql/unique.sql
2022-01-05 16:39:15.886517 (Thread-12): 16:39:15  Parsing macros/materializations/configs.sql
2022-01-05 16:39:15.888675 (Thread-12): 16:39:15  Parsing macros/materializations/hooks.sql
2022-01-05 16:39:15.892643 (Thread-12): 16:39:15  Parsing macros/materializations/snapshots/strategies.sql
2022-01-05 16:39:15.908294 (Thread-12): 16:39:15  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-05 16:39:15.909915 (Thread-12): 16:39:15  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-05 16:39:15.920676 (Thread-12): 16:39:15  Parsing macros/materializations/snapshots/helpers.sql
2022-01-05 16:39:15.930922 (Thread-12): 16:39:15  Parsing macros/materializations/seeds/seed.sql
2022-01-05 16:39:15.936404 (Thread-12): 16:39:15  Parsing macros/materializations/seeds/helpers.sql
2022-01-05 16:39:15.951479 (Thread-12): 16:39:15  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-05 16:39:15.953669 (Thread-12): 16:39:15  Parsing macros/materializations/models/view/view.sql
2022-01-05 16:39:15.960107 (Thread-12): 16:39:15  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-05 16:39:15.962643 (Thread-12): 16:39:15  Parsing macros/materializations/models/view/helpers.sql
2022-01-05 16:39:15.963902 (Thread-12): 16:39:15  Parsing macros/materializations/models/table/table.sql
2022-01-05 16:39:15.970722 (Thread-12): 16:39:15  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-05 16:39:15.973406 (Thread-12): 16:39:15  Parsing macros/materializations/models/incremental/merge.sql
2022-01-05 16:39:15.983881 (Thread-12): 16:39:15  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-05 16:39:15.998085 (Thread-12): 16:39:15  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-05 16:39:16.002311 (Thread-12): 16:39:16  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-05 16:39:16.011674 (Thread-12): 16:39:16  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-05 16:39:16.013090 (Thread-12): 16:39:16  Parsing macros/materializations/tests/test.sql
2022-01-05 16:39:16.017173 (Thread-12): 16:39:16  Parsing macros/materializations/tests/where_subquery.sql
2022-01-05 16:39:16.018889 (Thread-12): 16:39:16  Parsing macros/materializations/tests/helpers.sql
2022-01-05 16:39:16.020625 (Thread-12): 16:39:16  Parsing macros/etc/statement.sql
2022-01-05 16:39:16.024741 (Thread-12): 16:39:16  Parsing macros/etc/datetime.sql
2022-01-05 16:39:16.032723 (Thread-12): 16:39:16  Parsing macros/adapters/indexes.sql
2022-01-05 16:39:16.035236 (Thread-12): 16:39:16  Parsing macros/adapters/persist_docs.sql
2022-01-05 16:39:16.039379 (Thread-12): 16:39:16  Parsing macros/adapters/freshness.sql
2022-01-05 16:39:16.042166 (Thread-12): 16:39:16  Parsing macros/adapters/relation.sql
2022-01-05 16:39:16.051134 (Thread-12): 16:39:16  Parsing macros/adapters/metadata.sql
2022-01-05 16:39:16.057781 (Thread-12): 16:39:16  Parsing macros/adapters/columns.sql
2022-01-05 16:39:16.067020 (Thread-12): 16:39:16  Parsing macros/adapters/schema.sql
2022-01-05 16:39:16.069128 (Thread-12): 16:39:16  Parsing tests/generic/builtin.sql
2022-01-05 16:39:16.256897 (Thread-12): 16:39:16  1699: static parser successfully parsed dim_customers.sql
2022-01-05 16:39:16.268697 (Thread-12): 16:39:16  1699: static parser successfully parsed example/my_second_dbt_model.sql
2022-01-05 16:39:16.271022 (Thread-12): 16:39:16  1699: static parser successfully parsed example/my_first_dbt_model.sql
2022-01-05 16:39:16.370848 (Thread-12): 16:39:16  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae46209a0>]}
2022-01-05 16:39:17.928096 (Thread-13): handling status request
2022-01-05 16:39:17.928624 (Thread-13): 16:39:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45eb7c0>]}
2022-01-05 16:39:17.929847 (Thread-13): sending response (<Response 15820 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:39:17.939921 (Thread-14): handling status request
2022-01-05 16:39:17.940168 (Thread-14): 16:39:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4631c40>]}
2022-01-05 16:39:17.940913 (Thread-14): sending response (<Response 15820 bytes [200 OK]>) to 10.0.26.162
2022-01-05 16:39:17.949081 (Thread-15): handling ps request
2022-01-05 16:39:17.949360 (Thread-15): 16:39:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45c5820>]}
2022-01-05 16:39:17.949756 (Thread-15): sending response (<Response 105 bytes [200 OK]>) to 10.0.17.156
2022-01-05 16:39:17.964225 (Thread-16): handling status request
2022-01-05 16:39:17.964478 (Thread-16): 16:39:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae461e250>]}
2022-01-05 16:39:17.965217 (Thread-16): sending response (<Response 15820 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:39:50.871565 (Thread-17): handling status request
2022-01-05 16:39:50.872878 (Thread-17): 16:39:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae468f820>]}
2022-01-05 16:39:50.873813 (Thread-17): sending response (<Response 15820 bytes [200 OK]>) to 10.0.10.137
2022-01-05 16:39:51.223488 (Thread-18): handling run_sql request
2022-01-05 16:39:51.223867 (Thread-18): 16:39:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae468f670>]}
2022-01-05 16:39:53.278617 (Thread-18): sending response (<Response 138 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:39:53.303559 (MainThread): 16:39:53  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f31d62f7-8c41-42e9-8cf0-fa130dfe55ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22c0a841c0>]}
2022-01-05 16:39:53.304112 (MainThread): 16:39:53  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:39:53.304713 (Thread-1): 16:39:53  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:39:53.304846 (Thread-1): 16:39:53  Began compiling node rpc.my_new_project.request
2022-01-05 16:39:53.304936 (Thread-1): 16:39:53  Compiling rpc.my_new_project.request
2022-01-05 16:39:53.306112 (Thread-1): 16:39:53  finished collecting timing info
2022-01-05 16:39:53.306239 (Thread-1): 16:39:53  Began executing node rpc.my_new_project.request
2022-01-05 16:39:53.306337 (Thread-1): 16:39:53  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:39:53.306416 (Thread-1): 16:39:53  On rpc.my_new_project.request: create table jaffle_shop.customers(
  id integer,
  first_name varchar(50),
  last_name varchar(50)
);
	
create table jaffle_shop.orders(
  id integer,
  user_id integer,
  order_date date,
  status varchar(50),
  _etl_loaded_at timestamp default current_timestamp
);
	
create table stripe.payment(
  id integer,
  orderid integer,
  paymentmethod varchar(50),
  status varchar(50),
  amount integer,
  created date,
  _batched_at timestamp default current_timestamp
);




copy jaffle_shop.customers( id, first_name, last_name)
from 's3://dbt-tutorial-public/jaffle_shop_customers.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;



copy jaffle_shop.orders(id, user_id, order_date, status)
from 's3://dbt-tutorial-public/jaffle_shop_orders.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;

copy stripe.payment(id, orderid, paymentmethod, status, amount, created)
from 's3://dbt-tutorial-public/stripe_payments.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:39:53.306497 (Thread-1): 16:39:53  Opening a new connection, currently in state init
2022-01-05 16:39:53.306582 (Thread-1): 16:39:53  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:39:53.328406 (Thread-1): 16:39:53  Postgres adapter: Postgres error: schema "jaffle_shop" does not exist

2022-01-05 16:39:53.328568 (Thread-1): 16:39:53  finished collecting timing info
2022-01-05 16:39:53.328701 (Thread-1): 16:39:53  On rpc.my_new_project.request: Close
2022-01-05 16:39:53.328891 (Thread-1): Got an exception: Database Error
  schema "jaffle_shop" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidSchemaName: schema "jaffle_shop" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  schema "jaffle_shop" does not exist
2022-01-05 16:39:53.330092 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-01-05 16:39:53.700224 (Thread-19): handling poll request
2022-01-05 16:39:53.700677 (Thread-19): 16:39:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4631a30>]}
2022-01-05 16:39:53.701577 (Thread-19): sending response (<Response 18587 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:41:40.881062 (Thread-20): handling status request
2022-01-05 16:41:40.882660 (Thread-20): 16:41:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4183520>]}
2022-01-05 16:41:40.883603 (Thread-20): sending response (<Response 15820 bytes [200 OK]>) to 10.0.18.253
2022-01-05 16:41:41.485872 (Thread-21): handling run_sql request
2022-01-05 16:41:41.486261 (Thread-21): 16:41:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4183df0>]}
2022-01-05 16:41:43.559538 (Thread-21): sending response (<Response 138 bytes [200 OK]>) to 10.0.17.156
2022-01-05 16:41:43.586034 (MainThread): 16:41:43  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6665cc01-c3d7-4ede-9785-71af86e1a55f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29e0344280>]}
2022-01-05 16:41:43.586594 (MainThread): 16:41:43  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:41:43.587195 (Thread-1): 16:41:43  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:41:43.587325 (Thread-1): 16:41:43  Began compiling node rpc.my_new_project.request
2022-01-05 16:41:43.587415 (Thread-1): 16:41:43  Compiling rpc.my_new_project.request
2022-01-05 16:41:43.588545 (Thread-1): 16:41:43  finished collecting timing info
2022-01-05 16:41:43.588668 (Thread-1): 16:41:43  Began executing node rpc.my_new_project.request
2022-01-05 16:41:43.588769 (Thread-1): 16:41:43  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:41:43.588846 (Thread-1): 16:41:43  On rpc.my_new_project.request: create schema if not exists jaffle_shop;
	
create schema if not exists stripe;


create table jaffle_shop.customers(
  id integer,
  first_name varchar(50),
  last_name varchar(50)
);
	
create table jaffle_shop.orders(
  id integer,
  user_id integer,
  order_date date,
  status varchar(50),
  _etl_loaded_at timestamp default current_timestamp
);
	
create table stripe.payment(
  id integer,
  orderid integer,
  paymentmethod varchar(50),
  status varchar(50),
  amount integer,
  created date,
  _batched_at timestamp default current_timestamp
);




copy jaffle_shop.customers( id, first_name, last_name)
from 's3://dbt-tutorial-public/jaffle_shop_customers.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;



copy jaffle_shop.orders(id, user_id, order_date, status)
from 's3://dbt-tutorial-public/jaffle_shop_orders.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;

copy stripe.payment(id, orderid, paymentmethod, status, amount, created)
from 's3://dbt-tutorial-public/stripe_payments.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:41:43.588924 (Thread-1): 16:41:43  Opening a new connection, currently in state init
2022-01-05 16:41:43.589006 (Thread-1): 16:41:43  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:41:43.615589 (Thread-1): 16:41:43  Postgres adapter: Postgres error: schema "jaffle_shop" does not exist

2022-01-05 16:41:43.615751 (Thread-1): 16:41:43  finished collecting timing info
2022-01-05 16:41:43.615878 (Thread-1): 16:41:43  On rpc.my_new_project.request: Close
2022-01-05 16:41:43.616053 (Thread-1): Got an exception: Database Error
  schema "jaffle_shop" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidSchemaName: schema "jaffle_shop" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  schema "jaffle_shop" does not exist
2022-01-05 16:41:43.617146 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create schema if not exists jaffle_shop;\n\t\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create schema if not exists jaffle_shop;\n\t\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create schema if not exists jaffle_shop;\n\t\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create schema if not exists jaffle_shop;\n\t\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-01-05 16:41:44.027452 (Thread-22): handling poll request
2022-01-05 16:41:44.027905 (Thread-22): 16:41:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae46ab610>]}
2022-01-05 16:41:44.028771 (Thread-22): sending response (<Response 19220 bytes [200 OK]>) to 10.0.20.28
2022-01-05 16:42:09.542678 (Thread-23): handling status request
2022-01-05 16:42:09.544284 (Thread-23): 16:42:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae46abf10>]}
2022-01-05 16:42:09.545242 (Thread-23): sending response (<Response 15820 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:42:09.929808 (Thread-24): handling run_sql request
2022-01-05 16:42:09.930081 (Thread-24): 16:42:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45d3100>]}
2022-01-05 16:42:11.984256 (Thread-24): sending response (<Response 138 bytes [200 OK]>) to 10.0.30.3
2022-01-05 16:42:12.008081 (MainThread): 16:42:12  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '516653f5-0fc2-427c-8606-9f8e141f7c4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f580ad1d280>]}
2022-01-05 16:42:12.008607 (MainThread): 16:42:12  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:42:12.009187 (Thread-1): 16:42:12  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:42:12.009368 (Thread-1): 16:42:12  Began compiling node rpc.my_new_project.request
2022-01-05 16:42:12.009535 (Thread-1): 16:42:12  Compiling rpc.my_new_project.request
2022-01-05 16:42:12.010738 (Thread-1): 16:42:12  finished collecting timing info
2022-01-05 16:42:12.010865 (Thread-1): 16:42:12  Began executing node rpc.my_new_project.request
2022-01-05 16:42:12.010980 (Thread-1): 16:42:12  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:42:12.011066 (Thread-1): 16:42:12  On rpc.my_new_project.request: create schema if not exists jaffle_shop;
create schema if not exists stripe;


create table jaffle_shop.customers(
  id integer,
  first_name varchar(50),
  last_name varchar(50)
);
	
create table jaffle_shop.orders(
  id integer,
  user_id integer,
  order_date date,
  status varchar(50),
  _etl_loaded_at timestamp default current_timestamp
);
	
create table stripe.payment(
  id integer,
  orderid integer,
  paymentmethod varchar(50),
  status varchar(50),
  amount integer,
  created date,
  _batched_at timestamp default current_timestamp
);




copy jaffle_shop.customers( id, first_name, last_name)
from 's3://dbt-tutorial-public/jaffle_shop_customers.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;



copy jaffle_shop.orders(id, user_id, order_date, status)
from 's3://dbt-tutorial-public/jaffle_shop_orders.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;

copy stripe.payment(id, orderid, paymentmethod, status, amount, created)
from 's3://dbt-tutorial-public/stripe_payments.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:42:12.011150 (Thread-1): 16:42:12  Opening a new connection, currently in state init
2022-01-05 16:42:12.011236 (Thread-1): 16:42:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:42:12.034460 (Thread-1): 16:42:12  Postgres adapter: Postgres error: schema "jaffle_shop" does not exist

2022-01-05 16:42:12.034643 (Thread-1): 16:42:12  finished collecting timing info
2022-01-05 16:42:12.034784 (Thread-1): 16:42:12  On rpc.my_new_project.request: Close
2022-01-05 16:42:12.035078 (Thread-1): Got an exception: Database Error
  schema "jaffle_shop" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidSchemaName: schema "jaffle_shop" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  schema "jaffle_shop" does not exist
2022-01-05 16:42:12.036085 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create schema if not exists jaffle_shop;\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create schema if not exists jaffle_shop;\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create schema if not exists jaffle_shop;\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create schema if not exists jaffle_shop;\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-01-05 16:42:12.369185 (Thread-25): handling poll request
2022-01-05 16:42:12.369671 (Thread-25): 16:42:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae46222e0>]}
2022-01-05 16:42:12.370502 (Thread-25): sending response (<Response 19184 bytes [200 OK]>) to 10.0.32.67
2022-01-05 16:45:55.591816 (Thread-26): handling status request
2022-01-05 16:45:55.593518 (Thread-26): 16:45:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45be6a0>]}
2022-01-05 16:45:55.594475 (Thread-26): sending response (<Response 15820 bytes [200 OK]>) to 10.0.26.162
2022-01-05 16:45:56.024551 (Thread-27): handling run_sql request
2022-01-05 16:45:56.024960 (Thread-27): 16:45:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45befa0>]}
2022-01-05 16:45:58.156122 (Thread-27): sending response (<Response 138 bytes [200 OK]>) to 10.0.10.137
2022-01-05 16:45:58.181584 (MainThread): 16:45:58  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ba7393da-844d-4c5b-b182-0a0f9652e91c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ecd0001f0>]}
2022-01-05 16:45:58.182121 (MainThread): 16:45:58  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:45:58.182733 (Thread-1): 16:45:58  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:45:58.182865 (Thread-1): 16:45:58  Began compiling node rpc.my_new_project.request
2022-01-05 16:45:58.182953 (Thread-1): 16:45:58  Compiling rpc.my_new_project.request
2022-01-05 16:45:58.184088 (Thread-1): 16:45:58  finished collecting timing info
2022-01-05 16:45:58.184214 (Thread-1): 16:45:58  Began executing node rpc.my_new_project.request
2022-01-05 16:45:58.184312 (Thread-1): 16:45:58  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:45:58.184395 (Thread-1): 16:45:58  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:45:58.184475 (Thread-1): 16:45:58  Opening a new connection, currently in state init
2022-01-05 16:45:58.184557 (Thread-1): 16:45:58  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:45:58.212360 (Thread-1): 16:45:58  Postgres adapter: Postgres error: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^

2022-01-05 16:45:58.212560 (Thread-1): 16:45:58  finished collecting timing info
2022-01-05 16:45:58.212704 (Thread-1): 16:45:58  On rpc.my_new_project.request: Close
2022-01-05 16:45:58.212904 (Thread-1): Got an exception: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
2022-01-05 16:45:58.214091 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 16:45:58.558893 (Thread-28): handling poll request
2022-01-05 16:45:58.559396 (Thread-28): 16:45:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45eed00>]}
2022-01-05 16:45:58.560262 (Thread-28): sending response (<Response 15951 bytes [200 OK]>) to 10.0.38.111
2022-01-05 16:46:45.865147 (Thread-29): handling status request
2022-01-05 16:46:45.865585 (Thread-29): 16:46:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae41525b0>]}
2022-01-05 16:46:45.866555 (Thread-29): sending response (<Response 15820 bytes [200 OK]>) to 10.0.6.188
2022-01-05 16:46:46.311105 (Thread-30): handling run_sql request
2022-01-05 16:46:46.311512 (Thread-30): 16:46:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45ee400>]}
2022-01-05 16:46:48.377682 (Thread-30): sending response (<Response 138 bytes [200 OK]>) to 10.0.19.216
2022-01-05 16:46:48.401169 (MainThread): 16:46:48  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dd52ea4c-3fa5-4ce4-a507-e05bdb90f89a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d75e3a1c0>]}
2022-01-05 16:46:48.401730 (MainThread): 16:46:48  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:46:48.402302 (Thread-1): 16:46:48  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:46:48.402431 (Thread-1): 16:46:48  Began compiling node rpc.my_new_project.request
2022-01-05 16:46:48.402522 (Thread-1): 16:46:48  Compiling rpc.my_new_project.request
2022-01-05 16:46:48.403672 (Thread-1): 16:46:48  finished collecting timing info
2022-01-05 16:46:48.403801 (Thread-1): 16:46:48  Began executing node rpc.my_new_project.request
2022-01-05 16:46:48.403904 (Thread-1): 16:46:48  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:46:48.403982 (Thread-1): 16:46:48  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from dev.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from dev.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:46:48.404061 (Thread-1): 16:46:48  Opening a new connection, currently in state init
2022-01-05 16:46:48.404143 (Thread-1): 16:46:48  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:46:48.710458 (Thread-1): 16:46:48  SQL status: SELECT in 0.31 seconds
2022-01-05 16:46:48.711577 (Thread-1): 16:46:48  finished collecting timing info
2022-01-05 16:46:48.711747 (Thread-1): 16:46:48  On rpc.my_new_project.request: Close
2022-01-05 16:46:48.771036 (Thread-31): handling poll request
2022-01-05 16:46:48.771480 (Thread-31): 16:46:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4191850>]}
2022-01-05 16:46:48.772345 (Thread-31): sending response (<Response 5941 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:46:50.210348 (Thread-32): handling poll request
2022-01-05 16:46:50.210730 (Thread-32): 16:46:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4191910>]}
2022-01-05 16:46:50.211890 (Thread-32): sending response (<Response 6204 bytes [200 OK]>) to 10.0.10.137
2022-01-05 16:47:06.349240 (Thread-33): handling status request
2022-01-05 16:47:06.349704 (Thread-33): 16:47:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4191a30>]}
2022-01-05 16:47:06.350656 (Thread-33): sending response (<Response 15820 bytes [200 OK]>) to 10.0.30.3
2022-01-05 16:47:06.795521 (Thread-34): handling run_sql request
2022-01-05 16:47:06.795892 (Thread-34): 16:47:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae414d3d0>]}
2022-01-05 16:47:08.863842 (Thread-34): sending response (<Response 138 bytes [200 OK]>) to 10.0.32.67
2022-01-05 16:47:08.890748 (MainThread): 16:47:08  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cc0580c8-00ce-45ae-b957-d7d4dc307db9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7848df8280>]}
2022-01-05 16:47:08.891308 (MainThread): 16:47:08  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:47:08.891883 (Thread-1): 16:47:08  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:47:08.892013 (Thread-1): 16:47:08  Began compiling node rpc.my_new_project.request
2022-01-05 16:47:08.892101 (Thread-1): 16:47:08  Compiling rpc.my_new_project.request
2022-01-05 16:47:08.893311 (Thread-1): 16:47:08  finished collecting timing info
2022-01-05 16:47:08.893513 (Thread-1): 16:47:08  Began executing node rpc.my_new_project.request
2022-01-05 16:47:08.893652 (Thread-1): 16:47:08  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:47:08.893739 (Thread-1): 16:47:08  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from dev.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from dev.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:47:08.893848 (Thread-1): 16:47:08  Opening a new connection, currently in state init
2022-01-05 16:47:08.893941 (Thread-1): 16:47:08  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:47:08.916921 (Thread-1): 16:47:08  SQL status: SELECT in 0.02 seconds
2022-01-05 16:47:08.917927 (Thread-1): 16:47:08  finished collecting timing info
2022-01-05 16:47:08.918066 (Thread-1): 16:47:08  On rpc.my_new_project.request: Close
2022-01-05 16:47:09.255197 (Thread-35): handling poll request
2022-01-05 16:47:09.255629 (Thread-35): 16:47:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae415abb0>]}
2022-01-05 16:47:09.256752 (Thread-35): sending response (<Response 11760 bytes [200 OK]>) to 10.0.17.156
2022-01-05 16:52:53.345938 (Thread-36): handling status request
2022-01-05 16:52:53.347350 (Thread-36): 16:52:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae415a700>]}
2022-01-05 16:52:53.348294 (Thread-36): sending response (<Response 15820 bytes [200 OK]>) to 10.0.26.162
2022-01-05 16:52:54.265808 (Thread-37): handling run_sql request
2022-01-05 16:52:54.266188 (Thread-37): 16:52:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae415a4c0>]}
2022-01-05 16:52:56.353889 (Thread-37): sending response (<Response 138 bytes [200 OK]>) to 10.0.42.85
2022-01-05 16:52:56.380688 (MainThread): 16:52:56  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2788a387-77ee-4871-8262-f407dcbea91b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a0f8b220>]}
2022-01-05 16:52:56.381259 (MainThread): 16:52:56  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:52:56.381889 (Thread-1): 16:52:56  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:52:56.382020 (Thread-1): 16:52:56  Began compiling node rpc.my_new_project.request
2022-01-05 16:52:56.382119 (Thread-1): 16:52:56  Compiling rpc.my_new_project.request
2022-01-05 16:52:56.383264 (Thread-1): 16:52:56  finished collecting timing info
2022-01-05 16:52:56.383389 (Thread-1): 16:52:56  Began executing node rpc.my_new_project.request
2022-01-05 16:52:56.383487 (Thread-1): 16:52:56  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:52:56.383564 (Thread-1): 16:52:56  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:52:56.383643 (Thread-1): 16:52:56  Opening a new connection, currently in state init
2022-01-05 16:52:56.383727 (Thread-1): 16:52:56  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:52:56.406748 (Thread-1): 16:52:56  SQL status: SELECT in 0.02 seconds
2022-01-05 16:52:56.407735 (Thread-1): 16:52:56  finished collecting timing info
2022-01-05 16:52:56.407872 (Thread-1): 16:52:56  On rpc.my_new_project.request: Close
2022-01-05 16:52:56.807903 (Thread-38): handling poll request
2022-01-05 16:52:56.808340 (Thread-38): 16:52:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4125cd0>]}
2022-01-05 16:52:56.809566 (Thread-38): sending response (<Response 11720 bytes [200 OK]>) to 10.0.42.119
2022-01-05 16:53:05.020856 (Thread-39): handling ps request
2022-01-05 16:53:05.021235 (Thread-39): 16:53:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4125e80>]}
2022-01-05 16:53:05.024387 (Thread-40): handling status request
2022-01-05 16:53:05.024659 (Thread-40): 16:53:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4191100>]}
2022-01-05 16:53:05.033217 (Thread-41): handling status request
2022-01-05 16:53:05.033542 (Thread-41): 16:53:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4135520>]}
2022-01-05 16:53:05.052842 (Thread-39): sending response (<Response 3642 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:53:05.054062 (Thread-40): sending response (<Response 15820 bytes [200 OK]>) to 10.0.26.162
2022-01-05 16:53:05.055097 (Thread-41): sending response (<Response 15820 bytes [200 OK]>) to 10.0.18.253
2022-01-05 16:53:05.131998 (Thread-42): handling status request
2022-01-05 16:53:05.132357 (Thread-42): 16:53:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4125a30>]}
2022-01-05 16:53:05.133225 (Thread-42): sending response (<Response 15820 bytes [200 OK]>) to 10.0.5.1
2022-01-05 16:56:14.676625 (Thread-43): handling status request
2022-01-05 16:56:14.677878 (Thread-43): 16:56:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae412d7f0>]}
2022-01-05 16:56:14.678718 (Thread-43): sending response (<Response 15820 bytes [200 OK]>) to 10.0.10.137
2022-01-05 16:56:15.022745 (Thread-44): handling run_sql request
2022-01-05 16:56:15.023120 (Thread-44): 16:56:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae412db50>]}
2022-01-05 16:56:17.110459 (Thread-44): sending response (<Response 138 bytes [200 OK]>) to 10.0.17.156
2022-01-05 16:56:17.128067 (MainThread): 16:56:17  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '33eee4ca-108c-4402-9729-865713de7d25', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7ece0e2b0>]}
2022-01-05 16:56:17.128648 (MainThread): 16:56:17  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:56:17.129292 (Thread-1): 16:56:17  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:56:17.129455 (Thread-1): 16:56:17  Began compiling node rpc.my_new_project.request
2022-01-05 16:56:17.129557 (Thread-1): 16:56:17  Compiling rpc.my_new_project.request
2022-01-05 16:56:17.130838 (Thread-1): 16:56:17  finished collecting timing info
2022-01-05 16:56:17.130966 (Thread-1): 16:56:17  Began executing node rpc.my_new_project.request
2022-01-05 16:56:17.131072 (Thread-1): 16:56:17  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:56:17.131155 (Thread-1): 16:56:17  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:56:17.131236 (Thread-1): 16:56:17  Opening a new connection, currently in state init
2022-01-05 16:56:17.131323 (Thread-1): 16:56:17  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:56:17.191739 (Thread-1): 16:56:17  SQL status: SELECT in 0.06 seconds
2022-01-05 16:56:17.194886 (Thread-1): 16:56:17  finished collecting timing info
2022-01-05 16:56:17.195066 (Thread-1): 16:56:17  On rpc.my_new_project.request: Close
2022-01-05 16:56:17.526557 (Thread-45): handling poll request
2022-01-05 16:56:17.526992 (Thread-45): 16:56:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4135fd0>]}
2022-01-05 16:56:17.528603 (Thread-45): sending response (<Response 16788 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:57:13.672284 (Thread-46): 16:57:13  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 16:57:13.672516 (Thread-46): 16:57:13  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 16:57:13.678234 (Thread-46): 16:57:13  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac03b8a90>]}
2022-01-05 16:57:14.178227 (Thread-47): handling status request
2022-01-05 16:57:14.178600 (Thread-47): 16:57:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40b55b0>]}
2022-01-05 16:57:14.179127 (Thread-47): sending response (<Response 1241 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:57:14.245483 (Thread-48): handling status request
2022-01-05 16:57:14.245856 (Thread-48): 16:57:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40b51f0>]}
2022-01-05 16:57:14.246318 (Thread-48): sending response (<Response 1241 bytes [200 OK]>) to 10.0.42.85
2022-01-05 16:57:31.730616 (Thread-49): 16:57:31  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 16:57:31.730823 (Thread-49): 16:57:31  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 16:57:31.735672 (Thread-49): 16:57:31  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac034b970>]}
2022-01-05 16:57:32.334140 (Thread-50): handling status request
2022-01-05 16:57:32.334509 (Thread-50): 16:57:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae41913a0>]}
2022-01-05 16:57:32.334979 (Thread-50): sending response (<Response 1241 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:57:32.348009 (Thread-51): handling status request
2022-01-05 16:57:32.348379 (Thread-51): 16:57:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40d5310>]}
2022-01-05 16:57:32.348838 (Thread-51): sending response (<Response 1241 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:20:28.712209 (Thread-52): handling status request
2022-01-05 17:20:28.713633 (Thread-52): 17:20:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0376130>]}
2022-01-05 17:20:28.714135 (Thread-52): sending response (<Response 1241 bytes [200 OK]>) to 10.0.46.191
2022-01-05 17:20:28.789091 (Thread-53): handling status request
2022-01-05 17:20:28.789391 (Thread-53): 17:20:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0345cd0>]}
2022-01-05 17:20:28.789864 (Thread-53): sending response (<Response 1241 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:20:29.253632 (Thread-54): handling cli_args request
2022-01-05 17:20:29.253946 (Thread-54): 17:20:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0345c10>]}
2022-01-05 17:20:31.285207 (Thread-54): sending response (<Response 138 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:20:31.368158 (MainThread): 17:20:31  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 17:20:31.368548 (MainThread): 17:20:31  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 17:20:31.374483 (MainThread): 17:20:31  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3b071c71-0f21-4aec-a155-15949817d20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffaca2fdeb0>]}
2022-01-05 17:20:31.405575 (MainThread): 17:20:31  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3b071c71-0f21-4aec-a155-15949817d20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffaca4134c0>]}
2022-01-05 17:20:31.405805 (MainThread): 17:20:31  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:20:31.406772 (MainThread): 17:20:31  
2022-01-05 17:20:31.407040 (MainThread): 17:20:31  Acquiring new redshift connection "master"
2022-01-05 17:20:31.407820 (ThreadPoolExecutor-0_0): 17:20:31  Acquiring new redshift connection "list_dev"
2022-01-05 17:20:31.417518 (ThreadPoolExecutor-0_0): 17:20:31  Using redshift connection "list_dev"
2022-01-05 17:20:31.417619 (ThreadPoolExecutor-0_0): 17:20:31  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-05 17:20:31.417701 (ThreadPoolExecutor-0_0): 17:20:31  Opening a new connection, currently in state init
2022-01-05 17:20:31.417784 (ThreadPoolExecutor-0_0): 17:20:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:31.439471 (ThreadPoolExecutor-0_0): 17:20:31  SQL status: SELECT in 0.02 seconds
2022-01-05 17:20:31.440494 (ThreadPoolExecutor-0_0): 17:20:31  On list_dev: Close
2022-01-05 17:20:31.441532 (ThreadPoolExecutor-1_0): 17:20:31  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:20:31.447487 (ThreadPoolExecutor-1_0): 17:20:31  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:20:31.447585 (ThreadPoolExecutor-1_0): 17:20:31  On list_dev_dbt_nobodozie: BEGIN
2022-01-05 17:20:31.447666 (ThreadPoolExecutor-1_0): 17:20:31  Opening a new connection, currently in state closed
2022-01-05 17:20:31.447740 (ThreadPoolExecutor-1_0): 17:20:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:31.471806 (ThreadPoolExecutor-1_0): 17:20:31  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:20:31.471917 (ThreadPoolExecutor-1_0): 17:20:31  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:20:31.471991 (ThreadPoolExecutor-1_0): 17:20:31  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-05 17:20:31.488612 (ThreadPoolExecutor-1_0): 17:20:31  SQL status: SELECT in 0.02 seconds
2022-01-05 17:20:31.489727 (ThreadPoolExecutor-1_0): 17:20:31  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-05 17:20:31.492228 (ThreadPoolExecutor-1_0): 17:20:31  On list_dev_dbt_nobodozie: Close
2022-01-05 17:20:31.496455 (MainThread): 17:20:31  Using redshift connection "master"
2022-01-05 17:20:31.496567 (MainThread): 17:20:31  On master: BEGIN
2022-01-05 17:20:31.496649 (MainThread): 17:20:31  Opening a new connection, currently in state init
2022-01-05 17:20:31.496726 (MainThread): 17:20:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:31.649291 (Thread-55): handling poll request
2022-01-05 17:20:31.649733 (Thread-55): 17:20:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae412dc40>]}
2022-01-05 17:20:31.650759 (Thread-55): sending response (<Response 9949 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:20:32.186409 (MainThread): 17:20:32  SQL status: BEGIN in 0.69 seconds
2022-01-05 17:20:32.186572 (MainThread): 17:20:32  Using redshift connection "master"
2022-01-05 17:20:32.186655 (MainThread): 17:20:32  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-05 17:20:32.215191 (MainThread): 17:20:32  SQL status: SELECT in 0.03 seconds
2022-01-05 17:20:32.216314 (MainThread): 17:20:32  On master: ROLLBACK
2022-01-05 17:20:32.218517 (MainThread): 17:20:32  Using redshift connection "master"
2022-01-05 17:20:32.218629 (MainThread): 17:20:32  On master: BEGIN
2022-01-05 17:20:32.222972 (MainThread): 17:20:32  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:20:32.223083 (MainThread): 17:20:32  On master: COMMIT
2022-01-05 17:20:32.223154 (MainThread): 17:20:32  Using redshift connection "master"
2022-01-05 17:20:32.223222 (MainThread): 17:20:32  On master: COMMIT
2022-01-05 17:20:32.225162 (MainThread): 17:20:32  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:20:32.225270 (MainThread): 17:20:32  On master: Close
2022-01-05 17:20:32.225755 (MainThread): 17:20:32  Concurrency: 4 threads (target='default')
2022-01-05 17:20:32.225872 (MainThread): 17:20:32  
2022-01-05 17:20:32.227999 (Thread-1): 17:20:32  Began running node model.my_new_project.my_first_dbt_model
2022-01-05 17:20:32.228471 (Thread-1): 17:20:32  1 of 2 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-05 17:20:32.228760 (Thread-1): 17:20:32  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.228861 (Thread-1): 17:20:32  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-05 17:20:32.228955 (Thread-1): 17:20:32  Compiling model.my_new_project.my_first_dbt_model
2022-01-05 17:20:32.231288 (Thread-1): 17:20:32  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.249528 (Thread-1): 17:20:32  finished collecting timing info
2022-01-05 17:20:32.249671 (Thread-1): 17:20:32  Began executing node model.my_new_project.my_first_dbt_model
2022-01-05 17:20:32.280773 (Thread-1): 17:20:32  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.298262 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.298371 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:20:32.298454 (Thread-1): 17:20:32  Opening a new connection, currently in state closed
2022-01-05 17:20:32.298536 (Thread-1): 17:20:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:32.318595 (Thread-1): 17:20:32  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:20:32.318714 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.318810 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-05 17:20:32.365613 (Thread-1): 17:20:32  SQL status: SELECT in 0.05 seconds
2022-01-05 17:20:32.370908 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.371008 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-05 17:20:32.373565 (Thread-1): 17:20:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:20:32.375258 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.375353 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-05 17:20:32.377893 (Thread-1): 17:20:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:20:32.387953 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:20:32.388052 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.388125 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:20:32.428113 (Thread-1): 17:20:32  SQL status: COMMIT in 0.04 seconds
2022-01-05 17:20:32.428310 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.428388 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:20:32.430521 (Thread-1): 17:20:32  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:20:32.434356 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.434455 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-05 17:20:32.439373 (Thread-1): 17:20:32  SQL status: DROP TABLE in 0.0 seconds
2022-01-05 17:20:32.440326 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:20:32.440469 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.440591 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:20:32.470350 (Thread-1): 17:20:32  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:20:32.470467 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.470543 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:20:32.472715 (Thread-1): 17:20:32  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:20:32.473097 (Thread-1): 17:20:32  finished collecting timing info
2022-01-05 17:20:32.473222 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-05 17:20:32.475059 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: Close
2022-01-05 17:20:32.475486 (Thread-1): 17:20:32  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b071c71-0f21-4aec-a155-15949817d20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffac9ac1dc0>]}
2022-01-05 17:20:32.475800 (Thread-1): 17:20:32  1 of 2 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.25s]
2022-01-05 17:20:32.475912 (Thread-1): 17:20:32  Finished running node model.my_new_project.my_first_dbt_model
2022-01-05 17:20:32.476696 (Thread-3): 17:20:32  Began running node model.my_new_project.my_second_dbt_model
2022-01-05 17:20:32.476960 (Thread-3): 17:20:32  2 of 2 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-05 17:20:32.477221 (Thread-3): 17:20:32  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.477326 (Thread-3): 17:20:32  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-05 17:20:32.477439 (Thread-3): 17:20:32  Compiling model.my_new_project.my_second_dbt_model
2022-01-05 17:20:32.479411 (Thread-3): 17:20:32  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.500240 (Thread-3): 17:20:32  finished collecting timing info
2022-01-05 17:20:32.500380 (Thread-3): 17:20:32  Began executing node model.my_new_project.my_second_dbt_model
2022-01-05 17:20:32.516039 (Thread-3): 17:20:32  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.529333 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.529467 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:20:32.529556 (Thread-3): 17:20:32  Opening a new connection, currently in state init
2022-01-05 17:20:32.529638 (Thread-3): 17:20:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:32.548735 (Thread-3): 17:20:32  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:20:32.548852 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.548934 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-05 17:20:32.553734 (Thread-3): 17:20:32  SQL status: CREATE VIEW in 0.0 seconds
2022-01-05 17:20:32.555485 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.555584 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-05 17:20:32.557800 (Thread-3): 17:20:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:20:32.558745 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:20:32.558844 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.558920 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:20:32.587529 (Thread-3): 17:20:32  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:20:32.587743 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.587826 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:20:32.590380 (Thread-3): 17:20:32  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:20:32.591557 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.591654 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-05 17:20:32.593649 (Thread-3): 17:20:32  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 17:20:32.594260 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:20:32.594354 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.594429 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:20:32.618770 (Thread-3): 17:20:32  SQL status: COMMIT in 0.02 seconds
2022-01-05 17:20:32.618888 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.618963 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:20:32.621265 (Thread-3): 17:20:32  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:20:32.621658 (Thread-3): 17:20:32  finished collecting timing info
2022-01-05 17:20:32.621785 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-05 17:20:32.623930 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: Close
2022-01-05 17:20:32.624352 (Thread-3): 17:20:32  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b071c71-0f21-4aec-a155-15949817d20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffac81fd280>]}
2022-01-05 17:20:32.624653 (Thread-3): 17:20:32  2 of 2 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.15s]
2022-01-05 17:20:32.624762 (Thread-3): 17:20:32  Finished running node model.my_new_project.my_second_dbt_model
2022-01-05 17:20:32.626130 (MainThread): 17:20:32  Acquiring new redshift connection "master"
2022-01-05 17:20:32.626270 (MainThread): 17:20:32  Using redshift connection "master"
2022-01-05 17:20:32.626347 (MainThread): 17:20:32  On master: BEGIN
2022-01-05 17:20:32.626423 (MainThread): 17:20:32  Opening a new connection, currently in state closed
2022-01-05 17:20:32.626498 (MainThread): 17:20:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:32.649292 (MainThread): 17:20:32  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:20:32.649433 (MainThread): 17:20:32  On master: COMMIT
2022-01-05 17:20:32.649517 (MainThread): 17:20:32  Using redshift connection "master"
2022-01-05 17:20:32.649588 (MainThread): 17:20:32  On master: COMMIT
2022-01-05 17:20:32.651287 (MainThread): 17:20:32  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:20:32.651393 (MainThread): 17:20:32  On master: Close
2022-01-05 17:20:32.651758 (MainThread): 17:20:32  
2022-01-05 17:20:32.651867 (MainThread): 17:20:32  Finished running 1 table model, 1 view model in 1.24s.
2022-01-05 17:20:32.651946 (MainThread): 17:20:32  Connection 'master' was properly closed.
2022-01-05 17:20:32.652010 (MainThread): 17:20:32  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-05 17:20:32.652070 (MainThread): 17:20:32  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-05 17:20:32.722715 (MainThread): 17:20:32  
2022-01-05 17:20:32.722924 (MainThread): 17:20:32  Completed successfully
2022-01-05 17:20:32.723064 (MainThread): 17:20:32  
2022-01-05 17:20:32.723186 (MainThread): 17:20:32  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2022-01-05 17:20:33.191965 (Thread-56): handling poll request
2022-01-05 17:20:33.192318 (Thread-56): 17:20:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40e4c70>]}
2022-01-05 17:20:33.194331 (Thread-56): sending response (<Response 54422 bytes [200 OK]>) to 10.0.38.111
2022-01-05 17:20:33.906276 (Thread-57): handling status request
2022-01-05 17:20:33.906641 (Thread-57): 17:20:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40b5f40>]}
2022-01-05 17:20:33.907131 (Thread-57): sending response (<Response 1241 bytes [200 OK]>) to 10.0.9.25
2022-01-05 17:20:33.935630 (Thread-58): handling status request
2022-01-05 17:20:33.935882 (Thread-58): 17:20:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac034c670>]}
2022-01-05 17:20:33.936254 (Thread-58): sending response (<Response 1241 bytes [200 OK]>) to 10.0.12.39
2022-01-05 17:21:08.517276 (Thread-59): 17:21:08  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-05 17:21:08.517725 (Thread-59): 17:21:08  Partial parsing: updated file: my_new_project://models/dim_customers.sql
2022-01-05 17:21:08.522572 (Thread-59): 17:21:08  1699: static parser successfully parsed dim_customers.sql
2022-01-05 17:21:08.580279 (Thread-59): 17:21:08  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02cfdf0>]}
2022-01-05 17:21:09.322528 (Thread-60): handling status request
2022-01-05 17:21:09.322934 (Thread-60): 17:21:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40f6550>]}
2022-01-05 17:21:09.323407 (Thread-60): sending response (<Response 1552 bytes [200 OK]>) to 10.0.9.25
2022-01-05 17:21:09.397491 (Thread-61): handling status request
2022-01-05 17:21:09.397810 (Thread-61): 17:21:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac031d820>]}
2022-01-05 17:21:09.398263 (Thread-61): sending response (<Response 1552 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:21:12.432246 (Thread-62): handling status request
2022-01-05 17:21:12.432612 (Thread-62): 17:21:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40b5fa0>]}
2022-01-05 17:21:12.433097 (Thread-62): sending response (<Response 1552 bytes [200 OK]>) to 10.0.6.188
2022-01-05 17:21:12.667933 (Thread-63): handling status request
2022-01-05 17:21:12.668245 (Thread-63): 17:21:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40d57f0>]}
2022-01-05 17:21:12.668718 (Thread-63): sending response (<Response 1552 bytes [200 OK]>) to 10.0.17.156
2022-01-05 17:21:12.810381 (Thread-64): handling cli_args request
2022-01-05 17:21:12.810674 (Thread-64): 17:21:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40d5130>]}
2022-01-05 17:21:14.836598 (Thread-64): sending response (<Response 138 bytes [200 OK]>) to 10.0.5.1
2022-01-05 17:21:14.907400 (MainThread): 17:21:14  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 17:21:14.907770 (MainThread): 17:21:14  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 17:21:14.913252 (MainThread): 17:21:14  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '16de0e09-5bb9-4497-9935-603c3bf9fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1274c1df40>]}
2022-01-05 17:21:14.955618 (MainThread): 17:21:14  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '16de0e09-5bb9-4497-9935-603c3bf9fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1274c9af70>]}
2022-01-05 17:21:14.955872 (MainThread): 17:21:14  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:21:14.956878 (MainThread): 17:21:14  
2022-01-05 17:21:14.957142 (MainThread): 17:21:14  Acquiring new redshift connection "master"
2022-01-05 17:21:14.957973 (ThreadPoolExecutor-0_0): 17:21:14  Acquiring new redshift connection "list_dev"
2022-01-05 17:21:14.967709 (ThreadPoolExecutor-0_0): 17:21:14  Using redshift connection "list_dev"
2022-01-05 17:21:14.967805 (ThreadPoolExecutor-0_0): 17:21:14  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-05 17:21:14.967886 (ThreadPoolExecutor-0_0): 17:21:14  Opening a new connection, currently in state init
2022-01-05 17:21:14.968121 (ThreadPoolExecutor-0_0): 17:21:14  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:14.993579 (ThreadPoolExecutor-0_0): 17:21:14  SQL status: SELECT in 0.03 seconds
2022-01-05 17:21:14.994574 (ThreadPoolExecutor-0_0): 17:21:14  On list_dev: Close
2022-01-05 17:21:14.995625 (ThreadPoolExecutor-1_0): 17:21:14  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:21:15.001679 (ThreadPoolExecutor-1_0): 17:21:15  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:21:15.001775 (ThreadPoolExecutor-1_0): 17:21:15  On list_dev_dbt_nobodozie: BEGIN
2022-01-05 17:21:15.001850 (ThreadPoolExecutor-1_0): 17:21:15  Opening a new connection, currently in state closed
2022-01-05 17:21:15.001925 (ThreadPoolExecutor-1_0): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.031186 (ThreadPoolExecutor-1_0): 17:21:15  SQL status: BEGIN in 0.03 seconds
2022-01-05 17:21:15.031293 (ThreadPoolExecutor-1_0): 17:21:15  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:21:15.031365 (ThreadPoolExecutor-1_0): 17:21:15  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-05 17:21:15.042641 (ThreadPoolExecutor-1_0): 17:21:15  SQL status: SELECT in 0.01 seconds
2022-01-05 17:21:15.043583 (ThreadPoolExecutor-1_0): 17:21:15  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-05 17:21:15.045371 (ThreadPoolExecutor-1_0): 17:21:15  On list_dev_dbt_nobodozie: Close
2022-01-05 17:21:15.049242 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.049367 (MainThread): 17:21:15  On master: BEGIN
2022-01-05 17:21:15.049473 (MainThread): 17:21:15  Opening a new connection, currently in state init
2022-01-05 17:21:15.049553 (MainThread): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.073686 (MainThread): 17:21:15  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:21:15.073793 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.073867 (MainThread): 17:21:15  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-05 17:21:15.102599 (MainThread): 17:21:15  SQL status: SELECT in 0.03 seconds
2022-01-05 17:21:15.103507 (MainThread): 17:21:15  On master: ROLLBACK
2022-01-05 17:21:15.105431 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.105526 (MainThread): 17:21:15  On master: BEGIN
2022-01-05 17:21:15.109090 (MainThread): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.109193 (MainThread): 17:21:15  On master: COMMIT
2022-01-05 17:21:15.109264 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.109331 (MainThread): 17:21:15  On master: COMMIT
2022-01-05 17:21:15.111104 (MainThread): 17:21:15  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:21:15.111214 (MainThread): 17:21:15  On master: Close
2022-01-05 17:21:15.111559 (MainThread): 17:21:15  Concurrency: 4 threads (target='default')
2022-01-05 17:21:15.111668 (MainThread): 17:21:15  
2022-01-05 17:21:15.113807 (Thread-1): 17:21:15  Began running node model.my_new_project.dim_customers
2022-01-05 17:21:15.114049 (Thread-1): 17:21:15  1 of 3 START view model dbt_nobodozie.dim_customers............................. [RUN]
2022-01-05 17:21:15.114268 (Thread-1): 17:21:15  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.114355 (Thread-1): 17:21:15  Began compiling node model.my_new_project.dim_customers
2022-01-05 17:21:15.114440 (Thread-1): 17:21:15  Compiling model.my_new_project.dim_customers
2022-01-05 17:21:15.115450 (Thread-1): 17:21:15  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-05 17:21:15.115782 (Thread-2): 17:21:15  Began running node model.my_new_project.my_first_dbt_model
2022-01-05 17:21:15.116001 (Thread-2): 17:21:15  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-05 17:21:15.116228 (Thread-2): 17:21:15  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.116310 (Thread-2): 17:21:15  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-05 17:21:15.116387 (Thread-2): 17:21:15  Compiling model.my_new_project.my_first_dbt_model
2022-01-05 17:21:15.118220 (Thread-2): 17:21:15  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.127341 (Thread-1): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.127477 (Thread-1): 17:21:15  Began executing node model.my_new_project.dim_customers
2022-01-05 17:21:15.132653 (Thread-2): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.132777 (Thread-2): 17:21:15  Began executing node model.my_new_project.my_first_dbt_model
2022-01-05 17:21:15.164712 (Thread-1): 17:21:15  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-05 17:21:15.175278 (Thread-2): 17:21:15  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.180254 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.180361 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:21:15.180437 (Thread-1): 17:21:15  Opening a new connection, currently in state closed
2022-01-05 17:21:15.180511 (Thread-1): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.188069 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.188170 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:21:15.188244 (Thread-2): 17:21:15  Opening a new connection, currently in state init
2022-01-05 17:21:15.188316 (Thread-2): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.198488 (Thread-65): handling poll request
2022-01-05 17:21:15.198873 (Thread-65): 17:21:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02cbb80>]}
2022-01-05 17:21:15.200311 (Thread-65): sending response (<Response 26535 bytes [200 OK]>) to 10.0.42.119
2022-01-05 17:21:15.453858 (Thread-2): 17:21:15  SQL status: BEGIN in 0.27 seconds
2022-01-05 17:21:15.454013 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.454094 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-05 17:21:15.454468 (Thread-1): 17:21:15  SQL status: BEGIN in 0.27 seconds
2022-01-05 17:21:15.454593 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.454666 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create view "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  ) ;

2022-01-05 17:21:15.466507 (Thread-1): 17:21:15  SQL status: CREATE VIEW in 0.01 seconds
2022-01-05 17:21:15.471982 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.472081 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-05 17:21:15.475492 (Thread-1): 17:21:15  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:21:15.482025 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:21:15.482129 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.482201 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:21:15.515913 (Thread-2): 17:21:15  SQL status: SELECT in 0.06 seconds
2022-01-05 17:21:15.517827 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.517918 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-05 17:21:15.520834 (Thread-2): 17:21:15  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:21:15.522576 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.522667 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-05 17:21:15.525960 (Thread-2): 17:21:15  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:21:15.530338 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:21:15.530433 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.530503 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:21:15.530730 (Thread-1): 17:21:15  SQL status: COMMIT in 0.05 seconds
2022-01-05 17:21:15.530940 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.531016 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:21:15.533666 (Thread-1): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.537485 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.537579 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop view if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-05 17:21:15.541588 (Thread-1): 17:21:15  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 17:21:15.542182 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:21:15.542271 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.542341 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:21:15.590726 (Thread-2): 17:21:15  SQL status: COMMIT in 0.06 seconds
2022-01-05 17:21:15.591076 (Thread-1): 17:21:15  SQL status: COMMIT in 0.05 seconds
2022-01-05 17:21:15.591194 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.591265 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:21:15.593510 (Thread-1): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.593931 (Thread-1): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.594058 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: ROLLBACK
2022-01-05 17:21:15.594268 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.594364 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:21:15.595971 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: Close
2022-01-05 17:21:15.596416 (Thread-1): 17:21:15  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16de0e09-5bb9-4497-9935-603c3bf9fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12743f73d0>]}
2022-01-05 17:21:15.596734 (Thread-1): 17:21:15  1 of 3 OK created view model dbt_nobodozie.dim_customers........................ [CREATE VIEW in 0.48s]
2022-01-05 17:21:15.596880 (Thread-1): 17:21:15  Finished running node model.my_new_project.dim_customers
2022-01-05 17:21:15.597173 (Thread-2): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.598412 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.598503 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-05 17:21:15.604548 (Thread-2): 17:21:15  SQL status: DROP TABLE in 0.01 seconds
2022-01-05 17:21:15.605187 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:21:15.605278 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.605348 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:21:15.637193 (Thread-2): 17:21:15  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:21:15.637298 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.637366 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:21:15.639689 (Thread-2): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.640075 (Thread-2): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.640205 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-05 17:21:15.642097 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: Close
2022-01-05 17:21:15.642485 (Thread-2): 17:21:15  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16de0e09-5bb9-4497-9935-603c3bf9fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1274341730>]}
2022-01-05 17:21:15.642768 (Thread-2): 17:21:15  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.53s]
2022-01-05 17:21:15.642869 (Thread-2): 17:21:15  Finished running node model.my_new_project.my_first_dbt_model
2022-01-05 17:21:15.643640 (Thread-4): 17:21:15  Began running node model.my_new_project.my_second_dbt_model
2022-01-05 17:21:15.643873 (Thread-4): 17:21:15  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-05 17:21:15.644118 (Thread-4): 17:21:15  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.644200 (Thread-4): 17:21:15  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-05 17:21:15.644282 (Thread-4): 17:21:15  Compiling model.my_new_project.my_second_dbt_model
2022-01-05 17:21:15.647097 (Thread-4): 17:21:15  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.661218 (Thread-4): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.661345 (Thread-4): 17:21:15  Began executing node model.my_new_project.my_second_dbt_model
2022-01-05 17:21:15.663136 (Thread-4): 17:21:15  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.677988 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.678094 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:21:15.678175 (Thread-4): 17:21:15  Opening a new connection, currently in state init
2022-01-05 17:21:15.678254 (Thread-4): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.700850 (Thread-4): 17:21:15  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:21:15.700959 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.701032 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-05 17:21:15.705749 (Thread-4): 17:21:15  SQL status: CREATE VIEW in 0.0 seconds
2022-01-05 17:21:15.707442 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.707535 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-05 17:21:15.709641 (Thread-4): 17:21:15  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:21:15.710585 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:21:15.710676 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.710745 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:21:15.740617 (Thread-4): 17:21:15  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:21:15.740830 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.741071 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:21:15.743080 (Thread-4): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.744153 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.744248 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-05 17:21:15.746149 (Thread-4): 17:21:15  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 17:21:15.746749 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:21:15.746839 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.746910 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:21:15.772685 (Thread-4): 17:21:15  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:21:15.772799 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.772870 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:21:15.774836 (Thread-4): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.775204 (Thread-4): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.775327 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-05 17:21:15.776977 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: Close
2022-01-05 17:21:15.777381 (Thread-4): 17:21:15  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16de0e09-5bb9-4497-9935-603c3bf9fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12742ad820>]}
2022-01-05 17:21:15.777728 (Thread-4): 17:21:15  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.13s]
2022-01-05 17:21:15.777840 (Thread-4): 17:21:15  Finished running node model.my_new_project.my_second_dbt_model
2022-01-05 17:21:15.779138 (MainThread): 17:21:15  Acquiring new redshift connection "master"
2022-01-05 17:21:15.779276 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.779351 (MainThread): 17:21:15  On master: BEGIN
2022-01-05 17:21:15.779426 (MainThread): 17:21:15  Opening a new connection, currently in state closed
2022-01-05 17:21:15.779503 (MainThread): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.804313 (MainThread): 17:21:15  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:21:15.804426 (MainThread): 17:21:15  On master: COMMIT
2022-01-05 17:21:15.804497 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.804564 (MainThread): 17:21:15  On master: COMMIT
2022-01-05 17:21:15.806395 (MainThread): 17:21:15  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:21:15.806500 (MainThread): 17:21:15  On master: Close
2022-01-05 17:21:15.806886 (MainThread): 17:21:15  
2022-01-05 17:21:15.807008 (MainThread): 17:21:15  Finished running 2 view models, 1 table model in 0.85s.
2022-01-05 17:21:15.807090 (MainThread): 17:21:15  Connection 'master' was properly closed.
2022-01-05 17:21:15.807155 (MainThread): 17:21:15  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-05 17:21:15.807215 (MainThread): 17:21:15  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-05 17:21:15.807272 (MainThread): 17:21:15  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-05 17:21:15.870751 (MainThread): 17:21:15  
2022-01-05 17:21:15.870896 (MainThread): 17:21:15  Completed successfully
2022-01-05 17:21:15.870988 (MainThread): 17:21:15  
2022-01-05 17:21:15.871070 (MainThread): 17:21:15  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-05 17:21:16.602203 (Thread-66): handling poll request
2022-01-05 17:21:16.602577 (Thread-66): 17:21:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02ebee0>]}
2022-01-05 17:21:16.604615 (Thread-66): sending response (<Response 59270 bytes [200 OK]>) to 10.0.17.156
2022-01-05 17:21:17.208435 (Thread-67): handling status request
2022-01-05 17:21:17.208840 (Thread-67): 17:21:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02730d0>]}
2022-01-05 17:21:17.209350 (Thread-67): sending response (<Response 1552 bytes [200 OK]>) to 10.0.19.216
2022-01-05 17:21:17.264120 (Thread-68): handling status request
2022-01-05 17:21:17.264387 (Thread-68): 17:21:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02734c0>]}
2022-01-05 17:21:17.264801 (Thread-68): sending response (<Response 1552 bytes [200 OK]>) to 10.0.30.3
2022-01-05 17:24:05.359963 (Thread-69): handling status request
2022-01-05 17:24:05.361452 (Thread-69): 17:24:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0273700>]}
2022-01-05 17:24:05.389785 (Thread-69): sending response (<Response 1552 bytes [200 OK]>) to 10.0.20.28
2022-01-05 17:24:05.727924 (Thread-70): handling run_sql request
2022-01-05 17:24:05.728282 (Thread-70): 17:24:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02739a0>]}
2022-01-05 17:24:07.785613 (Thread-70): sending response (<Response 138 bytes [200 OK]>) to 10.0.42.119
2022-01-05 17:24:07.811994 (MainThread): 17:24:07  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '61ff180e-508c-425b-a6f6-868e8f8d5663', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81257eb100>]}
2022-01-05 17:24:07.812516 (MainThread): 17:24:07  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:24:07.813063 (Thread-1): 17:24:07  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 17:24:07.813187 (Thread-1): 17:24:07  Began compiling node rpc.my_new_project.request
2022-01-05 17:24:07.813274 (Thread-1): 17:24:07  Compiling rpc.my_new_project.request
2022-01-05 17:24:07.814403 (Thread-1): 17:24:07  finished collecting timing info
2022-01-05 17:24:07.814527 (Thread-1): 17:24:07  Began executing node rpc.my_new_project.request
2022-01-05 17:24:07.814632 (Thread-1): 17:24:07  Using redshift connection "rpc.my_new_project.request"
2022-01-05 17:24:07.814709 (Thread-1): 17:24:07  On rpc.my_new_project.request: SELECT *
FROM dev.dbt_nobodozie.my_second_dbt_model
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 17:24:07.814782 (Thread-1): 17:24:07  Opening a new connection, currently in state init
2022-01-05 17:24:07.814862 (Thread-1): 17:24:07  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:24:07.981462 (Thread-1): 17:24:07  SQL status: SELECT in 0.17 seconds
2022-01-05 17:24:07.982469 (Thread-1): 17:24:07  finished collecting timing info
2022-01-05 17:24:07.982625 (Thread-1): 17:24:07  On rpc.my_new_project.request: Close
2022-01-05 17:24:08.233339 (Thread-71): handling poll request
2022-01-05 17:24:08.233787 (Thread-71): 17:24:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac027a250>]}
2022-01-05 17:24:08.234931 (Thread-71): sending response (<Response 7182 bytes [200 OK]>) to 10.0.42.85
2022-01-05 17:24:33.494206 (Thread-72): handling status request
2022-01-05 17:24:33.494587 (Thread-72): 17:24:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac027a700>]}
2022-01-05 17:24:33.495097 (Thread-72): sending response (<Response 1552 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:24:33.931156 (Thread-73): handling run_sql request
2022-01-05 17:24:33.931520 (Thread-73): 17:24:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac027ab50>]}
2022-01-05 17:24:35.973403 (Thread-73): sending response (<Response 138 bytes [200 OK]>) to 10.0.5.1
2022-01-05 17:24:35.996999 (MainThread): 17:24:35  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '81b316fc-66b7-49fb-9cc8-45d7869fba76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd8fd3b280>]}
2022-01-05 17:24:35.997535 (MainThread): 17:24:35  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:24:35.998112 (Thread-1): 17:24:35  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 17:24:35.998245 (Thread-1): 17:24:35  Began compiling node rpc.my_new_project.request
2022-01-05 17:24:35.998337 (Thread-1): 17:24:35  Compiling rpc.my_new_project.request
2022-01-05 17:24:35.999529 (Thread-1): 17:24:35  finished collecting timing info
2022-01-05 17:24:35.999658 (Thread-1): 17:24:35  Began executing node rpc.my_new_project.request
2022-01-05 17:24:35.999761 (Thread-1): 17:24:35  Using redshift connection "rpc.my_new_project.request"
2022-01-05 17:24:35.999841 (Thread-1): 17:24:35  On rpc.my_new_project.request: SELECT *
FROM dev.dbt_nobodozie.dim_customers
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 17:24:35.999928 (Thread-1): 17:24:35  Opening a new connection, currently in state init
2022-01-05 17:24:36.000017 (Thread-1): 17:24:35  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:24:36.061063 (Thread-1): 17:24:36  SQL status: SELECT in 0.06 seconds
2022-01-05 17:24:36.064123 (Thread-1): 17:24:36  finished collecting timing info
2022-01-05 17:24:36.064287 (Thread-1): 17:24:36  On rpc.my_new_project.request: Close
2022-01-05 17:24:36.397917 (Thread-74): handling poll request
2022-01-05 17:24:36.398401 (Thread-74): 17:24:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac031dd00>]}
2022-01-05 17:24:36.400027 (Thread-74): sending response (<Response 12318 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:26:20.628671 (Thread-75): handling status request
2022-01-05 17:26:20.630305 (Thread-75): 17:26:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0275f40>]}
2022-01-05 17:26:20.630809 (Thread-75): sending response (<Response 1552 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:26:20.970191 (Thread-76): handling run_sql request
2022-01-05 17:26:20.970562 (Thread-76): 17:26:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02754c0>]}
2022-01-05 17:26:23.079128 (Thread-76): sending response (<Response 138 bytes [200 OK]>) to 10.0.46.191
2022-01-05 17:26:23.106146 (MainThread): 17:26:23  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '005825a7-53c0-4d65-ae4a-e7e45b153d38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0da7e48610>]}
2022-01-05 17:26:23.106687 (MainThread): 17:26:23  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:26:23.107244 (Thread-1): 17:26:23  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 17:26:23.107373 (Thread-1): 17:26:23  Began compiling node rpc.my_new_project.request
2022-01-05 17:26:23.107463 (Thread-1): 17:26:23  Compiling rpc.my_new_project.request
2022-01-05 17:26:23.109528 (Thread-1): 17:26:23  finished collecting timing info
2022-01-05 17:26:23.109661 (Thread-1): 17:26:23  Began executing node rpc.my_new_project.request
2022-01-05 17:26:23.109759 (Thread-1): 17:26:23  Using redshift connection "rpc.my_new_project.request"
2022-01-05 17:26:23.109845 (Thread-1): 17:26:23  On rpc.my_new_project.request: 

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 17:26:23.109919 (Thread-1): 17:26:23  Opening a new connection, currently in state init
2022-01-05 17:26:23.109995 (Thread-1): 17:26:23  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:23.143521 (Thread-1): 17:26:23  SQL status: SELECT in 0.03 seconds
2022-01-05 17:26:23.146588 (Thread-1): 17:26:23  finished collecting timing info
2022-01-05 17:26:23.146736 (Thread-1): 17:26:23  On rpc.my_new_project.request: Close
2022-01-05 17:26:23.530944 (Thread-77): handling poll request
2022-01-05 17:26:23.531383 (Thread-77): 17:26:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02976a0>]}
2022-01-05 17:26:23.532941 (Thread-77): sending response (<Response 16918 bytes [200 OK]>) to 10.0.12.39
2022-01-05 17:26:29.593023 (Thread-78): 17:26:29  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-05 17:26:29.593451 (Thread-78): 17:26:29  Partial parsing: updated file: my_new_project://models/dim_customers.sql
2022-01-05 17:26:29.597400 (Thread-78): 17:26:29  1699: static parser successfully parsed dim_customers.sql
2022-01-05 17:26:29.641716 (Thread-78): 17:26:29  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01e9a60>]}
2022-01-05 17:26:30.116418 (Thread-79): handling status request
2022-01-05 17:26:30.116791 (Thread-79): 17:26:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01bd760>]}
2022-01-05 17:26:30.117299 (Thread-79): sending response (<Response 1552 bytes [200 OK]>) to 10.0.6.188
2022-01-05 17:26:30.153082 (Thread-80): handling status request
2022-01-05 17:26:30.153389 (Thread-80): 17:26:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01bd4f0>]}
2022-01-05 17:26:30.153866 (Thread-80): sending response (<Response 1552 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:26:31.142331 (Thread-81): handling status request
2022-01-05 17:26:31.142705 (Thread-81): 17:26:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01bd280>]}
2022-01-05 17:26:31.143178 (Thread-81): sending response (<Response 1552 bytes [200 OK]>) to 10.0.9.25
2022-01-05 17:26:31.294467 (Thread-82): handling status request
2022-01-05 17:26:31.294852 (Thread-82): 17:26:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01bd070>]}
2022-01-05 17:26:31.295341 (Thread-82): sending response (<Response 1552 bytes [200 OK]>) to 10.0.19.216
2022-01-05 17:26:31.473115 (Thread-83): handling cli_args request
2022-01-05 17:26:31.473536 (Thread-83): 17:26:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0275100>]}
2022-01-05 17:26:33.515373 (Thread-83): sending response (<Response 138 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:26:33.592844 (MainThread): 17:26:33  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 17:26:33.593259 (MainThread): 17:26:33  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 17:26:33.598950 (MainThread): 17:26:33  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7559c76e-442f-4452-bf2d-d52ec843e089', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9cfe84fa0>]}
2022-01-05 17:26:33.633174 (MainThread): 17:26:33  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7559c76e-442f-4452-bf2d-d52ec843e089', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9cfef3fd0>]}
2022-01-05 17:26:33.633462 (MainThread): 17:26:33  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:26:33.634555 (MainThread): 17:26:33  
2022-01-05 17:26:33.634847 (MainThread): 17:26:33  Acquiring new redshift connection "master"
2022-01-05 17:26:33.635761 (ThreadPoolExecutor-0_0): 17:26:33  Acquiring new redshift connection "list_dev"
2022-01-05 17:26:33.645827 (ThreadPoolExecutor-0_0): 17:26:33  Using redshift connection "list_dev"
2022-01-05 17:26:33.645934 (ThreadPoolExecutor-0_0): 17:26:33  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-05 17:26:33.646017 (ThreadPoolExecutor-0_0): 17:26:33  Opening a new connection, currently in state init
2022-01-05 17:26:33.646097 (ThreadPoolExecutor-0_0): 17:26:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:33.667123 (ThreadPoolExecutor-0_0): 17:26:33  SQL status: SELECT in 0.02 seconds
2022-01-05 17:26:33.668166 (ThreadPoolExecutor-0_0): 17:26:33  On list_dev: Close
2022-01-05 17:26:33.669383 (ThreadPoolExecutor-1_0): 17:26:33  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:26:33.675534 (ThreadPoolExecutor-1_0): 17:26:33  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:26:33.675633 (ThreadPoolExecutor-1_0): 17:26:33  On list_dev_dbt_nobodozie: BEGIN
2022-01-05 17:26:33.675711 (ThreadPoolExecutor-1_0): 17:26:33  Opening a new connection, currently in state closed
2022-01-05 17:26:33.675786 (ThreadPoolExecutor-1_0): 17:26:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:33.699517 (ThreadPoolExecutor-1_0): 17:26:33  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:33.699635 (ThreadPoolExecutor-1_0): 17:26:33  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:26:33.699713 (ThreadPoolExecutor-1_0): 17:26:33  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-05 17:26:33.710913 (ThreadPoolExecutor-1_0): 17:26:33  SQL status: SELECT in 0.01 seconds
2022-01-05 17:26:33.711973 (ThreadPoolExecutor-1_0): 17:26:33  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-05 17:26:33.713848 (ThreadPoolExecutor-1_0): 17:26:33  On list_dev_dbt_nobodozie: Close
2022-01-05 17:26:33.718202 (MainThread): 17:26:33  Using redshift connection "master"
2022-01-05 17:26:33.718314 (MainThread): 17:26:33  On master: BEGIN
2022-01-05 17:26:33.718395 (MainThread): 17:26:33  Opening a new connection, currently in state init
2022-01-05 17:26:33.718472 (MainThread): 17:26:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:33.742645 (MainThread): 17:26:33  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:33.742760 (MainThread): 17:26:33  Using redshift connection "master"
2022-01-05 17:26:33.742838 (MainThread): 17:26:33  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-05 17:26:33.771943 (MainThread): 17:26:33  SQL status: SELECT in 0.03 seconds
2022-01-05 17:26:33.773031 (MainThread): 17:26:33  On master: ROLLBACK
2022-01-05 17:26:33.774950 (MainThread): 17:26:33  Using redshift connection "master"
2022-01-05 17:26:33.775047 (MainThread): 17:26:33  On master: BEGIN
2022-01-05 17:26:33.778761 (MainThread): 17:26:33  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:33.778866 (MainThread): 17:26:33  On master: COMMIT
2022-01-05 17:26:33.778938 (MainThread): 17:26:33  Using redshift connection "master"
2022-01-05 17:26:33.779007 (MainThread): 17:26:33  On master: COMMIT
2022-01-05 17:26:33.780800 (MainThread): 17:26:33  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:26:33.780906 (MainThread): 17:26:33  On master: Close
2022-01-05 17:26:33.781331 (MainThread): 17:26:33  Concurrency: 4 threads (target='default')
2022-01-05 17:26:33.781468 (MainThread): 17:26:33  
2022-01-05 17:26:33.783834 (Thread-1): 17:26:33  Began running node model.my_new_project.dim_customers
2022-01-05 17:26:33.784105 (Thread-1): 17:26:33  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-05 17:26:33.784355 (Thread-1): 17:26:33  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:33.784449 (Thread-1): 17:26:33  Began compiling node model.my_new_project.dim_customers
2022-01-05 17:26:33.784536 (Thread-1): 17:26:33  Compiling model.my_new_project.dim_customers
2022-01-05 17:26:33.786746 (Thread-1): 17:26:33  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-05 17:26:33.786971 (Thread-2): 17:26:33  Began running node model.my_new_project.my_first_dbt_model
2022-01-05 17:26:33.787198 (Thread-2): 17:26:33  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-05 17:26:33.787442 (Thread-2): 17:26:33  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.787525 (Thread-2): 17:26:33  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-05 17:26:33.787603 (Thread-2): 17:26:33  Compiling model.my_new_project.my_first_dbt_model
2022-01-05 17:26:33.789730 (Thread-2): 17:26:33  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.804175 (Thread-2): 17:26:33  finished collecting timing info
2022-01-05 17:26:33.804315 (Thread-2): 17:26:33  Began executing node model.my_new_project.my_first_dbt_model
2022-01-05 17:26:33.809433 (Thread-1): 17:26:33  finished collecting timing info
2022-01-05 17:26:33.809579 (Thread-1): 17:26:33  Began executing node model.my_new_project.dim_customers
2022-01-05 17:26:33.858912 (Thread-1): 17:26:33  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-05 17:26:33.860586 (Thread-2): 17:26:33  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.874136 (Thread-1): 17:26:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:33.874250 (Thread-1): 17:26:33  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:26:33.874334 (Thread-1): 17:26:33  Opening a new connection, currently in state closed
2022-01-05 17:26:33.874415 (Thread-1): 17:26:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:33.874730 (Thread-2): 17:26:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.874829 (Thread-2): 17:26:33  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:26:33.874911 (Thread-2): 17:26:33  Opening a new connection, currently in state init
2022-01-05 17:26:33.874988 (Thread-2): 17:26:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:33.898822 (Thread-1): 17:26:33  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:33.898943 (Thread-1): 17:26:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:33.899024 (Thread-1): 17:26:33  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-05 17:26:33.899718 (Thread-2): 17:26:33  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:33.899834 (Thread-2): 17:26:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.899921 (Thread-2): 17:26:33  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-05 17:26:33.958504 (Thread-84): handling poll request
2022-01-05 17:26:33.958937 (Thread-84): 17:26:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01e7a60>]}
2022-01-05 17:26:33.960390 (Thread-84): sending response (<Response 30570 bytes [200 OK]>) to 10.0.42.85
2022-01-05 17:26:33.987004 (Thread-2): 17:26:33  SQL status: SELECT in 0.09 seconds
2022-01-05 17:26:33.992960 (Thread-2): 17:26:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.993077 (Thread-2): 17:26:33  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-05 17:26:33.997300 (Thread-2): 17:26:33  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:26:33.999115 (Thread-2): 17:26:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.999212 (Thread-2): 17:26:33  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-05 17:26:34.002063 (Thread-2): 17:26:34  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:26:34.012080 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:26:34.012179 (Thread-2): 17:26:34  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:34.012251 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:26:34.064143 (Thread-2): 17:26:34  SQL status: COMMIT in 0.05 seconds
2022-01-05 17:26:34.064368 (Thread-2): 17:26:34  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:34.064449 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:26:34.067215 (Thread-2): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.071247 (Thread-2): 17:26:34  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:34.071342 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-05 17:26:34.076423 (Thread-2): 17:26:34  SQL status: DROP TABLE in 0.0 seconds
2022-01-05 17:26:34.077048 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:26:34.077139 (Thread-2): 17:26:34  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:34.077211 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:26:34.114712 (Thread-2): 17:26:34  SQL status: COMMIT in 0.04 seconds
2022-01-05 17:26:34.114823 (Thread-2): 17:26:34  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:34.114896 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:26:34.119364 (Thread-2): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.119803 (Thread-2): 17:26:34  finished collecting timing info
2022-01-05 17:26:34.119945 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-05 17:26:34.122629 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: Close
2022-01-05 17:26:34.123105 (Thread-2): 17:26:34  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7559c76e-442f-4452-bf2d-d52ec843e089', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9cf6412b0>]}
2022-01-05 17:26:34.123434 (Thread-2): 17:26:34  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.34s]
2022-01-05 17:26:34.123548 (Thread-2): 17:26:34  Finished running node model.my_new_project.my_first_dbt_model
2022-01-05 17:26:34.124103 (Thread-4): 17:26:34  Began running node model.my_new_project.my_second_dbt_model
2022-01-05 17:26:34.124340 (Thread-4): 17:26:34  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-05 17:26:34.124590 (Thread-4): 17:26:34  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.124678 (Thread-4): 17:26:34  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-05 17:26:34.124762 (Thread-4): 17:26:34  Compiling model.my_new_project.my_second_dbt_model
2022-01-05 17:26:34.127770 (Thread-4): 17:26:34  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.141733 (Thread-4): 17:26:34  finished collecting timing info
2022-01-05 17:26:34.141867 (Thread-4): 17:26:34  Began executing node model.my_new_project.my_second_dbt_model
2022-01-05 17:26:34.157163 (Thread-4): 17:26:34  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.174705 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.174813 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:26:34.174895 (Thread-4): 17:26:34  Opening a new connection, currently in state init
2022-01-05 17:26:34.174976 (Thread-4): 17:26:34  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:34.199508 (Thread-4): 17:26:34  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:34.199623 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.199701 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-05 17:26:34.206621 (Thread-4): 17:26:34  SQL status: CREATE VIEW in 0.01 seconds
2022-01-05 17:26:34.208961 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.209057 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-05 17:26:34.212263 (Thread-4): 17:26:34  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:26:34.213221 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:26:34.213314 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.213385 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:26:34.256152 (Thread-4): 17:26:34  SQL status: COMMIT in 0.04 seconds
2022-01-05 17:26:34.256383 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.256464 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:26:34.259599 (Thread-4): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.260936 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.261028 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-05 17:26:34.263961 (Thread-4): 17:26:34  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 17:26:34.264590 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:26:34.264678 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.264750 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:26:34.301626 (Thread-4): 17:26:34  SQL status: COMMIT in 0.04 seconds
2022-01-05 17:26:34.301747 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.301823 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:26:34.304859 (Thread-4): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.305280 (Thread-4): 17:26:34  finished collecting timing info
2022-01-05 17:26:34.305440 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-05 17:26:34.307905 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: Close
2022-01-05 17:26:34.308362 (Thread-4): 17:26:34  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7559c76e-442f-4452-bf2d-d52ec843e089', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9cf65e4c0>]}
2022-01-05 17:26:34.308723 (Thread-4): 17:26:34  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.18s]
2022-01-05 17:26:34.308838 (Thread-4): 17:26:34  Finished running node model.my_new_project.my_second_dbt_model
2022-01-05 17:26:34.719046 (Thread-1): 17:26:34  SQL status: SELECT in 0.82 seconds
2022-01-05 17:26:34.721364 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.721530 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-05 17:26:34.724371 (Thread-1): 17:26:34  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:26:34.726361 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.726459 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-05 17:26:34.728985 (Thread-1): 17:26:34  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:26:34.730173 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:26:34.730268 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.730338 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:26:34.779927 (Thread-1): 17:26:34  SQL status: COMMIT in 0.05 seconds
2022-01-05 17:26:34.780171 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.780253 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:26:34.782426 (Thread-1): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.783733 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.783827 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop view if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-05 17:26:34.788113 (Thread-1): 17:26:34  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 17:26:34.788839 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:26:34.788932 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.789006 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:26:34.823722 (Thread-1): 17:26:34  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:26:34.823850 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.823925 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:26:34.826064 (Thread-1): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.826516 (Thread-1): 17:26:34  finished collecting timing info
2022-01-05 17:26:34.826649 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: ROLLBACK
2022-01-05 17:26:34.828564 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: Close
2022-01-05 17:26:34.829147 (Thread-1): 17:26:34  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7559c76e-442f-4452-bf2d-d52ec843e089', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9cf65e070>]}
2022-01-05 17:26:34.829535 (Thread-1): 17:26:34  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 1.04s]
2022-01-05 17:26:34.829654 (Thread-1): 17:26:34  Finished running node model.my_new_project.dim_customers
2022-01-05 17:26:34.831057 (MainThread): 17:26:34  Acquiring new redshift connection "master"
2022-01-05 17:26:34.831201 (MainThread): 17:26:34  Using redshift connection "master"
2022-01-05 17:26:34.831276 (MainThread): 17:26:34  On master: BEGIN
2022-01-05 17:26:34.831352 (MainThread): 17:26:34  Opening a new connection, currently in state closed
2022-01-05 17:26:34.831432 (MainThread): 17:26:34  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:34.856096 (MainThread): 17:26:34  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:34.856216 (MainThread): 17:26:34  On master: COMMIT
2022-01-05 17:26:34.856290 (MainThread): 17:26:34  Using redshift connection "master"
2022-01-05 17:26:34.856359 (MainThread): 17:26:34  On master: COMMIT
2022-01-05 17:26:34.858098 (MainThread): 17:26:34  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:26:34.858206 (MainThread): 17:26:34  On master: Close
2022-01-05 17:26:34.858663 (MainThread): 17:26:34  
2022-01-05 17:26:34.858777 (MainThread): 17:26:34  Finished running 2 table models, 1 view model in 1.22s.
2022-01-05 17:26:34.858858 (MainThread): 17:26:34  Connection 'master' was properly closed.
2022-01-05 17:26:34.858924 (MainThread): 17:26:34  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-05 17:26:34.858985 (MainThread): 17:26:34  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-05 17:26:34.859046 (MainThread): 17:26:34  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-05 17:26:34.929737 (MainThread): 17:26:34  
2022-01-05 17:26:34.929944 (MainThread): 17:26:34  Completed successfully
2022-01-05 17:26:34.930039 (MainThread): 17:26:34  
2022-01-05 17:26:34.930123 (MainThread): 17:26:34  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-05 17:26:35.380716 (Thread-85): handling poll request
2022-01-05 17:26:35.381089 (Thread-85): 17:26:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02479d0>]}
2022-01-05 17:26:35.383114 (Thread-85): sending response (<Response 56622 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:26:36.089452 (Thread-86): handling status request
2022-01-05 17:26:36.089823 (Thread-86): 17:26:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0247220>]}
2022-01-05 17:26:36.090327 (Thread-86): sending response (<Response 1552 bytes [200 OK]>) to 10.0.46.191
2022-01-05 17:26:36.245259 (Thread-87): handling status request
2022-01-05 17:26:36.245677 (Thread-87): 17:26:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01bda30>]}
2022-01-05 17:26:36.246143 (Thread-87): sending response (<Response 1552 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:37:36.466305 (Thread-88): handling status request
2022-01-05 17:37:36.467732 (Thread-88): 17:37:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01e8340>]}
2022-01-05 17:37:36.468223 (Thread-88): sending response (<Response 1552 bytes [200 OK]>) to 10.0.30.3
2022-01-05 17:37:39.169785 (Thread-89): 17:37:39  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 17:37:39.170001 (Thread-89): 17:37:39  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 17:37:39.175096 (Thread-89): 17:37:39  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0111730>]}
2022-01-05 17:37:39.713062 (Thread-90): handling status request
2022-01-05 17:37:39.713507 (Thread-90): 17:37:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0247220>]}
2022-01-05 17:37:39.714030 (Thread-90): sending response (<Response 1241 bytes [200 OK]>) to 10.0.46.191
2022-01-05 17:37:39.720706 (Thread-91): handling status request
2022-01-05 17:37:39.721034 (Thread-91): 17:37:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01cbee0>]}
2022-01-05 17:37:39.721533 (Thread-91): sending response (<Response 1241 bytes [200 OK]>) to 10.0.12.39
2022-01-05 18:27:44.299651 (Thread-92): handling status request
2022-01-05 18:27:44.300025 (Thread-92): 18:27:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01e8a30>]}
2022-01-05 18:27:44.300487 (Thread-92): sending response (<Response 1241 bytes [200 OK]>) to 10.0.9.25
2022-01-05 18:27:44.314525 (Thread-93): handling status request
2022-01-05 18:27:44.314788 (Thread-93): 18:27:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01e8b20>]}
2022-01-05 18:27:44.315150 (Thread-93): sending response (<Response 1241 bytes [200 OK]>) to 10.0.18.253
2022-01-05 18:27:44.343297 (Thread-94): handling ps request
2022-01-05 18:27:44.343558 (Thread-94): 18:27:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01e8760>]}
2022-01-05 18:27:44.344343 (Thread-94): sending response (<Response 6873 bytes [200 OK]>) to 10.0.5.1
2022-01-05 18:27:44.365562 (Thread-95): handling status request
2022-01-05 18:27:44.365825 (Thread-95): 18:27:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0111b20>]}
2022-01-05 18:27:44.366188 (Thread-95): sending response (<Response 1241 bytes [200 OK]>) to 10.0.30.3
2022-01-05 18:27:44.950490 (Thread-96): handling poll request
2022-01-05 18:27:44.950850 (Thread-96): 18:27:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0111e20>]}
2022-01-05 18:27:44.953665 (Thread-96): sending response (<Response 86908 bytes [200 OK]>) to 10.0.46.191
2022-01-05 18:27:45.250026 (Thread-97): handling status request
2022-01-05 18:27:45.250816 (Thread-98): handling status request
2022-01-05 18:27:45.256565 (Thread-97): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02a6040>]}
2022-01-05 18:27:45.257084 (Thread-97): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:27:45.257303 (Thread-98): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0111f40>]}
2022-01-05 18:27:45.262654 (Thread-99): handling status request
2022-01-05 18:27:45.264728 (Thread-98): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:27:45.265124 (Thread-99): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0111fd0>]}
2022-01-05 18:27:45.271398 (Thread-100): handling list request
2022-01-05 18:27:45.273619 (Thread-101): handling list request
2022-01-05 18:27:45.273918 (Thread-100): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01c6100>]}
2022-01-05 18:27:45.282047 (Thread-101): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0113a60>]}
2022-01-05 18:27:45.291580 (Thread-99): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:27:45.336806 (Thread-102): sending response (<Response 214 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:27:45.645595 (Thread-103): handling status request
2022-01-05 18:27:45.645969 (Thread-103): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0113280>]}
2022-01-05 18:27:45.646442 (Thread-103): sending response (<Response 1241 bytes [200 OK]>) to 10.0.38.111
2022-01-05 18:27:45.692059 (Thread-104): handling status request
2022-01-05 18:27:45.692458 (Thread-104): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0113310>]}
2022-01-05 18:27:45.692946 (Thread-104): sending response (<Response 1241 bytes [200 OK]>) to 10.0.5.1
2022-01-05 18:27:45.739117 (Thread-105): handling status request
2022-01-05 18:27:45.739421 (Thread-105): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0122880>]}
2022-01-05 18:27:45.739856 (Thread-105): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:27:45.746041 (Thread-106): handling list request
2022-01-05 18:27:45.746290 (Thread-106): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01228b0>]}
2022-01-05 18:27:45.779461 (Thread-106): 18:27:45  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac00be700>]}
2022-01-05 18:27:45.779755 (Thread-106): 18:27:45  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 18:27:45.782118 (Thread-106): sending response (<Response 1686 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:52:02.003069 (Thread-107): handling status request
2022-01-05 18:52:02.004380 (Thread-107): 18:52:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01cbb20>]}
2022-01-05 18:52:02.004839 (Thread-107): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:52:02.010570 (Thread-108): handling list request
2022-01-05 18:52:02.010821 (Thread-108): 18:52:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01cb670>]}
2022-01-05 18:52:02.045093 (Thread-108): 18:52:02  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac00c6700>]}
2022-01-05 18:52:02.045390 (Thread-108): 18:52:02  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 18:52:02.051369 (Thread-108): sending response (<Response 1686 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:54:16.274809 (Thread-109): handling status request
2022-01-05 18:54:16.277206 (Thread-109): 18:54:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac00cb550>]}
2022-01-05 18:54:16.277696 (Thread-109): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:54:16.287710 (Thread-110): handling list request
2022-01-05 18:54:16.287947 (Thread-110): 18:54:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac00cb7c0>]}
2022-01-05 18:54:16.322182 (Thread-110): 18:54:16  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01134c0>]}
2022-01-05 18:54:16.322448 (Thread-110): 18:54:16  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 18:54:16.327571 (Thread-110): sending response (<Response 1686 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:55:34.190676 (Thread-111): handling status request
2022-01-05 18:55:34.192867 (Thread-111): 18:55:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0122eb0>]}
2022-01-05 18:55:34.193330 (Thread-111): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:55:34.199351 (Thread-112): handling list request
2022-01-05 18:55:34.199598 (Thread-112): 18:55:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac00bec70>]}
2022-01-05 18:55:34.229619 (Thread-112): 18:55:34  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac00d4970>]}
2022-01-05 18:55:34.229912 (Thread-112): 18:55:34  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 18:55:34.236528 (Thread-112): sending response (<Response 1686 bytes [200 OK]>) to 10.0.18.120
2022-01-06 14:08:10.690361 (MainThread): Running with dbt=1.0.1
2022-01-06 14:08:10.786543 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-06 14:08:10.792998 (MainThread): Tracking: tracking
2022-01-06 14:08:10.813238 (MainThread): 14:08:10  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effcca05b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb87434f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb87ea280>]}
2022-01-06 14:08:10.813622 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-06 14:08:10.813933 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-06 14:08:10.814144 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-06 14:08:10.861567 (Thread-12): 14:08:10  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:08:10.861795 (Thread-12): 14:08:10  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:08:10.867837 (Thread-12): 14:08:10  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86dc6d0>]}
2022-01-06 14:08:13.262573 (Thread-13): handling status request
2022-01-06 14:08:13.262957 (Thread-13): 14:08:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb87aa5e0>]}
2022-01-06 14:08:13.263522 (Thread-13): sending response (<Response 1241 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:08:13.284330 (Thread-14): handling status request
2022-01-06 14:08:13.284592 (Thread-14): 14:08:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb87aa2b0>]}
2022-01-06 14:08:13.284956 (Thread-14): sending response (<Response 1241 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:08:13.301138 (Thread-15): handling ps request
2022-01-06 14:08:13.301417 (Thread-15): 14:08:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86c9fd0>]}
2022-01-06 14:08:13.301768 (Thread-15): sending response (<Response 105 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:08:13.326480 (Thread-16): handling status request
2022-01-06 14:08:13.326723 (Thread-16): 14:08:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86c9eb0>]}
2022-01-06 14:08:13.327057 (Thread-16): sending response (<Response 1241 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:08:15.543591 (Thread-17): handling status request
2022-01-06 14:08:15.543977 (Thread-17): 14:08:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86c9a00>]}
2022-01-06 14:08:15.544445 (Thread-17): sending response (<Response 1219 bytes [200 OK]>) to 10.0.7.144
2022-01-06 14:08:15.548326 (Thread-18): handling status request
2022-01-06 14:08:15.548575 (Thread-18): 14:08:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86c9880>]}
2022-01-06 14:08:15.548926 (Thread-18): sending response (<Response 1219 bytes [200 OK]>) to 10.0.7.144
2022-01-06 14:08:15.549815 (Thread-19): handling list request
2022-01-06 14:08:15.550162 (Thread-19): 14:08:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb87eab80>]}
2022-01-06 14:08:15.590223 (Thread-22): sending response (<Response 214 bytes [200 OK]>) to 10.0.7.144
2022-01-06 14:08:16.812792 (Thread-23): handling status request
2022-01-06 14:08:16.813182 (Thread-23): 14:08:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86c9610>]}
2022-01-06 14:08:16.813686 (Thread-23): sending response (<Response 1219 bytes [200 OK]>) to 10.0.7.144
2022-01-06 14:08:16.819085 (Thread-24): handling list request
2022-01-06 14:08:16.819347 (Thread-24): 14:08:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86c9430>]}
2022-01-06 14:08:16.844556 (Thread-24): 14:08:16  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86a7df0>]}
2022-01-06 14:08:16.844819 (Thread-24): 14:08:16  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:08:16.847644 (Thread-24): sending response (<Response 1682 bytes [200 OK]>) to 10.0.7.144
2022-01-06 14:08:20.139460 (Thread-25): handling status request
2022-01-06 14:08:20.139840 (Thread-25): 14:08:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8633520>]}
2022-01-06 14:08:20.140327 (Thread-25): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:08:20.588708 (Thread-26): handling run_sql request
2022-01-06 14:08:20.589119 (Thread-26): 14:08:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8633eb0>]}
2022-01-06 14:08:22.654390 (Thread-26): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:08:22.678937 (MainThread): 14:08:22  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '73aa9c02-b013-4f21-a5a9-b5d486d8dbc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f5ae13a60>]}
2022-01-06 14:08:22.679505 (MainThread): 14:08:22  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:08:22.680091 (Thread-1): 14:08:22  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:08:22.680220 (Thread-1): 14:08:22  Began compiling node rpc.my_new_project.request
2022-01-06 14:08:22.680309 (Thread-1): 14:08:22  Compiling rpc.my_new_project.request
2022-01-06 14:08:22.682362 (Thread-1): 14:08:22  finished collecting timing info
2022-01-06 14:08:22.682493 (Thread-1): 14:08:22  Began executing node rpc.my_new_project.request
2022-01-06 14:08:22.682592 (Thread-1): 14:08:22  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:08:22.682667 (Thread-1): 14:08:22  On rpc.my_new_project.request: 

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:08:22.682744 (Thread-1): 14:08:22  Opening a new connection, currently in state init
2022-01-06 14:08:22.682820 (Thread-1): 14:08:22  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:08:22.706450 (Thread-1): 14:08:22  SQL status: SELECT in 0.02 seconds
2022-01-06 14:08:22.709782 (Thread-1): 14:08:22  finished collecting timing info
2022-01-06 14:08:22.709945 (Thread-1): 14:08:22  On rpc.my_new_project.request: Close
2022-01-06 14:08:23.081492 (Thread-27): handling poll request
2022-01-06 14:08:23.081943 (Thread-27): 14:08:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86a7fd0>]}
2022-01-06 14:08:23.083620 (Thread-27): sending response (<Response 16920 bytes [200 OK]>) to 10.0.21.176
2022-01-06 14:08:36.923297 (Thread-28): handling status request
2022-01-06 14:08:36.924825 (Thread-28): 14:08:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86a7d30>]}
2022-01-06 14:08:36.925345 (Thread-28): sending response (<Response 1241 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:08:37.131938 (Thread-29): handling status request
2022-01-06 14:08:37.132283 (Thread-29): 14:08:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8644c70>]}
2022-01-06 14:08:37.132724 (Thread-29): sending response (<Response 1241 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:08:37.239015 (Thread-30): handling docs.generate request
2022-01-06 14:08:37.239289 (Thread-30): 14:08:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8644eb0>]}
2022-01-06 14:08:39.309620 (Thread-30): sending response (<Response 138 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:08:39.337874 (MainThread): 14:08:39  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9ada3381-031b-4a9a-aad2-e7db08da0a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0302449d90>]}
2022-01-06 14:08:39.338162 (MainThread): 14:08:39  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:08:39.339360 (MainThread): 14:08:39  
2022-01-06 14:08:39.339512 (MainThread): 14:08:39  Acquiring new redshift connection "master"
2022-01-06 14:08:39.340196 (ThreadPoolExecutor-0_0): 14:08:39  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:08:39.353267 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/catalog.sql
2022-01-06 14:08:39.366855 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters.sql
2022-01-06 14:08:39.394551 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/relations.sql
2022-01-06 14:08:39.395266 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 14:08:39.396210 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/catalog.sql
2022-01-06 14:08:39.398452 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters.sql
2022-01-06 14:08:39.419268 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/relations.sql
2022-01-06 14:08:39.420655 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 14:08:39.423555 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-06 14:08:39.425134 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-06 14:08:39.426785 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-06 14:08:39.429419 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-06 14:08:39.430851 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/generic_test_sql/not_null.sql
2022-01-06 14:08:39.431529 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/generic_test_sql/relationships.sql
2022-01-06 14:08:39.432506 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/generic_test_sql/unique.sql
2022-01-06 14:08:39.433363 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/configs.sql
2022-01-06 14:08:39.435693 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/hooks.sql
2022-01-06 14:08:39.439506 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/snapshots/strategies.sql
2022-01-06 14:08:39.456099 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-06 14:08:39.457855 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-06 14:08:39.468799 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/snapshots/helpers.sql
2022-01-06 14:08:39.479420 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/seeds/seed.sql
2022-01-06 14:08:39.485264 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/seeds/helpers.sql
2022-01-06 14:08:39.500742 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-06 14:08:39.503127 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/view/view.sql
2022-01-06 14:08:39.510103 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-06 14:08:39.512774 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/view/helpers.sql
2022-01-06 14:08:39.514204 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/table/table.sql
2022-01-06 14:08:39.521349 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-06 14:08:39.524259 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/incremental/merge.sql
2022-01-06 14:08:39.535196 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-06 14:08:39.550080 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-06 14:08:39.554486 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-06 14:08:39.564258 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-06 14:08:39.565849 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/tests/test.sql
2022-01-06 14:08:39.570187 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/tests/where_subquery.sql
2022-01-06 14:08:39.572034 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/tests/helpers.sql
2022-01-06 14:08:39.573875 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/etc/statement.sql
2022-01-06 14:08:39.578201 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/etc/datetime.sql
2022-01-06 14:08:39.586275 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters/indexes.sql
2022-01-06 14:08:39.588999 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters/persist_docs.sql
2022-01-06 14:08:39.593471 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters/freshness.sql
2022-01-06 14:08:39.596389 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters/relation.sql
2022-01-06 14:08:39.605641 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters/metadata.sql
2022-01-06 14:08:39.612619 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters/columns.sql
2022-01-06 14:08:39.622240 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters/schema.sql
2022-01-06 14:08:39.634244 (ThreadPoolExecutor-0_0): 14:08:39  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:08:39.634362 (ThreadPoolExecutor-0_0): 14:08:39  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:08:39.634448 (ThreadPoolExecutor-0_0): 14:08:39  Opening a new connection, currently in state init
2022-01-06 14:08:39.634529 (ThreadPoolExecutor-0_0): 14:08:39  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:08:39.653795 (ThreadPoolExecutor-0_0): 14:08:39  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:08:39.653902 (ThreadPoolExecutor-0_0): 14:08:39  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:08:39.653974 (ThreadPoolExecutor-0_0): 14:08:39  On list_dev_dbt_nobodozie: select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:08:39.665091 (ThreadPoolExecutor-0_0): 14:08:39  SQL status: SELECT in 0.01 seconds
2022-01-06 14:08:39.666172 (ThreadPoolExecutor-0_0): 14:08:39  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:08:39.668073 (ThreadPoolExecutor-0_0): 14:08:39  On list_dev_dbt_nobodozie: Close
2022-01-06 14:08:39.673542 (MainThread): 14:08:39  Using redshift connection "master"
2022-01-06 14:08:39.673700 (MainThread): 14:08:39  On master: BEGIN
2022-01-06 14:08:39.673824 (MainThread): 14:08:39  Opening a new connection, currently in state init
2022-01-06 14:08:39.673944 (MainThread): 14:08:39  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:08:39.696735 (MainThread): 14:08:39  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:08:39.696889 (MainThread): 14:08:39  Using redshift connection "master"
2022-01-06 14:08:39.697006 (MainThread): 14:08:39  On master: with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:08:39.720595 (Thread-31): handling poll request
2022-01-06 14:08:39.720943 (Thread-31): 14:08:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8668070>]}
2022-01-06 14:08:39.722229 (Thread-31): sending response (<Response 23421 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:08:39.726020 (MainThread): 14:08:39  SQL status: SELECT in 0.03 seconds
2022-01-06 14:08:39.727648 (MainThread): 14:08:39  On master: ROLLBACK
2022-01-06 14:08:39.729594 (MainThread): 14:08:39  On master: Close
2022-01-06 14:08:39.730001 (MainThread): 14:08:39  Concurrency: 4 threads (target='default')
2022-01-06 14:08:39.730176 (MainThread): 14:08:39  
2022-01-06 14:08:39.733031 (Thread-1): 14:08:39  Began running node model.my_new_project.dim_customers
2022-01-06 14:08:39.733198 (Thread-1): 14:08:39  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:08:39.733332 (Thread-1): 14:08:39  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:08:39.733429 (Thread-1): 14:08:39  Compiling model.my_new_project.dim_customers
2022-01-06 14:08:39.735518 (Thread-1): 14:08:39  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:08:39.735745 (Thread-2): 14:08:39  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:08:39.735921 (Thread-2): 14:08:39  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:08:39.736001 (Thread-2): 14:08:39  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:08:39.736078 (Thread-2): 14:08:39  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:08:39.738718 (Thread-2): 14:08:39  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:08:39.751721 (Thread-2): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.751862 (Thread-2): 14:08:39  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:08:39.751962 (Thread-2): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.752104 (Thread-2): 14:08:39  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:08:39.752282 (Thread-1): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.752413 (Thread-1): 14:08:39  Began executing node model.my_new_project.dim_customers
2022-01-06 14:08:39.752503 (Thread-1): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.752634 (Thread-1): 14:08:39  Finished running node model.my_new_project.dim_customers
2022-01-06 14:08:39.753525 (Thread-4): 14:08:39  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:08:39.753687 (Thread-4): 14:08:39  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:08:39.753768 (Thread-4): 14:08:39  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:08:39.753843 (Thread-4): 14:08:39  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:08:39.755773 (Thread-4): 14:08:39  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:08:39.756042 (Thread-3): 14:08:39  Began running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 14:08:39.756371 (Thread-3): 14:08:39  Acquiring new redshift connection "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-06 14:08:39.756462 (Thread-3): 14:08:39  Began compiling node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 14:08:39.756536 (Thread-3): 14:08:39  Compiling test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 14:08:39.761160 (Thread-2): 14:08:39  Began running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 14:08:39.761380 (Thread-2): 14:08:39  Acquiring new redshift connection "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-06 14:08:39.761496 (Thread-2): 14:08:39  Began compiling node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 14:08:39.761603 (Thread-2): 14:08:39  Compiling test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 14:08:39.781498 (Thread-3): 14:08:39  Writing injected SQL for node "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-06 14:08:39.782932 (Thread-2): 14:08:39  Writing injected SQL for node "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-06 14:08:39.788529 (Thread-4): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.788728 (Thread-4): 14:08:39  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:08:39.788870 (Thread-4): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.789074 (Thread-4): 14:08:39  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:08:39.790004 (Thread-1): 14:08:39  Began running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 14:08:39.790186 (Thread-1): 14:08:39  Acquiring new redshift connection "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2022-01-06 14:08:39.790277 (Thread-1): 14:08:39  Began compiling node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 14:08:39.790356 (Thread-1): 14:08:39  Compiling test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 14:08:39.793530 (Thread-1): 14:08:39  Writing injected SQL for node "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2022-01-06 14:08:39.793726 (Thread-4): 14:08:39  Began running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 14:08:39.793875 (Thread-4): 14:08:39  Acquiring new redshift connection "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2022-01-06 14:08:39.793954 (Thread-4): 14:08:39  Began compiling node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 14:08:39.794028 (Thread-4): 14:08:39  Compiling test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 14:08:39.797009 (Thread-4): 14:08:39  Writing injected SQL for node "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2022-01-06 14:08:39.802562 (Thread-3): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.802695 (Thread-3): 14:08:39  Began executing node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 14:08:39.802788 (Thread-3): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.802926 (Thread-3): 14:08:39  Finished running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 14:08:39.803199 (Thread-2): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.803331 (Thread-2): 14:08:39  Began executing node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 14:08:39.803424 (Thread-2): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.803556 (Thread-2): 14:08:39  Finished running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 14:08:39.806250 (Thread-4): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.806364 (Thread-4): 14:08:39  Began executing node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 14:08:39.806449 (Thread-4): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.806569 (Thread-4): 14:08:39  Finished running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 14:08:39.811347 (Thread-1): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.811480 (Thread-1): 14:08:39  Began executing node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 14:08:39.811575 (Thread-1): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.811718 (Thread-1): 14:08:39  Finished running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 14:08:39.812887 (MainThread): 14:08:39  Connection 'master' was properly closed.
2022-01-06 14:08:39.812997 (MainThread): 14:08:39  Connection 'test.my_new_project.not_null_my_second_dbt_model_id.151b76d778' was properly closed.
2022-01-06 14:08:39.813064 (MainThread): 14:08:39  Connection 'test.my_new_project.unique_my_first_dbt_model_id.16e066b321' was properly closed.
2022-01-06 14:08:39.813125 (MainThread): 14:08:39  Connection 'test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
2022-01-06 14:08:39.813183 (MainThread): 14:08:39  Connection 'test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
2022-01-06 14:08:39.875972 (MainThread): 14:08:39  Done.
2022-01-06 14:08:39.916937 (MainThread): 14:08:39  Acquiring new redshift connection "generate_catalog"
2022-01-06 14:08:39.917060 (MainThread): 14:08:39  Building catalog
2022-01-06 14:08:39.918139 (ThreadPoolExecutor-1_0): 14:08:39  Acquiring new redshift connection "dev.information_schema"
2022-01-06 14:08:39.928694 (ThreadPoolExecutor-1_0): 14:08:39  Using redshift connection "dev.information_schema"
2022-01-06 14:08:39.928801 (ThreadPoolExecutor-1_0): 14:08:39  On dev.information_schema: BEGIN
2022-01-06 14:08:39.928885 (ThreadPoolExecutor-1_0): 14:08:39  Opening a new connection, currently in state init
2022-01-06 14:08:39.928964 (ThreadPoolExecutor-1_0): 14:08:39  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:08:40.512788 (ThreadPoolExecutor-1_0): 14:08:40  SQL status: BEGIN in 0.58 seconds
2022-01-06 14:08:40.512950 (ThreadPoolExecutor-1_0): 14:08:40  Using redshift connection "dev.information_schema"
2022-01-06 14:08:40.513029 (ThreadPoolExecutor-1_0): 14:08:40  On dev.information_schema: 
    

    with late_binding as (
      select
        'dev'::varchar as table_database,
        table_schema,
        table_name,
        'LATE BINDING VIEW'::varchar as table_type,
        null::text as table_comment,

        column_name,
        column_index,
        column_type,
        null::text as column_comment
      from pg_get_late_binding_view_cols()
        cols(table_schema name, table_name name, column_name name,
             column_type varchar,
             column_index int)
        order by "column_index"
    ),

    early_binding as (
        select
            'dev'::varchar as table_database,
            sch.nspname as table_schema,
            tbl.relname as table_name,
            case tbl.relkind
                when 'v' then 'VIEW'
                else 'BASE TABLE'
            end as table_type,
            tbl_desc.description as table_comment,
            col.attname as column_name,
            col.attnum as column_index,
            pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
            col_desc.description as column_comment

        from pg_catalog.pg_namespace sch
        join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
        join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
        left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
        left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
        where (upper(sch.nspname) = upper('dbt_nobodozie'))
            and tbl.relkind in ('r', 'v', 'f', 'p')
            and col.attnum > 0
            and not col.attisdropped
    ),

    table_owners as (

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            tablename as table_name,
            tableowner as table_owner

        from pg_tables

        union all

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            viewname as table_name,
            viewowner as table_owner

        from pg_views

    ),

    unioned as (

        select *
        from early_binding

        union all

        select *
        from late_binding

    )

    select *,
        table_database || '.' || table_schema || '.' || table_name as table_id

    from unioned
    join table_owners using (table_database, table_schema, table_name)

    where (upper(table_schema) = upper('dbt_nobodozie'))

    order by "column_index"
2022-01-06 14:08:40.570610 (ThreadPoolExecutor-1_0): 14:08:40  SQL status: SELECT in 0.06 seconds
2022-01-06 14:08:40.574446 (ThreadPoolExecutor-1_0): 14:08:40  Using redshift connection "dev.information_schema"
2022-01-06 14:08:40.574561 (ThreadPoolExecutor-1_0): 14:08:40  On dev.information_schema: select has_table_privilege(current_user, 'svv_table_info', 'SELECT') as can_select
2022-01-06 14:08:40.577254 (ThreadPoolExecutor-1_0): 14:08:40  SQL status: SELECT in 0.0 seconds
2022-01-06 14:08:40.581051 (ThreadPoolExecutor-1_0): 14:08:40  Using redshift connection "dev.information_schema"
2022-01-06 14:08:40.581146 (ThreadPoolExecutor-1_0): 14:08:40  On dev.information_schema: select
        "database" || '.' || "schema" || '.' || "table" as table_id,

        'Encoded'::text as "stats:encoded:label",
        encoded as "stats:encoded:value",
        'Indicates whether any column in the table has compression encoding defined.'::text as "stats:encoded:description",
        true as "stats:encoded:include",

        'Dist Style' as "stats:diststyle:label",
        diststyle as "stats:diststyle:value",
        'Distribution style or distribution key column, if key distribution is defined.'::text as "stats:diststyle:description",
        true as "stats:diststyle:include",

        'Sort Key 1' as "stats:sortkey1:label",
        -- handle 0xFF byte in response for interleaved sort styles
        case
            when sortkey1 like 'INTERLEAVED%' then 'INTERLEAVED'::text
            else sortkey1
        end as "stats:sortkey1:value",
        'First column in the sort key.'::text as "stats:sortkey1:description",
        (sortkey1 is not null) as "stats:sortkey1:include",

        'Max Varchar' as "stats:max_varchar:label",
        max_varchar as "stats:max_varchar:value",
        'Size of the largest column that uses a VARCHAR data type.'::text as "stats:max_varchar:description",
        true as "stats:max_varchar:include",

        -- exclude this, as the data is strangely returned with null-byte characters
        'Sort Key 1 Encoding' as "stats:sortkey1_enc:label",
        sortkey1_enc as "stats:sortkey1_enc:value",
        'Compression encoding of the first column in the sort key.' as "stats:sortkey1_enc:description",
        false as "stats:sortkey1_enc:include",

        '# Sort Keys' as "stats:sortkey_num:label",
        sortkey_num as "stats:sortkey_num:value",
        'Number of columns defined as sort keys.' as "stats:sortkey_num:description",
        (sortkey_num > 0) as "stats:sortkey_num:include",

        'Approximate Size' as "stats:size:label",
        size * 1000000 as "stats:size:value",
        'Approximate size of the table, calculated from a count of 1MB blocks'::text as "stats:size:description",
        true as "stats:size:include",

        'Disk Utilization' as "stats:pct_used:label",
        pct_used / 100.0 as "stats:pct_used:value",
        'Percent of available space that is used by the table.'::text as "stats:pct_used:description",
        true as "stats:pct_used:include",

        'Unsorted %' as "stats:unsorted:label",
        unsorted / 100.0 as "stats:unsorted:value",
        'Percent of unsorted rows in the table.'::text as "stats:unsorted:description",
        (unsorted is not null) as "stats:unsorted:include",

        'Stats Off' as "stats:stats_off:label",
        stats_off as "stats:stats_off:value",
        'Number that indicates how stale the table statistics are; 0 is current, 100 is out of date.'::text as "stats:stats_off:description",
        true as "stats:stats_off:include",

        'Approximate Row Count' as "stats:rows:label",
        tbl_rows as "stats:rows:value",
        'Approximate number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed.'::text as "stats:rows:description",
        true as "stats:rows:include",

        'Sort Key Skew' as "stats:skew_sortkey1:label",
        skew_sortkey1 as "stats:skew_sortkey1:value",
        'Ratio of the size of the largest non-sort key column to the size of the first column of the sort key.'::text as "stats:skew_sortkey1:description",
        (skew_sortkey1 is not null) as "stats:skew_sortkey1:include",

        'Skew Rows' as "stats:skew_rows:label",
        skew_rows as "stats:skew_rows:value",
        'Ratio of the number of rows in the slice with the most rows to the number of rows in the slice with the fewest rows.'::text as "stats:skew_rows:description",
        (skew_rows is not null) as "stats:skew_rows:include"

    from svv_table_info
    where (upper(schema) = upper('dbt_nobodozie'))
2022-01-06 14:08:41.072551 (Thread-32): handling poll request
2022-01-06 14:08:41.072918 (Thread-32): 14:08:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb85f6700>]}
2022-01-06 14:08:41.074295 (Thread-32): sending response (<Response 43713 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:08:42.519789 (Thread-33): handling poll request
2022-01-06 14:08:42.520139 (Thread-33): 14:08:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb85f68b0>]}
2022-01-06 14:08:42.520610 (Thread-33): sending response (<Response 296 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:08:43.897904 (ThreadPoolExecutor-1_0): 14:08:43  SQL status: SELECT in 3.32 seconds
2022-01-06 14:08:43.907055 (ThreadPoolExecutor-1_0): 14:08:43  On dev.information_schema: ROLLBACK
2022-01-06 14:08:43.909307 (ThreadPoolExecutor-1_0): 14:08:43  On dev.information_schema: Close
2022-01-06 14:08:43.929920 (Thread-34): handling poll request
2022-01-06 14:08:43.930215 (Thread-34): 14:08:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb85f6d00>]}
2022-01-06 14:08:43.930696 (Thread-34): sending response (<Response 1163 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:08:43.966087 (MainThread): 14:08:43  Catalog written to /usr/src/develop/user-52374/environment-57794/repository-46678/target/catalog.json
2022-01-06 14:08:45.297770 (Thread-35): handling poll request
2022-01-06 14:08:45.298137 (Thread-35): 14:08:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86a7910>]}
2022-01-06 14:08:45.298851 (Thread-35): sending response (<Response 5346 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:08:45.958940 (Thread-36): handling status request
2022-01-06 14:08:45.959559 (Thread-36): 14:08:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb860e100>]}
2022-01-06 14:08:45.960057 (Thread-37): handling status request
2022-01-06 14:08:45.962575 (Thread-37): 14:08:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb860ea00>]}
2022-01-06 14:08:45.986051 (Thread-36): sending response (<Response 1241 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:08:45.986452 (Thread-37): sending response (<Response 1241 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:08:46.018314 (Thread-38): handling status request
2022-01-06 14:08:46.018596 (Thread-38): 14:08:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb860e280>]}
2022-01-06 14:08:46.018972 (Thread-38): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:25:04.380519 (Thread-39): 14:25:04  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-01-06 14:25:04.381862 (Thread-39): 14:25:04  Partial parsing: added file: my_new_project://models/stg_customers.sql
2022-01-06 14:25:04.393273 (Thread-39): 14:25:04  1699: static parser successfully parsed stg_customers.sql
2022-01-06 14:25:04.466532 (Thread-39): 14:25:04  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb855de20>]}
2022-01-06 14:25:04.971976 (Thread-40): handling status request
2022-01-06 14:25:04.972438 (Thread-40): 14:25:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8612a30>]}
2022-01-06 14:25:04.972957 (Thread-40): sending response (<Response 1550 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:25:05.045057 (Thread-41): handling status request
2022-01-06 14:25:05.045445 (Thread-41): 14:25:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb85359a0>]}
2022-01-06 14:25:05.045937 (Thread-41): sending response (<Response 1550 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:26:15.862281 (Thread-42): handling status request
2022-01-06 14:26:15.863663 (Thread-42): 14:26:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8535a60>]}
2022-01-06 14:26:15.864130 (Thread-42): sending response (<Response 1550 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:26:16.305254 (Thread-43): handling run_sql request
2022-01-06 14:26:16.305674 (Thread-43): 14:26:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8535220>]}
2022-01-06 14:26:18.405311 (Thread-43): sending response (<Response 138 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:26:18.431130 (MainThread): 14:26:18  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '49716b01-59dd-49cd-a94f-81af900c41a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73d9aaf4c0>]}
2022-01-06 14:26:18.431648 (MainThread): 14:26:18  Found 4 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:26:18.432227 (Thread-1): 14:26:18  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:26:18.432357 (Thread-1): 14:26:18  Began compiling node rpc.my_new_project.request
2022-01-06 14:26:18.432447 (Thread-1): 14:26:18  Compiling rpc.my_new_project.request
2022-01-06 14:26:18.433592 (Thread-1): 14:26:18  finished collecting timing info
2022-01-06 14:26:18.433715 (Thread-1): 14:26:18  Began executing node rpc.my_new_project.request
2022-01-06 14:26:18.433812 (Thread-1): 14:26:18  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:26:18.433891 (Thread-1): 14:26:18  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:26:18.433972 (Thread-1): 14:26:18  Opening a new connection, currently in state init
2022-01-06 14:26:18.434055 (Thread-1): 14:26:18  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:26:18.606758 (Thread-1): 14:26:18  SQL status: SELECT in 0.17 seconds
2022-01-06 14:26:18.608682 (Thread-1): 14:26:18  finished collecting timing info
2022-01-06 14:26:18.608834 (Thread-1): 14:26:18  On rpc.my_new_project.request: Close
2022-01-06 14:26:18.756528 (Thread-44): handling poll request
2022-01-06 14:26:18.756951 (Thread-44): 14:26:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8539e50>]}
2022-01-06 14:26:18.758302 (Thread-44): sending response (<Response 10140 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:27:00.217999 (Thread-45): 14:27:00  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-01-06 14:27:00.218315 (Thread-45): 14:27:00  Partial parsing: added file: my_new_project://models/stg_orders.sql
2022-01-06 14:27:00.222647 (Thread-45): 14:27:00  1699: static parser successfully parsed stg_orders.sql
2022-01-06 14:27:00.264448 (Thread-45): 14:27:00  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb80a1ca0>]}
2022-01-06 14:27:00.799471 (Thread-46): handling status request
2022-01-06 14:27:00.799831 (Thread-46): 14:27:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb808aa60>]}
2022-01-06 14:27:00.800366 (Thread-46): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:27:00.828613 (Thread-47): handling status request
2022-01-06 14:27:00.828904 (Thread-47): 14:27:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb808a490>]}
2022-01-06 14:27:00.829349 (Thread-47): sending response (<Response 1544 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:27:45.472646 (Thread-48): handling status request
2022-01-06 14:27:45.473018 (Thread-48): 14:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb85f67f0>]}
2022-01-06 14:27:45.473532 (Thread-48): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:27:45.530679 (Thread-49): handling status request
2022-01-06 14:27:45.530960 (Thread-49): 14:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb808a670>]}
2022-01-06 14:27:45.531372 (Thread-49): sending response (<Response 1544 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:27:45.821883 (Thread-50): handling run_sql request
2022-01-06 14:27:45.822205 (Thread-50): 14:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb808a430>]}
2022-01-06 14:27:45.844831 (Thread-51): handling run_sql request
2022-01-06 14:27:45.845531 (Thread-51): 14:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb85438b0>]}
2022-01-06 14:27:47.899314 (Thread-50): sending response (<Response 138 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:27:47.923434 (Thread-51): sending response (<Response 138 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:27:47.923262 (MainThread): 14:27:47  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a081489e-a681-48b6-882c-ba9bd64d4ba3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9634875790>]}
2022-01-06 14:27:47.923785 (MainThread): 14:27:47  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:27:47.924360 (Thread-1): 14:27:47  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:27:47.924484 (Thread-1): 14:27:47  Began compiling node rpc.my_new_project.request
2022-01-06 14:27:47.924574 (Thread-1): 14:27:47  Compiling rpc.my_new_project.request
2022-01-06 14:27:47.925747 (Thread-1): 14:27:47  finished collecting timing info
2022-01-06 14:27:47.925872 (Thread-1): 14:27:47  Began executing node rpc.my_new_project.request
2022-01-06 14:27:47.925976 (Thread-1): 14:27:47  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:27:47.926058 (Thread-1): 14:27:47  On rpc.my_new_project.request: with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from dev.jaffle_shop.orders

)
select * from orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:27:47.926136 (Thread-1): 14:27:47  Opening a new connection, currently in state init
2022-01-06 14:27:47.926220 (Thread-1): 14:27:47  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:27:47.948106 (MainThread): 14:27:47  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '63b5c5f5-1b75-4484-aed7-7be18326b73a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12f309f820>]}
2022-01-06 14:27:47.948785 (MainThread): 14:27:47  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:27:47.949366 (Thread-1): 14:27:47  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:27:47.949519 (Thread-1): 14:27:47  Began compiling node rpc.my_new_project.request
2022-01-06 14:27:47.949619 (Thread-1): 14:27:47  Compiling rpc.my_new_project.request
2022-01-06 14:27:47.950738 (Thread-1): 14:27:47  finished collecting timing info
2022-01-06 14:27:47.950864 (Thread-1): 14:27:47  Began executing node rpc.my_new_project.request
2022-01-06 14:27:47.950964 (Thread-1): 14:27:47  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:27:47.951046 (Thread-1): 14:27:47  On rpc.my_new_project.request: with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from dev.jaffle_shop.orders

)
select * from orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:27:47.951122 (Thread-1): 14:27:47  Opening a new connection, currently in state init
2022-01-06 14:27:47.951204 (Thread-1): 14:27:47  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:27:48.159683 (Thread-1): 14:27:48  SQL status: SELECT in 0.23 seconds
2022-01-06 14:27:48.162275 (Thread-1): 14:27:48  finished collecting timing info
2022-01-06 14:27:48.162423 (Thread-1): 14:27:48  On rpc.my_new_project.request: Close
2022-01-06 14:27:48.162636 (Thread-1): 14:27:48  SQL status: SELECT in 0.21 seconds
2022-01-06 14:27:48.165279 (Thread-1): 14:27:48  finished collecting timing info
2022-01-06 14:27:48.165428 (Thread-1): 14:27:48  On rpc.my_new_project.request: Close
2022-01-06 14:27:48.240692 (Thread-52): handling poll request
2022-01-06 14:27:48.241662 (Thread-52): 14:27:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb80f56a0>]}
2022-01-06 14:27:48.242582 (Thread-52): sending response (<Response 5174 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:27:48.256600 (Thread-53): handling poll request
2022-01-06 14:27:48.256948 (Thread-53): 14:27:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb808aac0>]}
2022-01-06 14:27:48.257582 (Thread-53): sending response (<Response 5174 bytes [200 OK]>) to 10.0.40.39
2022-01-06 14:27:49.618632 (Thread-54): handling poll request
2022-01-06 14:27:49.619024 (Thread-54): 14:27:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb808ac40>]}
2022-01-06 14:27:49.620160 (Thread-54): sending response (<Response 7067 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:27:49.703208 (Thread-55): handling poll request
2022-01-06 14:27:49.703451 (Thread-55): 14:27:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb808ab50>]}
2022-01-06 14:27:49.704325 (Thread-55): sending response (<Response 7067 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:31:06.601343 (Thread-56): handling status request
2022-01-06 14:31:06.602790 (Thread-56): 14:31:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb80a1d90>]}
2022-01-06 14:31:06.603308 (Thread-56): sending response (<Response 1544 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:31:06.962276 (Thread-57): handling compile_sql request
2022-01-06 14:31:06.962649 (Thread-57): 14:31:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb809a400>]}
2022-01-06 14:31:09.024135 (Thread-57): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:31:09.051054 (MainThread): 14:31:09  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5ba18145-4c56-4f22-a659-a92a9fba1110', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6482876970>]}
2022-01-06 14:31:09.051555 (MainThread): 14:31:09  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:31:09.052113 (Thread-1): 14:31:09  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:31:09.052242 (Thread-1): 14:31:09  Began compiling node rpc.my_new_project.request
2022-01-06 14:31:09.052331 (Thread-1): 14:31:09  Compiling rpc.my_new_project.request
2022-01-06 14:31:09.054803 (Thread-1): 14:31:09  finished collecting timing info
2022-01-06 14:31:09.054926 (Thread-1): 14:31:09  Began executing node rpc.my_new_project.request
2022-01-06 14:31:09.055020 (Thread-1): 14:31:09  finished collecting timing info
2022-01-06 14:31:09.923670 (Thread-58): handling poll request
2022-01-06 14:31:09.924108 (Thread-58): 14:31:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8024820>]}
2022-01-06 14:31:09.925197 (Thread-58): sending response (<Response 8440 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:32:02.022239 (Thread-59): handling status request
2022-01-06 14:32:02.022591 (Thread-59): 14:32:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb80249a0>]}
2022-01-06 14:32:02.023100 (Thread-59): sending response (<Response 1544 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:32:02.184417 (Thread-60): handling status request
2022-01-06 14:32:02.184777 (Thread-60): 14:32:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8024dc0>]}
2022-01-06 14:32:02.185261 (Thread-60): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:32:02.365414 (Thread-61): handling cli_args request
2022-01-06 14:32:02.365782 (Thread-61): 14:32:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8024fd0>]}
2022-01-06 14:32:04.459650 (Thread-61): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:32:04.547590 (MainThread): 14:32:04  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:32:04.547965 (MainThread): 14:32:04  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:32:04.553572 (MainThread): 14:32:04  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b78f090a-48bd-4bcd-800b-82f3bb015fa5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ccbba6be0>]}
2022-01-06 14:32:04.580650 (MainThread): 14:32:04  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b78f090a-48bd-4bcd-800b-82f3bb015fa5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ccbc1ab80>]}
2022-01-06 14:32:04.580905 (MainThread): 14:32:04  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:32:04.582052 (MainThread): 14:32:04  
2022-01-06 14:32:04.582321 (MainThread): 14:32:04  Acquiring new redshift connection "master"
2022-01-06 14:32:04.583263 (ThreadPoolExecutor-0_0): 14:32:04  Acquiring new redshift connection "list_dev"
2022-01-06 14:32:04.593355 (ThreadPoolExecutor-0_0): 14:32:04  Using redshift connection "list_dev"
2022-01-06 14:32:04.593477 (ThreadPoolExecutor-0_0): 14:32:04  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:32:04.593565 (ThreadPoolExecutor-0_0): 14:32:04  Opening a new connection, currently in state init
2022-01-06 14:32:04.593650 (ThreadPoolExecutor-0_0): 14:32:04  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:04.613956 (ThreadPoolExecutor-0_0): 14:32:04  SQL status: SELECT in 0.02 seconds
2022-01-06 14:32:04.614989 (ThreadPoolExecutor-0_0): 14:32:04  On list_dev: Close
2022-01-06 14:32:04.616179 (ThreadPoolExecutor-1_0): 14:32:04  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:04.622669 (ThreadPoolExecutor-1_0): 14:32:04  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:04.622769 (ThreadPoolExecutor-1_0): 14:32:04  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:32:04.622849 (ThreadPoolExecutor-1_0): 14:32:04  Opening a new connection, currently in state closed
2022-01-06 14:32:04.622929 (ThreadPoolExecutor-1_0): 14:32:04  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:04.645528 (ThreadPoolExecutor-1_0): 14:32:04  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:04.645638 (ThreadPoolExecutor-1_0): 14:32:04  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:04.645713 (ThreadPoolExecutor-1_0): 14:32:04  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:32:04.656680 (ThreadPoolExecutor-1_0): 14:32:04  SQL status: SELECT in 0.01 seconds
2022-01-06 14:32:04.657707 (ThreadPoolExecutor-1_0): 14:32:04  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:32:04.659438 (ThreadPoolExecutor-1_0): 14:32:04  On list_dev_dbt_nobodozie: Close
2022-01-06 14:32:04.663174 (MainThread): 14:32:04  Using redshift connection "master"
2022-01-06 14:32:04.663284 (MainThread): 14:32:04  On master: BEGIN
2022-01-06 14:32:04.663363 (MainThread): 14:32:04  Opening a new connection, currently in state init
2022-01-06 14:32:04.663452 (MainThread): 14:32:04  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:04.686738 (MainThread): 14:32:04  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:04.686845 (MainThread): 14:32:04  Using redshift connection "master"
2022-01-06 14:32:04.686933 (MainThread): 14:32:04  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:32:04.715453 (MainThread): 14:32:04  SQL status: SELECT in 0.03 seconds
2022-01-06 14:32:04.716430 (MainThread): 14:32:04  On master: ROLLBACK
2022-01-06 14:32:04.718274 (MainThread): 14:32:04  Using redshift connection "master"
2022-01-06 14:32:04.718375 (MainThread): 14:32:04  On master: BEGIN
2022-01-06 14:32:04.721789 (MainThread): 14:32:04  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:04.721910 (MainThread): 14:32:04  On master: COMMIT
2022-01-06 14:32:04.721994 (MainThread): 14:32:04  Using redshift connection "master"
2022-01-06 14:32:04.722065 (MainThread): 14:32:04  On master: COMMIT
2022-01-06 14:32:04.723746 (MainThread): 14:32:04  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:32:04.723853 (MainThread): 14:32:04  On master: Close
2022-01-06 14:32:04.724242 (MainThread): 14:32:04  Concurrency: 4 threads (target='default')
2022-01-06 14:32:04.724357 (MainThread): 14:32:04  
2022-01-06 14:32:04.726532 (Thread-1): 14:32:04  Began running node model.my_new_project.dim_customers
2022-01-06 14:32:04.726771 (Thread-1): 14:32:04  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:32:04.727001 (Thread-1): 14:32:04  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:04.727093 (Thread-1): 14:32:04  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:32:04.727191 (Thread-1): 14:32:04  Compiling model.my_new_project.dim_customers
2022-01-06 14:32:04.729206 (Thread-1): 14:32:04  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:32:04.729466 (Thread-2): 14:32:04  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:04.729700 (Thread-2): 14:32:04  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:32:04.729939 (Thread-2): 14:32:04  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:04.730025 (Thread-2): 14:32:04  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:04.730106 (Thread-2): 14:32:04  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:32:04.732067 (Thread-2): 14:32:04  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:04.743563 (Thread-1): 14:32:04  finished collecting timing info
2022-01-06 14:32:04.743709 (Thread-1): 14:32:04  Began executing node model.my_new_project.dim_customers
2022-01-06 14:32:04.748963 (Thread-2): 14:32:04  finished collecting timing info
2022-01-06 14:32:04.749149 (Thread-2): 14:32:04  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:04.807346 (Thread-1): 14:32:04  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:32:04.810515 (Thread-2): 14:32:04  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:04.824757 (Thread-2): 14:32:04  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:04.824913 (Thread-2): 14:32:04  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:04.825040 (Thread-2): 14:32:04  Opening a new connection, currently in state init
2022-01-06 14:32:04.825161 (Thread-2): 14:32:04  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:04.825491 (Thread-1): 14:32:04  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:04.825590 (Thread-1): 14:32:04  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:04.825668 (Thread-1): 14:32:04  Opening a new connection, currently in state closed
2022-01-06 14:32:04.825743 (Thread-1): 14:32:04  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:04.852489 (Thread-1): 14:32:04  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:32:04.852605 (Thread-1): 14:32:04  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:04.852684 (Thread-1): 14:32:04  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:32:04.852843 (Thread-2): 14:32:04  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:32:04.852957 (Thread-2): 14:32:04  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:04.853035 (Thread-2): 14:32:04  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:32:04.940858 (Thread-2): 14:32:04  SQL status: SELECT in 0.09 seconds
2022-01-06 14:32:04.946554 (Thread-2): 14:32:04  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:04.946658 (Thread-2): 14:32:04  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:32:04.951832 (Thread-2): 14:32:04  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:32:04.953595 (Thread-2): 14:32:04  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:04.953693 (Thread-2): 14:32:04  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:32:04.956932 (Thread-2): 14:32:04  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:04.962231 (Thread-1): 14:32:04  SQL status: SELECT in 0.11 seconds
2022-01-06 14:32:04.964085 (Thread-1): 14:32:04  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:04.964182 (Thread-1): 14:32:04  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:32:04.969581 (Thread-1): 14:32:04  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:32:04.971242 (Thread-1): 14:32:04  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:04.971337 (Thread-1): 14:32:04  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:32:04.971451 (Thread-2): 14:32:04  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:04.971562 (Thread-2): 14:32:04  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:04.971638 (Thread-2): 14:32:04  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:04.974569 (Thread-1): 14:32:04  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:04.976645 (Thread-1): 14:32:04  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:04.976740 (Thread-1): 14:32:04  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:04.976812 (Thread-1): 14:32:04  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:04.989187 (Thread-62): handling poll request
2022-01-06 14:32:04.989585 (Thread-62): 14:32:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb803d1c0>]}
2022-01-06 14:32:04.991170 (Thread-62): sending response (<Response 38501 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:32:05.069345 (Thread-2): 14:32:05  SQL status: COMMIT in 0.1 seconds
2022-01-06 14:32:05.069567 (Thread-2): 14:32:05  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:05.069651 (Thread-2): 14:32:05  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:05.069899 (Thread-1): 14:32:05  SQL status: COMMIT in 0.09 seconds
2022-01-06 14:32:05.071777 (Thread-2): 14:32:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:05.075719 (Thread-2): 14:32:05  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:05.075815 (Thread-2): 14:32:05  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:32:05.080849 (Thread-2): 14:32:05  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:32:05.081505 (Thread-2): 14:32:05  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:05.081598 (Thread-2): 14:32:05  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:05.081672 (Thread-2): 14:32:05  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:05.112276 (Thread-2): 14:32:05  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:05.112384 (Thread-2): 14:32:05  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:05.112456 (Thread-2): 14:32:05  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:05.114532 (Thread-2): 14:32:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:05.114910 (Thread-2): 14:32:05  finished collecting timing info
2022-01-06 14:32:05.115037 (Thread-2): 14:32:05  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:32:05.115227 (Thread-1): 14:32:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:05.115334 (Thread-1): 14:32:05  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:05.117573 (Thread-1): 14:32:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:05.118682 (Thread-1): 14:32:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:05.118778 (Thread-1): 14:32:05  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:32:05.118952 (Thread-2): 14:32:05  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:32:05.119405 (Thread-2): 14:32:05  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b78f090a-48bd-4bcd-800b-82f3bb015fa5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cc82e1820>]}
2022-01-06 14:32:05.119718 (Thread-2): 14:32:05  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.39s]
2022-01-06 14:32:05.119830 (Thread-2): 14:32:05  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:05.120407 (Thread-4): 14:32:05  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:05.120644 (Thread-4): 14:32:05  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:32:05.120893 (Thread-4): 14:32:05  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.120981 (Thread-4): 14:32:05  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:05.121065 (Thread-4): 14:32:05  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:32:05.123077 (Thread-4): 14:32:05  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.124357 (Thread-1): 14:32:05  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 14:32:05.124979 (Thread-1): 14:32:05  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:05.125072 (Thread-1): 14:32:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:05.125145 (Thread-1): 14:32:05  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:05.135448 (Thread-4): 14:32:05  finished collecting timing info
2022-01-06 14:32:05.135587 (Thread-4): 14:32:05  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:05.151463 (Thread-4): 14:32:05  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.156629 (Thread-1): 14:32:05  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:05.156746 (Thread-1): 14:32:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:05.156821 (Thread-1): 14:32:05  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:05.158830 (Thread-1): 14:32:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:05.159195 (Thread-1): 14:32:05  finished collecting timing info
2022-01-06 14:32:05.159317 (Thread-1): 14:32:05  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:32:05.161023 (Thread-1): 14:32:05  On model.my_new_project.dim_customers: Close
2022-01-06 14:32:05.161475 (Thread-1): 14:32:05  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b78f090a-48bd-4bcd-800b-82f3bb015fa5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cc82b9fa0>]}
2022-01-06 14:32:05.161774 (Thread-1): 14:32:05  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.43s]
2022-01-06 14:32:05.161914 (Thread-1): 14:32:05  Finished running node model.my_new_project.dim_customers
2022-01-06 14:32:05.164065 (Thread-4): 14:32:05  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.164174 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:05.164258 (Thread-4): 14:32:05  Opening a new connection, currently in state init
2022-01-06 14:32:05.164339 (Thread-4): 14:32:05  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:05.186940 (Thread-4): 14:32:05  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:05.187051 (Thread-4): 14:32:05  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.187128 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:32:05.191974 (Thread-4): 14:32:05  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:32:05.193838 (Thread-4): 14:32:05  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.193933 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:32:05.196005 (Thread-4): 14:32:05  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:05.196912 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:05.197006 (Thread-4): 14:32:05  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.197079 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:05.225984 (Thread-4): 14:32:05  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:05.226201 (Thread-4): 14:32:05  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.226285 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:05.228878 (Thread-4): 14:32:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:05.230144 (Thread-4): 14:32:05  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.230240 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:32:05.232177 (Thread-4): 14:32:05  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:32:05.232845 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:05.232938 (Thread-4): 14:32:05  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.233011 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:05.258375 (Thread-4): 14:32:05  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:05.258488 (Thread-4): 14:32:05  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.258574 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:05.260592 (Thread-4): 14:32:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:05.260951 (Thread-4): 14:32:05  finished collecting timing info
2022-01-06 14:32:05.261071 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:32:05.262776 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:32:05.263153 (Thread-4): 14:32:05  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b78f090a-48bd-4bcd-800b-82f3bb015fa5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cc82aec40>]}
2022-01-06 14:32:05.263502 (Thread-4): 14:32:05  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.14s]
2022-01-06 14:32:05.263663 (Thread-4): 14:32:05  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:05.264928 (MainThread): 14:32:05  Acquiring new redshift connection "master"
2022-01-06 14:32:05.265073 (MainThread): 14:32:05  Using redshift connection "master"
2022-01-06 14:32:05.265151 (MainThread): 14:32:05  On master: BEGIN
2022-01-06 14:32:05.265259 (MainThread): 14:32:05  Opening a new connection, currently in state closed
2022-01-06 14:32:05.265342 (MainThread): 14:32:05  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:05.289073 (MainThread): 14:32:05  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:05.289188 (MainThread): 14:32:05  On master: COMMIT
2022-01-06 14:32:05.289285 (MainThread): 14:32:05  Using redshift connection "master"
2022-01-06 14:32:05.289356 (MainThread): 14:32:05  On master: COMMIT
2022-01-06 14:32:05.291037 (MainThread): 14:32:05  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:32:05.291139 (MainThread): 14:32:05  On master: Close
2022-01-06 14:32:05.291605 (MainThread): 14:32:05  
2022-01-06 14:32:05.291718 (MainThread): 14:32:05  Finished running 2 table models, 1 view model in 0.71s.
2022-01-06 14:32:05.291800 (MainThread): 14:32:05  Connection 'master' was properly closed.
2022-01-06 14:32:05.291895 (MainThread): 14:32:05  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:32:05.291959 (MainThread): 14:32:05  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:32:05.292019 (MainThread): 14:32:05  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:32:05.365730 (MainThread): 14:32:05  
2022-01-06 14:32:05.365890 (MainThread): 14:32:05  Completed successfully
2022-01-06 14:32:05.365986 (MainThread): 14:32:05  
2022-01-06 14:32:05.366072 (MainThread): 14:32:05  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:32:06.376356 (Thread-63): handling poll request
2022-01-06 14:32:06.376753 (Thread-63): 14:32:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff981da5b0>]}
2022-01-06 14:32:06.378778 (Thread-63): sending response (<Response 48689 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:32:07.017930 (Thread-64): handling status request
2022-01-06 14:32:07.018289 (Thread-64): 14:32:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff981da490>]}
2022-01-06 14:32:07.018819 (Thread-64): sending response (<Response 1544 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:32:07.067412 (Thread-65): handling status request
2022-01-06 14:32:07.067676 (Thread-65): 14:32:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff981da9a0>]}
2022-01-06 14:32:07.068092 (Thread-65): sending response (<Response 1544 bytes [200 OK]>) to 10.0.40.39
2022-01-06 14:32:13.930299 (Thread-66): handling status request
2022-01-06 14:32:13.930724 (Thread-66): 14:32:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff981cb550>]}
2022-01-06 14:32:13.956162 (Thread-66): sending response (<Response 1544 bytes [200 OK]>) to 10.0.5.191
2022-01-06 14:32:14.189197 (Thread-67): handling status request
2022-01-06 14:32:14.189570 (Thread-67): 14:32:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff981dacd0>]}
2022-01-06 14:32:14.190051 (Thread-67): sending response (<Response 1544 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:32:14.291153 (Thread-68): handling cli_args request
2022-01-06 14:32:14.291428 (Thread-68): 14:32:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff981f0190>]}
2022-01-06 14:32:16.412527 (Thread-68): sending response (<Response 138 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:32:16.490872 (MainThread): 14:32:16  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:32:16.491284 (MainThread): 14:32:16  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:32:16.497030 (MainThread): 14:32:16  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '89b90ef5-5a7b-4597-8c3e-6401a6831e24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a93b0c10>]}
2022-01-06 14:32:16.524455 (MainThread): 14:32:16  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '89b90ef5-5a7b-4597-8c3e-6401a6831e24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a9426c70>]}
2022-01-06 14:32:16.524718 (MainThread): 14:32:16  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:32:16.525863 (MainThread): 14:32:16  
2022-01-06 14:32:16.526156 (MainThread): 14:32:16  Acquiring new redshift connection "master"
2022-01-06 14:32:16.527207 (ThreadPoolExecutor-0_0): 14:32:16  Acquiring new redshift connection "list_dev"
2022-01-06 14:32:16.537629 (ThreadPoolExecutor-0_0): 14:32:16  Using redshift connection "list_dev"
2022-01-06 14:32:16.537732 (ThreadPoolExecutor-0_0): 14:32:16  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:32:16.537815 (ThreadPoolExecutor-0_0): 14:32:16  Opening a new connection, currently in state init
2022-01-06 14:32:16.537897 (ThreadPoolExecutor-0_0): 14:32:16  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:16.558147 (ThreadPoolExecutor-0_0): 14:32:16  SQL status: SELECT in 0.02 seconds
2022-01-06 14:32:16.559238 (ThreadPoolExecutor-0_0): 14:32:16  On list_dev: Close
2022-01-06 14:32:16.560595 (ThreadPoolExecutor-1_0): 14:32:16  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:16.567258 (ThreadPoolExecutor-1_0): 14:32:16  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:16.567354 (ThreadPoolExecutor-1_0): 14:32:16  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:32:16.567433 (ThreadPoolExecutor-1_0): 14:32:16  Opening a new connection, currently in state closed
2022-01-06 14:32:16.567510 (ThreadPoolExecutor-1_0): 14:32:16  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:16.589647 (ThreadPoolExecutor-1_0): 14:32:16  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:16.589805 (ThreadPoolExecutor-1_0): 14:32:16  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:16.589925 (ThreadPoolExecutor-1_0): 14:32:16  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:32:16.601244 (ThreadPoolExecutor-1_0): 14:32:16  SQL status: SELECT in 0.01 seconds
2022-01-06 14:32:16.602944 (ThreadPoolExecutor-1_0): 14:32:16  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:32:16.605035 (ThreadPoolExecutor-1_0): 14:32:16  On list_dev_dbt_nobodozie: Close
2022-01-06 14:32:16.609166 (MainThread): 14:32:16  Using redshift connection "master"
2022-01-06 14:32:16.609311 (MainThread): 14:32:16  On master: BEGIN
2022-01-06 14:32:16.609395 (MainThread): 14:32:16  Opening a new connection, currently in state init
2022-01-06 14:32:16.609472 (MainThread): 14:32:16  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:16.631307 (MainThread): 14:32:16  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:16.631420 (MainThread): 14:32:16  Using redshift connection "master"
2022-01-06 14:32:16.631498 (MainThread): 14:32:16  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:32:16.659795 (MainThread): 14:32:16  SQL status: SELECT in 0.03 seconds
2022-01-06 14:32:16.660862 (MainThread): 14:32:16  On master: ROLLBACK
2022-01-06 14:32:16.662749 (MainThread): 14:32:16  Using redshift connection "master"
2022-01-06 14:32:16.662849 (MainThread): 14:32:16  On master: BEGIN
2022-01-06 14:32:16.666642 (MainThread): 14:32:16  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:16.666745 (MainThread): 14:32:16  On master: COMMIT
2022-01-06 14:32:16.666816 (MainThread): 14:32:16  Using redshift connection "master"
2022-01-06 14:32:16.666884 (MainThread): 14:32:16  On master: COMMIT
2022-01-06 14:32:16.668657 (MainThread): 14:32:16  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:32:16.668762 (MainThread): 14:32:16  On master: Close
2022-01-06 14:32:16.669161 (MainThread): 14:32:16  Concurrency: 4 threads (target='default')
2022-01-06 14:32:16.669307 (MainThread): 14:32:16  
2022-01-06 14:32:16.671822 (Thread-1): 14:32:16  Began running node model.my_new_project.dim_customers
2022-01-06 14:32:16.672180 (Thread-1): 14:32:16  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:32:16.672453 (Thread-1): 14:32:16  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:16.672548 (Thread-1): 14:32:16  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:32:16.672666 (Thread-1): 14:32:16  Compiling model.my_new_project.dim_customers
2022-01-06 14:32:16.674940 (Thread-1): 14:32:16  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:32:16.675175 (Thread-2): 14:32:16  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:16.675400 (Thread-2): 14:32:16  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:32:16.675649 (Thread-2): 14:32:16  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.675734 (Thread-2): 14:32:16  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:16.675814 (Thread-2): 14:32:16  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:32:16.677872 (Thread-2): 14:32:16  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.690489 (Thread-1): 14:32:16  finished collecting timing info
2022-01-06 14:32:16.690627 (Thread-1): 14:32:16  Began executing node model.my_new_project.dim_customers
2022-01-06 14:32:16.695619 (Thread-2): 14:32:16  finished collecting timing info
2022-01-06 14:32:16.695747 (Thread-2): 14:32:16  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:16.747320 (Thread-1): 14:32:16  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:32:16.748218 (Thread-2): 14:32:16  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.761840 (Thread-1): 14:32:16  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:16.761959 (Thread-1): 14:32:16  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:16.762044 (Thread-1): 14:32:16  Opening a new connection, currently in state closed
2022-01-06 14:32:16.762126 (Thread-1): 14:32:16  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:16.762376 (Thread-2): 14:32:16  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.762478 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:16.762556 (Thread-2): 14:32:16  Opening a new connection, currently in state init
2022-01-06 14:32:16.762630 (Thread-2): 14:32:16  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:16.786592 (Thread-1): 14:32:16  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:16.786709 (Thread-1): 14:32:16  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:16.786787 (Thread-1): 14:32:16  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:32:16.788896 (Thread-2): 14:32:16  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:32:16.789012 (Thread-2): 14:32:16  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.789091 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:32:16.868220 (Thread-2): 14:32:16  SQL status: SELECT in 0.08 seconds
2022-01-06 14:32:16.874493 (Thread-2): 14:32:16  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.874608 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:32:16.878890 (Thread-2): 14:32:16  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:16.880629 (Thread-2): 14:32:16  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.880732 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:32:16.885816 (Thread-2): 14:32:16  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:16.896238 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:16.896352 (Thread-2): 14:32:16  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.896429 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:16.900778 (Thread-1): 14:32:16  SQL status: SELECT in 0.11 seconds
2022-01-06 14:32:16.903693 (Thread-1): 14:32:16  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:16.903792 (Thread-1): 14:32:16  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:32:16.907207 (Thread-1): 14:32:16  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:16.908935 (Thread-1): 14:32:16  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:16.909033 (Thread-1): 14:32:16  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:32:16.912335 (Thread-1): 14:32:16  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:16.913696 (Thread-1): 14:32:16  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:16.913796 (Thread-1): 14:32:16  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:16.913871 (Thread-1): 14:32:16  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:16.952978 (Thread-69): handling poll request
2022-01-06 14:32:16.953406 (Thread-69): 14:32:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff98193ee0>]}
2022-01-06 14:32:16.956855 (Thread-69): sending response (<Response 38499 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:32:16.968427 (Thread-2): 14:32:16  SQL status: COMMIT in 0.07 seconds
2022-01-06 14:32:16.968662 (Thread-2): 14:32:16  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.968749 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:16.969122 (Thread-1): 14:32:16  SQL status: COMMIT in 0.06 seconds
2022-01-06 14:32:16.970901 (Thread-2): 14:32:16  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:16.974810 (Thread-2): 14:32:16  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.974908 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:32:16.979784 (Thread-2): 14:32:16  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:32:16.980725 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:16.980856 (Thread-2): 14:32:16  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.980967 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:17.010406 (Thread-2): 14:32:17  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:17.010531 (Thread-2): 14:32:17  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:17.010610 (Thread-2): 14:32:17  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:17.013064 (Thread-2): 14:32:17  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:17.013516 (Thread-2): 14:32:17  finished collecting timing info
2022-01-06 14:32:17.013671 (Thread-2): 14:32:17  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:32:17.013949 (Thread-1): 14:32:17  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:17.014063 (Thread-1): 14:32:17  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:17.016261 (Thread-1): 14:32:17  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:17.017503 (Thread-1): 14:32:17  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:17.017603 (Thread-1): 14:32:17  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:32:17.017894 (Thread-2): 14:32:17  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:32:17.018464 (Thread-2): 14:32:17  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89b90ef5-5a7b-4597-8c3e-6401a6831e24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a82f4be0>]}
2022-01-06 14:32:17.018821 (Thread-2): 14:32:17  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.34s]
2022-01-06 14:32:17.018962 (Thread-2): 14:32:17  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:17.019674 (Thread-4): 14:32:17  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:17.019922 (Thread-4): 14:32:17  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:32:17.020176 (Thread-4): 14:32:17  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.020288 (Thread-4): 14:32:17  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:17.020387 (Thread-4): 14:32:17  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:32:17.022580 (Thread-4): 14:32:17  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.022829 (Thread-1): 14:32:17  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 14:32:17.023517 (Thread-1): 14:32:17  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:17.023613 (Thread-1): 14:32:17  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:17.023689 (Thread-1): 14:32:17  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:17.037027 (Thread-4): 14:32:17  finished collecting timing info
2022-01-06 14:32:17.037170 (Thread-4): 14:32:17  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:17.053178 (Thread-4): 14:32:17  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.058081 (Thread-1): 14:32:17  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:17.058211 (Thread-1): 14:32:17  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:17.058291 (Thread-1): 14:32:17  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:17.060405 (Thread-1): 14:32:17  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:17.060797 (Thread-1): 14:32:17  finished collecting timing info
2022-01-06 14:32:17.060923 (Thread-1): 14:32:17  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:32:17.062719 (Thread-1): 14:32:17  On model.my_new_project.dim_customers: Close
2022-01-06 14:32:17.063180 (Thread-1): 14:32:17  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89b90ef5-5a7b-4597-8c3e-6401a6831e24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a833a730>]}
2022-01-06 14:32:17.063525 (Thread-1): 14:32:17  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.39s]
2022-01-06 14:32:17.063693 (Thread-1): 14:32:17  Finished running node model.my_new_project.dim_customers
2022-01-06 14:32:17.064780 (Thread-4): 14:32:17  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.064897 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:17.064982 (Thread-4): 14:32:17  Opening a new connection, currently in state init
2022-01-06 14:32:17.065064 (Thread-4): 14:32:17  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:17.594466 (Thread-4): 14:32:17  SQL status: BEGIN in 0.53 seconds
2022-01-06 14:32:17.594652 (Thread-4): 14:32:17  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.594746 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:32:17.599576 (Thread-4): 14:32:17  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:32:17.602087 (Thread-4): 14:32:17  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.602204 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:32:17.604411 (Thread-4): 14:32:17  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:17.605550 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:17.605653 (Thread-4): 14:32:17  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.605729 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:17.635650 (Thread-4): 14:32:17  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:17.635999 (Thread-4): 14:32:17  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.636092 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:17.638334 (Thread-4): 14:32:17  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:17.639917 (Thread-4): 14:32:17  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.640026 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:32:17.641986 (Thread-4): 14:32:17  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:32:17.642802 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:17.642900 (Thread-4): 14:32:17  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.642977 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:17.668719 (Thread-4): 14:32:17  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:17.668868 (Thread-4): 14:32:17  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.668949 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:17.671039 (Thread-4): 14:32:17  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:17.671557 (Thread-4): 14:32:17  finished collecting timing info
2022-01-06 14:32:17.671701 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:32:17.673576 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:32:17.674083 (Thread-4): 14:32:17  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89b90ef5-5a7b-4597-8c3e-6401a6831e24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a82c8e20>]}
2022-01-06 14:32:17.674426 (Thread-4): 14:32:17  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.65s]
2022-01-06 14:32:17.674540 (Thread-4): 14:32:17  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:17.676038 (MainThread): 14:32:17  Acquiring new redshift connection "master"
2022-01-06 14:32:17.676189 (MainThread): 14:32:17  Using redshift connection "master"
2022-01-06 14:32:17.676269 (MainThread): 14:32:17  On master: BEGIN
2022-01-06 14:32:17.676348 (MainThread): 14:32:17  Opening a new connection, currently in state closed
2022-01-06 14:32:17.676428 (MainThread): 14:32:17  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:17.701102 (MainThread): 14:32:17  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:17.701280 (MainThread): 14:32:17  On master: COMMIT
2022-01-06 14:32:17.701371 (MainThread): 14:32:17  Using redshift connection "master"
2022-01-06 14:32:17.701457 (MainThread): 14:32:17  On master: COMMIT
2022-01-06 14:32:17.703336 (MainThread): 14:32:17  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:32:17.703461 (MainThread): 14:32:17  On master: Close
2022-01-06 14:32:17.703944 (MainThread): 14:32:17  
2022-01-06 14:32:17.704059 (MainThread): 14:32:17  Finished running 2 table models, 1 view model in 1.18s.
2022-01-06 14:32:17.704141 (MainThread): 14:32:17  Connection 'master' was properly closed.
2022-01-06 14:32:17.704216 (MainThread): 14:32:17  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:32:17.704279 (MainThread): 14:32:17  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:32:17.704339 (MainThread): 14:32:17  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:32:17.771881 (MainThread): 14:32:17  
2022-01-06 14:32:17.772138 (MainThread): 14:32:17  Completed successfully
2022-01-06 14:32:17.772296 (MainThread): 14:32:17  
2022-01-06 14:32:17.772438 (MainThread): 14:32:17  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:32:18.381335 (Thread-70): handling poll request
2022-01-06 14:32:18.381678 (Thread-70): 14:32:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8024a30>]}
2022-01-06 14:32:18.383529 (Thread-70): sending response (<Response 48693 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:32:18.996813 (Thread-71): handling status request
2022-01-06 14:32:18.997193 (Thread-71): 14:32:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8040f70>]}
2022-01-06 14:32:18.997736 (Thread-71): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:32:19.031127 (Thread-72): handling status request
2022-01-06 14:32:19.034493 (Thread-72): 14:32:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8040a90>]}
2022-01-06 14:32:19.034962 (Thread-72): sending response (<Response 1544 bytes [200 OK]>) to 10.0.21.176
2022-01-06 14:32:25.551964 (Thread-73): handling status request
2022-01-06 14:32:25.552351 (Thread-73): 14:32:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8040190>]}
2022-01-06 14:32:25.552882 (Thread-73): sending response (<Response 1544 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:32:25.743760 (Thread-74): handling status request
2022-01-06 14:32:25.744051 (Thread-74): 14:32:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb80403d0>]}
2022-01-06 14:32:25.744506 (Thread-74): sending response (<Response 1544 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:32:25.917242 (Thread-75): handling cli_args request
2022-01-06 14:32:25.917595 (Thread-75): 14:32:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8051100>]}
2022-01-06 14:32:27.945080 (Thread-75): sending response (<Response 138 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:32:28.019872 (MainThread): 14:32:28  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:32:28.020251 (MainThread): 14:32:28  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:32:28.025784 (MainThread): 14:32:28  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a4ad54c5-1880-4281-835a-3b6c72461a7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf44f50d60>]}
2022-01-06 14:32:28.050065 (MainThread): 14:32:28  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a4ad54c5-1880-4281-835a-3b6c72461a7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf44fc7dc0>]}
2022-01-06 14:32:28.050299 (MainThread): 14:32:28  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:32:28.051347 (MainThread): 14:32:28  
2022-01-06 14:32:28.051612 (MainThread): 14:32:28  Acquiring new redshift connection "master"
2022-01-06 14:32:28.052526 (ThreadPoolExecutor-0_0): 14:32:28  Acquiring new redshift connection "list_dev"
2022-01-06 14:32:28.062207 (ThreadPoolExecutor-0_0): 14:32:28  Using redshift connection "list_dev"
2022-01-06 14:32:28.062310 (ThreadPoolExecutor-0_0): 14:32:28  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:32:28.062392 (ThreadPoolExecutor-0_0): 14:32:28  Opening a new connection, currently in state init
2022-01-06 14:32:28.062473 (ThreadPoolExecutor-0_0): 14:32:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:28.083825 (ThreadPoolExecutor-0_0): 14:32:28  SQL status: SELECT in 0.02 seconds
2022-01-06 14:32:28.084847 (ThreadPoolExecutor-0_0): 14:32:28  On list_dev: Close
2022-01-06 14:32:28.085992 (ThreadPoolExecutor-1_0): 14:32:28  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:28.092475 (ThreadPoolExecutor-1_0): 14:32:28  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:28.092575 (ThreadPoolExecutor-1_0): 14:32:28  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:32:28.092653 (ThreadPoolExecutor-1_0): 14:32:28  Opening a new connection, currently in state closed
2022-01-06 14:32:28.092725 (ThreadPoolExecutor-1_0): 14:32:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:28.115256 (ThreadPoolExecutor-1_0): 14:32:28  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:28.115366 (ThreadPoolExecutor-1_0): 14:32:28  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:28.115441 (ThreadPoolExecutor-1_0): 14:32:28  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:32:28.126737 (ThreadPoolExecutor-1_0): 14:32:28  SQL status: SELECT in 0.01 seconds
2022-01-06 14:32:28.127729 (ThreadPoolExecutor-1_0): 14:32:28  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:32:28.129552 (ThreadPoolExecutor-1_0): 14:32:28  On list_dev_dbt_nobodozie: Close
2022-01-06 14:32:28.133109 (MainThread): 14:32:28  Using redshift connection "master"
2022-01-06 14:32:28.133251 (MainThread): 14:32:28  On master: BEGIN
2022-01-06 14:32:28.133334 (MainThread): 14:32:28  Opening a new connection, currently in state init
2022-01-06 14:32:28.133409 (MainThread): 14:32:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:28.224963 (MainThread): 14:32:28  SQL status: BEGIN in 0.09 seconds
2022-01-06 14:32:28.225074 (MainThread): 14:32:28  Using redshift connection "master"
2022-01-06 14:32:28.225150 (MainThread): 14:32:28  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:32:28.253978 (MainThread): 14:32:28  SQL status: SELECT in 0.03 seconds
2022-01-06 14:32:28.254976 (MainThread): 14:32:28  On master: ROLLBACK
2022-01-06 14:32:28.257022 (MainThread): 14:32:28  Using redshift connection "master"
2022-01-06 14:32:28.257132 (MainThread): 14:32:28  On master: BEGIN
2022-01-06 14:32:28.260739 (MainThread): 14:32:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:28.260857 (MainThread): 14:32:28  On master: COMMIT
2022-01-06 14:32:28.260931 (MainThread): 14:32:28  Using redshift connection "master"
2022-01-06 14:32:28.261000 (MainThread): 14:32:28  On master: COMMIT
2022-01-06 14:32:28.262754 (MainThread): 14:32:28  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:32:28.262878 (MainThread): 14:32:28  On master: Close
2022-01-06 14:32:28.263373 (MainThread): 14:32:28  Concurrency: 4 threads (target='default')
2022-01-06 14:32:28.263497 (MainThread): 14:32:28  
2022-01-06 14:32:28.265857 (Thread-1): 14:32:28  Began running node model.my_new_project.dim_customers
2022-01-06 14:32:28.266108 (Thread-1): 14:32:28  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:32:28.266362 (Thread-1): 14:32:28  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.266456 (Thread-1): 14:32:28  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:32:28.266552 (Thread-1): 14:32:28  Compiling model.my_new_project.dim_customers
2022-01-06 14:32:28.268731 (Thread-1): 14:32:28  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:32:28.268961 (Thread-2): 14:32:28  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:28.269211 (Thread-2): 14:32:28  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:32:28.269474 (Thread-2): 14:32:28  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.269560 (Thread-2): 14:32:28  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:28.269642 (Thread-2): 14:32:28  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:32:28.271679 (Thread-2): 14:32:28  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.282940 (Thread-2): 14:32:28  finished collecting timing info
2022-01-06 14:32:28.283090 (Thread-2): 14:32:28  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:28.288306 (Thread-1): 14:32:28  finished collecting timing info
2022-01-06 14:32:28.288448 (Thread-1): 14:32:28  Began executing node model.my_new_project.dim_customers
2022-01-06 14:32:28.333846 (Thread-76): handling poll request
2022-01-06 14:32:28.331408 (Thread-2): 14:32:28  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.334419 (Thread-76): 14:32:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8040d60>]}
2022-01-06 14:32:28.333203 (Thread-1): 14:32:28  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:32:28.335937 (Thread-76): sending response (<Response 23716 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:32:28.345045 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.345152 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:28.345268 (Thread-1): 14:32:28  Opening a new connection, currently in state closed
2022-01-06 14:32:28.345350 (Thread-1): 14:32:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:28.345597 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.345697 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:28.345774 (Thread-2): 14:32:28  Opening a new connection, currently in state init
2022-01-06 14:32:28.345849 (Thread-2): 14:32:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:28.371992 (Thread-2): 14:32:28  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:32:28.372103 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.372180 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:32:28.372439 (Thread-1): 14:32:28  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:32:28.372549 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.372625 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:32:28.467929 (Thread-2): 14:32:28  SQL status: SELECT in 0.1 seconds
2022-01-06 14:32:28.473607 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.473712 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:32:28.482022 (Thread-2): 14:32:28  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:32:28.483906 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.484004 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:32:28.487005 (Thread-2): 14:32:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:28.497989 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:28.498113 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.498190 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:28.514722 (Thread-1): 14:32:28  SQL status: SELECT in 0.14 seconds
2022-01-06 14:32:28.516511 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.516607 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:32:28.520693 (Thread-1): 14:32:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:28.523362 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.523458 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:32:28.526549 (Thread-1): 14:32:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:28.527589 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:28.527684 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.527755 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:28.563779 (Thread-2): 14:32:28  SQL status: COMMIT in 0.07 seconds
2022-01-06 14:32:28.563998 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.564081 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:28.564305 (Thread-1): 14:32:28  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:32:28.566246 (Thread-2): 14:32:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:28.570189 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.570288 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:32:28.575251 (Thread-2): 14:32:28  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:32:28.575878 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:28.575974 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.576055 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:28.605341 (Thread-2): 14:32:28  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:28.605455 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.605529 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:28.607645 (Thread-2): 14:32:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:28.608021 (Thread-2): 14:32:28  finished collecting timing info
2022-01-06 14:32:28.608146 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:32:28.608356 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.608465 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:28.610849 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:32:28.611047 (Thread-1): 14:32:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:28.612136 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.612231 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:32:28.612654 (Thread-2): 14:32:28  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4ad54c5-1880-4281-835a-3b6c72461a7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf44679f70>]}
2022-01-06 14:32:28.612972 (Thread-2): 14:32:28  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.34s]
2022-01-06 14:32:28.613085 (Thread-2): 14:32:28  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:28.613824 (Thread-4): 14:32:28  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:28.614059 (Thread-4): 14:32:28  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:32:28.614480 (Thread-4): 14:32:28  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.614576 (Thread-4): 14:32:28  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:28.614662 (Thread-4): 14:32:28  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:32:28.616443 (Thread-4): 14:32:28  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.616992 (Thread-1): 14:32:28  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:32:28.617647 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:28.617742 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.617816 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:28.629283 (Thread-4): 14:32:28  finished collecting timing info
2022-01-06 14:32:28.629420 (Thread-4): 14:32:28  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:28.644806 (Thread-4): 14:32:28  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.650979 (Thread-1): 14:32:28  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:28.651098 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.651171 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:28.653518 (Thread-1): 14:32:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:28.653867 (Thread-1): 14:32:28  finished collecting timing info
2022-01-06 14:32:28.653986 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:32:28.655642 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: Close
2022-01-06 14:32:28.656036 (Thread-1): 14:32:28  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4ad54c5-1880-4281-835a-3b6c72461a7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf4468c610>]}
2022-01-06 14:32:28.656325 (Thread-1): 14:32:28  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.39s]
2022-01-06 14:32:28.656432 (Thread-1): 14:32:28  Finished running node model.my_new_project.dim_customers
2022-01-06 14:32:28.657350 (Thread-4): 14:32:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.657465 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:28.657548 (Thread-4): 14:32:28  Opening a new connection, currently in state init
2022-01-06 14:32:28.657627 (Thread-4): 14:32:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:28.681740 (Thread-4): 14:32:28  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:28.681865 (Thread-4): 14:32:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.681943 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:32:28.686841 (Thread-4): 14:32:28  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:32:28.688599 (Thread-4): 14:32:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.688694 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:32:28.691147 (Thread-4): 14:32:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:28.692041 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:28.692134 (Thread-4): 14:32:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.692206 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:28.724094 (Thread-4): 14:32:28  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:28.724311 (Thread-4): 14:32:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.724395 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:28.726550 (Thread-4): 14:32:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:28.727759 (Thread-4): 14:32:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.727856 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:32:28.729816 (Thread-4): 14:32:28  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:32:28.730472 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:28.730566 (Thread-4): 14:32:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.730640 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:28.754835 (Thread-4): 14:32:28  SQL status: COMMIT in 0.02 seconds
2022-01-06 14:32:28.754945 (Thread-4): 14:32:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.755017 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:28.757200 (Thread-4): 14:32:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:28.757576 (Thread-4): 14:32:28  finished collecting timing info
2022-01-06 14:32:28.757694 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:32:28.759386 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:32:28.759755 (Thread-4): 14:32:28  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4ad54c5-1880-4281-835a-3b6c72461a7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf4470ccd0>]}
2022-01-06 14:32:28.760036 (Thread-4): 14:32:28  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.15s]
2022-01-06 14:32:28.760138 (Thread-4): 14:32:28  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:28.761536 (MainThread): 14:32:28  Acquiring new redshift connection "master"
2022-01-06 14:32:28.761677 (MainThread): 14:32:28  Using redshift connection "master"
2022-01-06 14:32:28.761755 (MainThread): 14:32:28  On master: BEGIN
2022-01-06 14:32:28.761831 (MainThread): 14:32:28  Opening a new connection, currently in state closed
2022-01-06 14:32:28.761925 (MainThread): 14:32:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:28.786573 (MainThread): 14:32:28  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:28.786690 (MainThread): 14:32:28  On master: COMMIT
2022-01-06 14:32:28.786764 (MainThread): 14:32:28  Using redshift connection "master"
2022-01-06 14:32:28.786833 (MainThread): 14:32:28  On master: COMMIT
2022-01-06 14:32:28.788579 (MainThread): 14:32:28  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:32:28.788692 (MainThread): 14:32:28  On master: Close
2022-01-06 14:32:28.789137 (MainThread): 14:32:28  
2022-01-06 14:32:28.789284 (MainThread): 14:32:28  Finished running 2 table models, 1 view model in 0.74s.
2022-01-06 14:32:28.789371 (MainThread): 14:32:28  Connection 'master' was properly closed.
2022-01-06 14:32:28.789457 (MainThread): 14:32:28  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:32:28.789566 (MainThread): 14:32:28  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:32:28.789676 (MainThread): 14:32:28  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:32:28.840604 (MainThread): 14:32:28  
2022-01-06 14:32:28.840796 (MainThread): 14:32:28  Completed successfully
2022-01-06 14:32:28.840904 (MainThread): 14:32:28  
2022-01-06 14:32:28.840994 (MainThread): 14:32:28  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:32:29.761072 (Thread-77): handling poll request
2022-01-06 14:32:29.761482 (Thread-77): 14:32:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9814f250>]}
2022-01-06 14:32:29.763725 (Thread-77): sending response (<Response 63477 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:32:30.419180 (Thread-78): handling status request
2022-01-06 14:32:30.419539 (Thread-78): 14:32:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9814f130>]}
2022-01-06 14:32:30.420038 (Thread-78): sending response (<Response 1544 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:32:30.729569 (Thread-79): handling status request
2022-01-06 14:32:30.729957 (Thread-79): 14:32:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9814f6a0>]}
2022-01-06 14:32:30.730443 (Thread-79): sending response (<Response 1544 bytes [200 OK]>) to 10.0.5.191
2022-01-06 14:33:29.790718 (Thread-80): handling status request
2022-01-06 14:33:29.791091 (Thread-80): 14:33:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9814f880>]}
2022-01-06 14:33:29.791562 (Thread-80): sending response (<Response 1544 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:33:30.016887 (Thread-81): handling status request
2022-01-06 14:33:30.017253 (Thread-81): 14:33:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9814fb50>]}
2022-01-06 14:33:30.017714 (Thread-81): sending response (<Response 1544 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:33:30.111158 (Thread-82): handling cli_args request
2022-01-06 14:33:30.111498 (Thread-82): 14:33:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9814fdc0>]}
2022-01-06 14:33:32.278189 (Thread-82): sending response (<Response 138 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:33:32.364809 (MainThread): 14:33:32  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:33:32.365251 (MainThread): 14:33:32  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:33:32.370902 (MainThread): 14:33:32  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '90bdc5b0-c565-4a2e-897d-16812ba900de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4279f9d60>]}
2022-01-06 14:33:32.395165 (MainThread): 14:33:32  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '90bdc5b0-c565-4a2e-897d-16812ba900de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe427a70dc0>]}
2022-01-06 14:33:32.395407 (MainThread): 14:33:32  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:33:32.396463 (MainThread): 14:33:32  
2022-01-06 14:33:32.396728 (MainThread): 14:33:32  Acquiring new redshift connection "master"
2022-01-06 14:33:32.397711 (ThreadPoolExecutor-0_0): 14:33:32  Acquiring new redshift connection "list_dev"
2022-01-06 14:33:32.407738 (ThreadPoolExecutor-0_0): 14:33:32  Using redshift connection "list_dev"
2022-01-06 14:33:32.407845 (ThreadPoolExecutor-0_0): 14:33:32  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:33:32.407945 (ThreadPoolExecutor-0_0): 14:33:32  Opening a new connection, currently in state init
2022-01-06 14:33:32.408047 (ThreadPoolExecutor-0_0): 14:33:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:33:32.428638 (ThreadPoolExecutor-0_0): 14:33:32  SQL status: SELECT in 0.02 seconds
2022-01-06 14:33:32.429711 (ThreadPoolExecutor-0_0): 14:33:32  On list_dev: Close
2022-01-06 14:33:32.430874 (ThreadPoolExecutor-1_0): 14:33:32  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:33:32.437246 (ThreadPoolExecutor-1_0): 14:33:32  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:33:32.437348 (ThreadPoolExecutor-1_0): 14:33:32  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:33:32.437429 (ThreadPoolExecutor-1_0): 14:33:32  Opening a new connection, currently in state closed
2022-01-06 14:33:32.437507 (ThreadPoolExecutor-1_0): 14:33:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:33:32.458378 (ThreadPoolExecutor-1_0): 14:33:32  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:33:32.458487 (ThreadPoolExecutor-1_0): 14:33:32  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:33:32.458574 (ThreadPoolExecutor-1_0): 14:33:32  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:33:32.469471 (ThreadPoolExecutor-1_0): 14:33:32  SQL status: SELECT in 0.01 seconds
2022-01-06 14:33:32.470452 (ThreadPoolExecutor-1_0): 14:33:32  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:33:32.472267 (ThreadPoolExecutor-1_0): 14:33:32  On list_dev_dbt_nobodozie: Close
2022-01-06 14:33:32.475865 (MainThread): 14:33:32  Using redshift connection "master"
2022-01-06 14:33:32.475977 (MainThread): 14:33:32  On master: BEGIN
2022-01-06 14:33:32.476059 (MainThread): 14:33:32  Opening a new connection, currently in state init
2022-01-06 14:33:32.476135 (MainThread): 14:33:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:33:32.499384 (MainThread): 14:33:32  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:33:32.499496 (MainThread): 14:33:32  Using redshift connection "master"
2022-01-06 14:33:32.499572 (MainThread): 14:33:32  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:33:32.528462 (MainThread): 14:33:32  SQL status: SELECT in 0.03 seconds
2022-01-06 14:33:32.529442 (MainThread): 14:33:32  On master: ROLLBACK
2022-01-06 14:33:32.531227 (MainThread): 14:33:32  Using redshift connection "master"
2022-01-06 14:33:32.531327 (MainThread): 14:33:32  On master: BEGIN
2022-01-06 14:33:32.534768 (MainThread): 14:33:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:33:32.534878 (MainThread): 14:33:32  On master: COMMIT
2022-01-06 14:33:32.534951 (MainThread): 14:33:32  Using redshift connection "master"
2022-01-06 14:33:32.535018 (MainThread): 14:33:32  On master: COMMIT
2022-01-06 14:33:32.536695 (MainThread): 14:33:32  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:33:32.536805 (MainThread): 14:33:32  On master: Close
2022-01-06 14:33:32.537172 (MainThread): 14:33:32  Concurrency: 4 threads (target='default')
2022-01-06 14:33:32.537317 (MainThread): 14:33:32  
2022-01-06 14:33:32.539520 (Thread-1): 14:33:32  Began running node model.my_new_project.dim_customers
2022-01-06 14:33:32.539752 (Thread-1): 14:33:32  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:33:32.539979 (Thread-1): 14:33:32  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.540071 (Thread-1): 14:33:32  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:33:32.540168 (Thread-1): 14:33:32  Compiling model.my_new_project.dim_customers
2022-01-06 14:33:32.542189 (Thread-1): 14:33:32  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:33:32.542421 (Thread-2): 14:33:32  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:33:32.542647 (Thread-2): 14:33:32  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:33:32.542892 (Thread-2): 14:33:32  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.542978 (Thread-2): 14:33:32  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:33:32.543060 (Thread-2): 14:33:32  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:33:32.545113 (Thread-2): 14:33:32  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.558539 (Thread-1): 14:33:32  finished collecting timing info
2022-01-06 14:33:32.558678 (Thread-1): 14:33:32  Began executing node model.my_new_project.dim_customers
2022-01-06 14:33:32.563729 (Thread-2): 14:33:32  finished collecting timing info
2022-01-06 14:33:32.563860 (Thread-2): 14:33:32  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:33:32.598411 (Thread-83): handling poll request
2022-01-06 14:33:32.598801 (Thread-83): 14:33:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff98171e50>]}
2022-01-06 14:33:32.599998 (Thread-83): sending response (<Response 22988 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:33:32.613876 (Thread-2): 14:33:32  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.616155 (Thread-1): 14:33:32  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:33:32.629384 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.629506 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:33:32.629594 (Thread-2): 14:33:32  Opening a new connection, currently in state init
2022-01-06 14:33:32.629678 (Thread-2): 14:33:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:33:32.629930 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.630034 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:33:32.630114 (Thread-1): 14:33:32  Opening a new connection, currently in state closed
2022-01-06 14:33:32.630192 (Thread-1): 14:33:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:33:32.656685 (Thread-1): 14:33:32  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:33:32.656854 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.656944 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:33:32.657129 (Thread-2): 14:33:32  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:33:32.657283 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.657364 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:33:32.739177 (Thread-2): 14:33:32  SQL status: SELECT in 0.08 seconds
2022-01-06 14:33:32.746637 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.746962 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:33:32.750848 (Thread-2): 14:33:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:33:32.752994 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.753112 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:33:32.756850 (Thread-2): 14:33:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:33:32.767235 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:33:32.767350 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.767427 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:33:32.770343 (Thread-1): 14:33:32  SQL status: SELECT in 0.11 seconds
2022-01-06 14:33:32.773268 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.773373 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:33:32.777410 (Thread-1): 14:33:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:33:32.779071 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.779167 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:33:32.784019 (Thread-1): 14:33:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:33:32.785094 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:33:32.785191 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.785305 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:33:32.828945 (Thread-2): 14:33:32  SQL status: COMMIT in 0.06 seconds
2022-01-06 14:33:32.829165 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.829275 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:33:32.829498 (Thread-1): 14:33:32  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:33:32.831371 (Thread-2): 14:33:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:33:32.835396 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.835495 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:33:32.840350 (Thread-2): 14:33:32  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:33:32.840977 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:33:32.841072 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.841146 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:33:32.871762 (Thread-2): 14:33:32  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:33:32.871879 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.871953 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:33:32.874017 (Thread-2): 14:33:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:33:32.874436 (Thread-2): 14:33:32  finished collecting timing info
2022-01-06 14:33:32.874567 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:33:32.874765 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.874871 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:33:32.877355 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:33:32.877496 (Thread-1): 14:33:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:33:32.878771 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.878866 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:33:32.879295 (Thread-2): 14:33:32  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90bdc5b0-c565-4a2e-897d-16812ba900de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe424134a90>]}
2022-01-06 14:33:32.879684 (Thread-2): 14:33:32  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.34s]
2022-01-06 14:33:32.879804 (Thread-2): 14:33:32  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:33:32.880529 (Thread-4): 14:33:32  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:33:32.880774 (Thread-4): 14:33:32  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:33:32.881035 (Thread-4): 14:33:32  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.881125 (Thread-4): 14:33:32  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:33:32.881241 (Thread-4): 14:33:32  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:33:32.883247 (Thread-4): 14:33:32  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.883805 (Thread-1): 14:33:32  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:33:32.884460 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:33:32.884556 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.884632 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:33:32.897349 (Thread-4): 14:33:32  finished collecting timing info
2022-01-06 14:33:32.897489 (Thread-4): 14:33:32  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:33:32.912985 (Thread-4): 14:33:32  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.916399 (Thread-1): 14:33:32  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:33:32.916522 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.916600 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:33:32.918626 (Thread-1): 14:33:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:33:32.918997 (Thread-1): 14:33:32  finished collecting timing info
2022-01-06 14:33:32.919121 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:33:32.920850 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: Close
2022-01-06 14:33:32.921347 (Thread-1): 14:33:32  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90bdc5b0-c565-4a2e-897d-16812ba900de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe424134be0>]}
2022-01-06 14:33:32.921727 (Thread-1): 14:33:32  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.38s]
2022-01-06 14:33:32.921842 (Thread-1): 14:33:32  Finished running node model.my_new_project.dim_customers
2022-01-06 14:33:32.927308 (Thread-4): 14:33:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.927422 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:33:32.927508 (Thread-4): 14:33:32  Opening a new connection, currently in state init
2022-01-06 14:33:32.927591 (Thread-4): 14:33:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:33:32.948728 (Thread-4): 14:33:32  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:33:32.948844 (Thread-4): 14:33:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.948921 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:33:32.953657 (Thread-4): 14:33:32  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:33:32.955460 (Thread-4): 14:33:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.955553 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:33:32.957683 (Thread-4): 14:33:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:33:32.958617 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:33:32.958712 (Thread-4): 14:33:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.958787 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:33:32.989390 (Thread-4): 14:33:32  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:33:32.989609 (Thread-4): 14:33:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.989696 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:33:32.992516 (Thread-4): 14:33:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:33:32.993772 (Thread-4): 14:33:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.993868 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:33:32.996465 (Thread-4): 14:33:32  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:33:32.997150 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:33:32.997280 (Thread-4): 14:33:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.997360 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:33:33.030503 (Thread-4): 14:33:33  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:33:33.030625 (Thread-4): 14:33:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:33.030702 (Thread-4): 14:33:33  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:33:33.032839 (Thread-4): 14:33:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:33:33.033295 (Thread-4): 14:33:33  finished collecting timing info
2022-01-06 14:33:33.033433 (Thread-4): 14:33:33  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:33:33.035195 (Thread-4): 14:33:33  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:33:33.035672 (Thread-4): 14:33:33  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90bdc5b0-c565-4a2e-897d-16812ba900de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe42408cb80>]}
2022-01-06 14:33:33.035997 (Thread-4): 14:33:33  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.15s]
2022-01-06 14:33:33.036109 (Thread-4): 14:33:33  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:33:33.037602 (MainThread): 14:33:33  Acquiring new redshift connection "master"
2022-01-06 14:33:33.037745 (MainThread): 14:33:33  Using redshift connection "master"
2022-01-06 14:33:33.037824 (MainThread): 14:33:33  On master: BEGIN
2022-01-06 14:33:33.037903 (MainThread): 14:33:33  Opening a new connection, currently in state closed
2022-01-06 14:33:33.037984 (MainThread): 14:33:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:33:33.061178 (MainThread): 14:33:33  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:33:33.061353 (MainThread): 14:33:33  On master: COMMIT
2022-01-06 14:33:33.061435 (MainThread): 14:33:33  Using redshift connection "master"
2022-01-06 14:33:33.061506 (MainThread): 14:33:33  On master: COMMIT
2022-01-06 14:33:33.063236 (MainThread): 14:33:33  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:33:33.063347 (MainThread): 14:33:33  On master: Close
2022-01-06 14:33:33.063753 (MainThread): 14:33:33  
2022-01-06 14:33:33.063868 (MainThread): 14:33:33  Finished running 2 table models, 1 view model in 0.67s.
2022-01-06 14:33:33.063950 (MainThread): 14:33:33  Connection 'master' was properly closed.
2022-01-06 14:33:33.064018 (MainThread): 14:33:33  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:33:33.064081 (MainThread): 14:33:33  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:33:33.064142 (MainThread): 14:33:33  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:33:33.114237 (MainThread): 14:33:33  
2022-01-06 14:33:33.114391 (MainThread): 14:33:33  Completed successfully
2022-01-06 14:33:33.114488 (MainThread): 14:33:33  
2022-01-06 14:33:33.114574 (MainThread): 14:33:33  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:33:33.915781 (Thread-84): handling poll request
2022-01-06 14:33:33.916139 (Thread-84): 14:33:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9812a610>]}
2022-01-06 14:33:33.918534 (Thread-84): sending response (<Response 64203 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:33:34.555498 (Thread-85): handling status request
2022-01-06 14:33:34.555860 (Thread-85): 14:33:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9812a7c0>]}
2022-01-06 14:33:34.556361 (Thread-85): sending response (<Response 1544 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:33:34.622730 (Thread-86): handling status request
2022-01-06 14:33:34.623008 (Thread-86): 14:33:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9812abb0>]}
2022-01-06 14:33:34.623430 (Thread-86): sending response (<Response 1544 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:34:44.217137 (Thread-87): handling status request
2022-01-06 14:34:44.218722 (Thread-87): 14:34:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9812adf0>]}
2022-01-06 14:34:44.219202 (Thread-87): sending response (<Response 1544 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:34:44.548211 (Thread-88): handling run_sql request
2022-01-06 14:34:44.548547 (Thread-88): 14:34:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9811f5b0>]}
2022-01-06 14:34:46.649670 (Thread-88): sending response (<Response 138 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:34:46.676824 (MainThread): 14:34:46  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c364d61f-2d97-49fe-aa0f-c7d8a4c9300a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8441e7970>]}
2022-01-06 14:34:46.677367 (MainThread): 14:34:46  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:34:46.677924 (Thread-1): 14:34:46  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:34:46.678052 (Thread-1): 14:34:46  Began compiling node rpc.my_new_project.request
2022-01-06 14:34:46.678150 (Thread-1): 14:34:46  Compiling rpc.my_new_project.request
2022-01-06 14:34:46.680651 (Thread-1): 14:34:46  finished collecting timing info
2022-01-06 14:34:46.680778 (Thread-1): 14:34:46  Began executing node rpc.my_new_project.request
2022-01-06 14:34:46.680872 (Thread-1): 14:34:46  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:34:46.680946 (Thread-1): 14:34:46  On rpc.my_new_project.request: 

with customers as (
    select * from "dev"."dbt_nobodozie"."stg_customers"
),
orders as (
    select * from "dev"."dbt_nobodozie"."stg_orders"
),
customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:34:46.681022 (Thread-1): 14:34:46  Opening a new connection, currently in state init
2022-01-06 14:34:46.681101 (Thread-1): 14:34:46  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:34:46.706363 (Thread-1): 14:34:46  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 14:34:46.706592 (Thread-1): 14:34:46  finished collecting timing info
2022-01-06 14:34:46.706778 (Thread-1): 14:34:46  On rpc.my_new_project.request: Close
2022-01-06 14:34:46.707051 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 14:34:46.708427 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n    select * from {{ref(\'stg_customers\')}}\n),\norders as (\n    select * from {{ref(\'stg_orders\')}}\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\norders as (\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n    select * from {{ref(\'stg_customers\')}}\n),\norders as (\n    select * from {{ref(\'stg_orders\')}}\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\norders as (\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 14:34:47.084253 (Thread-89): handling poll request
2022-01-06 14:34:47.084686 (Thread-89): 14:34:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980be2e0>]}
2022-01-06 14:34:47.085534 (Thread-89): sending response (<Response 14613 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:35:12.141930 (Thread-90): handling status request
2022-01-06 14:35:12.142288 (Thread-90): 14:35:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980be7f0>]}
2022-01-06 14:35:12.142814 (Thread-90): sending response (<Response 1544 bytes [200 OK]>) to 10.0.40.39
2022-01-06 14:35:12.501932 (Thread-91): handling compile_sql request
2022-01-06 14:35:12.502234 (Thread-91): 14:35:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980beaf0>]}
2022-01-06 14:35:14.568667 (Thread-91): sending response (<Response 138 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:35:14.594087 (MainThread): 14:35:14  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '73df3c1b-9ba4-4c55-9e81-15667f4580cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa48cbcd9a0>]}
2022-01-06 14:35:14.594616 (MainThread): 14:35:14  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:35:14.595185 (Thread-1): 14:35:14  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:35:14.595315 (Thread-1): 14:35:14  Began compiling node rpc.my_new_project.request
2022-01-06 14:35:14.595406 (Thread-1): 14:35:14  Compiling rpc.my_new_project.request
2022-01-06 14:35:14.597885 (Thread-1): 14:35:14  finished collecting timing info
2022-01-06 14:35:14.598013 (Thread-1): 14:35:14  Began executing node rpc.my_new_project.request
2022-01-06 14:35:14.598111 (Thread-1): 14:35:14  finished collecting timing info
2022-01-06 14:35:14.906320 (Thread-92): handling poll request
2022-01-06 14:35:14.906757 (Thread-92): 14:35:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980c6370>]}
2022-01-06 14:35:14.907824 (Thread-92): sending response (<Response 8440 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:36:38.627614 (Thread-93): handling status request
2022-01-06 14:36:38.629123 (Thread-93): 14:36:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980c6520>]}
2022-01-06 14:36:38.629712 (Thread-93): sending response (<Response 1544 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:36:39.059130 (Thread-94): handling run_sql request
2022-01-06 14:36:39.059488 (Thread-94): 14:36:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980c6910>]}
2022-01-06 14:36:41.159494 (Thread-94): sending response (<Response 138 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:36:41.186758 (MainThread): 14:36:41  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '72cfb2cc-c81b-47b2-bb51-c59e6ff3733f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c2f8b6a60>]}
2022-01-06 14:36:41.187333 (MainThread): 14:36:41  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:36:41.188003 (Thread-1): 14:36:41  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:36:41.188137 (Thread-1): 14:36:41  Began compiling node rpc.my_new_project.request
2022-01-06 14:36:41.188237 (Thread-1): 14:36:41  Compiling rpc.my_new_project.request
2022-01-06 14:36:41.190799 (Thread-1): 14:36:41  finished collecting timing info
2022-01-06 14:36:41.190926 (Thread-1): 14:36:41  Began executing node rpc.my_new_project.request
2022-01-06 14:36:41.191021 (Thread-1): 14:36:41  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:36:41.191095 (Thread-1): 14:36:41  On rpc.my_new_project.request: 

with customers as (
    select * from "dev"."dbt_nobodozie"."stg_customers"
),
orders as (
    select * from "dev"."dbt_nobodozie"."stg_orders"
),
customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:36:41.191171 (Thread-1): 14:36:41  Opening a new connection, currently in state init
2022-01-06 14:36:41.191249 (Thread-1): 14:36:41  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:36:41.211581 (Thread-1): 14:36:41  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 14:36:41.211733 (Thread-1): 14:36:41  finished collecting timing info
2022-01-06 14:36:41.211845 (Thread-1): 14:36:41  On rpc.my_new_project.request: Close
2022-01-06 14:36:41.212110 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 14:36:41.213044 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n    select * from {{ref(\'stg_customers\')}}\n),\norders as (\n    select * from {{ref(\'stg_orders\')}}\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\norders as (\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n    select * from {{ref(\'stg_customers\')}}\n),\norders as (\n    select * from {{ref(\'stg_orders\')}}\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\norders as (\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 14:36:41.597461 (Thread-95): handling poll request
2022-01-06 14:36:41.597884 (Thread-95): 14:36:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980cbb20>]}
2022-01-06 14:36:41.598710 (Thread-95): sending response (<Response 14613 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:36:43.399729 (Thread-96): handling status request
2022-01-06 14:36:43.400102 (Thread-96): 14:36:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980d8070>]}
2022-01-06 14:36:43.423259 (Thread-96): sending response (<Response 1544 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:36:43.902536 (Thread-97): handling compile_sql request
2022-01-06 14:36:43.902922 (Thread-97): 14:36:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980d81f0>]}
2022-01-06 14:36:45.985960 (Thread-97): sending response (<Response 138 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:36:46.011269 (MainThread): 14:36:46  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dd7f2c92-d136-4d33-a0fa-924e024900aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f169a6cfa90>]}
2022-01-06 14:36:46.011773 (MainThread): 14:36:46  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:36:46.012336 (Thread-1): 14:36:46  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:36:46.012468 (Thread-1): 14:36:46  Began compiling node rpc.my_new_project.request
2022-01-06 14:36:46.012558 (Thread-1): 14:36:46  Compiling rpc.my_new_project.request
2022-01-06 14:36:46.015075 (Thread-1): 14:36:46  finished collecting timing info
2022-01-06 14:36:46.015202 (Thread-1): 14:36:46  Began executing node rpc.my_new_project.request
2022-01-06 14:36:46.015297 (Thread-1): 14:36:46  finished collecting timing info
2022-01-06 14:36:46.399857 (Thread-98): handling poll request
2022-01-06 14:36:46.400261 (Thread-98): 14:36:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980dd340>]}
2022-01-06 14:36:46.401364 (Thread-98): sending response (<Response 8440 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:36:50.104693 (Thread-99): handling status request
2022-01-06 14:36:50.105049 (Thread-99): 14:36:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980dd3d0>]}
2022-01-06 14:36:50.105647 (Thread-99): sending response (<Response 1544 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:36:50.424477 (Thread-100): handling run_sql request
2022-01-06 14:36:50.424844 (Thread-100): 14:36:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980dda60>]}
2022-01-06 14:36:52.461004 (Thread-100): sending response (<Response 138 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:36:52.486212 (MainThread): 14:36:52  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '468ab41c-cb3e-4ee2-9943-c3d5020ece6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2bcb8707c0>]}
2022-01-06 14:36:52.486718 (MainThread): 14:36:52  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:36:52.487267 (Thread-1): 14:36:52  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:36:52.487396 (Thread-1): 14:36:52  Began compiling node rpc.my_new_project.request
2022-01-06 14:36:52.487487 (Thread-1): 14:36:52  Compiling rpc.my_new_project.request
2022-01-06 14:36:52.490003 (Thread-1): 14:36:52  finished collecting timing info
2022-01-06 14:36:52.490127 (Thread-1): 14:36:52  Began executing node rpc.my_new_project.request
2022-01-06 14:36:52.490222 (Thread-1): 14:36:52  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:36:52.490296 (Thread-1): 14:36:52  On rpc.my_new_project.request: 

with customers as (
    select * from "dev"."dbt_nobodozie"."stg_customers"
),
orders as (
    select * from "dev"."dbt_nobodozie"."stg_orders"
),
customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:36:52.490370 (Thread-1): 14:36:52  Opening a new connection, currently in state init
2022-01-06 14:36:52.490445 (Thread-1): 14:36:52  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:36:52.510314 (Thread-1): 14:36:52  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 14:36:52.510463 (Thread-1): 14:36:52  finished collecting timing info
2022-01-06 14:36:52.510577 (Thread-1): 14:36:52  On rpc.my_new_project.request: Close
2022-01-06 14:36:52.510746 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 14:36:52.511763 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n    select * from {{ref(\'stg_customers\')}}\n),\norders as (\n    select * from {{ref(\'stg_orders\')}}\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\norders as (\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n    select * from {{ref(\'stg_customers\')}}\n),\norders as (\n    select * from {{ref(\'stg_orders\')}}\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\norders as (\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 14:36:52.785980 (Thread-101): handling poll request
2022-01-06 14:36:52.786408 (Thread-101): 14:36:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980e5b80>]}
2022-01-06 14:36:52.787219 (Thread-101): sending response (<Response 14613 bytes [200 OK]>) to 10.0.40.39
2022-01-06 14:37:09.981316 (Thread-102): handling status request
2022-01-06 14:37:09.981699 (Thread-102): 14:37:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980ef0d0>]}
2022-01-06 14:37:09.982233 (Thread-102): sending response (<Response 1544 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:37:10.180519 (Thread-103): handling status request
2022-01-06 14:37:10.180880 (Thread-103): 14:37:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980ef3d0>]}
2022-01-06 14:37:10.181395 (Thread-103): sending response (<Response 1544 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:37:10.349665 (Thread-104): handling cli_args request
2022-01-06 14:37:10.350096 (Thread-104): 14:37:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980ef640>]}
2022-01-06 14:37:12.424129 (Thread-104): sending response (<Response 138 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:37:12.513069 (MainThread): 14:37:12  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:37:12.513516 (MainThread): 14:37:12  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:37:12.519922 (MainThread): 14:37:12  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a6514d0f-3cb5-4a04-bba7-e84a22dbcc78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d51c8bca0>]}
2022-01-06 14:37:12.547370 (MainThread): 14:37:12  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a6514d0f-3cb5-4a04-bba7-e84a22dbcc78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d51d01d00>]}
2022-01-06 14:37:12.547636 (MainThread): 14:37:12  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:37:12.548732 (MainThread): 14:37:12  
2022-01-06 14:37:12.549020 (MainThread): 14:37:12  Acquiring new redshift connection "master"
2022-01-06 14:37:12.550088 (ThreadPoolExecutor-0_0): 14:37:12  Acquiring new redshift connection "list_dev"
2022-01-06 14:37:12.559843 (ThreadPoolExecutor-0_0): 14:37:12  Using redshift connection "list_dev"
2022-01-06 14:37:12.560108 (ThreadPoolExecutor-0_0): 14:37:12  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:37:12.560195 (ThreadPoolExecutor-0_0): 14:37:12  Opening a new connection, currently in state init
2022-01-06 14:37:12.560277 (ThreadPoolExecutor-0_0): 14:37:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:37:12.580532 (ThreadPoolExecutor-0_0): 14:37:12  SQL status: SELECT in 0.02 seconds
2022-01-06 14:37:12.581667 (ThreadPoolExecutor-0_0): 14:37:12  On list_dev: Close
2022-01-06 14:37:12.582838 (ThreadPoolExecutor-1_0): 14:37:12  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:37:12.589316 (ThreadPoolExecutor-1_0): 14:37:12  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:37:12.589416 (ThreadPoolExecutor-1_0): 14:37:12  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:37:12.589497 (ThreadPoolExecutor-1_0): 14:37:12  Opening a new connection, currently in state closed
2022-01-06 14:37:12.589575 (ThreadPoolExecutor-1_0): 14:37:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:37:12.611164 (ThreadPoolExecutor-1_0): 14:37:12  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:37:12.611279 (ThreadPoolExecutor-1_0): 14:37:12  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:37:12.611357 (ThreadPoolExecutor-1_0): 14:37:12  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:37:12.622029 (ThreadPoolExecutor-1_0): 14:37:12  SQL status: SELECT in 0.01 seconds
2022-01-06 14:37:12.623089 (ThreadPoolExecutor-1_0): 14:37:12  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:37:12.624856 (ThreadPoolExecutor-1_0): 14:37:12  On list_dev_dbt_nobodozie: Close
2022-01-06 14:37:12.628649 (MainThread): 14:37:12  Using redshift connection "master"
2022-01-06 14:37:12.628762 (MainThread): 14:37:12  On master: BEGIN
2022-01-06 14:37:12.628845 (MainThread): 14:37:12  Opening a new connection, currently in state init
2022-01-06 14:37:12.628923 (MainThread): 14:37:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:37:12.651063 (MainThread): 14:37:12  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:37:12.651180 (MainThread): 14:37:12  Using redshift connection "master"
2022-01-06 14:37:12.651257 (MainThread): 14:37:12  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:37:12.679082 (MainThread): 14:37:12  SQL status: SELECT in 0.03 seconds
2022-01-06 14:37:12.680258 (MainThread): 14:37:12  On master: ROLLBACK
2022-01-06 14:37:12.682111 (MainThread): 14:37:12  Using redshift connection "master"
2022-01-06 14:37:12.682229 (MainThread): 14:37:12  On master: BEGIN
2022-01-06 14:37:12.685713 (MainThread): 14:37:12  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:37:12.685816 (MainThread): 14:37:12  On master: COMMIT
2022-01-06 14:37:12.685888 (MainThread): 14:37:12  Using redshift connection "master"
2022-01-06 14:37:12.685956 (MainThread): 14:37:12  On master: COMMIT
2022-01-06 14:37:12.687621 (MainThread): 14:37:12  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:37:12.687802 (MainThread): 14:37:12  On master: Close
2022-01-06 14:37:12.688350 (MainThread): 14:37:12  Concurrency: 4 threads (target='default')
2022-01-06 14:37:12.688483 (MainThread): 14:37:12  
2022-01-06 14:37:12.690925 (Thread-1): 14:37:12  Began running node model.my_new_project.dim_customers
2022-01-06 14:37:12.691202 (Thread-1): 14:37:12  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:37:12.691482 (Thread-1): 14:37:12  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:12.691580 (Thread-1): 14:37:12  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:37:12.691678 (Thread-1): 14:37:12  Compiling model.my_new_project.dim_customers
2022-01-06 14:37:12.694064 (Thread-1): 14:37:12  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:37:12.694294 (Thread-2): 14:37:12  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:37:12.694525 (Thread-2): 14:37:12  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:37:12.694800 (Thread-2): 14:37:12  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.694887 (Thread-2): 14:37:12  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:37:12.694968 (Thread-2): 14:37:12  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:37:12.697058 (Thread-2): 14:37:12  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.708524 (Thread-1): 14:37:12  finished collecting timing info
2022-01-06 14:37:12.708672 (Thread-1): 14:37:12  Began executing node model.my_new_project.dim_customers
2022-01-06 14:37:12.713894 (Thread-2): 14:37:12  finished collecting timing info
2022-01-06 14:37:12.714028 (Thread-2): 14:37:12  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:37:12.771790 (Thread-2): 14:37:12  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.774168 (Thread-1): 14:37:12  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:37:12.793544 (Thread-1): 14:37:12  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:12.793766 (Thread-1): 14:37:12  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:37:12.793923 (Thread-1): 14:37:12  Opening a new connection, currently in state closed
2022-01-06 14:37:12.794067 (Thread-1): 14:37:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:37:12.794427 (Thread-2): 14:37:12  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.794540 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:37:12.794626 (Thread-2): 14:37:12  Opening a new connection, currently in state init
2022-01-06 14:37:12.794702 (Thread-2): 14:37:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:37:12.818654 (Thread-1): 14:37:12  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:37:12.818853 (Thread-1): 14:37:12  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:12.818991 (Thread-1): 14:37:12  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:37:12.819643 (Thread-2): 14:37:12  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:37:12.819769 (Thread-2): 14:37:12  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.819849 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:37:12.832586 (Thread-105): handling poll request
2022-01-06 14:37:12.832966 (Thread-105): 14:37:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980cb640>]}
2022-01-06 14:37:12.834388 (Thread-105): sending response (<Response 30570 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:37:12.897828 (Thread-2): 14:37:12  SQL status: SELECT in 0.08 seconds
2022-01-06 14:37:12.904027 (Thread-2): 14:37:12  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.904147 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:37:12.908433 (Thread-2): 14:37:12  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:37:12.910411 (Thread-2): 14:37:12  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.910518 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:37:12.914148 (Thread-2): 14:37:12  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:37:12.924450 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:37:12.924578 (Thread-2): 14:37:12  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.924656 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:37:12.926553 (Thread-1): 14:37:12  SQL status: SELECT in 0.11 seconds
2022-01-06 14:37:12.931377 (Thread-1): 14:37:12  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:12.931538 (Thread-1): 14:37:12  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:37:12.936852 (Thread-1): 14:37:12  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:37:12.939765 (Thread-1): 14:37:12  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:12.939918 (Thread-1): 14:37:12  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:37:12.943065 (Thread-1): 14:37:12  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:37:12.944858 (Thread-1): 14:37:12  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:37:12.945011 (Thread-1): 14:37:12  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:12.945141 (Thread-1): 14:37:12  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:37:12.986727 (Thread-2): 14:37:12  SQL status: COMMIT in 0.06 seconds
2022-01-06 14:37:12.986970 (Thread-2): 14:37:12  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.987055 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:37:12.987651 (Thread-1): 14:37:12  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:37:12.989260 (Thread-2): 14:37:12  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:37:12.993419 (Thread-2): 14:37:12  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.993518 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:37:12.998285 (Thread-2): 14:37:12  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:37:12.999017 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:37:12.999116 (Thread-2): 14:37:12  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.999190 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:37:13.029867 (Thread-2): 14:37:13  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:37:13.029996 (Thread-2): 14:37:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:13.030074 (Thread-2): 14:37:13  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:37:13.032179 (Thread-2): 14:37:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:37:13.032663 (Thread-2): 14:37:13  finished collecting timing info
2022-01-06 14:37:13.032798 (Thread-2): 14:37:13  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:37:13.033156 (Thread-1): 14:37:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:13.033384 (Thread-1): 14:37:13  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:37:13.035779 (Thread-1): 14:37:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:37:13.038143 (Thread-1): 14:37:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:13.038293 (Thread-1): 14:37:13  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:37:13.038478 (Thread-2): 14:37:13  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:37:13.038942 (Thread-2): 14:37:13  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6514d0f-3cb5-4a04-bba7-e84a22dbcc78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d503ccbb0>]}
2022-01-06 14:37:13.039347 (Thread-2): 14:37:13  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.34s]
2022-01-06 14:37:13.039476 (Thread-2): 14:37:13  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:37:13.040044 (Thread-4): 14:37:13  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:37:13.040281 (Thread-4): 14:37:13  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:37:13.040534 (Thread-4): 14:37:13  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.040622 (Thread-4): 14:37:13  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:37:13.040708 (Thread-4): 14:37:13  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:37:13.042854 (Thread-4): 14:37:13  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.043425 (Thread-1): 14:37:13  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 14:37:13.044135 (Thread-1): 14:37:13  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:37:13.044233 (Thread-1): 14:37:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:13.044308 (Thread-1): 14:37:13  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:37:13.055258 (Thread-4): 14:37:13  finished collecting timing info
2022-01-06 14:37:13.055478 (Thread-4): 14:37:13  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:37:13.074947 (Thread-4): 14:37:13  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.075819 (Thread-1): 14:37:13  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:37:13.075944 (Thread-1): 14:37:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:13.076020 (Thread-1): 14:37:13  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:37:13.078203 (Thread-1): 14:37:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:37:13.078620 (Thread-1): 14:37:13  finished collecting timing info
2022-01-06 14:37:13.078749 (Thread-1): 14:37:13  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:37:13.080549 (Thread-1): 14:37:13  On model.my_new_project.dim_customers: Close
2022-01-06 14:37:13.080995 (Thread-1): 14:37:13  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6514d0f-3cb5-4a04-bba7-e84a22dbcc78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d503ccf70>]}
2022-01-06 14:37:13.081353 (Thread-1): 14:37:13  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.39s]
2022-01-06 14:37:13.081471 (Thread-1): 14:37:13  Finished running node model.my_new_project.dim_customers
2022-01-06 14:37:13.086472 (Thread-4): 14:37:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.086580 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:37:13.086662 (Thread-4): 14:37:13  Opening a new connection, currently in state init
2022-01-06 14:37:13.086741 (Thread-4): 14:37:13  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:37:13.109167 (Thread-4): 14:37:13  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:37:13.109324 (Thread-4): 14:37:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.109416 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:37:13.114137 (Thread-4): 14:37:13  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:37:13.116127 (Thread-4): 14:37:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.116223 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:37:13.118421 (Thread-4): 14:37:13  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:37:13.119392 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:37:13.119488 (Thread-4): 14:37:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.119560 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:37:13.147986 (Thread-4): 14:37:13  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:37:13.148212 (Thread-4): 14:37:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.148296 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:37:13.150333 (Thread-4): 14:37:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:37:13.151605 (Thread-4): 14:37:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.151700 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:37:13.153676 (Thread-4): 14:37:13  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:37:13.154359 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:37:13.154455 (Thread-4): 14:37:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.154528 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:37:13.178439 (Thread-4): 14:37:13  SQL status: COMMIT in 0.02 seconds
2022-01-06 14:37:13.178549 (Thread-4): 14:37:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.178622 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:37:13.180632 (Thread-4): 14:37:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:37:13.181036 (Thread-4): 14:37:13  finished collecting timing info
2022-01-06 14:37:13.181162 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:37:13.182882 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:37:13.183310 (Thread-4): 14:37:13  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6514d0f-3cb5-4a04-bba7-e84a22dbcc78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d50390160>]}
2022-01-06 14:37:13.183624 (Thread-4): 14:37:13  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.14s]
2022-01-06 14:37:13.183736 (Thread-4): 14:37:13  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:37:13.185086 (MainThread): 14:37:13  Acquiring new redshift connection "master"
2022-01-06 14:37:13.185263 (MainThread): 14:37:13  Using redshift connection "master"
2022-01-06 14:37:13.185348 (MainThread): 14:37:13  On master: BEGIN
2022-01-06 14:37:13.185428 (MainThread): 14:37:13  Opening a new connection, currently in state closed
2022-01-06 14:37:13.185506 (MainThread): 14:37:13  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:37:13.208398 (MainThread): 14:37:13  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:37:13.208528 (MainThread): 14:37:13  On master: COMMIT
2022-01-06 14:37:13.208604 (MainThread): 14:37:13  Using redshift connection "master"
2022-01-06 14:37:13.208674 (MainThread): 14:37:13  On master: COMMIT
2022-01-06 14:37:13.210294 (MainThread): 14:37:13  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:37:13.210401 (MainThread): 14:37:13  On master: Close
2022-01-06 14:37:13.210809 (MainThread): 14:37:13  
2022-01-06 14:37:13.210919 (MainThread): 14:37:13  Finished running 2 table models, 1 view model in 0.66s.
2022-01-06 14:37:13.211037 (MainThread): 14:37:13  Connection 'master' was properly closed.
2022-01-06 14:37:13.211107 (MainThread): 14:37:13  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:37:13.211170 (MainThread): 14:37:13  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:37:13.211230 (MainThread): 14:37:13  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:37:13.262073 (MainThread): 14:37:13  
2022-01-06 14:37:13.262295 (MainThread): 14:37:13  Completed successfully
2022-01-06 14:37:13.262402 (MainThread): 14:37:13  
2022-01-06 14:37:13.262490 (MainThread): 14:37:13  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:37:14.175223 (Thread-106): handling poll request
2022-01-06 14:37:14.175577 (Thread-106): 14:37:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8092f70>]}
2022-01-06 14:37:14.177685 (Thread-106): sending response (<Response 56625 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:37:14.784188 (Thread-107): handling status request
2022-01-06 14:37:14.784598 (Thread-107): 14:37:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8092be0>]}
2022-01-06 14:37:14.785144 (Thread-107): sending response (<Response 1544 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:37:14.841722 (Thread-108): handling status request
2022-01-06 14:37:14.842046 (Thread-108): 14:37:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980dd4f0>]}
2022-01-06 14:37:14.842502 (Thread-108): sending response (<Response 1544 bytes [200 OK]>) to 10.0.40.39
2022-01-06 14:41:29.929643 (Thread-109): handling status request
2022-01-06 14:41:29.931057 (Thread-109): 14:41:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb854b130>]}
2022-01-06 14:41:29.931560 (Thread-109): sending response (<Response 1544 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:41:30.142734 (Thread-110): handling status request
2022-01-06 14:41:30.143042 (Thread-110): 14:41:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb854b610>]}
2022-01-06 14:41:30.143485 (Thread-110): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:41:30.261117 (Thread-111): handling cli_args request
2022-01-06 14:41:30.261398 (Thread-111): 14:41:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb854d640>]}
2022-01-06 14:41:32.309413 (Thread-111): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:41:32.405107 (MainThread): 14:41:32  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:41:32.405525 (MainThread): 14:41:32  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:41:32.411124 (MainThread): 14:41:32  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7ac5b96e-f7a0-4351-8399-5ff50478a7a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57cefc3d90>]}
2022-01-06 14:41:32.439624 (MainThread): 14:41:32  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7ac5b96e-f7a0-4351-8399-5ff50478a7a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57cf0605e0>]}
2022-01-06 14:41:32.439855 (MainThread): 14:41:32  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:41:32.440885 (MainThread): 14:41:32  
2022-01-06 14:41:32.441145 (MainThread): 14:41:32  Acquiring new redshift connection "master"
2022-01-06 14:41:32.442117 (ThreadPoolExecutor-0_0): 14:41:32  Acquiring new redshift connection "list_dev"
2022-01-06 14:41:32.451844 (ThreadPoolExecutor-0_0): 14:41:32  Using redshift connection "list_dev"
2022-01-06 14:41:32.452104 (ThreadPoolExecutor-0_0): 14:41:32  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:41:32.452198 (ThreadPoolExecutor-0_0): 14:41:32  Opening a new connection, currently in state init
2022-01-06 14:41:32.452284 (ThreadPoolExecutor-0_0): 14:41:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:32.474101 (ThreadPoolExecutor-0_0): 14:41:32  SQL status: SELECT in 0.02 seconds
2022-01-06 14:41:32.475140 (ThreadPoolExecutor-0_0): 14:41:32  On list_dev: Close
2022-01-06 14:41:32.476291 (ThreadPoolExecutor-1_0): 14:41:32  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:41:32.482791 (ThreadPoolExecutor-1_0): 14:41:32  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:41:32.482891 (ThreadPoolExecutor-1_0): 14:41:32  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:41:32.482975 (ThreadPoolExecutor-1_0): 14:41:32  Opening a new connection, currently in state closed
2022-01-06 14:41:32.483060 (ThreadPoolExecutor-1_0): 14:41:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:32.512965 (ThreadPoolExecutor-1_0): 14:41:32  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:41:32.513076 (ThreadPoolExecutor-1_0): 14:41:32  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:41:32.513152 (ThreadPoolExecutor-1_0): 14:41:32  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:41:32.528266 (ThreadPoolExecutor-1_0): 14:41:32  SQL status: SELECT in 0.02 seconds
2022-01-06 14:41:32.529328 (ThreadPoolExecutor-1_0): 14:41:32  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:41:32.531547 (ThreadPoolExecutor-1_0): 14:41:32  On list_dev_dbt_nobodozie: Close
2022-01-06 14:41:32.535112 (MainThread): 14:41:32  Using redshift connection "master"
2022-01-06 14:41:32.535222 (MainThread): 14:41:32  On master: BEGIN
2022-01-06 14:41:32.535302 (MainThread): 14:41:32  Opening a new connection, currently in state init
2022-01-06 14:41:32.535379 (MainThread): 14:41:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:32.561470 (MainThread): 14:41:32  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:41:32.561581 (MainThread): 14:41:32  Using redshift connection "master"
2022-01-06 14:41:32.561669 (MainThread): 14:41:32  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:41:32.593597 (MainThread): 14:41:32  SQL status: SELECT in 0.03 seconds
2022-01-06 14:41:32.594607 (MainThread): 14:41:32  On master: ROLLBACK
2022-01-06 14:41:32.596571 (MainThread): 14:41:32  Using redshift connection "master"
2022-01-06 14:41:32.596691 (MainThread): 14:41:32  On master: BEGIN
2022-01-06 14:41:32.600248 (MainThread): 14:41:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:32.600354 (MainThread): 14:41:32  On master: COMMIT
2022-01-06 14:41:32.600426 (MainThread): 14:41:32  Using redshift connection "master"
2022-01-06 14:41:32.600493 (MainThread): 14:41:32  On master: COMMIT
2022-01-06 14:41:32.602157 (MainThread): 14:41:32  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:41:32.602261 (MainThread): 14:41:32  On master: Close
2022-01-06 14:41:32.602623 (MainThread): 14:41:32  Concurrency: 4 threads (target='default')
2022-01-06 14:41:32.602734 (MainThread): 14:41:32  
2022-01-06 14:41:32.604922 (Thread-1): 14:41:32  Began running node model.my_new_project.dim_customers
2022-01-06 14:41:32.605185 (Thread-1): 14:41:32  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:41:32.605453 (Thread-1): 14:41:32  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:32.605547 (Thread-1): 14:41:32  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:41:32.605645 (Thread-1): 14:41:32  Compiling model.my_new_project.dim_customers
2022-01-06 14:41:32.607828 (Thread-1): 14:41:32  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:41:32.608054 (Thread-2): 14:41:32  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:41:32.608263 (Thread-2): 14:41:32  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:41:32.608569 (Thread-2): 14:41:32  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.608669 (Thread-2): 14:41:32  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:41:32.608751 (Thread-2): 14:41:32  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:41:32.610745 (Thread-2): 14:41:32  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.625473 (Thread-1): 14:41:32  finished collecting timing info
2022-01-06 14:41:32.625629 (Thread-1): 14:41:32  Began executing node model.my_new_project.dim_customers
2022-01-06 14:41:32.630823 (Thread-2): 14:41:32  finished collecting timing info
2022-01-06 14:41:32.656813 (Thread-112): handling poll request
2022-01-06 14:41:32.657159 (Thread-112): 14:41:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9808bfa0>]}
2022-01-06 14:41:32.658529 (Thread-112): sending response (<Response 22631 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:41:32.630952 (Thread-2): 14:41:32  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:41:32.681318 (Thread-2): 14:41:32  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.681904 (Thread-1): 14:41:32  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:41:32.696899 (Thread-1): 14:41:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:32.697019 (Thread-1): 14:41:32  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:41:32.697107 (Thread-1): 14:41:32  Opening a new connection, currently in state closed
2022-01-06 14:41:32.697191 (Thread-1): 14:41:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:32.697499 (Thread-2): 14:41:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.697600 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:41:32.697679 (Thread-2): 14:41:32  Opening a new connection, currently in state init
2022-01-06 14:41:32.697757 (Thread-2): 14:41:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:32.736497 (Thread-1): 14:41:32  SQL status: BEGIN in 0.04 seconds
2022-01-06 14:41:32.736614 (Thread-1): 14:41:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:32.736692 (Thread-1): 14:41:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:41:32.737487 (Thread-2): 14:41:32  SQL status: BEGIN in 0.04 seconds
2022-01-06 14:41:32.737610 (Thread-2): 14:41:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.737719 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:41:32.836556 (Thread-2): 14:41:32  SQL status: SELECT in 0.1 seconds
2022-01-06 14:41:32.842851 (Thread-2): 14:41:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.842966 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:41:32.856792 (Thread-2): 14:41:32  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:41:32.858760 (Thread-2): 14:41:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.858859 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:41:32.863108 (Thread-2): 14:41:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:41:32.873808 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:41:32.873923 (Thread-2): 14:41:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.873998 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:41:32.908487 (Thread-1): 14:41:32  SQL status: SELECT in 0.17 seconds
2022-01-06 14:41:32.911579 (Thread-1): 14:41:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:32.911679 (Thread-1): 14:41:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:41:32.915209 (Thread-1): 14:41:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:41:32.916884 (Thread-1): 14:41:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:32.916980 (Thread-1): 14:41:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:41:32.920420 (Thread-1): 14:41:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:41:32.921535 (Thread-1): 14:41:32  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:41:32.921633 (Thread-1): 14:41:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:32.921706 (Thread-1): 14:41:32  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:41:32.957869 (Thread-2): 14:41:32  SQL status: COMMIT in 0.08 seconds
2022-01-06 14:41:32.958079 (Thread-2): 14:41:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.958159 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:41:32.959342 (Thread-1): 14:41:32  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:41:32.960754 (Thread-2): 14:41:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:32.964790 (Thread-2): 14:41:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.964888 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:41:32.975558 (Thread-2): 14:41:32  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 14:41:32.976183 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:41:32.976277 (Thread-2): 14:41:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.976350 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:41:33.065024 (Thread-2): 14:41:33  SQL status: COMMIT in 0.09 seconds
2022-01-06 14:41:33.065144 (Thread-2): 14:41:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:33.065258 (Thread-2): 14:41:33  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:41:33.067933 (Thread-2): 14:41:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:33.068378 (Thread-2): 14:41:33  finished collecting timing info
2022-01-06 14:41:33.068515 (Thread-2): 14:41:33  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:41:33.068736 (Thread-1): 14:41:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:33.068856 (Thread-1): 14:41:33  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:41:33.070763 (Thread-2): 14:41:33  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:41:33.071260 (Thread-2): 14:41:33  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7ac5b96e-f7a0-4351-8399-5ff50478a7a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57cc709040>]}
2022-01-06 14:41:33.071592 (Thread-2): 14:41:33  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.46s]
2022-01-06 14:41:33.071709 (Thread-2): 14:41:33  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:41:33.072296 (Thread-4): 14:41:33  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:41:33.072541 (Thread-4): 14:41:33  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:41:33.072799 (Thread-4): 14:41:33  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.072891 (Thread-4): 14:41:33  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:41:33.072976 (Thread-4): 14:41:33  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:41:33.075042 (Thread-4): 14:41:33  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.075330 (Thread-1): 14:41:33  SQL status: BEGIN in 0.01 seconds
2022-01-06 14:41:33.076544 (Thread-1): 14:41:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:33.076640 (Thread-1): 14:41:33  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:41:33.081552 (Thread-1): 14:41:33  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:41:33.082183 (Thread-1): 14:41:33  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:41:33.082278 (Thread-1): 14:41:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:33.082351 (Thread-1): 14:41:33  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:41:33.089249 (Thread-4): 14:41:33  finished collecting timing info
2022-01-06 14:41:33.089393 (Thread-4): 14:41:33  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:41:33.104833 (Thread-4): 14:41:33  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.117990 (Thread-4): 14:41:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.118095 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:41:33.118177 (Thread-4): 14:41:33  Opening a new connection, currently in state init
2022-01-06 14:41:33.118262 (Thread-4): 14:41:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:33.118577 (Thread-1): 14:41:33  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:41:33.118682 (Thread-1): 14:41:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:33.118755 (Thread-1): 14:41:33  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:41:33.121519 (Thread-1): 14:41:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:33.121887 (Thread-1): 14:41:33  finished collecting timing info
2022-01-06 14:41:33.122007 (Thread-1): 14:41:33  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:41:33.127831 (Thread-1): 14:41:33  On model.my_new_project.dim_customers: Close
2022-01-06 14:41:33.128266 (Thread-1): 14:41:33  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7ac5b96e-f7a0-4351-8399-5ff50478a7a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57cc6e9fa0>]}
2022-01-06 14:41:33.128579 (Thread-1): 14:41:33  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.52s]
2022-01-06 14:41:33.128687 (Thread-1): 14:41:33  Finished running node model.my_new_project.dim_customers
2022-01-06 14:41:33.347367 (Thread-4): 14:41:33  SQL status: BEGIN in 0.23 seconds
2022-01-06 14:41:33.347487 (Thread-4): 14:41:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.347567 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:41:33.354370 (Thread-4): 14:41:33  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 14:41:33.356253 (Thread-4): 14:41:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.356349 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:41:33.359168 (Thread-4): 14:41:33  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:41:33.360111 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:41:33.360205 (Thread-4): 14:41:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.360277 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:41:33.397772 (Thread-4): 14:41:33  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:41:33.397981 (Thread-4): 14:41:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.398064 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:41:33.400960 (Thread-4): 14:41:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:33.402188 (Thread-4): 14:41:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.402282 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:41:33.404981 (Thread-4): 14:41:33  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:41:33.405673 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:41:33.405766 (Thread-4): 14:41:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.405838 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:41:33.442307 (Thread-4): 14:41:33  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:41:33.442417 (Thread-4): 14:41:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.442494 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:41:33.445235 (Thread-4): 14:41:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:33.445607 (Thread-4): 14:41:33  finished collecting timing info
2022-01-06 14:41:33.445728 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:41:33.448151 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:41:33.448566 (Thread-4): 14:41:33  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7ac5b96e-f7a0-4351-8399-5ff50478a7a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57cc6d3520>]}
2022-01-06 14:41:33.448855 (Thread-4): 14:41:33  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.38s]
2022-01-06 14:41:33.448976 (Thread-4): 14:41:33  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:41:33.450452 (MainThread): 14:41:33  Acquiring new redshift connection "master"
2022-01-06 14:41:33.450594 (MainThread): 14:41:33  Using redshift connection "master"
2022-01-06 14:41:33.450672 (MainThread): 14:41:33  On master: BEGIN
2022-01-06 14:41:33.450748 (MainThread): 14:41:33  Opening a new connection, currently in state closed
2022-01-06 14:41:33.450825 (MainThread): 14:41:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:33.725732 (MainThread): 14:41:33  SQL status: BEGIN in 0.27 seconds
2022-01-06 14:41:33.725860 (MainThread): 14:41:33  On master: COMMIT
2022-01-06 14:41:33.725937 (MainThread): 14:41:33  Using redshift connection "master"
2022-01-06 14:41:33.726009 (MainThread): 14:41:33  On master: COMMIT
2022-01-06 14:41:33.728125 (MainThread): 14:41:33  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:41:33.728234 (MainThread): 14:41:33  On master: Close
2022-01-06 14:41:33.728684 (MainThread): 14:41:33  
2022-01-06 14:41:33.728798 (MainThread): 14:41:33  Finished running 2 table models, 1 view model in 1.29s.
2022-01-06 14:41:33.728908 (MainThread): 14:41:33  Connection 'master' was properly closed.
2022-01-06 14:41:33.729025 (MainThread): 14:41:33  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:41:33.729094 (MainThread): 14:41:33  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:41:33.729155 (MainThread): 14:41:33  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:41:33.778807 (MainThread): 14:41:33  
2022-01-06 14:41:33.778971 (MainThread): 14:41:33  Completed successfully
2022-01-06 14:41:33.779068 (MainThread): 14:41:33  
2022-01-06 14:41:33.779154 (MainThread): 14:41:33  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:41:33.992211 (Thread-113): handling poll request
2022-01-06 14:41:33.992562 (Thread-113): 14:41:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9803e6d0>]}
2022-01-06 14:41:33.994865 (Thread-113): sending response (<Response 64564 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:41:34.609939 (Thread-114): handling status request
2022-01-06 14:41:34.610291 (Thread-114): 14:41:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9803e880>]}
2022-01-06 14:41:34.610796 (Thread-114): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:41:34.670665 (Thread-115): handling status request
2022-01-06 14:41:34.670924 (Thread-115): 14:41:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9803ec70>]}
2022-01-06 14:41:34.671309 (Thread-115): sending response (<Response 1544 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:41:39.956915 (Thread-116): handling status request
2022-01-06 14:41:39.957317 (Thread-116): 14:41:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9803eeb0>]}
2022-01-06 14:41:39.957816 (Thread-116): sending response (<Response 1544 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:41:40.332392 (Thread-117): handling status request
2022-01-06 14:41:40.332710 (Thread-117): 14:41:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980590d0>]}
2022-01-06 14:41:40.333155 (Thread-117): sending response (<Response 1544 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:41:40.351166 (Thread-118): handling cli_args request
2022-01-06 14:41:40.351405 (Thread-118): 14:41:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980593d0>]}
2022-01-06 14:41:42.446556 (Thread-118): sending response (<Response 138 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:41:42.523060 (MainThread): 14:41:42  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:41:42.523445 (MainThread): 14:41:42  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:41:42.529305 (MainThread): 14:41:42  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '37edf41f-893d-4448-9f4e-8d7c35770865', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98db832c70>]}
2022-01-06 14:41:42.563101 (MainThread): 14:41:42  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '37edf41f-893d-4448-9f4e-8d7c35770865', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98db8a8cd0>]}
2022-01-06 14:41:42.563354 (MainThread): 14:41:42  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:41:42.564400 (MainThread): 14:41:42  
2022-01-06 14:41:42.564690 (MainThread): 14:41:42  Acquiring new redshift connection "master"
2022-01-06 14:41:42.565701 (ThreadPoolExecutor-0_0): 14:41:42  Acquiring new redshift connection "list_dev"
2022-01-06 14:41:42.575579 (ThreadPoolExecutor-0_0): 14:41:42  Using redshift connection "list_dev"
2022-01-06 14:41:42.575681 (ThreadPoolExecutor-0_0): 14:41:42  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:41:42.575766 (ThreadPoolExecutor-0_0): 14:41:42  Opening a new connection, currently in state init
2022-01-06 14:41:42.575849 (ThreadPoolExecutor-0_0): 14:41:42  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:42.596528 (ThreadPoolExecutor-0_0): 14:41:42  SQL status: SELECT in 0.02 seconds
2022-01-06 14:41:42.597624 (ThreadPoolExecutor-0_0): 14:41:42  On list_dev: Close
2022-01-06 14:41:42.598877 (ThreadPoolExecutor-1_0): 14:41:42  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:41:42.605431 (ThreadPoolExecutor-1_0): 14:41:42  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:41:42.605531 (ThreadPoolExecutor-1_0): 14:41:42  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:41:42.605613 (ThreadPoolExecutor-1_0): 14:41:42  Opening a new connection, currently in state closed
2022-01-06 14:41:42.605691 (ThreadPoolExecutor-1_0): 14:41:42  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:42.627117 (ThreadPoolExecutor-1_0): 14:41:42  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:41:42.627227 (ThreadPoolExecutor-1_0): 14:41:42  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:41:42.627303 (ThreadPoolExecutor-1_0): 14:41:42  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:41:42.638291 (ThreadPoolExecutor-1_0): 14:41:42  SQL status: SELECT in 0.01 seconds
2022-01-06 14:41:42.639299 (ThreadPoolExecutor-1_0): 14:41:42  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:41:42.641020 (ThreadPoolExecutor-1_0): 14:41:42  On list_dev_dbt_nobodozie: Close
2022-01-06 14:41:42.644642 (MainThread): 14:41:42  Using redshift connection "master"
2022-01-06 14:41:42.644755 (MainThread): 14:41:42  On master: BEGIN
2022-01-06 14:41:42.644835 (MainThread): 14:41:42  Opening a new connection, currently in state init
2022-01-06 14:41:42.644909 (MainThread): 14:41:42  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:42.668933 (MainThread): 14:41:42  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:41:42.669057 (MainThread): 14:41:42  Using redshift connection "master"
2022-01-06 14:41:42.669136 (MainThread): 14:41:42  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:41:42.697857 (MainThread): 14:41:42  SQL status: SELECT in 0.03 seconds
2022-01-06 14:41:42.699145 (MainThread): 14:41:42  On master: ROLLBACK
2022-01-06 14:41:42.701068 (MainThread): 14:41:42  Using redshift connection "master"
2022-01-06 14:41:42.701175 (MainThread): 14:41:42  On master: BEGIN
2022-01-06 14:41:42.704792 (MainThread): 14:41:42  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:42.704897 (MainThread): 14:41:42  On master: COMMIT
2022-01-06 14:41:42.704971 (MainThread): 14:41:42  Using redshift connection "master"
2022-01-06 14:41:42.705045 (MainThread): 14:41:42  On master: COMMIT
2022-01-06 14:41:42.706742 (MainThread): 14:41:42  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:41:42.706853 (MainThread): 14:41:42  On master: Close
2022-01-06 14:41:42.707302 (MainThread): 14:41:42  Concurrency: 4 threads (target='default')
2022-01-06 14:41:42.707421 (MainThread): 14:41:42  
2022-01-06 14:41:42.738778 (Thread-1): 14:41:42  Began running node model.my_new_project.dim_customers
2022-01-06 14:41:42.739057 (Thread-1): 14:41:42  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:41:42.739360 (Thread-1): 14:41:42  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:42.739481 (Thread-1): 14:41:42  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:41:42.739593 (Thread-1): 14:41:42  Compiling model.my_new_project.dim_customers
2022-01-06 14:41:42.742136 (Thread-1): 14:41:42  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:41:42.742400 (Thread-2): 14:41:42  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:41:42.742644 (Thread-2): 14:41:42  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:41:42.742922 (Thread-2): 14:41:42  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.743022 (Thread-2): 14:41:42  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:41:42.743128 (Thread-2): 14:41:42  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:41:42.745436 (Thread-2): 14:41:42  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.758117 (Thread-2): 14:41:42  finished collecting timing info
2022-01-06 14:41:42.758274 (Thread-2): 14:41:42  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:41:42.763525 (Thread-1): 14:41:42  finished collecting timing info
2022-01-06 14:41:42.763665 (Thread-1): 14:41:42  Began executing node model.my_new_project.dim_customers
2022-01-06 14:41:42.815194 (Thread-2): 14:41:42  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.817576 (Thread-1): 14:41:42  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:41:42.829485 (Thread-2): 14:41:42  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.829606 (Thread-2): 14:41:42  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:41:42.829703 (Thread-2): 14:41:42  Opening a new connection, currently in state init
2022-01-06 14:41:42.829789 (Thread-2): 14:41:42  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:42.831583 (Thread-1): 14:41:42  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:42.831700 (Thread-1): 14:41:42  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:41:42.831784 (Thread-1): 14:41:42  Opening a new connection, currently in state closed
2022-01-06 14:41:42.831864 (Thread-1): 14:41:42  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:42.855706 (Thread-2): 14:41:42  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:41:42.855828 (Thread-2): 14:41:42  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.855905 (Thread-2): 14:41:42  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:41:42.856346 (Thread-1): 14:41:42  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:41:42.856473 (Thread-1): 14:41:42  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:42.856552 (Thread-1): 14:41:42  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:41:42.878653 (Thread-119): handling poll request
2022-01-06 14:41:42.879049 (Thread-119): 14:41:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9805f0d0>]}
2022-01-06 14:41:42.880367 (Thread-119): sending response (<Response 30569 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:41:42.928206 (Thread-2): 14:41:42  SQL status: SELECT in 0.07 seconds
2022-01-06 14:41:42.934311 (Thread-2): 14:41:42  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.934421 (Thread-2): 14:41:42  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:41:42.938694 (Thread-2): 14:41:42  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:41:42.940478 (Thread-2): 14:41:42  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.940577 (Thread-2): 14:41:42  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:41:42.944399 (Thread-2): 14:41:42  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:41:42.954628 (Thread-2): 14:41:42  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:41:42.954780 (Thread-2): 14:41:42  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.954857 (Thread-2): 14:41:42  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:41:42.973714 (Thread-1): 14:41:42  SQL status: SELECT in 0.12 seconds
2022-01-06 14:41:42.976552 (Thread-1): 14:41:42  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:42.976649 (Thread-1): 14:41:42  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:41:42.979657 (Thread-1): 14:41:42  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:41:42.981338 (Thread-1): 14:41:42  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:42.981438 (Thread-1): 14:41:42  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:41:42.987929 (Thread-1): 14:41:42  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:41:42.989190 (Thread-1): 14:41:42  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:41:42.989320 (Thread-1): 14:41:42  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:42.989397 (Thread-1): 14:41:42  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:41:42.994784 (Thread-2): 14:41:42  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:41:42.995012 (Thread-2): 14:41:42  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.995095 (Thread-2): 14:41:42  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:41:42.997760 (Thread-2): 14:41:42  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:43.001455 (Thread-2): 14:41:43  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:43.001553 (Thread-2): 14:41:43  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:41:43.019871 (Thread-2): 14:41:43  SQL status: DROP TABLE in 0.02 seconds
2022-01-06 14:41:43.020618 (Thread-2): 14:41:43  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:41:43.020715 (Thread-2): 14:41:43  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:43.020790 (Thread-2): 14:41:43  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:41:43.024816 (Thread-1): 14:41:43  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:41:43.048880 (Thread-2): 14:41:43  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:41:43.048991 (Thread-2): 14:41:43  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:43.049063 (Thread-2): 14:41:43  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:41:43.051101 (Thread-2): 14:41:43  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:43.051486 (Thread-2): 14:41:43  finished collecting timing info
2022-01-06 14:41:43.051614 (Thread-2): 14:41:43  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:41:43.051812 (Thread-1): 14:41:43  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:43.051919 (Thread-1): 14:41:43  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:41:43.054291 (Thread-1): 14:41:43  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:43.055393 (Thread-1): 14:41:43  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:43.055488 (Thread-1): 14:41:43  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:41:43.055624 (Thread-2): 14:41:43  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:41:43.056131 (Thread-2): 14:41:43  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '37edf41f-893d-4448-9f4e-8d7c35770865', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98d874d040>]}
2022-01-06 14:41:43.056463 (Thread-2): 14:41:43  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.31s]
2022-01-06 14:41:43.056584 (Thread-2): 14:41:43  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:41:43.057173 (Thread-4): 14:41:43  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:41:43.057438 (Thread-4): 14:41:43  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:41:43.057693 (Thread-4): 14:41:43  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.057783 (Thread-4): 14:41:43  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:41:43.057871 (Thread-4): 14:41:43  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:41:43.059840 (Thread-4): 14:41:43  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.064173 (Thread-1): 14:41:43  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 14:41:43.064804 (Thread-1): 14:41:43  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:41:43.064900 (Thread-1): 14:41:43  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:43.064975 (Thread-1): 14:41:43  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:41:43.071155 (Thread-4): 14:41:43  finished collecting timing info
2022-01-06 14:41:43.071294 (Thread-4): 14:41:43  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:41:43.086663 (Thread-4): 14:41:43  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.096626 (Thread-1): 14:41:43  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:41:43.096749 (Thread-1): 14:41:43  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:43.096825 (Thread-1): 14:41:43  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:41:43.098921 (Thread-1): 14:41:43  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:43.099281 (Thread-1): 14:41:43  finished collecting timing info
2022-01-06 14:41:43.099415 (Thread-1): 14:41:43  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:41:43.101181 (Thread-1): 14:41:43  On model.my_new_project.dim_customers: Close
2022-01-06 14:41:43.101609 (Thread-1): 14:41:43  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '37edf41f-893d-4448-9f4e-8d7c35770865', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98d8769370>]}
2022-01-06 14:41:43.101898 (Thread-1): 14:41:43  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.36s]
2022-01-06 14:41:43.102005 (Thread-1): 14:41:43  Finished running node model.my_new_project.dim_customers
2022-01-06 14:41:43.103454 (Thread-4): 14:41:43  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.103571 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:41:43.103658 (Thread-4): 14:41:43  Opening a new connection, currently in state init
2022-01-06 14:41:43.103741 (Thread-4): 14:41:43  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:43.125958 (Thread-4): 14:41:43  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:41:43.126072 (Thread-4): 14:41:43  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.126149 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:41:43.130812 (Thread-4): 14:41:43  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:41:43.132593 (Thread-4): 14:41:43  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.132687 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:41:43.134780 (Thread-4): 14:41:43  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:41:43.135673 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:41:43.135770 (Thread-4): 14:41:43  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.135843 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:41:43.165387 (Thread-4): 14:41:43  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:41:43.165592 (Thread-4): 14:41:43  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.165673 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:41:43.167780 (Thread-4): 14:41:43  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:43.169010 (Thread-4): 14:41:43  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.169110 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:41:43.171022 (Thread-4): 14:41:43  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:41:43.171696 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:41:43.171789 (Thread-4): 14:41:43  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.171862 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:41:43.196297 (Thread-4): 14:41:43  SQL status: COMMIT in 0.02 seconds
2022-01-06 14:41:43.196402 (Thread-4): 14:41:43  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.196472 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:41:43.198465 (Thread-4): 14:41:43  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:43.198804 (Thread-4): 14:41:43  finished collecting timing info
2022-01-06 14:41:43.198921 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:41:43.200657 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:41:43.201022 (Thread-4): 14:41:43  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '37edf41f-893d-4448-9f4e-8d7c35770865', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98dafef190>]}
2022-01-06 14:41:43.201331 (Thread-4): 14:41:43  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.14s]
2022-01-06 14:41:43.201438 (Thread-4): 14:41:43  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:41:43.202737 (MainThread): 14:41:43  Acquiring new redshift connection "master"
2022-01-06 14:41:43.202873 (MainThread): 14:41:43  Using redshift connection "master"
2022-01-06 14:41:43.202948 (MainThread): 14:41:43  On master: BEGIN
2022-01-06 14:41:43.203026 (MainThread): 14:41:43  Opening a new connection, currently in state closed
2022-01-06 14:41:43.203101 (MainThread): 14:41:43  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:43.226549 (MainThread): 14:41:43  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:41:43.226667 (MainThread): 14:41:43  On master: COMMIT
2022-01-06 14:41:43.226743 (MainThread): 14:41:43  Using redshift connection "master"
2022-01-06 14:41:43.226812 (MainThread): 14:41:43  On master: COMMIT
2022-01-06 14:41:43.228636 (MainThread): 14:41:43  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:41:43.228738 (MainThread): 14:41:43  On master: Close
2022-01-06 14:41:43.229116 (MainThread): 14:41:43  
2022-01-06 14:41:43.229261 (MainThread): 14:41:43  Finished running 2 table models, 1 view model in 0.66s.
2022-01-06 14:41:43.229348 (MainThread): 14:41:43  Connection 'master' was properly closed.
2022-01-06 14:41:43.229415 (MainThread): 14:41:43  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:41:43.229479 (MainThread): 14:41:43  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:41:43.229539 (MainThread): 14:41:43  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:41:43.274478 (MainThread): 14:41:43  
2022-01-06 14:41:43.274627 (MainThread): 14:41:43  Completed successfully
2022-01-06 14:41:43.274722 (MainThread): 14:41:43  
2022-01-06 14:41:43.274808 (MainThread): 14:41:43  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:41:44.289370 (Thread-120): handling poll request
2022-01-06 14:41:44.289740 (Thread-120): 14:41:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff783deb80>]}
2022-01-06 14:41:44.291762 (Thread-120): sending response (<Response 56626 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:41:44.912347 (Thread-121): handling status request
2022-01-06 14:41:44.912705 (Thread-121): 14:41:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff783ded30>]}
2022-01-06 14:41:44.913245 (Thread-121): sending response (<Response 1544 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:41:44.935944 (Thread-122): handling status request
2022-01-06 14:41:44.936204 (Thread-122): 14:41:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff783e60a0>]}
2022-01-06 14:41:44.936576 (Thread-122): sending response (<Response 1544 bytes [200 OK]>) to 10.0.21.176
2022-01-06 14:41:58.692866 (Thread-123): handling status request
2022-01-06 14:41:58.693288 (Thread-123): 14:41:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff783e63a0>]}
2022-01-06 14:41:58.693836 (Thread-123): sending response (<Response 1544 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:41:58.825934 (Thread-124): handling status request
2022-01-06 14:41:58.826240 (Thread-124): 14:41:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff783e6610>]}
2022-01-06 14:41:58.826715 (Thread-124): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:41:59.039660 (Thread-125): handling cli_args request
2022-01-06 14:41:59.040007 (Thread-125): 14:41:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff783e6880>]}
2022-01-06 14:42:01.143006 (Thread-125): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:42:01.222302 (MainThread): 14:42:01  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:42:01.222699 (MainThread): 14:42:01  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:42:01.228403 (MainThread): 14:42:01  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '93e223e9-6153-4e75-9589-589c0a8168b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50dd052c70>]}
2022-01-06 14:42:01.255517 (MainThread): 14:42:01  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '93e223e9-6153-4e75-9589-589c0a8168b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50dd0c9cd0>]}
2022-01-06 14:42:01.255753 (MainThread): 14:42:01  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:42:01.256765 (MainThread): 14:42:01  
2022-01-06 14:42:01.257027 (MainThread): 14:42:01  Acquiring new redshift connection "master"
2022-01-06 14:42:01.258028 (ThreadPoolExecutor-0_0): 14:42:01  Acquiring new redshift connection "list_dev"
2022-01-06 14:42:01.267714 (ThreadPoolExecutor-0_0): 14:42:01  Using redshift connection "list_dev"
2022-01-06 14:42:01.267814 (ThreadPoolExecutor-0_0): 14:42:01  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:42:01.268055 (ThreadPoolExecutor-0_0): 14:42:01  Opening a new connection, currently in state init
2022-01-06 14:42:01.268142 (ThreadPoolExecutor-0_0): 14:42:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:01.289092 (ThreadPoolExecutor-0_0): 14:42:01  SQL status: SELECT in 0.02 seconds
2022-01-06 14:42:01.290148 (ThreadPoolExecutor-0_0): 14:42:01  On list_dev: Close
2022-01-06 14:42:01.291303 (ThreadPoolExecutor-1_0): 14:42:01  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:42:01.297743 (ThreadPoolExecutor-1_0): 14:42:01  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:42:01.297842 (ThreadPoolExecutor-1_0): 14:42:01  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:42:01.297920 (ThreadPoolExecutor-1_0): 14:42:01  Opening a new connection, currently in state closed
2022-01-06 14:42:01.297995 (ThreadPoolExecutor-1_0): 14:42:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:01.320366 (ThreadPoolExecutor-1_0): 14:42:01  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:01.320478 (ThreadPoolExecutor-1_0): 14:42:01  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:42:01.320555 (ThreadPoolExecutor-1_0): 14:42:01  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:42:01.331448 (ThreadPoolExecutor-1_0): 14:42:01  SQL status: SELECT in 0.01 seconds
2022-01-06 14:42:01.332420 (ThreadPoolExecutor-1_0): 14:42:01  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:42:01.334169 (ThreadPoolExecutor-1_0): 14:42:01  On list_dev_dbt_nobodozie: Close
2022-01-06 14:42:01.337754 (MainThread): 14:42:01  Using redshift connection "master"
2022-01-06 14:42:01.337866 (MainThread): 14:42:01  On master: BEGIN
2022-01-06 14:42:01.337945 (MainThread): 14:42:01  Opening a new connection, currently in state init
2022-01-06 14:42:01.338020 (MainThread): 14:42:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:01.361323 (MainThread): 14:42:01  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:01.361434 (MainThread): 14:42:01  Using redshift connection "master"
2022-01-06 14:42:01.361509 (MainThread): 14:42:01  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:42:01.389947 (MainThread): 14:42:01  SQL status: SELECT in 0.03 seconds
2022-01-06 14:42:01.391037 (MainThread): 14:42:01  On master: ROLLBACK
2022-01-06 14:42:01.392960 (MainThread): 14:42:01  Using redshift connection "master"
2022-01-06 14:42:01.393058 (MainThread): 14:42:01  On master: BEGIN
2022-01-06 14:42:01.396533 (MainThread): 14:42:01  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:01.396647 (MainThread): 14:42:01  On master: COMMIT
2022-01-06 14:42:01.396719 (MainThread): 14:42:01  Using redshift connection "master"
2022-01-06 14:42:01.396787 (MainThread): 14:42:01  On master: COMMIT
2022-01-06 14:42:01.398507 (MainThread): 14:42:01  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:42:01.398614 (MainThread): 14:42:01  On master: Close
2022-01-06 14:42:01.398979 (MainThread): 14:42:01  Concurrency: 4 threads (target='default')
2022-01-06 14:42:01.399089 (MainThread): 14:42:01  
2022-01-06 14:42:01.401355 (Thread-1): 14:42:01  Began running node model.my_new_project.dim_customers
2022-01-06 14:42:01.401587 (Thread-1): 14:42:01  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:42:01.401812 (Thread-1): 14:42:01  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.401901 (Thread-1): 14:42:01  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:42:01.401985 (Thread-1): 14:42:01  Compiling model.my_new_project.dim_customers
2022-01-06 14:42:01.403992 (Thread-1): 14:42:01  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:42:01.404218 (Thread-2): 14:42:01  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:42:01.404439 (Thread-2): 14:42:01  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:42:01.404678 (Thread-2): 14:42:01  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.404762 (Thread-2): 14:42:01  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:42:01.404841 (Thread-2): 14:42:01  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:42:01.406821 (Thread-2): 14:42:01  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.418338 (Thread-1): 14:42:01  finished collecting timing info
2022-01-06 14:42:01.418479 (Thread-1): 14:42:01  Began executing node model.my_new_project.dim_customers
2022-01-06 14:42:01.423671 (Thread-2): 14:42:01  finished collecting timing info
2022-01-06 14:42:01.423802 (Thread-2): 14:42:01  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:42:01.476715 (Thread-1): 14:42:01  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:42:01.477030 (Thread-2): 14:42:01  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.488457 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.488566 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:42:01.488645 (Thread-2): 14:42:01  Opening a new connection, currently in state init
2022-01-06 14:42:01.488720 (Thread-2): 14:42:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:01.489137 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.489274 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:42:01.489356 (Thread-1): 14:42:01  Opening a new connection, currently in state closed
2022-01-06 14:42:01.489430 (Thread-1): 14:42:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:01.513521 (Thread-2): 14:42:01  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:01.513635 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.513713 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:42:01.514859 (Thread-1): 14:42:01  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:42:01.514980 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.515057 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:42:01.591407 (Thread-2): 14:42:01  SQL status: SELECT in 0.08 seconds
2022-01-06 14:42:01.597494 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.597614 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:42:01.602447 (Thread-2): 14:42:01  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:42:01.604359 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.604461 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:42:01.607707 (Thread-2): 14:42:01  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:42:01.618087 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:42:01.619531 (Thread-126): handling poll request
2022-01-06 14:42:01.618211 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.620110 (Thread-126): 14:42:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7839f2e0>]}
2022-01-06 14:42:01.618289 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:42:01.673508 (Thread-1): 14:42:01  SQL status: SELECT in 0.16 seconds
2022-01-06 14:42:01.676771 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.676882 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:42:01.684808 (Thread-1): 14:42:01  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:42:01.686640 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.686737 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:42:01.691648 (Thread-2): 14:42:01  SQL status: COMMIT in 0.07 seconds
2022-01-06 14:42:01.691883 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.691967 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:42:01.692123 (Thread-1): 14:42:01  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:42:01.693298 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:42:01.693396 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.693469 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:42:01.694093 (Thread-2): 14:42:01  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:01.698214 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.698327 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:42:01.723746 (Thread-2): 14:42:01  SQL status: DROP TABLE in 0.03 seconds
2022-01-06 14:42:01.724358 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:42:01.724451 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.724524 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:42:01.726791 (Thread-1): 14:42:01  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:42:01.752909 (Thread-2): 14:42:01  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:42:01.753022 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.753095 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:42:01.755179 (Thread-2): 14:42:01  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:01.755580 (Thread-2): 14:42:01  finished collecting timing info
2022-01-06 14:42:01.755708 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:42:01.755912 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.756024 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:42:01.758236 (Thread-1): 14:42:01  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:01.759696 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.759807 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:42:01.759999 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:42:01.760467 (Thread-2): 14:42:01  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '93e223e9-6153-4e75-9589-589c0a8168b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50dc796b80>]}
2022-01-06 14:42:01.760799 (Thread-2): 14:42:01  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.36s]
2022-01-06 14:42:01.760914 (Thread-2): 14:42:01  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:42:01.761544 (Thread-4): 14:42:01  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:42:01.761788 (Thread-4): 14:42:01  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:42:01.762040 (Thread-4): 14:42:01  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.762126 (Thread-4): 14:42:01  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:42:01.762211 (Thread-4): 14:42:01  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:42:01.764223 (Thread-4): 14:42:01  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.764618 (Thread-1): 14:42:01  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:42:01.765290 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:42:01.765391 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.765468 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:42:01.780529 (Thread-4): 14:42:01  finished collecting timing info
2022-01-06 14:42:01.780668 (Thread-4): 14:42:01  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:42:01.796077 (Thread-4): 14:42:01  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.798730 (Thread-1): 14:42:01  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:42:01.798852 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.798928 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:42:01.801001 (Thread-1): 14:42:01  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:01.801397 (Thread-1): 14:42:01  finished collecting timing info
2022-01-06 14:42:01.801520 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:42:01.803249 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: Close
2022-01-06 14:42:01.803689 (Thread-1): 14:42:01  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '93e223e9-6153-4e75-9589-589c0a8168b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50dc771100>]}
2022-01-06 14:42:01.803983 (Thread-1): 14:42:01  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.40s]
2022-01-06 14:42:01.804165 (Thread-1): 14:42:01  Finished running node model.my_new_project.dim_customers
2022-01-06 14:42:01.810413 (Thread-4): 14:42:01  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.810524 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:42:01.810609 (Thread-4): 14:42:01  Opening a new connection, currently in state init
2022-01-06 14:42:01.810687 (Thread-4): 14:42:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:01.830386 (Thread-126): sending response (<Response 58759 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:42:01.833371 (Thread-4): 14:42:01  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:01.833492 (Thread-4): 14:42:01  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.833570 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:42:01.838400 (Thread-4): 14:42:01  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:42:01.840391 (Thread-4): 14:42:01  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.840489 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:42:01.842614 (Thread-4): 14:42:01  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:42:01.843580 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:42:01.843675 (Thread-4): 14:42:01  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.843747 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:42:01.874605 (Thread-4): 14:42:01  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:42:01.874832 (Thread-4): 14:42:01  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.874913 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:42:01.877088 (Thread-4): 14:42:01  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:01.878463 (Thread-4): 14:42:01  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.878561 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:42:01.880618 (Thread-4): 14:42:01  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:42:01.881355 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:42:01.881450 (Thread-4): 14:42:01  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.881525 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:42:01.906618 (Thread-4): 14:42:01  SQL status: COMMIT in 0.02 seconds
2022-01-06 14:42:01.906732 (Thread-4): 14:42:01  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.906804 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:42:01.908922 (Thread-4): 14:42:01  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:01.909351 (Thread-4): 14:42:01  finished collecting timing info
2022-01-06 14:42:01.909480 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:42:01.911270 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:42:01.911713 (Thread-4): 14:42:01  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '93e223e9-6153-4e75-9589-589c0a8168b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50dc7621f0>]}
2022-01-06 14:42:01.912033 (Thread-4): 14:42:01  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.15s]
2022-01-06 14:42:01.912143 (Thread-4): 14:42:01  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:42:01.913538 (MainThread): 14:42:01  Acquiring new redshift connection "master"
2022-01-06 14:42:01.913683 (MainThread): 14:42:01  Using redshift connection "master"
2022-01-06 14:42:01.913760 (MainThread): 14:42:01  On master: BEGIN
2022-01-06 14:42:01.913836 (MainThread): 14:42:01  Opening a new connection, currently in state closed
2022-01-06 14:42:01.913914 (MainThread): 14:42:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:01.938191 (MainThread): 14:42:01  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:01.938323 (MainThread): 14:42:01  On master: COMMIT
2022-01-06 14:42:01.938400 (MainThread): 14:42:01  Using redshift connection "master"
2022-01-06 14:42:01.938471 (MainThread): 14:42:01  On master: COMMIT
2022-01-06 14:42:01.940199 (MainThread): 14:42:01  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:42:01.940302 (MainThread): 14:42:01  On master: Close
2022-01-06 14:42:01.940709 (MainThread): 14:42:01  
2022-01-06 14:42:01.940836 (MainThread): 14:42:01  Finished running 2 table models, 1 view model in 0.68s.
2022-01-06 14:42:01.940916 (MainThread): 14:42:01  Connection 'master' was properly closed.
2022-01-06 14:42:01.940982 (MainThread): 14:42:01  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:42:01.941043 (MainThread): 14:42:01  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:42:01.941101 (MainThread): 14:42:01  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:42:01.986607 (MainThread): 14:42:01  
2022-01-06 14:42:01.986786 (MainThread): 14:42:01  Completed successfully
2022-01-06 14:42:01.986883 (MainThread): 14:42:01  
2022-01-06 14:42:01.986966 (MainThread): 14:42:01  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:42:03.230299 (Thread-127): handling poll request
2022-01-06 14:42:03.230673 (Thread-127): 14:42:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7833e400>]}
2022-01-06 14:42:03.232024 (Thread-127): sending response (<Response 28436 bytes [200 OK]>) to 10.0.5.191
2022-01-06 14:42:03.878873 (Thread-128): handling status request
2022-01-06 14:42:03.879237 (Thread-128): 14:42:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7833e5b0>]}
2022-01-06 14:42:03.879741 (Thread-128): sending response (<Response 1544 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:42:03.947033 (Thread-129): handling status request
2022-01-06 14:42:03.947393 (Thread-129): 14:42:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7833e9a0>]}
2022-01-06 14:42:03.947936 (Thread-129): sending response (<Response 1544 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:42:10.235495 (Thread-130): handling status request
2022-01-06 14:42:10.235858 (Thread-130): 14:42:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7833ebe0>]}
2022-01-06 14:42:10.236327 (Thread-130): sending response (<Response 1544 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:42:10.484283 (Thread-131): handling status request
2022-01-06 14:42:10.484608 (Thread-131): 14:42:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7833ee50>]}
2022-01-06 14:42:10.485056 (Thread-131): sending response (<Response 1544 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:42:10.645366 (Thread-132): handling cli_args request
2022-01-06 14:42:10.645704 (Thread-132): 14:42:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78349100>]}
2022-01-06 14:42:12.686467 (Thread-132): sending response (<Response 138 bytes [200 OK]>) to 10.0.5.191
2022-01-06 14:42:12.760900 (MainThread): 14:42:12  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:42:12.761329 (MainThread): 14:42:12  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:42:12.767662 (MainThread): 14:42:12  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '112add87-861b-4fcf-a1fb-571d514a8d12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6450f88df0>]}
2022-01-06 14:42:12.793386 (MainThread): 14:42:12  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '112add87-861b-4fcf-a1fb-571d514a8d12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6450ffedc0>]}
2022-01-06 14:42:12.793626 (MainThread): 14:42:12  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:42:12.794658 (MainThread): 14:42:12  
2022-01-06 14:42:12.794927 (MainThread): 14:42:12  Acquiring new redshift connection "master"
2022-01-06 14:42:12.795874 (ThreadPoolExecutor-0_0): 14:42:12  Acquiring new redshift connection "list_dev"
2022-01-06 14:42:12.805577 (ThreadPoolExecutor-0_0): 14:42:12  Using redshift connection "list_dev"
2022-01-06 14:42:12.805678 (ThreadPoolExecutor-0_0): 14:42:12  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:42:12.805759 (ThreadPoolExecutor-0_0): 14:42:12  Opening a new connection, currently in state init
2022-01-06 14:42:12.805838 (ThreadPoolExecutor-0_0): 14:42:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:12.826438 (ThreadPoolExecutor-0_0): 14:42:12  SQL status: SELECT in 0.02 seconds
2022-01-06 14:42:12.827457 (ThreadPoolExecutor-0_0): 14:42:12  On list_dev: Close
2022-01-06 14:42:12.828676 (ThreadPoolExecutor-1_0): 14:42:12  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:42:12.835147 (ThreadPoolExecutor-1_0): 14:42:12  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:42:12.835246 (ThreadPoolExecutor-1_0): 14:42:12  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:42:12.835325 (ThreadPoolExecutor-1_0): 14:42:12  Opening a new connection, currently in state closed
2022-01-06 14:42:12.835403 (ThreadPoolExecutor-1_0): 14:42:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:12.857880 (ThreadPoolExecutor-1_0): 14:42:12  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:12.857990 (ThreadPoolExecutor-1_0): 14:42:12  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:42:12.858065 (ThreadPoolExecutor-1_0): 14:42:12  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:42:12.868392 (ThreadPoolExecutor-1_0): 14:42:12  SQL status: SELECT in 0.01 seconds
2022-01-06 14:42:12.869460 (ThreadPoolExecutor-1_0): 14:42:12  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:42:12.871216 (ThreadPoolExecutor-1_0): 14:42:12  On list_dev_dbt_nobodozie: Close
2022-01-06 14:42:12.874868 (MainThread): 14:42:12  Using redshift connection "master"
2022-01-06 14:42:12.874980 (MainThread): 14:42:12  On master: BEGIN
2022-01-06 14:42:12.875059 (MainThread): 14:42:12  Opening a new connection, currently in state init
2022-01-06 14:42:12.875134 (MainThread): 14:42:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:12.898508 (MainThread): 14:42:12  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:12.898619 (MainThread): 14:42:12  Using redshift connection "master"
2022-01-06 14:42:12.898696 (MainThread): 14:42:12  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:42:12.927255 (MainThread): 14:42:12  SQL status: SELECT in 0.03 seconds
2022-01-06 14:42:12.928214 (MainThread): 14:42:12  On master: ROLLBACK
2022-01-06 14:42:12.930023 (MainThread): 14:42:12  Using redshift connection "master"
2022-01-06 14:42:12.930123 (MainThread): 14:42:12  On master: BEGIN
2022-01-06 14:42:12.933568 (MainThread): 14:42:12  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:12.933680 (MainThread): 14:42:12  On master: COMMIT
2022-01-06 14:42:12.933751 (MainThread): 14:42:12  Using redshift connection "master"
2022-01-06 14:42:12.933818 (MainThread): 14:42:12  On master: COMMIT
2022-01-06 14:42:12.935516 (MainThread): 14:42:12  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:42:12.935618 (MainThread): 14:42:12  On master: Close
2022-01-06 14:42:12.935975 (MainThread): 14:42:12  Concurrency: 4 threads (target='default')
2022-01-06 14:42:12.936088 (MainThread): 14:42:12  
2022-01-06 14:42:12.938324 (Thread-1): 14:42:12  Began running node model.my_new_project.dim_customers
2022-01-06 14:42:12.938559 (Thread-1): 14:42:12  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:42:12.938783 (Thread-1): 14:42:12  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:12.938874 (Thread-1): 14:42:12  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:42:12.938973 (Thread-1): 14:42:12  Compiling model.my_new_project.dim_customers
2022-01-06 14:42:12.940958 (Thread-1): 14:42:12  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:42:12.941179 (Thread-2): 14:42:12  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:42:12.941418 (Thread-2): 14:42:12  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:42:12.941656 (Thread-2): 14:42:12  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:12.941742 (Thread-2): 14:42:12  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:42:12.941822 (Thread-2): 14:42:12  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:42:12.943756 (Thread-2): 14:42:12  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:12.955990 (Thread-2): 14:42:12  finished collecting timing info
2022-01-06 14:42:12.956126 (Thread-2): 14:42:12  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:42:12.967978 (Thread-1): 14:42:12  finished collecting timing info
2022-01-06 14:42:12.968104 (Thread-1): 14:42:12  Began executing node model.my_new_project.dim_customers
2022-01-06 14:42:13.009607 (Thread-2): 14:42:13  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.010479 (Thread-1): 14:42:13  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:42:13.023666 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.023779 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:42:13.023861 (Thread-2): 14:42:13  Opening a new connection, currently in state init
2022-01-06 14:42:13.023942 (Thread-2): 14:42:13  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:13.024184 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.024284 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:42:13.024362 (Thread-1): 14:42:13  Opening a new connection, currently in state closed
2022-01-06 14:42:13.024438 (Thread-1): 14:42:13  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:13.049561 (Thread-2): 14:42:13  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:42:13.049674 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.049752 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:42:13.049915 (Thread-1): 14:42:13  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:42:13.050025 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.050101 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:42:13.118096 (Thread-2): 14:42:13  SQL status: SELECT in 0.07 seconds
2022-01-06 14:42:13.123598 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.123823 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:42:13.132710 (Thread-2): 14:42:13  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:42:13.134542 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.134638 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:42:13.138166 (Thread-2): 14:42:13  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:42:13.148315 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:42:13.148496 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.148626 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:42:13.162983 (Thread-133): handling poll request
2022-01-06 14:42:13.163614 (Thread-133): 14:42:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78349700>]}
2022-01-06 14:42:13.165207 (Thread-133): sending response (<Response 34593 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:42:13.162451 (Thread-1): 14:42:13  SQL status: SELECT in 0.11 seconds
2022-01-06 14:42:13.165193 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.165350 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:42:13.168681 (Thread-1): 14:42:13  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:42:13.170318 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.170412 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:42:13.173761 (Thread-1): 14:42:13  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:42:13.174849 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:42:13.174944 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.175015 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:42:13.213323 (Thread-2): 14:42:13  SQL status: COMMIT in 0.06 seconds
2022-01-06 14:42:13.213534 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.213617 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:42:13.213833 (Thread-1): 14:42:13  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:42:13.216101 (Thread-2): 14:42:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:13.220013 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.220109 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:42:13.225638 (Thread-2): 14:42:13  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 14:42:13.226252 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:42:13.226345 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.226419 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:42:13.257945 (Thread-2): 14:42:13  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:42:13.258059 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.258134 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:42:13.260121 (Thread-2): 14:42:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:13.260513 (Thread-2): 14:42:13  finished collecting timing info
2022-01-06 14:42:13.260639 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:42:13.260836 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.260942 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:42:13.263688 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:42:13.263896 (Thread-1): 14:42:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:13.265853 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.265989 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:42:13.266649 (Thread-2): 14:42:13  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '112add87-861b-4fcf-a1fb-571d514a8d12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64506cb8b0>]}
2022-01-06 14:42:13.267025 (Thread-2): 14:42:13  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.33s]
2022-01-06 14:42:13.267143 (Thread-2): 14:42:13  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:42:13.267794 (Thread-4): 14:42:13  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:42:13.268023 (Thread-4): 14:42:13  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:42:13.268275 (Thread-4): 14:42:13  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.268381 (Thread-4): 14:42:13  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:42:13.268466 (Thread-4): 14:42:13  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:42:13.270451 (Thread-4): 14:42:13  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.272519 (Thread-1): 14:42:13  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 14:42:13.273150 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:42:13.273281 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.273361 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:42:13.282176 (Thread-4): 14:42:13  finished collecting timing info
2022-01-06 14:42:13.282320 (Thread-4): 14:42:13  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:42:13.297820 (Thread-4): 14:42:13  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.305403 (Thread-1): 14:42:13  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:42:13.305520 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.305593 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:42:13.307601 (Thread-1): 14:42:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:13.307957 (Thread-1): 14:42:13  finished collecting timing info
2022-01-06 14:42:13.308078 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:42:13.309889 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: Close
2022-01-06 14:42:13.310305 (Thread-1): 14:42:13  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '112add87-861b-4fcf-a1fb-571d514a8d12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64506d3970>]}
2022-01-06 14:42:13.310601 (Thread-1): 14:42:13  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.37s]
2022-01-06 14:42:13.310708 (Thread-1): 14:42:13  Finished running node model.my_new_project.dim_customers
2022-01-06 14:42:13.310989 (Thread-4): 14:42:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.311097 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:42:13.311179 (Thread-4): 14:42:13  Opening a new connection, currently in state init
2022-01-06 14:42:13.311260 (Thread-4): 14:42:13  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:13.335647 (Thread-4): 14:42:13  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:13.335758 (Thread-4): 14:42:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.335835 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:42:13.340599 (Thread-4): 14:42:13  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:42:13.342449 (Thread-4): 14:42:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.342544 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:42:13.344742 (Thread-4): 14:42:13  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:42:13.345679 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:42:13.345774 (Thread-4): 14:42:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.345847 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:42:13.372991 (Thread-4): 14:42:13  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:42:13.373236 (Thread-4): 14:42:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.373324 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:42:13.375367 (Thread-4): 14:42:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:13.376662 (Thread-4): 14:42:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.376759 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:42:13.378621 (Thread-4): 14:42:13  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:42:13.379298 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:42:13.379393 (Thread-4): 14:42:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.379466 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:42:13.403722 (Thread-4): 14:42:13  SQL status: COMMIT in 0.02 seconds
2022-01-06 14:42:13.403848 (Thread-4): 14:42:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.403922 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:42:13.405907 (Thread-4): 14:42:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:13.406345 (Thread-4): 14:42:13  finished collecting timing info
2022-01-06 14:42:13.406477 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:42:13.408256 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:42:13.408727 (Thread-4): 14:42:13  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '112add87-861b-4fcf-a1fb-571d514a8d12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64507087c0>]}
2022-01-06 14:42:13.409064 (Thread-4): 14:42:13  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.14s]
2022-01-06 14:42:13.409176 (Thread-4): 14:42:13  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:42:13.410793 (MainThread): 14:42:13  Acquiring new redshift connection "master"
2022-01-06 14:42:13.410989 (MainThread): 14:42:13  Using redshift connection "master"
2022-01-06 14:42:13.411107 (MainThread): 14:42:13  On master: BEGIN
2022-01-06 14:42:13.411219 (MainThread): 14:42:13  Opening a new connection, currently in state closed
2022-01-06 14:42:13.411336 (MainThread): 14:42:13  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:13.434808 (MainThread): 14:42:13  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:13.435016 (MainThread): 14:42:13  On master: COMMIT
2022-01-06 14:42:13.435152 (MainThread): 14:42:13  Using redshift connection "master"
2022-01-06 14:42:13.435274 (MainThread): 14:42:13  On master: COMMIT
2022-01-06 14:42:13.437137 (MainThread): 14:42:13  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:42:13.437350 (MainThread): 14:42:13  On master: Close
2022-01-06 14:42:13.438056 (MainThread): 14:42:13  
2022-01-06 14:42:13.438238 (MainThread): 14:42:13  Finished running 2 table models, 1 view model in 0.64s.
2022-01-06 14:42:13.438401 (MainThread): 14:42:13  Connection 'master' was properly closed.
2022-01-06 14:42:13.438529 (MainThread): 14:42:13  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:42:13.438642 (MainThread): 14:42:13  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:42:13.438756 (MainThread): 14:42:13  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:42:13.484833 (MainThread): 14:42:13  
2022-01-06 14:42:13.485029 (MainThread): 14:42:13  Completed successfully
2022-01-06 14:42:13.485124 (MainThread): 14:42:13  
2022-01-06 14:42:13.485208 (MainThread): 14:42:13  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:42:14.655202 (Thread-134): handling poll request
2022-01-06 14:42:14.655582 (Thread-134): 14:42:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980898e0>]}
2022-01-06 14:42:14.657634 (Thread-134): sending response (<Response 52595 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:42:15.416064 (Thread-135): handling status request
2022-01-06 14:42:15.416433 (Thread-135): 14:42:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff98089280>]}
2022-01-06 14:42:15.416957 (Thread-135): sending response (<Response 1544 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:42:15.494602 (Thread-136): handling status request
2022-01-06 14:42:15.494869 (Thread-136): 14:42:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8038f40>]}
2022-01-06 14:42:15.495261 (Thread-136): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:42:55.299432 (Thread-137): handling status request
2022-01-06 14:42:55.299798 (Thread-137): 14:42:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb803dbe0>]}
2022-01-06 14:42:55.300274 (Thread-137): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:42:55.620557 (Thread-138): handling run_sql request
2022-01-06 14:42:55.620868 (Thread-138): 14:42:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8546220>]}
2022-01-06 14:42:57.661375 (Thread-138): sending response (<Response 138 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:42:57.685069 (MainThread): 14:42:57  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7d49e94f-fee3-4846-8467-9d3e06eed911', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa29ef49820>]}
2022-01-06 14:42:57.685605 (MainThread): 14:42:57  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:42:57.686157 (Thread-1): 14:42:57  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:42:57.686284 (Thread-1): 14:42:57  Began compiling node rpc.my_new_project.request
2022-01-06 14:42:57.686374 (Thread-1): 14:42:57  Compiling rpc.my_new_project.request
2022-01-06 14:42:57.687511 (Thread-1): 14:42:57  finished collecting timing info
2022-01-06 14:42:57.687638 (Thread-1): 14:42:57  Began executing node rpc.my_new_project.request
2022-01-06 14:42:57.687732 (Thread-1): 14:42:57  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:42:57.687813 (Thread-1): 14:42:57  On rpc.my_new_project.request: with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:42:57.687891 (Thread-1): 14:42:57  Opening a new connection, currently in state init
2022-01-06 14:42:57.687976 (Thread-1): 14:42:57  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:57.710055 (Thread-1): 14:42:57  SQL status: SELECT in 0.02 seconds
2022-01-06 14:42:57.712513 (Thread-1): 14:42:57  finished collecting timing info
2022-01-06 14:42:57.712645 (Thread-1): 14:42:57  On rpc.my_new_project.request: Close
2022-01-06 14:42:58.017277 (Thread-139): handling poll request
2022-01-06 14:42:58.017712 (Thread-139): 14:42:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78350640>]}
2022-01-06 14:42:58.019247 (Thread-139): sending response (<Response 11838 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:44:53.204225 (Thread-140): handling status request
2022-01-06 14:44:53.205531 (Thread-140): 14:44:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78350370>]}
2022-01-06 14:44:53.206058 (Thread-140): sending response (<Response 1544 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:44:53.747703 (Thread-141): handling compile_sql request
2022-01-06 14:44:53.748015 (Thread-141): 14:44:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78350e50>]}
2022-01-06 14:44:55.826213 (Thread-141): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:44:55.845928 (MainThread): 14:44:55  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4f8cc452-a25b-4ec4-b7ff-513c70e1544c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58b2564790>]}
2022-01-06 14:44:55.846467 (MainThread): 14:44:55  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:44:55.847041 (Thread-1): 14:44:55  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:44:55.847173 (Thread-1): 14:44:55  Began compiling node rpc.my_new_project.request
2022-01-06 14:44:55.847262 (Thread-1): 14:44:55  Compiling rpc.my_new_project.request
2022-01-06 14:44:55.848442 (Thread-1): 14:44:55  finished collecting timing info
2022-01-06 14:44:55.848570 (Thread-1): 14:44:55  Began executing node rpc.my_new_project.request
2022-01-06 14:44:55.848667 (Thread-1): 14:44:55  finished collecting timing info
2022-01-06 14:44:56.292707 (Thread-142): handling poll request
2022-01-06 14:44:56.293150 (Thread-142): 14:44:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782f2130>]}
2022-01-06 14:44:56.294600 (Thread-142): sending response (<Response 5736 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:45:04.243524 (Thread-143): handling status request
2022-01-06 14:45:04.243896 (Thread-143): 14:45:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78350bb0>]}
2022-01-06 14:45:04.244428 (Thread-143): sending response (<Response 1544 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:45:04.674547 (Thread-144): handling compile_sql request
2022-01-06 14:45:04.674912 (Thread-144): 14:45:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8038cd0>]}
2022-01-06 14:45:06.720207 (Thread-144): sending response (<Response 138 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:45:06.745378 (MainThread): 14:45:06  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '173c2128-d304-4efc-b14d-40180975c81c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6979a4ac0>]}
2022-01-06 14:45:06.745872 (MainThread): 14:45:06  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:45:06.746410 (Thread-1): 14:45:06  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:45:06.746537 (Thread-1): 14:45:06  Began compiling node rpc.my_new_project.request
2022-01-06 14:45:06.746625 (Thread-1): 14:45:06  Compiling rpc.my_new_project.request
2022-01-06 14:45:06.749102 (Thread-1): 14:45:06  finished collecting timing info
2022-01-06 14:45:06.749257 (Thread-1): 14:45:06  Began executing node rpc.my_new_project.request
2022-01-06 14:45:06.749354 (Thread-1): 14:45:06  finished collecting timing info
2022-01-06 14:45:07.037852 (Thread-145): handling poll request
2022-01-06 14:45:07.038297 (Thread-145): 14:45:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782f2e50>]}
2022-01-06 14:45:07.039375 (Thread-145): sending response (<Response 8440 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:45:15.362791 (Thread-146): handling status request
2022-01-06 14:45:15.363159 (Thread-146): 14:45:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782fa100>]}
2022-01-06 14:45:15.363695 (Thread-146): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:45:15.697554 (Thread-147): handling run_sql request
2022-01-06 14:45:15.697829 (Thread-147): 14:45:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782fa400>]}
2022-01-06 14:45:17.749128 (Thread-147): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:45:17.774342 (MainThread): 14:45:17  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd1af0cb1-dbf9-49ec-87fe-23143873e50c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0588d2820>]}
2022-01-06 14:45:17.774847 (MainThread): 14:45:17  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:45:17.775428 (Thread-1): 14:45:17  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:45:17.775557 (Thread-1): 14:45:17  Began compiling node rpc.my_new_project.request
2022-01-06 14:45:17.775647 (Thread-1): 14:45:17  Compiling rpc.my_new_project.request
2022-01-06 14:45:17.778165 (Thread-1): 14:45:17  finished collecting timing info
2022-01-06 14:45:17.778307 (Thread-1): 14:45:17  Began executing node rpc.my_new_project.request
2022-01-06 14:45:17.778405 (Thread-1): 14:45:17  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:45:17.778479 (Thread-1): 14:45:17  On rpc.my_new_project.request: 

with customers as (
    select * from "dev"."dbt_nobodozie"."stg_customers"
),
orders as (
    select * from "dev"."dbt_nobodozie"."stg_orders"
),
customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:45:17.778556 (Thread-1): 14:45:17  Opening a new connection, currently in state init
2022-01-06 14:45:17.778633 (Thread-1): 14:45:17  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:45:17.799287 (Thread-1): 14:45:17  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 14:45:17.799442 (Thread-1): 14:45:17  finished collecting timing info
2022-01-06 14:45:17.799560 (Thread-1): 14:45:17  On rpc.my_new_project.request: Close
2022-01-06 14:45:17.799757 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 14:45:17.800830 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n    select * from {{ ref(\'stg_customers\')}}\n),\norders as (\n    select * from {{ ref(\'stg_orders\')}}\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\norders as (\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n    select * from {{ ref(\'stg_customers\')}}\n),\norders as (\n    select * from {{ ref(\'stg_orders\')}}\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\norders as (\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 14:45:18.161630 (Thread-148): handling poll request
2022-01-06 14:45:18.162086 (Thread-148): 14:45:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78301640>]}
2022-01-06 14:45:18.162907 (Thread-148): sending response (<Response 14619 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:47:07.010943 (Thread-149): handling status request
2022-01-06 14:47:07.012365 (Thread-149): 14:47:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78301b50>]}
2022-01-06 14:47:07.012914 (Thread-149): sending response (<Response 1544 bytes [200 OK]>) to 10.0.5.191
2022-01-06 14:47:07.270683 (Thread-150): handling status request
2022-01-06 14:47:07.271110 (Thread-150): 14:47:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78301e20>]}
2022-01-06 14:47:07.271597 (Thread-150): sending response (<Response 1544 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:47:07.396335 (Thread-151): handling cli_args request
2022-01-06 14:47:07.396587 (Thread-151): 14:47:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7830c070>]}
2022-01-06 14:47:09.462996 (Thread-151): sending response (<Response 138 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:47:09.551382 (MainThread): 14:47:09  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:47:09.551782 (MainThread): 14:47:09  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:47:09.557359 (MainThread): 14:47:09  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198e5c9-e30f-4ddc-abeb-be8ec4a6af63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70a33f4d90>]}
2022-01-06 14:47:09.582250 (MainThread): 14:47:09  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e198e5c9-e30f-4ddc-abeb-be8ec4a6af63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70a34945e0>]}
2022-01-06 14:47:09.582486 (MainThread): 14:47:09  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:47:09.583502 (MainThread): 14:47:09  
2022-01-06 14:47:09.583769 (MainThread): 14:47:09  Acquiring new redshift connection "master"
2022-01-06 14:47:09.584763 (ThreadPoolExecutor-0_0): 14:47:09  Acquiring new redshift connection "list_dev"
2022-01-06 14:47:09.594905 (ThreadPoolExecutor-0_0): 14:47:09  Using redshift connection "list_dev"
2022-01-06 14:47:09.595009 (ThreadPoolExecutor-0_0): 14:47:09  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:47:09.595093 (ThreadPoolExecutor-0_0): 14:47:09  Opening a new connection, currently in state init
2022-01-06 14:47:09.595175 (ThreadPoolExecutor-0_0): 14:47:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:47:09.615304 (ThreadPoolExecutor-0_0): 14:47:09  SQL status: SELECT in 0.02 seconds
2022-01-06 14:47:09.616348 (ThreadPoolExecutor-0_0): 14:47:09  On list_dev: Close
2022-01-06 14:47:09.617471 (ThreadPoolExecutor-1_0): 14:47:09  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:47:09.623849 (ThreadPoolExecutor-1_0): 14:47:09  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:47:09.623950 (ThreadPoolExecutor-1_0): 14:47:09  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:47:09.624032 (ThreadPoolExecutor-1_0): 14:47:09  Opening a new connection, currently in state closed
2022-01-06 14:47:09.624109 (ThreadPoolExecutor-1_0): 14:47:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:47:09.647075 (ThreadPoolExecutor-1_0): 14:47:09  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:47:09.647188 (ThreadPoolExecutor-1_0): 14:47:09  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:47:09.647264 (ThreadPoolExecutor-1_0): 14:47:09  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:47:09.658688 (ThreadPoolExecutor-1_0): 14:47:09  SQL status: SELECT in 0.01 seconds
2022-01-06 14:47:09.659721 (ThreadPoolExecutor-1_0): 14:47:09  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:47:09.661498 (ThreadPoolExecutor-1_0): 14:47:09  On list_dev_dbt_nobodozie: Close
2022-01-06 14:47:09.665112 (MainThread): 14:47:09  Using redshift connection "master"
2022-01-06 14:47:09.665251 (MainThread): 14:47:09  On master: BEGIN
2022-01-06 14:47:09.665334 (MainThread): 14:47:09  Opening a new connection, currently in state init
2022-01-06 14:47:09.665411 (MainThread): 14:47:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:47:09.689520 (MainThread): 14:47:09  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:47:09.689631 (MainThread): 14:47:09  Using redshift connection "master"
2022-01-06 14:47:09.689707 (MainThread): 14:47:09  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:47:09.718670 (MainThread): 14:47:09  SQL status: SELECT in 0.03 seconds
2022-01-06 14:47:09.719665 (MainThread): 14:47:09  On master: ROLLBACK
2022-01-06 14:47:09.721567 (MainThread): 14:47:09  Using redshift connection "master"
2022-01-06 14:47:09.721672 (MainThread): 14:47:09  On master: BEGIN
2022-01-06 14:47:09.725186 (MainThread): 14:47:09  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:47:09.725333 (MainThread): 14:47:09  On master: COMMIT
2022-01-06 14:47:09.725410 (MainThread): 14:47:09  Using redshift connection "master"
2022-01-06 14:47:09.725493 (MainThread): 14:47:09  On master: COMMIT
2022-01-06 14:47:09.727209 (MainThread): 14:47:09  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:47:09.727315 (MainThread): 14:47:09  On master: Close
2022-01-06 14:47:09.727711 (MainThread): 14:47:09  Concurrency: 4 threads (target='default')
2022-01-06 14:47:09.727828 (MainThread): 14:47:09  
2022-01-06 14:47:09.730076 (Thread-1): 14:47:09  Began running node model.my_new_project.dim_customers
2022-01-06 14:47:09.730351 (Thread-1): 14:47:09  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:47:09.730595 (Thread-1): 14:47:09  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:09.730690 (Thread-1): 14:47:09  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:47:09.730790 (Thread-1): 14:47:09  Compiling model.my_new_project.dim_customers
2022-01-06 14:47:09.732984 (Thread-1): 14:47:09  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:47:09.733254 (Thread-2): 14:47:09  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:47:09.733496 (Thread-2): 14:47:09  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:47:09.733755 (Thread-2): 14:47:09  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:09.733846 (Thread-2): 14:47:09  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:47:09.733930 (Thread-2): 14:47:09  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:47:09.735984 (Thread-2): 14:47:09  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:09.749039 (Thread-1): 14:47:09  finished collecting timing info
2022-01-06 14:47:09.749188 (Thread-1): 14:47:09  Began executing node model.my_new_project.dim_customers
2022-01-06 14:47:09.754162 (Thread-2): 14:47:09  finished collecting timing info
2022-01-06 14:47:09.754348 (Thread-2): 14:47:09  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:47:09.815886 (Thread-2): 14:47:09  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:09.818680 (Thread-1): 14:47:09  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:47:09.833567 (Thread-2): 14:47:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:09.833708 (Thread-2): 14:47:09  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:47:09.833801 (Thread-2): 14:47:09  Opening a new connection, currently in state init
2022-01-06 14:47:09.833884 (Thread-2): 14:47:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:47:09.834296 (Thread-1): 14:47:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:09.834415 (Thread-1): 14:47:09  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:47:09.834499 (Thread-1): 14:47:09  Opening a new connection, currently in state closed
2022-01-06 14:47:09.834578 (Thread-1): 14:47:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:47:09.860592 (Thread-2): 14:47:09  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:47:09.860742 (Thread-2): 14:47:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:09.860824 (Thread-2): 14:47:09  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:47:09.861249 (Thread-1): 14:47:09  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:47:09.861401 (Thread-1): 14:47:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:09.861489 (Thread-1): 14:47:09  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:47:09.869755 (Thread-152): handling poll request
2022-01-06 14:47:09.870134 (Thread-152): 14:47:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78312160>]}
2022-01-06 14:47:09.871522 (Thread-152): sending response (<Response 30570 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:47:09.958590 (Thread-2): 14:47:09  SQL status: SELECT in 0.1 seconds
2022-01-06 14:47:09.964709 (Thread-2): 14:47:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:09.964835 (Thread-2): 14:47:09  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:47:09.968226 (Thread-2): 14:47:09  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:47:09.970132 (Thread-2): 14:47:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:09.970235 (Thread-2): 14:47:09  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:47:09.975792 (Thread-2): 14:47:09  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:47:09.985805 (Thread-2): 14:47:09  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:47:09.985909 (Thread-2): 14:47:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:09.985985 (Thread-2): 14:47:09  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:47:09.988782 (Thread-1): 14:47:09  SQL status: SELECT in 0.13 seconds
2022-01-06 14:47:09.990721 (Thread-1): 14:47:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:09.990820 (Thread-1): 14:47:09  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:47:09.997990 (Thread-1): 14:47:09  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:47:10.000793 (Thread-1): 14:47:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:10.000907 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:47:10.003841 (Thread-1): 14:47:10  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:47:10.005254 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:47:10.005378 (Thread-1): 14:47:10  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:10.005488 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:47:10.046537 (Thread-2): 14:47:10  SQL status: COMMIT in 0.06 seconds
2022-01-06 14:47:10.046753 (Thread-2): 14:47:10  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:10.046837 (Thread-2): 14:47:10  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:47:10.047082 (Thread-1): 14:47:10  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:47:10.049123 (Thread-2): 14:47:10  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:47:10.053058 (Thread-2): 14:47:10  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:10.053156 (Thread-2): 14:47:10  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:47:10.058057 (Thread-2): 14:47:10  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:47:10.058687 (Thread-2): 14:47:10  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:47:10.058781 (Thread-2): 14:47:10  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:10.058854 (Thread-2): 14:47:10  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:47:10.087982 (Thread-2): 14:47:10  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:47:10.088096 (Thread-2): 14:47:10  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:10.088181 (Thread-2): 14:47:10  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:47:10.090368 (Thread-2): 14:47:10  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:47:10.090765 (Thread-2): 14:47:10  finished collecting timing info
2022-01-06 14:47:10.090895 (Thread-2): 14:47:10  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:47:10.091110 (Thread-1): 14:47:10  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:10.091222 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:47:10.093376 (Thread-1): 14:47:10  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:47:10.094496 (Thread-1): 14:47:10  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:10.094592 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:47:10.094879 (Thread-2): 14:47:10  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:47:10.095351 (Thread-2): 14:47:10  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e198e5c9-e30f-4ddc-abeb-be8ec4a6af63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70a031bbb0>]}
2022-01-06 14:47:10.095678 (Thread-2): 14:47:10  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.36s]
2022-01-06 14:47:10.095809 (Thread-2): 14:47:10  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:47:10.096409 (Thread-4): 14:47:10  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:47:10.096651 (Thread-4): 14:47:10  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:47:10.096908 (Thread-4): 14:47:10  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.097000 (Thread-4): 14:47:10  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:47:10.097088 (Thread-4): 14:47:10  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:47:10.099103 (Thread-4): 14:47:10  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.099945 (Thread-1): 14:47:10  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 14:47:10.100579 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:47:10.100676 (Thread-1): 14:47:10  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:10.100751 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:47:10.111690 (Thread-4): 14:47:10  finished collecting timing info
2022-01-06 14:47:10.111832 (Thread-4): 14:47:10  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:47:10.127361 (Thread-4): 14:47:10  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.132285 (Thread-1): 14:47:10  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:47:10.132412 (Thread-1): 14:47:10  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:10.132490 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:47:10.134531 (Thread-1): 14:47:10  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:47:10.134905 (Thread-1): 14:47:10  finished collecting timing info
2022-01-06 14:47:10.135027 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:47:10.136836 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: Close
2022-01-06 14:47:10.137304 (Thread-1): 14:47:10  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e198e5c9-e30f-4ddc-abeb-be8ec4a6af63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70a0319fa0>]}
2022-01-06 14:47:10.137623 (Thread-1): 14:47:10  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.41s]
2022-01-06 14:47:10.137760 (Thread-1): 14:47:10  Finished running node model.my_new_project.dim_customers
2022-01-06 14:47:10.139787 (Thread-4): 14:47:10  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.139902 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:47:10.139987 (Thread-4): 14:47:10  Opening a new connection, currently in state init
2022-01-06 14:47:10.140069 (Thread-4): 14:47:10  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:47:10.195298 (Thread-4): 14:47:10  SQL status: BEGIN in 0.06 seconds
2022-01-06 14:47:10.195414 (Thread-4): 14:47:10  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.195494 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:47:10.200277 (Thread-4): 14:47:10  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:47:10.202200 (Thread-4): 14:47:10  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.202297 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:47:10.204582 (Thread-4): 14:47:10  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:47:10.205543 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:47:10.205640 (Thread-4): 14:47:10  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.205714 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:47:10.237188 (Thread-4): 14:47:10  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:47:10.237436 (Thread-4): 14:47:10  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.237521 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:47:10.239516 (Thread-4): 14:47:10  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:47:10.240764 (Thread-4): 14:47:10  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.240880 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:47:10.242783 (Thread-4): 14:47:10  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:47:10.243450 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:47:10.243545 (Thread-4): 14:47:10  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.243620 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:47:10.269019 (Thread-4): 14:47:10  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:47:10.269129 (Thread-4): 14:47:10  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.269203 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:47:10.271228 (Thread-4): 14:47:10  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:47:10.271586 (Thread-4): 14:47:10  finished collecting timing info
2022-01-06 14:47:10.271702 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:47:10.273399 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:47:10.273793 (Thread-4): 14:47:10  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e198e5c9-e30f-4ddc-abeb-be8ec4a6af63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70a2bab8e0>]}
2022-01-06 14:47:10.274088 (Thread-4): 14:47:10  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.18s]
2022-01-06 14:47:10.274193 (Thread-4): 14:47:10  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:47:10.275444 (MainThread): 14:47:10  Acquiring new redshift connection "master"
2022-01-06 14:47:10.275590 (MainThread): 14:47:10  Using redshift connection "master"
2022-01-06 14:47:10.275668 (MainThread): 14:47:10  On master: BEGIN
2022-01-06 14:47:10.275745 (MainThread): 14:47:10  Opening a new connection, currently in state closed
2022-01-06 14:47:10.275822 (MainThread): 14:47:10  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:47:10.299555 (MainThread): 14:47:10  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:47:10.299675 (MainThread): 14:47:10  On master: COMMIT
2022-01-06 14:47:10.299752 (MainThread): 14:47:10  Using redshift connection "master"
2022-01-06 14:47:10.299823 (MainThread): 14:47:10  On master: COMMIT
2022-01-06 14:47:10.301495 (MainThread): 14:47:10  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:47:10.301601 (MainThread): 14:47:10  On master: Close
2022-01-06 14:47:10.302000 (MainThread): 14:47:10  
2022-01-06 14:47:10.302115 (MainThread): 14:47:10  Finished running 2 table models, 1 view model in 0.72s.
2022-01-06 14:47:10.302198 (MainThread): 14:47:10  Connection 'master' was properly closed.
2022-01-06 14:47:10.302265 (MainThread): 14:47:10  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:47:10.302327 (MainThread): 14:47:10  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:47:10.302388 (MainThread): 14:47:10  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:47:10.348452 (MainThread): 14:47:10  
2022-01-06 14:47:10.348602 (MainThread): 14:47:10  Completed successfully
2022-01-06 14:47:10.348699 (MainThread): 14:47:10  
2022-01-06 14:47:10.348785 (MainThread): 14:47:10  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:47:11.206657 (Thread-153): handling poll request
2022-01-06 14:47:11.207052 (Thread-153): 14:47:11  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782d5490>]}
2022-01-06 14:47:11.209104 (Thread-153): sending response (<Response 56626 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:47:11.831333 (Thread-154): handling status request
2022-01-06 14:47:11.831708 (Thread-154): 14:47:11  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782d5640>]}
2022-01-06 14:47:11.837931 (Thread-154): sending response (<Response 1544 bytes [200 OK]>) to 10.0.21.176
2022-01-06 14:47:11.866090 (Thread-155): handling status request
2022-01-06 14:47:11.866365 (Thread-155): 14:47:11  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782d5a30>]}
2022-01-06 14:47:11.866790 (Thread-155): sending response (<Response 1544 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:48:37.334229 (Thread-156): handling status request
2022-01-06 14:48:37.335741 (Thread-156): 14:48:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782d5c70>]}
2022-01-06 14:48:37.358981 (Thread-156): sending response (<Response 1544 bytes [200 OK]>) to 10.0.40.39
2022-01-06 14:48:40.203729 (Thread-157): 14:48:40  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:48:40.203932 (Thread-157): 14:48:40  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:48:40.208986 (Thread-157): 14:48:40  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781fdfd0>]}
2022-01-06 14:48:40.792691 (Thread-158): handling status request
2022-01-06 14:48:40.793059 (Thread-158): 14:48:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781f4670>]}
2022-01-06 14:48:40.793576 (Thread-158): sending response (<Response 1244 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:48:40.819629 (Thread-159): handling status request
2022-01-06 14:48:40.819912 (Thread-159): 14:48:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781f4400>]}
2022-01-06 14:48:40.820318 (Thread-159): sending response (<Response 1244 bytes [200 OK]>) to 10.0.40.39
2022-01-06 14:50:15.588984 (Thread-160): handling status request
2022-01-06 14:50:15.589396 (Thread-160): 14:50:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7837bf70>]}
2022-01-06 14:50:15.589875 (Thread-160): sending response (<Response 1244 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:50:15.628922 (Thread-161): handling status request
2022-01-06 14:50:15.629317 (Thread-161): 14:50:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781f4100>]}
2022-01-06 14:50:15.629885 (Thread-161): sending response (<Response 1244 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:50:15.631079 (Thread-162): handling status request
2022-01-06 14:50:15.631410 (Thread-162): 14:50:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb80a1bb0>]}
2022-01-06 14:50:15.631774 (Thread-162): sending response (<Response 1244 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:50:16.266196 (Thread-163): handling ps request
2022-01-06 14:50:16.266573 (Thread-163): 14:50:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781f2490>]}
2022-01-06 14:50:16.267838 (Thread-163): sending response (<Response 12681 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:50:17.046631 (Thread-164): handling poll request
2022-01-06 14:50:17.047044 (Thread-164): 14:50:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782d9bb0>]}
2022-01-06 14:50:17.049486 (Thread-164): sending response (<Response 86912 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:50:17.862362 (Thread-165): handling status request
2022-01-06 14:50:17.862755 (Thread-165): 14:50:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781f2af0>]}
2022-01-06 14:50:17.863248 (Thread-165): sending response (<Response 1244 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:50:17.939956 (Thread-166): handling status request
2022-01-06 14:50:17.940318 (Thread-166): 14:50:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782d5730>]}
2022-01-06 14:50:17.940788 (Thread-166): sending response (<Response 1244 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:50:48.783531 (Thread-167): handling status request
2022-01-06 14:50:48.783911 (Thread-167): 14:50:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782779d0>]}
2022-01-06 14:50:48.784384 (Thread-167): sending response (<Response 1244 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:50:48.984509 (Thread-168): handling status request
2022-01-06 14:50:48.984798 (Thread-168): 14:50:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78277d60>]}
2022-01-06 14:50:48.985208 (Thread-168): sending response (<Response 1244 bytes [200 OK]>) to 10.0.40.39
2022-01-06 14:50:49.125933 (Thread-169): handling cli_args request
2022-01-06 14:50:49.126186 (Thread-169): 14:50:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78277910>]}
2022-01-06 14:50:51.203902 (Thread-169): sending response (<Response 138 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:50:51.289890 (MainThread): 14:50:51  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:50:51.290279 (MainThread): 14:50:51  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:50:51.295994 (MainThread): 14:50:51  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7e44ce6a-0584-455d-b8aa-f21405f76e23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6b75e6c10>]}
2022-01-06 14:50:51.323791 (MainThread): 14:50:51  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7e44ce6a-0584-455d-b8aa-f21405f76e23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6b7650c70>]}
2022-01-06 14:50:51.324026 (MainThread): 14:50:51  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:50:51.324915 (MainThread): 14:50:51  
2022-01-06 14:50:51.325172 (MainThread): 14:50:51  Acquiring new redshift connection "master"
2022-01-06 14:50:51.325893 (ThreadPoolExecutor-0_0): 14:50:51  Acquiring new redshift connection "list_dev"
2022-01-06 14:50:51.335611 (ThreadPoolExecutor-0_0): 14:50:51  Using redshift connection "list_dev"
2022-01-06 14:50:51.335709 (ThreadPoolExecutor-0_0): 14:50:51  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:50:51.335790 (ThreadPoolExecutor-0_0): 14:50:51  Opening a new connection, currently in state init
2022-01-06 14:50:51.336049 (ThreadPoolExecutor-0_0): 14:50:51  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:50:51.356828 (ThreadPoolExecutor-0_0): 14:50:51  SQL status: SELECT in 0.02 seconds
2022-01-06 14:50:51.357877 (ThreadPoolExecutor-0_0): 14:50:51  On list_dev: Close
2022-01-06 14:50:51.359030 (ThreadPoolExecutor-1_0): 14:50:51  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:50:51.365407 (ThreadPoolExecutor-1_0): 14:50:51  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:50:51.365505 (ThreadPoolExecutor-1_0): 14:50:51  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:50:51.365585 (ThreadPoolExecutor-1_0): 14:50:51  Opening a new connection, currently in state closed
2022-01-06 14:50:51.365659 (ThreadPoolExecutor-1_0): 14:50:51  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:50:51.386444 (ThreadPoolExecutor-1_0): 14:50:51  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:50:51.386553 (ThreadPoolExecutor-1_0): 14:50:51  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:50:51.386639 (ThreadPoolExecutor-1_0): 14:50:51  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:50:51.397455 (ThreadPoolExecutor-1_0): 14:50:51  SQL status: SELECT in 0.01 seconds
2022-01-06 14:50:51.398450 (ThreadPoolExecutor-1_0): 14:50:51  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:50:51.400419 (ThreadPoolExecutor-1_0): 14:50:51  On list_dev_dbt_nobodozie: Close
2022-01-06 14:50:51.403958 (MainThread): 14:50:51  Using redshift connection "master"
2022-01-06 14:50:51.404069 (MainThread): 14:50:51  On master: BEGIN
2022-01-06 14:50:51.404149 (MainThread): 14:50:51  Opening a new connection, currently in state init
2022-01-06 14:50:51.404221 (MainThread): 14:50:51  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:50:51.426885 (MainThread): 14:50:51  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:50:51.426992 (MainThread): 14:50:51  Using redshift connection "master"
2022-01-06 14:50:51.427068 (MainThread): 14:50:51  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:50:51.456142 (MainThread): 14:50:51  SQL status: SELECT in 0.03 seconds
2022-01-06 14:50:51.457621 (MainThread): 14:50:51  On master: ROLLBACK
2022-01-06 14:50:51.459594 (MainThread): 14:50:51  Using redshift connection "master"
2022-01-06 14:50:51.459745 (MainThread): 14:50:51  On master: BEGIN
2022-01-06 14:50:51.463347 (MainThread): 14:50:51  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:50:51.463464 (MainThread): 14:50:51  On master: COMMIT
2022-01-06 14:50:51.463540 (MainThread): 14:50:51  Using redshift connection "master"
2022-01-06 14:50:51.463609 (MainThread): 14:50:51  On master: COMMIT
2022-01-06 14:50:51.465321 (MainThread): 14:50:51  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:50:51.465426 (MainThread): 14:50:51  On master: Close
2022-01-06 14:50:51.465787 (MainThread): 14:50:51  Concurrency: 4 threads (target='default')
2022-01-06 14:50:51.465902 (MainThread): 14:50:51  
2022-01-06 14:50:51.468066 (Thread-1): 14:50:51  Began running node model.my_new_project.dim_customers
2022-01-06 14:50:51.468312 (Thread-1): 14:50:51  1 of 1 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:50:51.468542 (Thread-1): 14:50:51  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:50:51.468632 (Thread-1): 14:50:51  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:50:51.468718 (Thread-1): 14:50:51  Compiling model.my_new_project.dim_customers
2022-01-06 14:50:51.470729 (Thread-1): 14:50:51  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:50:51.484609 (Thread-1): 14:50:51  finished collecting timing info
2022-01-06 14:50:51.484744 (Thread-1): 14:50:51  Began executing node model.my_new_project.dim_customers
2022-01-06 14:50:51.515618 (Thread-1): 14:50:51  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:50:51.528969 (Thread-1): 14:50:51  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:50:51.529075 (Thread-1): 14:50:51  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:50:51.529153 (Thread-1): 14:50:51  Opening a new connection, currently in state closed
2022-01-06 14:50:51.529252 (Thread-1): 14:50:51  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:50:51.549103 (Thread-1): 14:50:51  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:50:51.549234 (Thread-1): 14:50:51  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:50:51.549318 (Thread-1): 14:50:51  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:50:51.590044 (Thread-170): handling poll request
2022-01-06 14:50:51.590370 (Thread-170): 14:50:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781f76a0>]}
2022-01-06 14:50:51.591567 (Thread-170): sending response (<Response 23668 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:50:51.617325 (Thread-1): 14:50:51  SQL status: SELECT in 0.07 seconds
2022-01-06 14:50:51.622562 (Thread-1): 14:50:51  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:50:51.622669 (Thread-1): 14:50:51  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:50:51.625514 (Thread-1): 14:50:51  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:50:51.627334 (Thread-1): 14:50:51  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:50:51.627435 (Thread-1): 14:50:51  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:50:51.629944 (Thread-1): 14:50:51  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:50:51.639913 (Thread-1): 14:50:51  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:50:51.640013 (Thread-1): 14:50:51  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:50:51.640088 (Thread-1): 14:50:51  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:50:51.688202 (Thread-1): 14:50:51  SQL status: COMMIT in 0.05 seconds
2022-01-06 14:50:51.688409 (Thread-1): 14:50:51  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:50:51.688490 (Thread-1): 14:50:51  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:50:51.690718 (Thread-1): 14:50:51  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:50:51.694552 (Thread-1): 14:50:51  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:50:51.694648 (Thread-1): 14:50:51  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:50:51.698187 (Thread-1): 14:50:51  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:50:51.698781 (Thread-1): 14:50:51  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:50:51.698874 (Thread-1): 14:50:51  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:50:51.698947 (Thread-1): 14:50:51  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:50:51.728810 (Thread-1): 14:50:51  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:50:51.728913 (Thread-1): 14:50:51  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:50:51.728982 (Thread-1): 14:50:51  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:50:51.731159 (Thread-1): 14:50:51  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:50:51.731524 (Thread-1): 14:50:51  finished collecting timing info
2022-01-06 14:50:51.731642 (Thread-1): 14:50:51  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:50:51.733424 (Thread-1): 14:50:51  On model.my_new_project.dim_customers: Close
2022-01-06 14:50:51.733812 (Thread-1): 14:50:51  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e44ce6a-0584-455d-b8aa-f21405f76e23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6b6563160>]}
2022-01-06 14:50:51.734107 (Thread-1): 14:50:51  1 of 1 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.27s]
2022-01-06 14:50:51.734218 (Thread-1): 14:50:51  Finished running node model.my_new_project.dim_customers
2022-01-06 14:50:51.735650 (MainThread): 14:50:51  Acquiring new redshift connection "master"
2022-01-06 14:50:51.735847 (MainThread): 14:50:51  Using redshift connection "master"
2022-01-06 14:50:51.735967 (MainThread): 14:50:51  On master: BEGIN
2022-01-06 14:50:51.736082 (MainThread): 14:50:51  Opening a new connection, currently in state closed
2022-01-06 14:50:51.736201 (MainThread): 14:50:51  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:50:51.760831 (MainThread): 14:50:51  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:50:51.760982 (MainThread): 14:50:51  On master: COMMIT
2022-01-06 14:50:51.761091 (MainThread): 14:50:51  Using redshift connection "master"
2022-01-06 14:50:51.761201 (MainThread): 14:50:51  On master: COMMIT
2022-01-06 14:50:51.762952 (MainThread): 14:50:51  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:50:51.763066 (MainThread): 14:50:51  On master: Close
2022-01-06 14:50:51.763437 (MainThread): 14:50:51  
2022-01-06 14:50:51.763545 (MainThread): 14:50:51  Finished running 1 table model in 0.44s.
2022-01-06 14:50:51.763624 (MainThread): 14:50:51  Connection 'master' was properly closed.
2022-01-06 14:50:51.763690 (MainThread): 14:50:51  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:50:51.816359 (MainThread): 14:50:51  
2022-01-06 14:50:51.816511 (MainThread): 14:50:51  Completed successfully
2022-01-06 14:50:51.816603 (MainThread): 14:50:51  
2022-01-06 14:50:51.816687 (MainThread): 14:50:51  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2022-01-06 14:50:53.033590 (Thread-171): handling poll request
2022-01-06 14:50:53.033952 (Thread-171): 14:50:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78208dc0>]}
2022-01-06 14:50:53.035502 (Thread-171): sending response (<Response 21550 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:50:53.726826 (Thread-172): handling status request
2022-01-06 14:50:53.727191 (Thread-172): 14:50:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782d55b0>]}
2022-01-06 14:50:53.727678 (Thread-172): sending response (<Response 1244 bytes [200 OK]>) to 10.0.21.176
2022-01-06 14:50:53.778292 (Thread-173): handling status request
2022-01-06 14:50:53.778667 (Thread-173): 14:50:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782c2610>]}
2022-01-06 14:50:53.779138 (Thread-173): sending response (<Response 1244 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:52:37.463724 (Thread-174): handling status request
2022-01-06 14:52:37.465265 (Thread-174): 14:52:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782e1dc0>]}
2022-01-06 14:52:37.465748 (Thread-174): sending response (<Response 1244 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:52:37.933524 (Thread-175): handling compile_sql request
2022-01-06 14:52:37.933857 (Thread-175): 14:52:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781f4730>]}
2022-01-06 14:52:39.998905 (Thread-175): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:52:40.025857 (MainThread): 14:52:40  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '819f9d48-15c9-4ec3-8ba0-fd412bd38316', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc94e8b9e20>]}
2022-01-06 14:52:40.026365 (MainThread): 14:52:40  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:52:40.026927 (Thread-1): 14:52:40  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:52:40.027057 (Thread-1): 14:52:40  Began compiling node rpc.my_new_project.request
2022-01-06 14:52:40.027146 (Thread-1): 14:52:40  Compiling rpc.my_new_project.request
2022-01-06 14:52:40.029692 (Thread-1): 14:52:40  finished collecting timing info
2022-01-06 14:52:40.029821 (Thread-1): 14:52:40  Began executing node rpc.my_new_project.request
2022-01-06 14:52:40.029917 (Thread-1): 14:52:40  finished collecting timing info
2022-01-06 14:52:40.376041 (Thread-176): handling poll request
2022-01-06 14:52:40.376475 (Thread-176): 14:52:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78215a00>]}
2022-01-06 14:52:40.377619 (Thread-176): sending response (<Response 8496 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:52:51.137466 (Thread-177): handling status request
2022-01-06 14:52:51.137831 (Thread-177): 14:52:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78215bb0>]}
2022-01-06 14:52:51.138345 (Thread-177): sending response (<Response 1244 bytes [200 OK]>) to 10.0.21.176
2022-01-06 14:52:51.165393 (Thread-178): handling ps request
2022-01-06 14:52:51.165659 (Thread-178): 14:52:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78215fa0>]}
2022-01-06 14:52:51.167043 (Thread-178): sending response (<Response 13613 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:52:51.206712 (Thread-179): handling status request
2022-01-06 14:52:51.207006 (Thread-179): 14:52:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7821d190>]}
2022-01-06 14:52:51.207401 (Thread-179): sending response (<Response 1244 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:52:51.397623 (Thread-180): handling status request
2022-01-06 14:52:51.397964 (Thread-180): 14:52:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7821d490>]}
2022-01-06 14:52:51.398414 (Thread-180): sending response (<Response 1244 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:52:52.323892 (Thread-181): handling poll request
2022-01-06 14:52:52.324257 (Thread-181): 14:52:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7821d700>]}
2022-01-06 14:52:52.326163 (Thread-181): sending response (<Response 44911 bytes [200 OK]>) to 10.0.5.191
2022-01-06 14:52:52.971912 (Thread-182): handling status request
2022-01-06 14:52:52.972290 (Thread-182): 14:52:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78215cd0>]}
2022-01-06 14:52:52.972754 (Thread-182): sending response (<Response 1244 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:52:53.033971 (Thread-183): handling status request
2022-01-06 14:52:53.034595 (Thread-183): 14:52:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78215550>]}
2022-01-06 14:52:53.035027 (Thread-183): sending response (<Response 1244 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:53:03.840163 (Thread-184): handling status request
2022-01-06 14:53:03.840550 (Thread-184): 14:53:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781f72b0>]}
2022-01-06 14:53:03.841008 (Thread-184): sending response (<Response 1244 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:53:03.990648 (Thread-185): handling status request
2022-01-06 14:53:03.991026 (Thread-185): 14:53:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78208c70>]}
2022-01-06 14:53:03.991497 (Thread-185): sending response (<Response 1244 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:53:04.205690 (Thread-186): handling cli_args request
2022-01-06 14:53:04.206070 (Thread-186): 14:53:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7821d3d0>]}
2022-01-06 14:53:06.279428 (Thread-186): sending response (<Response 138 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:53:06.355641 (MainThread): 14:53:06  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:53:06.356003 (MainThread): 14:53:06  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:53:06.361472 (MainThread): 14:53:06  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '542f81ea-48d0-44be-9c6c-3e9d4ded4c84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc43f4b9b50>]}
2022-01-06 14:53:06.384440 (MainThread): 14:53:06  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '542f81ea-48d0-44be-9c6c-3e9d4ded4c84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc43f52fbb0>]}
2022-01-06 14:53:06.384673 (MainThread): 14:53:06  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:53:06.385683 (MainThread): 14:53:06  
2022-01-06 14:53:06.385942 (MainThread): 14:53:06  Acquiring new redshift connection "master"
2022-01-06 14:53:06.386619 (ThreadPoolExecutor-0_0): 14:53:06  Acquiring new redshift connection "list_dev"
2022-01-06 14:53:06.396411 (ThreadPoolExecutor-0_0): 14:53:06  Using redshift connection "list_dev"
2022-01-06 14:53:06.396514 (ThreadPoolExecutor-0_0): 14:53:06  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:53:06.396598 (ThreadPoolExecutor-0_0): 14:53:06  Opening a new connection, currently in state init
2022-01-06 14:53:06.396766 (ThreadPoolExecutor-0_0): 14:53:06  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:53:06.417071 (ThreadPoolExecutor-0_0): 14:53:06  SQL status: SELECT in 0.02 seconds
2022-01-06 14:53:06.418081 (ThreadPoolExecutor-0_0): 14:53:06  On list_dev: Close
2022-01-06 14:53:06.419255 (ThreadPoolExecutor-1_0): 14:53:06  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:53:06.425633 (ThreadPoolExecutor-1_0): 14:53:06  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:53:06.425732 (ThreadPoolExecutor-1_0): 14:53:06  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:53:06.425830 (ThreadPoolExecutor-1_0): 14:53:06  Opening a new connection, currently in state closed
2022-01-06 14:53:06.425907 (ThreadPoolExecutor-1_0): 14:53:06  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:53:06.448477 (ThreadPoolExecutor-1_0): 14:53:06  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:53:06.448587 (ThreadPoolExecutor-1_0): 14:53:06  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:53:06.448662 (ThreadPoolExecutor-1_0): 14:53:06  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:53:06.459251 (ThreadPoolExecutor-1_0): 14:53:06  SQL status: SELECT in 0.01 seconds
2022-01-06 14:53:06.460227 (ThreadPoolExecutor-1_0): 14:53:06  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:53:06.462029 (ThreadPoolExecutor-1_0): 14:53:06  On list_dev_dbt_nobodozie: Close
2022-01-06 14:53:06.465609 (MainThread): 14:53:06  Using redshift connection "master"
2022-01-06 14:53:06.465720 (MainThread): 14:53:06  On master: BEGIN
2022-01-06 14:53:06.465800 (MainThread): 14:53:06  Opening a new connection, currently in state init
2022-01-06 14:53:06.465873 (MainThread): 14:53:06  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:53:06.488709 (MainThread): 14:53:06  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:53:06.488820 (MainThread): 14:53:06  Using redshift connection "master"
2022-01-06 14:53:06.488896 (MainThread): 14:53:06  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:53:06.517113 (MainThread): 14:53:06  SQL status: SELECT in 0.03 seconds
2022-01-06 14:53:06.518084 (MainThread): 14:53:06  On master: ROLLBACK
2022-01-06 14:53:06.520711 (MainThread): 14:53:06  Using redshift connection "master"
2022-01-06 14:53:06.520812 (MainThread): 14:53:06  On master: BEGIN
2022-01-06 14:53:06.525855 (MainThread): 14:53:06  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:53:06.525964 (MainThread): 14:53:06  On master: COMMIT
2022-01-06 14:53:06.526036 (MainThread): 14:53:06  Using redshift connection "master"
2022-01-06 14:53:06.526104 (MainThread): 14:53:06  On master: COMMIT
2022-01-06 14:53:06.529617 (MainThread): 14:53:06  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:53:06.529729 (MainThread): 14:53:06  On master: Close
2022-01-06 14:53:06.530060 (MainThread): 14:53:06  Concurrency: 4 threads (target='default')
2022-01-06 14:53:06.530173 (MainThread): 14:53:06  
2022-01-06 14:53:06.532334 (Thread-1): 14:53:06  Began running node model.my_new_project.dim_customers
2022-01-06 14:53:06.532562 (Thread-1): 14:53:06  1 of 1 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:53:06.532788 (Thread-1): 14:53:06  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:06.532880 (Thread-1): 14:53:06  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:53:06.532972 (Thread-1): 14:53:06  Compiling model.my_new_project.dim_customers
2022-01-06 14:53:06.534930 (Thread-1): 14:53:06  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:53:06.547998 (Thread-1): 14:53:06  finished collecting timing info
2022-01-06 14:53:06.548152 (Thread-1): 14:53:06  Began executing node model.my_new_project.dim_customers
2022-01-06 14:53:06.578961 (Thread-1): 14:53:06  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:53:06.593154 (Thread-1): 14:53:06  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:06.593282 (Thread-1): 14:53:06  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:53:06.593364 (Thread-1): 14:53:06  Opening a new connection, currently in state closed
2022-01-06 14:53:06.593438 (Thread-1): 14:53:06  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:53:06.617246 (Thread-1): 14:53:06  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:53:06.617358 (Thread-1): 14:53:06  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:06.617435 (Thread-1): 14:53:06  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:53:06.643310 (Thread-187): handling poll request
2022-01-06 14:53:06.643651 (Thread-187): 14:53:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781bf370>]}
2022-01-06 14:53:06.644878 (Thread-187): sending response (<Response 23728 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:53:06.680634 (Thread-1): 14:53:06  SQL status: SELECT in 0.06 seconds
2022-01-06 14:53:06.686236 (Thread-1): 14:53:06  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:06.686343 (Thread-1): 14:53:06  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:53:06.689034 (Thread-1): 14:53:06  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:53:06.690956 (Thread-1): 14:53:06  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:06.691059 (Thread-1): 14:53:06  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:53:06.693425 (Thread-1): 14:53:06  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:53:06.703515 (Thread-1): 14:53:06  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:53:06.703617 (Thread-1): 14:53:06  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:06.703766 (Thread-1): 14:53:06  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:53:06.756138 (Thread-1): 14:53:06  SQL status: COMMIT in 0.05 seconds
2022-01-06 14:53:06.756418 (Thread-1): 14:53:06  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:06.756522 (Thread-1): 14:53:06  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:53:06.758742 (Thread-1): 14:53:06  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:53:06.763147 (Thread-1): 14:53:06  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:06.763258 (Thread-1): 14:53:06  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:53:06.766906 (Thread-1): 14:53:06  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:53:06.767563 (Thread-1): 14:53:06  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:53:06.767657 (Thread-1): 14:53:06  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:06.767730 (Thread-1): 14:53:06  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:53:06.797394 (Thread-1): 14:53:06  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:53:06.797512 (Thread-1): 14:53:06  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:06.797586 (Thread-1): 14:53:06  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:53:06.799708 (Thread-1): 14:53:06  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:53:06.800147 (Thread-1): 14:53:06  finished collecting timing info
2022-01-06 14:53:06.800292 (Thread-1): 14:53:06  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:53:06.802207 (Thread-1): 14:53:06  On model.my_new_project.dim_customers: Close
2022-01-06 14:53:06.802687 (Thread-1): 14:53:06  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '542f81ea-48d0-44be-9c6c-3e9d4ded4c84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc43e4330a0>]}
2022-01-06 14:53:06.803029 (Thread-1): 14:53:06  1 of 1 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.27s]
2022-01-06 14:53:06.803152 (Thread-1): 14:53:06  Finished running node model.my_new_project.dim_customers
2022-01-06 14:53:06.804464 (MainThread): 14:53:06  Acquiring new redshift connection "master"
2022-01-06 14:53:06.804632 (MainThread): 14:53:06  Using redshift connection "master"
2022-01-06 14:53:06.804716 (MainThread): 14:53:06  On master: BEGIN
2022-01-06 14:53:06.804796 (MainThread): 14:53:06  Opening a new connection, currently in state closed
2022-01-06 14:53:06.804872 (MainThread): 14:53:06  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:53:06.828616 (MainThread): 14:53:06  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:53:06.828741 (MainThread): 14:53:06  On master: COMMIT
2022-01-06 14:53:06.828817 (MainThread): 14:53:06  Using redshift connection "master"
2022-01-06 14:53:06.828887 (MainThread): 14:53:06  On master: COMMIT
2022-01-06 14:53:06.830558 (MainThread): 14:53:06  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:53:06.830684 (MainThread): 14:53:06  On master: Close
2022-01-06 14:53:06.831147 (MainThread): 14:53:06  
2022-01-06 14:53:06.831280 (MainThread): 14:53:06  Finished running 1 table model in 0.45s.
2022-01-06 14:53:06.831372 (MainThread): 14:53:06  Connection 'master' was properly closed.
2022-01-06 14:53:06.831448 (MainThread): 14:53:06  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:53:06.879669 (MainThread): 14:53:06  
2022-01-06 14:53:06.879873 (MainThread): 14:53:06  Completed successfully
2022-01-06 14:53:06.879968 (MainThread): 14:53:06  
2022-01-06 14:53:06.880054 (MainThread): 14:53:06  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2022-01-06 14:53:08.060082 (Thread-188): handling poll request
2022-01-06 14:53:08.060483 (Thread-188): 14:53:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781d79a0>]}
2022-01-06 14:53:08.061801 (Thread-188): sending response (<Response 21599 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:53:08.738549 (Thread-189): handling status request
2022-01-06 14:53:08.738913 (Thread-189): 14:53:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781d7b50>]}
2022-01-06 14:53:08.739404 (Thread-189): sending response (<Response 1244 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:53:08.773784 (Thread-190): handling status request
2022-01-06 14:53:08.774047 (Thread-190): 14:53:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781d7f40>]}
2022-01-06 14:53:08.774430 (Thread-190): sending response (<Response 1244 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:53:29.859870 (Thread-191): handling status request
2022-01-06 14:53:29.860269 (Thread-191): 14:53:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781da580>]}
2022-01-06 14:53:29.860804 (Thread-191): sending response (<Response 1244 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:53:30.070186 (Thread-192): handling status request
2022-01-06 14:53:30.072321 (Thread-192): 14:53:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781d7ca0>]}
2022-01-06 14:53:30.072803 (Thread-192): sending response (<Response 1244 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:53:30.222438 (Thread-193): handling cli_args request
2022-01-06 14:53:30.222694 (Thread-193): 14:53:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781d75e0>]}
2022-01-06 14:53:32.327460 (Thread-193): sending response (<Response 138 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:53:32.402923 (MainThread): 14:53:32  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:53:32.403306 (MainThread): 14:53:32  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:53:32.408915 (MainThread): 14:53:32  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e182e191-6698-486b-879a-155bd24b05c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff231185c40>]}
2022-01-06 14:53:32.433404 (MainThread): 14:53:32  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e182e191-6698-486b-879a-155bd24b05c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2311fcbe0>]}
2022-01-06 14:53:32.433639 (MainThread): 14:53:32  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:53:32.434694 (MainThread): 14:53:32  
2022-01-06 14:53:32.434962 (MainThread): 14:53:32  Acquiring new redshift connection "master"
2022-01-06 14:53:32.436385 (ThreadPoolExecutor-0_0): 14:53:32  Acquiring new redshift connection "list_dev"
2022-01-06 14:53:32.446236 (ThreadPoolExecutor-0_0): 14:53:32  Using redshift connection "list_dev"
2022-01-06 14:53:32.446458 (ThreadPoolExecutor-0_0): 14:53:32  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:53:32.446565 (ThreadPoolExecutor-0_0): 14:53:32  Opening a new connection, currently in state init
2022-01-06 14:53:32.446653 (ThreadPoolExecutor-0_0): 14:53:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:53:32.466758 (ThreadPoolExecutor-0_0): 14:53:32  SQL status: SELECT in 0.02 seconds
2022-01-06 14:53:32.467835 (ThreadPoolExecutor-0_0): 14:53:32  On list_dev: Close
2022-01-06 14:53:32.469078 (ThreadPoolExecutor-1_0): 14:53:32  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:53:32.475500 (ThreadPoolExecutor-1_0): 14:53:32  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:53:32.475602 (ThreadPoolExecutor-1_0): 14:53:32  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:53:32.475679 (ThreadPoolExecutor-1_0): 14:53:32  Opening a new connection, currently in state closed
2022-01-06 14:53:32.475756 (ThreadPoolExecutor-1_0): 14:53:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:53:32.497383 (ThreadPoolExecutor-1_0): 14:53:32  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:53:32.497495 (ThreadPoolExecutor-1_0): 14:53:32  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:53:32.497571 (ThreadPoolExecutor-1_0): 14:53:32  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:53:32.508443 (ThreadPoolExecutor-1_0): 14:53:32  SQL status: SELECT in 0.01 seconds
2022-01-06 14:53:32.509440 (ThreadPoolExecutor-1_0): 14:53:32  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:53:32.511215 (ThreadPoolExecutor-1_0): 14:53:32  On list_dev_dbt_nobodozie: Close
2022-01-06 14:53:32.514808 (MainThread): 14:53:32  Using redshift connection "master"
2022-01-06 14:53:32.514923 (MainThread): 14:53:32  On master: BEGIN
2022-01-06 14:53:32.515001 (MainThread): 14:53:32  Opening a new connection, currently in state init
2022-01-06 14:53:32.515076 (MainThread): 14:53:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:53:32.671685 (Thread-194): handling poll request
2022-01-06 14:53:32.672098 (Thread-194): 14:53:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78288400>]}
2022-01-06 14:53:32.673209 (Thread-194): sending response (<Response 9977 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:53:33.047174 (MainThread): 14:53:33  SQL status: BEGIN in 0.53 seconds
2022-01-06 14:53:33.047344 (MainThread): 14:53:33  Using redshift connection "master"
2022-01-06 14:53:33.047430 (MainThread): 14:53:33  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:53:33.085586 (MainThread): 14:53:33  SQL status: SELECT in 0.04 seconds
2022-01-06 14:53:33.086756 (MainThread): 14:53:33  On master: ROLLBACK
2022-01-06 14:53:33.088703 (MainThread): 14:53:33  Using redshift connection "master"
2022-01-06 14:53:33.088815 (MainThread): 14:53:33  On master: BEGIN
2022-01-06 14:53:33.092376 (MainThread): 14:53:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:53:33.092502 (MainThread): 14:53:33  On master: COMMIT
2022-01-06 14:53:33.092577 (MainThread): 14:53:33  Using redshift connection "master"
2022-01-06 14:53:33.092647 (MainThread): 14:53:33  On master: COMMIT
2022-01-06 14:53:33.094373 (MainThread): 14:53:33  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:53:33.094499 (MainThread): 14:53:33  On master: Close
2022-01-06 14:53:33.094944 (MainThread): 14:53:33  Concurrency: 4 threads (target='default')
2022-01-06 14:53:33.095059 (MainThread): 14:53:33  
2022-01-06 14:53:33.097516 (Thread-1): 14:53:33  Began running node model.my_new_project.dim_customers
2022-01-06 14:53:33.097791 (Thread-1): 14:53:33  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:53:33.098082 (Thread-1): 14:53:33  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:33.098183 (Thread-1): 14:53:33  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:53:33.098282 (Thread-1): 14:53:33  Compiling model.my_new_project.dim_customers
2022-01-06 14:53:33.100649 (Thread-1): 14:53:33  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:53:33.100888 (Thread-2): 14:53:33  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:53:33.101126 (Thread-2): 14:53:33  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:53:33.101421 (Thread-2): 14:53:33  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:53:33.101510 (Thread-2): 14:53:33  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:53:33.101592 (Thread-2): 14:53:33  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:53:33.103711 (Thread-2): 14:53:33  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:53:33.115156 (Thread-1): 14:53:33  finished collecting timing info
2022-01-06 14:53:33.115298 (Thread-1): 14:53:33  Began executing node model.my_new_project.dim_customers
2022-01-06 14:53:33.120477 (Thread-2): 14:53:33  finished collecting timing info
2022-01-06 14:53:33.120606 (Thread-2): 14:53:33  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:53:33.171796 (Thread-2): 14:53:33  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:53:33.173051 (Thread-1): 14:53:33  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:53:33.186360 (Thread-2): 14:53:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:53:33.186469 (Thread-2): 14:53:33  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:53:33.186549 (Thread-2): 14:53:33  Opening a new connection, currently in state init
2022-01-06 14:53:33.186628 (Thread-2): 14:53:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:53:33.186869 (Thread-1): 14:53:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:33.186966 (Thread-1): 14:53:33  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:53:33.187044 (Thread-1): 14:53:33  Opening a new connection, currently in state closed
2022-01-06 14:53:33.187120 (Thread-1): 14:53:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:53:33.210693 (Thread-2): 14:53:33  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:53:33.210803 (Thread-2): 14:53:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:53:33.210880 (Thread-2): 14:53:33  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:53:33.213111 (Thread-1): 14:53:33  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:53:33.213259 (Thread-1): 14:53:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:33.213344 (Thread-1): 14:53:33  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:53:33.301081 (Thread-2): 14:53:33  SQL status: SELECT in 0.09 seconds
2022-01-06 14:53:33.306480 (Thread-2): 14:53:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:53:33.306582 (Thread-2): 14:53:33  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:53:33.310311 (Thread-2): 14:53:33  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:53:33.312083 (Thread-2): 14:53:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:53:33.312188 (Thread-2): 14:53:33  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:53:33.320784 (Thread-2): 14:53:33  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:53:33.331337 (Thread-2): 14:53:33  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:53:33.331453 (Thread-2): 14:53:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:53:33.331531 (Thread-2): 14:53:33  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:53:33.352604 (Thread-1): 14:53:33  SQL status: SELECT in 0.14 seconds
2022-01-06 14:53:33.355294 (Thread-1): 14:53:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:33.355392 (Thread-1): 14:53:33  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:53:33.358383 (Thread-1): 14:53:33  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:53:33.360009 (Thread-1): 14:53:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:33.360104 (Thread-1): 14:53:33  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:53:33.362905 (Thread-1): 14:53:33  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:53:33.364040 (Thread-1): 14:53:33  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:53:33.364136 (Thread-1): 14:53:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:33.364208 (Thread-1): 14:53:33  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:53:33.405293 (Thread-2): 14:53:33  SQL status: COMMIT in 0.07 seconds
2022-01-06 14:53:33.405507 (Thread-2): 14:53:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:53:33.405590 (Thread-2): 14:53:33  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:53:33.405838 (Thread-1): 14:53:33  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:53:33.407722 (Thread-2): 14:53:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:53:33.411662 (Thread-2): 14:53:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:53:33.411762 (Thread-2): 14:53:33  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:53:33.416548 (Thread-2): 14:53:33  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:53:33.417169 (Thread-2): 14:53:33  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:53:33.417296 (Thread-2): 14:53:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:53:33.417373 (Thread-2): 14:53:33  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:53:33.445893 (Thread-2): 14:53:33  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:53:33.446003 (Thread-2): 14:53:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:53:33.446075 (Thread-2): 14:53:33  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:53:33.448087 (Thread-2): 14:53:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:53:33.448476 (Thread-2): 14:53:33  finished collecting timing info
2022-01-06 14:53:33.448600 (Thread-2): 14:53:33  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:53:33.448798 (Thread-1): 14:53:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:33.448904 (Thread-1): 14:53:33  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:53:33.451353 (Thread-1): 14:53:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:53:33.452546 (Thread-1): 14:53:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:33.452641 (Thread-1): 14:53:33  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:53:33.452786 (Thread-2): 14:53:33  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:53:33.453306 (Thread-2): 14:53:33  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e182e191-6698-486b-879a-155bd24b05c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2300c7850>]}
2022-01-06 14:53:33.453617 (Thread-2): 14:53:33  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.35s]
2022-01-06 14:53:33.453730 (Thread-2): 14:53:33  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:53:33.454294 (Thread-4): 14:53:33  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:53:33.454531 (Thread-4): 14:53:33  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:53:33.454781 (Thread-4): 14:53:33  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:53:33.454869 (Thread-4): 14:53:33  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:53:33.454976 (Thread-4): 14:53:33  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:53:33.456879 (Thread-4): 14:53:33  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:53:33.457678 (Thread-1): 14:53:33  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:53:33.458324 (Thread-1): 14:53:33  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:53:33.458419 (Thread-1): 14:53:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:33.458494 (Thread-1): 14:53:33  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:53:33.468802 (Thread-4): 14:53:33  finished collecting timing info
2022-01-06 14:53:33.468939 (Thread-4): 14:53:33  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:53:33.484262 (Thread-4): 14:53:33  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:53:33.491714 (Thread-1): 14:53:33  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:53:33.491830 (Thread-1): 14:53:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:53:33.491906 (Thread-1): 14:53:33  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:53:33.494001 (Thread-1): 14:53:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:53:33.494340 (Thread-1): 14:53:33  finished collecting timing info
2022-01-06 14:53:33.494459 (Thread-1): 14:53:33  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:53:33.496197 (Thread-1): 14:53:33  On model.my_new_project.dim_customers: Close
2022-01-06 14:53:33.496614 (Thread-1): 14:53:33  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e182e191-6698-486b-879a-155bd24b05c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2300a0f10>]}
2022-01-06 14:53:33.496911 (Thread-1): 14:53:33  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.40s]
2022-01-06 14:53:33.497091 (Thread-1): 14:53:33  Finished running node model.my_new_project.dim_customers
2022-01-06 14:53:33.497370 (Thread-4): 14:53:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:53:33.497477 (Thread-4): 14:53:33  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:53:33.497557 (Thread-4): 14:53:33  Opening a new connection, currently in state init
2022-01-06 14:53:33.497637 (Thread-4): 14:53:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:53:33.521185 (Thread-4): 14:53:33  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:53:33.521341 (Thread-4): 14:53:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:53:33.521423 (Thread-4): 14:53:33  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:53:33.526236 (Thread-4): 14:53:33  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:53:33.527987 (Thread-4): 14:53:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:53:33.528085 (Thread-4): 14:53:33  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:53:33.530253 (Thread-4): 14:53:33  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:53:33.531151 (Thread-4): 14:53:33  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:53:33.531244 (Thread-4): 14:53:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:53:33.531317 (Thread-4): 14:53:33  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:53:33.560714 (Thread-4): 14:53:33  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:53:33.560930 (Thread-4): 14:53:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:53:33.561012 (Thread-4): 14:53:33  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:53:33.563148 (Thread-4): 14:53:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:53:33.564325 (Thread-4): 14:53:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:53:33.564421 (Thread-4): 14:53:33  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:53:33.566341 (Thread-4): 14:53:33  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:53:33.567010 (Thread-4): 14:53:33  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:53:33.567103 (Thread-4): 14:53:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:53:33.567176 (Thread-4): 14:53:33  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:53:33.592782 (Thread-4): 14:53:33  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:53:33.592895 (Thread-4): 14:53:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:53:33.592967 (Thread-4): 14:53:33  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:53:33.595281 (Thread-4): 14:53:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:53:33.595634 (Thread-4): 14:53:33  finished collecting timing info
2022-01-06 14:53:33.595752 (Thread-4): 14:53:33  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:53:33.597490 (Thread-4): 14:53:33  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:53:33.597885 (Thread-4): 14:53:33  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e182e191-6698-486b-879a-155bd24b05c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff23093d100>]}
2022-01-06 14:53:33.598185 (Thread-4): 14:53:33  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.14s]
2022-01-06 14:53:33.598289 (Thread-4): 14:53:33  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:53:33.599608 (MainThread): 14:53:33  Acquiring new redshift connection "master"
2022-01-06 14:53:33.599748 (MainThread): 14:53:33  Using redshift connection "master"
2022-01-06 14:53:33.599825 (MainThread): 14:53:33  On master: BEGIN
2022-01-06 14:53:33.599901 (MainThread): 14:53:33  Opening a new connection, currently in state closed
2022-01-06 14:53:33.599976 (MainThread): 14:53:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:53:33.625372 (MainThread): 14:53:33  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:53:33.625488 (MainThread): 14:53:33  On master: COMMIT
2022-01-06 14:53:33.625563 (MainThread): 14:53:33  Using redshift connection "master"
2022-01-06 14:53:33.625634 (MainThread): 14:53:33  On master: COMMIT
2022-01-06 14:53:33.627405 (MainThread): 14:53:33  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:53:33.627514 (MainThread): 14:53:33  On master: Close
2022-01-06 14:53:33.627898 (MainThread): 14:53:33  
2022-01-06 14:53:33.628020 (MainThread): 14:53:33  Finished running 2 table models, 1 view model in 1.19s.
2022-01-06 14:53:33.628103 (MainThread): 14:53:33  Connection 'master' was properly closed.
2022-01-06 14:53:33.628172 (MainThread): 14:53:33  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:53:33.628246 (MainThread): 14:53:33  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:53:33.628330 (MainThread): 14:53:33  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:53:33.677240 (MainThread): 14:53:33  
2022-01-06 14:53:33.677401 (MainThread): 14:53:33  Completed successfully
2022-01-06 14:53:33.677499 (MainThread): 14:53:33  
2022-01-06 14:53:33.677586 (MainThread): 14:53:33  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:53:34.071036 (Thread-195): handling poll request
2022-01-06 14:53:34.071398 (Thread-195): 14:53:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78175a00>]}
2022-01-06 14:53:34.073995 (Thread-195): sending response (<Response 77415 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:53:34.700241 (Thread-196): handling status request
2022-01-06 14:53:34.700602 (Thread-196): 14:53:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78175bb0>]}
2022-01-06 14:53:34.701091 (Thread-196): sending response (<Response 1244 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:53:34.762047 (Thread-197): handling status request
2022-01-06 14:53:34.762342 (Thread-197): 14:53:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78175fa0>]}
2022-01-06 14:53:34.762761 (Thread-197): sending response (<Response 1244 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:54:29.819292 (Thread-198): handling status request
2022-01-06 14:54:29.819657 (Thread-198): 14:54:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78178190>]}
2022-01-06 14:54:29.820128 (Thread-198): sending response (<Response 1244 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:54:30.042980 (Thread-199): handling status request
2022-01-06 14:54:30.043282 (Thread-199): 14:54:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78178490>]}
2022-01-06 14:54:30.043706 (Thread-199): sending response (<Response 1244 bytes [200 OK]>) to 10.0.21.176
2022-01-06 14:54:30.148681 (Thread-200): handling cli_args request
2022-01-06 14:54:30.148929 (Thread-200): 14:54:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78178700>]}
2022-01-06 14:54:32.184814 (Thread-200): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:54:32.260381 (MainThread): 14:54:32  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:54:32.260753 (MainThread): 14:54:32  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:54:32.266317 (MainThread): 14:54:32  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '69f285af-6ebb-47d4-8cd8-73e0ff17ff45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c70795c40>]}
2022-01-06 14:54:32.292191 (MainThread): 14:54:32  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '69f285af-6ebb-47d4-8cd8-73e0ff17ff45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c7080dca0>]}
2022-01-06 14:54:32.292422 (MainThread): 14:54:32  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:54:32.293336 (MainThread): 14:54:32  
2022-01-06 14:54:32.293596 (MainThread): 14:54:32  Acquiring new redshift connection "master"
2022-01-06 14:54:32.294403 (ThreadPoolExecutor-0_0): 14:54:32  Acquiring new redshift connection "list_dev"
2022-01-06 14:54:32.303993 (ThreadPoolExecutor-0_0): 14:54:32  Using redshift connection "list_dev"
2022-01-06 14:54:32.304095 (ThreadPoolExecutor-0_0): 14:54:32  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:54:32.304177 (ThreadPoolExecutor-0_0): 14:54:32  Opening a new connection, currently in state init
2022-01-06 14:54:32.304408 (ThreadPoolExecutor-0_0): 14:54:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:54:32.325061 (ThreadPoolExecutor-0_0): 14:54:32  SQL status: SELECT in 0.02 seconds
2022-01-06 14:54:32.326112 (ThreadPoolExecutor-0_0): 14:54:32  On list_dev: Close
2022-01-06 14:54:32.327229 (ThreadPoolExecutor-1_0): 14:54:32  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:54:32.333606 (ThreadPoolExecutor-1_0): 14:54:32  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:54:32.333705 (ThreadPoolExecutor-1_0): 14:54:32  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:54:32.333783 (ThreadPoolExecutor-1_0): 14:54:32  Opening a new connection, currently in state closed
2022-01-06 14:54:32.333857 (ThreadPoolExecutor-1_0): 14:54:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:54:32.356736 (ThreadPoolExecutor-1_0): 14:54:32  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:54:32.356846 (ThreadPoolExecutor-1_0): 14:54:32  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:54:32.356922 (ThreadPoolExecutor-1_0): 14:54:32  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:54:32.368166 (ThreadPoolExecutor-1_0): 14:54:32  SQL status: SELECT in 0.01 seconds
2022-01-06 14:54:32.369147 (ThreadPoolExecutor-1_0): 14:54:32  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:54:32.370961 (ThreadPoolExecutor-1_0): 14:54:32  On list_dev_dbt_nobodozie: Close
2022-01-06 14:54:32.374481 (MainThread): 14:54:32  Using redshift connection "master"
2022-01-06 14:54:32.374594 (MainThread): 14:54:32  On master: BEGIN
2022-01-06 14:54:32.374674 (MainThread): 14:54:32  Opening a new connection, currently in state init
2022-01-06 14:54:32.374748 (MainThread): 14:54:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:54:32.398472 (MainThread): 14:54:32  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:54:32.398581 (MainThread): 14:54:32  Using redshift connection "master"
2022-01-06 14:54:32.398657 (MainThread): 14:54:32  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:54:32.427589 (MainThread): 14:54:32  SQL status: SELECT in 0.03 seconds
2022-01-06 14:54:32.428555 (MainThread): 14:54:32  On master: ROLLBACK
2022-01-06 14:54:32.430430 (MainThread): 14:54:32  Using redshift connection "master"
2022-01-06 14:54:32.430530 (MainThread): 14:54:32  On master: BEGIN
2022-01-06 14:54:32.433967 (MainThread): 14:54:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:54:32.434069 (MainThread): 14:54:32  On master: COMMIT
2022-01-06 14:54:32.434138 (MainThread): 14:54:32  Using redshift connection "master"
2022-01-06 14:54:32.434203 (MainThread): 14:54:32  On master: COMMIT
2022-01-06 14:54:32.435911 (MainThread): 14:54:32  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:54:32.436012 (MainThread): 14:54:32  On master: Close
2022-01-06 14:54:32.436359 (MainThread): 14:54:32  Concurrency: 4 threads (target='default')
2022-01-06 14:54:32.436472 (MainThread): 14:54:32  
2022-01-06 14:54:32.438628 (Thread-1): 14:54:32  Began running node model.my_new_project.dim_customers
2022-01-06 14:54:32.438868 (Thread-1): 14:54:32  1 of 1 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:54:32.439104 (Thread-1): 14:54:32  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:54:32.439197 (Thread-1): 14:54:32  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:54:32.439283 (Thread-1): 14:54:32  Compiling model.my_new_project.dim_customers
2022-01-06 14:54:32.441360 (Thread-1): 14:54:32  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:54:32.453290 (Thread-1): 14:54:32  finished collecting timing info
2022-01-06 14:54:32.453432 (Thread-1): 14:54:32  Began executing node model.my_new_project.dim_customers
2022-01-06 14:54:32.486251 (Thread-1): 14:54:32  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:54:32.499731 (Thread-1): 14:54:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:54:32.499839 (Thread-1): 14:54:32  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:54:32.499919 (Thread-1): 14:54:32  Opening a new connection, currently in state closed
2022-01-06 14:54:32.499995 (Thread-1): 14:54:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:54:32.518592 (Thread-1): 14:54:32  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:54:32.518703 (Thread-1): 14:54:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:54:32.518781 (Thread-1): 14:54:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:54:32.583936 (Thread-1): 14:54:32  SQL status: SELECT in 0.07 seconds
2022-01-06 14:54:32.589279 (Thread-1): 14:54:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:54:32.589395 (Thread-1): 14:54:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:54:32.592256 (Thread-1): 14:54:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:54:32.594213 (Thread-1): 14:54:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:54:32.594311 (Thread-1): 14:54:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:54:32.596710 (Thread-1): 14:54:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:54:32.606761 (Thread-1): 14:54:32  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:54:32.606862 (Thread-1): 14:54:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:54:32.606937 (Thread-1): 14:54:32  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:54:32.657042 (Thread-1): 14:54:32  SQL status: COMMIT in 0.05 seconds
2022-01-06 14:54:32.657279 (Thread-1): 14:54:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:54:32.657367 (Thread-1): 14:54:32  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:54:32.659480 (Thread-1): 14:54:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:54:32.664514 (Thread-1): 14:54:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:54:32.664786 (Thread-1): 14:54:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:54:32.668637 (Thread-1): 14:54:32  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:54:32.669312 (Thread-1): 14:54:32  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:54:32.669409 (Thread-1): 14:54:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:54:32.669484 (Thread-1): 14:54:32  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:54:32.698730 (Thread-1): 14:54:32  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:54:32.698883 (Thread-1): 14:54:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:54:32.698997 (Thread-1): 14:54:32  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:54:32.701195 (Thread-1): 14:54:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:54:32.701650 (Thread-1): 14:54:32  finished collecting timing info
2022-01-06 14:54:32.701781 (Thread-1): 14:54:32  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:54:32.703503 (Thread-1): 14:54:32  On model.my_new_project.dim_customers: Close
2022-01-06 14:54:32.703954 (Thread-1): 14:54:32  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69f285af-6ebb-47d4-8cd8-73e0ff17ff45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c6f711190>]}
2022-01-06 14:54:32.704281 (Thread-1): 14:54:32  1 of 1 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.26s]
2022-01-06 14:54:32.704395 (Thread-1): 14:54:32  Finished running node model.my_new_project.dim_customers
2022-01-06 14:54:32.705743 (MainThread): 14:54:32  Acquiring new redshift connection "master"
2022-01-06 14:54:32.705885 (MainThread): 14:54:32  Using redshift connection "master"
2022-01-06 14:54:32.705965 (MainThread): 14:54:32  On master: BEGIN
2022-01-06 14:54:32.706042 (MainThread): 14:54:32  Opening a new connection, currently in state closed
2022-01-06 14:54:32.706117 (MainThread): 14:54:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:54:32.730174 (MainThread): 14:54:32  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:54:32.730289 (MainThread): 14:54:32  On master: COMMIT
2022-01-06 14:54:32.730364 (MainThread): 14:54:32  Using redshift connection "master"
2022-01-06 14:54:32.730435 (MainThread): 14:54:32  On master: COMMIT
2022-01-06 14:54:32.732150 (MainThread): 14:54:32  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:54:32.732256 (MainThread): 14:54:32  On master: Close
2022-01-06 14:54:32.732629 (MainThread): 14:54:32  
2022-01-06 14:54:32.732739 (MainThread): 14:54:32  Finished running 1 table model in 0.44s.
2022-01-06 14:54:32.732819 (MainThread): 14:54:32  Connection 'master' was properly closed.
2022-01-06 14:54:32.732884 (MainThread): 14:54:32  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:54:32.781028 (MainThread): 14:54:32  
2022-01-06 14:54:32.781300 (MainThread): 14:54:32  Completed successfully
2022-01-06 14:54:32.781459 (MainThread): 14:54:32  
2022-01-06 14:54:32.781588 (MainThread): 14:54:32  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2022-01-06 14:54:32.916580 (Thread-201): handling poll request
2022-01-06 14:54:32.917021 (Thread-201): 14:54:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781b0e20>]}
2022-01-06 14:54:32.918901 (Thread-201): sending response (<Response 40969 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:54:34.517735 (Thread-202): handling poll request
2022-01-06 14:54:34.518125 (Thread-202): 14:54:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7817e460>]}
2022-01-06 14:54:34.518911 (Thread-202): sending response (<Response 4364 bytes [200 OK]>) to 10.0.21.176
2022-01-06 14:54:35.239810 (Thread-203): handling status request
2022-01-06 14:54:35.240173 (Thread-203): 14:54:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781876a0>]}
2022-01-06 14:54:35.240662 (Thread-203): sending response (<Response 1244 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:54:35.278119 (Thread-204): handling status request
2022-01-06 14:54:35.278398 (Thread-204): 14:54:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78187eb0>]}
2022-01-06 14:54:35.278808 (Thread-204): sending response (<Response 1244 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:55:06.502500 (Thread-205): handling status request
2022-01-06 14:55:06.502861 (Thread-205): 14:55:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78197370>]}
2022-01-06 14:55:06.503327 (Thread-205): sending response (<Response 1244 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:55:06.797447 (Thread-206): handling status request
2022-01-06 14:55:06.798037 (Thread-206): 14:55:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781b0e20>]}
2022-01-06 14:55:06.798556 (Thread-206): sending response (<Response 1244 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:55:06.920148 (Thread-207): handling docs.generate request
2022-01-06 14:55:06.920526 (Thread-207): 14:55:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7813e070>]}
2022-01-06 14:55:08.965399 (Thread-207): sending response (<Response 138 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:55:08.996382 (MainThread): 14:55:08  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dad4929d-8b48-4ec5-a9cc-e80d0c977e15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c377bc340>]}
2022-01-06 14:55:08.996734 (MainThread): 14:55:08  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:55:08.998073 (MainThread): 14:55:08  
2022-01-06 14:55:08.998278 (MainThread): 14:55:08  Acquiring new redshift connection "master"
2022-01-06 14:55:08.999149 (ThreadPoolExecutor-0_0): 14:55:08  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:55:09.009657 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/catalog.sql
2022-01-06 14:55:09.023259 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/adapters.sql
2022-01-06 14:55:09.050606 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/relations.sql
2022-01-06 14:55:09.051328 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 14:55:09.052331 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/catalog.sql
2022-01-06 14:55:09.054703 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/adapters.sql
2022-01-06 14:55:09.076362 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/relations.sql
2022-01-06 14:55:09.077823 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 14:55:09.080824 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-06 14:55:09.082421 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-06 14:55:09.084109 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-06 14:55:09.086842 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-06 14:55:09.088277 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/generic_test_sql/not_null.sql
2022-01-06 14:55:09.088954 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/generic_test_sql/relationships.sql
2022-01-06 14:55:09.089942 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/generic_test_sql/unique.sql
2022-01-06 14:55:09.090741 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/configs.sql
2022-01-06 14:55:09.093127 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/hooks.sql
2022-01-06 14:55:09.097181 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/snapshots/strategies.sql
2022-01-06 14:55:09.113899 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-06 14:55:09.115676 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-06 14:55:09.126928 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/snapshots/helpers.sql
2022-01-06 14:55:09.137679 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/seeds/seed.sql
2022-01-06 14:55:09.143532 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/seeds/helpers.sql
2022-01-06 14:55:09.159397 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-06 14:55:09.161782 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/models/view/view.sql
2022-01-06 14:55:09.168434 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-06 14:55:09.171294 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/models/view/helpers.sql
2022-01-06 14:55:09.172687 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/models/table/table.sql
2022-01-06 14:55:09.179815 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-06 14:55:09.182766 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/models/incremental/merge.sql
2022-01-06 14:55:09.193592 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-06 14:55:09.208401 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-06 14:55:09.213256 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-06 14:55:09.223253 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-06 14:55:09.225095 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/tests/test.sql
2022-01-06 14:55:09.229477 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/tests/where_subquery.sql
2022-01-06 14:55:09.231372 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/materializations/tests/helpers.sql
2022-01-06 14:55:09.233206 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/etc/statement.sql
2022-01-06 14:55:09.237656 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/etc/datetime.sql
2022-01-06 14:55:09.245655 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/adapters/indexes.sql
2022-01-06 14:55:09.248444 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/adapters/persist_docs.sql
2022-01-06 14:55:09.252841 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/adapters/freshness.sql
2022-01-06 14:55:09.255782 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/adapters/relation.sql
2022-01-06 14:55:09.265122 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/adapters/metadata.sql
2022-01-06 14:55:09.272098 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/adapters/columns.sql
2022-01-06 14:55:09.282578 (ThreadPoolExecutor-0_0): 14:55:09  Parsing macros/adapters/schema.sql
2022-01-06 14:55:09.294828 (ThreadPoolExecutor-0_0): 14:55:09  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:55:09.294948 (ThreadPoolExecutor-0_0): 14:55:09  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:55:09.295035 (ThreadPoolExecutor-0_0): 14:55:09  Opening a new connection, currently in state init
2022-01-06 14:55:09.295117 (ThreadPoolExecutor-0_0): 14:55:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:55:09.314508 (ThreadPoolExecutor-0_0): 14:55:09  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:55:09.314617 (ThreadPoolExecutor-0_0): 14:55:09  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:55:09.314691 (ThreadPoolExecutor-0_0): 14:55:09  On list_dev_dbt_nobodozie: select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:55:09.317662 (Thread-208): handling poll request
2022-01-06 14:55:09.318043 (Thread-208): 14:55:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781523d0>]}
2022-01-06 14:55:09.319162 (Thread-208): sending response (<Response 18409 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:55:09.325691 (ThreadPoolExecutor-0_0): 14:55:09  SQL status: SELECT in 0.01 seconds
2022-01-06 14:55:09.326763 (ThreadPoolExecutor-0_0): 14:55:09  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:55:09.328565 (ThreadPoolExecutor-0_0): 14:55:09  On list_dev_dbt_nobodozie: Close
2022-01-06 14:55:09.332225 (MainThread): 14:55:09  Using redshift connection "master"
2022-01-06 14:55:09.332336 (MainThread): 14:55:09  On master: BEGIN
2022-01-06 14:55:09.332417 (MainThread): 14:55:09  Opening a new connection, currently in state init
2022-01-06 14:55:09.332491 (MainThread): 14:55:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:55:09.356141 (MainThread): 14:55:09  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:55:09.356247 (MainThread): 14:55:09  Using redshift connection "master"
2022-01-06 14:55:09.356320 (MainThread): 14:55:09  On master: with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:55:09.384111 (MainThread): 14:55:09  SQL status: SELECT in 0.03 seconds
2022-01-06 14:55:09.385166 (MainThread): 14:55:09  On master: ROLLBACK
2022-01-06 14:55:09.387077 (MainThread): 14:55:09  On master: Close
2022-01-06 14:55:09.387388 (MainThread): 14:55:09  Concurrency: 4 threads (target='default')
2022-01-06 14:55:09.387501 (MainThread): 14:55:09  
2022-01-06 14:55:09.390017 (Thread-1): 14:55:09  Began running node model.my_new_project.dim_customers
2022-01-06 14:55:09.390186 (Thread-1): 14:55:09  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:55:09.390273 (Thread-1): 14:55:09  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:55:09.390359 (Thread-1): 14:55:09  Compiling model.my_new_project.dim_customers
2022-01-06 14:55:09.392548 (Thread-1): 14:55:09  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:55:09.392795 (Thread-2): 14:55:09  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:55:09.392984 (Thread-2): 14:55:09  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:55:09.393082 (Thread-2): 14:55:09  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:55:09.393177 (Thread-2): 14:55:09  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:55:09.395866 (Thread-2): 14:55:09  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:55:09.407579 (Thread-1): 14:55:09  finished collecting timing info
2022-01-06 14:55:09.407716 (Thread-1): 14:55:09  Began executing node model.my_new_project.dim_customers
2022-01-06 14:55:09.407814 (Thread-1): 14:55:09  finished collecting timing info
2022-01-06 14:55:09.407967 (Thread-1): 14:55:09  Finished running node model.my_new_project.dim_customers
2022-01-06 14:55:09.411425 (Thread-2): 14:55:09  finished collecting timing info
2022-01-06 14:55:09.411532 (Thread-2): 14:55:09  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:55:09.411615 (Thread-2): 14:55:09  finished collecting timing info
2022-01-06 14:55:09.411730 (Thread-2): 14:55:09  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:55:09.412551 (Thread-4): 14:55:09  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:55:09.412725 (Thread-4): 14:55:09  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:55:09.412804 (Thread-4): 14:55:09  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:55:09.412878 (Thread-4): 14:55:09  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:55:09.414828 (Thread-4): 14:55:09  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:55:09.415040 (Thread-3): 14:55:09  Began running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 14:55:09.415200 (Thread-3): 14:55:09  Acquiring new redshift connection "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-06 14:55:09.415278 (Thread-3): 14:55:09  Began compiling node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 14:55:09.415352 (Thread-3): 14:55:09  Compiling test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 14:55:09.420241 (Thread-1): 14:55:09  Began running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 14:55:09.420416 (Thread-1): 14:55:09  Acquiring new redshift connection "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-06 14:55:09.420562 (Thread-1): 14:55:09  Began compiling node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 14:55:09.420712 (Thread-1): 14:55:09  Compiling test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 14:55:09.430143 (Thread-3): 14:55:09  Writing injected SQL for node "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-06 14:55:09.435647 (Thread-1): 14:55:09  Writing injected SQL for node "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-06 14:55:09.441239 (Thread-4): 14:55:09  finished collecting timing info
2022-01-06 14:55:09.441400 (Thread-4): 14:55:09  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:55:09.441519 (Thread-4): 14:55:09  finished collecting timing info
2022-01-06 14:55:09.441658 (Thread-4): 14:55:09  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:55:09.442240 (Thread-2): 14:55:09  Began running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 14:55:09.442376 (Thread-2): 14:55:09  Acquiring new redshift connection "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2022-01-06 14:55:09.442460 (Thread-2): 14:55:09  Began compiling node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 14:55:09.442534 (Thread-2): 14:55:09  Compiling test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 14:55:09.445546 (Thread-2): 14:55:09  Writing injected SQL for node "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2022-01-06 14:55:09.445748 (Thread-4): 14:55:09  Began running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 14:55:09.445903 (Thread-4): 14:55:09  Acquiring new redshift connection "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2022-01-06 14:55:09.445984 (Thread-4): 14:55:09  Began compiling node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 14:55:09.446056 (Thread-4): 14:55:09  Compiling test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 14:55:09.449145 (Thread-4): 14:55:09  Writing injected SQL for node "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2022-01-06 14:55:09.449473 (Thread-3): 14:55:09  finished collecting timing info
2022-01-06 14:55:09.449588 (Thread-3): 14:55:09  Began executing node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 14:55:09.449675 (Thread-3): 14:55:09  finished collecting timing info
2022-01-06 14:55:09.449800 (Thread-3): 14:55:09  Finished running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 14:55:09.455026 (Thread-1): 14:55:09  finished collecting timing info
2022-01-06 14:55:09.455207 (Thread-1): 14:55:09  Began executing node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 14:55:09.455356 (Thread-1): 14:55:09  finished collecting timing info
2022-01-06 14:55:09.455563 (Thread-1): 14:55:09  Finished running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 14:55:09.463117 (Thread-2): 14:55:09  finished collecting timing info
2022-01-06 14:55:09.463236 (Thread-2): 14:55:09  Began executing node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 14:55:09.463323 (Thread-2): 14:55:09  finished collecting timing info
2022-01-06 14:55:09.463442 (Thread-2): 14:55:09  Finished running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 14:55:09.463612 (Thread-4): 14:55:09  finished collecting timing info
2022-01-06 14:55:09.463738 (Thread-4): 14:55:09  Began executing node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 14:55:09.463836 (Thread-4): 14:55:09  finished collecting timing info
2022-01-06 14:55:09.463987 (Thread-4): 14:55:09  Finished running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 14:55:09.465358 (MainThread): 14:55:09  Connection 'master' was properly closed.
2022-01-06 14:55:09.465462 (MainThread): 14:55:09  Connection 'test.my_new_project.unique_my_first_dbt_model_id.16e066b321' was properly closed.
2022-01-06 14:55:09.465527 (MainThread): 14:55:09  Connection 'test.my_new_project.not_null_my_second_dbt_model_id.151b76d778' was properly closed.
2022-01-06 14:55:09.465587 (MainThread): 14:55:09  Connection 'test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
2022-01-06 14:55:09.465645 (MainThread): 14:55:09  Connection 'test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
2022-01-06 14:55:09.514643 (MainThread): 14:55:09  Done.
2022-01-06 14:55:09.583018 (MainThread): 14:55:09  Acquiring new redshift connection "generate_catalog"
2022-01-06 14:55:09.583165 (MainThread): 14:55:09  Building catalog
2022-01-06 14:55:09.584499 (ThreadPoolExecutor-1_0): 14:55:09  Acquiring new redshift connection "dev.information_schema"
2022-01-06 14:55:09.595299 (ThreadPoolExecutor-1_0): 14:55:09  Using redshift connection "dev.information_schema"
2022-01-06 14:55:09.595404 (ThreadPoolExecutor-1_0): 14:55:09  On dev.information_schema: BEGIN
2022-01-06 14:55:09.595484 (ThreadPoolExecutor-1_0): 14:55:09  Opening a new connection, currently in state init
2022-01-06 14:55:09.595560 (ThreadPoolExecutor-1_0): 14:55:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:55:09.614525 (ThreadPoolExecutor-1_0): 14:55:09  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:55:09.614639 (ThreadPoolExecutor-1_0): 14:55:09  Using redshift connection "dev.information_schema"
2022-01-06 14:55:09.614712 (ThreadPoolExecutor-1_0): 14:55:09  On dev.information_schema: 
    

    with late_binding as (
      select
        'dev'::varchar as table_database,
        table_schema,
        table_name,
        'LATE BINDING VIEW'::varchar as table_type,
        null::text as table_comment,

        column_name,
        column_index,
        column_type,
        null::text as column_comment
      from pg_get_late_binding_view_cols()
        cols(table_schema name, table_name name, column_name name,
             column_type varchar,
             column_index int)
        order by "column_index"
    ),

    early_binding as (
        select
            'dev'::varchar as table_database,
            sch.nspname as table_schema,
            tbl.relname as table_name,
            case tbl.relkind
                when 'v' then 'VIEW'
                else 'BASE TABLE'
            end as table_type,
            tbl_desc.description as table_comment,
            col.attname as column_name,
            col.attnum as column_index,
            pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
            col_desc.description as column_comment

        from pg_catalog.pg_namespace sch
        join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
        join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
        left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
        left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
        where (upper(sch.nspname) = upper('dbt_nobodozie'))
            and tbl.relkind in ('r', 'v', 'f', 'p')
            and col.attnum > 0
            and not col.attisdropped
    ),

    table_owners as (

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            tablename as table_name,
            tableowner as table_owner

        from pg_tables

        union all

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            viewname as table_name,
            viewowner as table_owner

        from pg_views

    ),

    unioned as (

        select *
        from early_binding

        union all

        select *
        from late_binding

    )

    select *,
        table_database || '.' || table_schema || '.' || table_name as table_id

    from unioned
    join table_owners using (table_database, table_schema, table_name)

    where (upper(table_schema) = upper('dbt_nobodozie'))

    order by "column_index"
2022-01-06 14:55:09.670866 (ThreadPoolExecutor-1_0): 14:55:09  SQL status: SELECT in 0.06 seconds
2022-01-06 14:55:09.674360 (ThreadPoolExecutor-1_0): 14:55:09  Using redshift connection "dev.information_schema"
2022-01-06 14:55:09.674458 (ThreadPoolExecutor-1_0): 14:55:09  On dev.information_schema: select has_table_privilege(current_user, 'svv_table_info', 'SELECT') as can_select
2022-01-06 14:55:09.676781 (ThreadPoolExecutor-1_0): 14:55:09  SQL status: SELECT in 0.0 seconds
2022-01-06 14:55:09.680518 (ThreadPoolExecutor-1_0): 14:55:09  Using redshift connection "dev.information_schema"
2022-01-06 14:55:09.680611 (ThreadPoolExecutor-1_0): 14:55:09  On dev.information_schema: select
        "database" || '.' || "schema" || '.' || "table" as table_id,

        'Encoded'::text as "stats:encoded:label",
        encoded as "stats:encoded:value",
        'Indicates whether any column in the table has compression encoding defined.'::text as "stats:encoded:description",
        true as "stats:encoded:include",

        'Dist Style' as "stats:diststyle:label",
        diststyle as "stats:diststyle:value",
        'Distribution style or distribution key column, if key distribution is defined.'::text as "stats:diststyle:description",
        true as "stats:diststyle:include",

        'Sort Key 1' as "stats:sortkey1:label",
        -- handle 0xFF byte in response for interleaved sort styles
        case
            when sortkey1 like 'INTERLEAVED%' then 'INTERLEAVED'::text
            else sortkey1
        end as "stats:sortkey1:value",
        'First column in the sort key.'::text as "stats:sortkey1:description",
        (sortkey1 is not null) as "stats:sortkey1:include",

        'Max Varchar' as "stats:max_varchar:label",
        max_varchar as "stats:max_varchar:value",
        'Size of the largest column that uses a VARCHAR data type.'::text as "stats:max_varchar:description",
        true as "stats:max_varchar:include",

        -- exclude this, as the data is strangely returned with null-byte characters
        'Sort Key 1 Encoding' as "stats:sortkey1_enc:label",
        sortkey1_enc as "stats:sortkey1_enc:value",
        'Compression encoding of the first column in the sort key.' as "stats:sortkey1_enc:description",
        false as "stats:sortkey1_enc:include",

        '# Sort Keys' as "stats:sortkey_num:label",
        sortkey_num as "stats:sortkey_num:value",
        'Number of columns defined as sort keys.' as "stats:sortkey_num:description",
        (sortkey_num > 0) as "stats:sortkey_num:include",

        'Approximate Size' as "stats:size:label",
        size * 1000000 as "stats:size:value",
        'Approximate size of the table, calculated from a count of 1MB blocks'::text as "stats:size:description",
        true as "stats:size:include",

        'Disk Utilization' as "stats:pct_used:label",
        pct_used / 100.0 as "stats:pct_used:value",
        'Percent of available space that is used by the table.'::text as "stats:pct_used:description",
        true as "stats:pct_used:include",

        'Unsorted %' as "stats:unsorted:label",
        unsorted / 100.0 as "stats:unsorted:value",
        'Percent of unsorted rows in the table.'::text as "stats:unsorted:description",
        (unsorted is not null) as "stats:unsorted:include",

        'Stats Off' as "stats:stats_off:label",
        stats_off as "stats:stats_off:value",
        'Number that indicates how stale the table statistics are; 0 is current, 100 is out of date.'::text as "stats:stats_off:description",
        true as "stats:stats_off:include",

        'Approximate Row Count' as "stats:rows:label",
        tbl_rows as "stats:rows:value",
        'Approximate number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed.'::text as "stats:rows:description",
        true as "stats:rows:include",

        'Sort Key Skew' as "stats:skew_sortkey1:label",
        skew_sortkey1 as "stats:skew_sortkey1:value",
        'Ratio of the size of the largest non-sort key column to the size of the first column of the sort key.'::text as "stats:skew_sortkey1:description",
        (skew_sortkey1 is not null) as "stats:skew_sortkey1:include",

        'Skew Rows' as "stats:skew_rows:label",
        skew_rows as "stats:skew_rows:value",
        'Ratio of the number of rows in the slice with the most rows to the number of rows in the slice with the fewest rows.'::text as "stats:skew_rows:description",
        (skew_rows is not null) as "stats:skew_rows:include"

    from svv_table_info
    where (upper(schema) = upper('dbt_nobodozie'))
2022-01-06 14:55:10.489362 (ThreadPoolExecutor-1_0): 14:55:10  SQL status: SELECT in 0.81 seconds
2022-01-06 14:55:10.498389 (ThreadPoolExecutor-1_0): 14:55:10  On dev.information_schema: ROLLBACK
2022-01-06 14:55:10.500529 (ThreadPoolExecutor-1_0): 14:55:10  On dev.information_schema: Close
2022-01-06 14:55:10.570125 (MainThread): 14:55:10  Catalog written to /usr/src/develop/user-52374/environment-57794/repository-46678/target/catalog.json
2022-01-06 14:55:10.777380 (Thread-209): handling poll request
2022-01-06 14:55:10.777740 (Thread-209): 14:55:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780f63a0>]}
2022-01-06 14:55:10.779453 (Thread-209): sending response (<Response 54807 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:55:11.490855 (Thread-210): handling status request
2022-01-06 14:55:11.491216 (Thread-210): 14:55:11  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780f69a0>]}
2022-01-06 14:55:11.491726 (Thread-210): sending response (<Response 1244 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:55:11.559185 (Thread-211): handling status request
2022-01-06 14:55:11.559482 (Thread-211): 14:55:11  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780f6d60>]}
2022-01-06 14:55:11.559910 (Thread-211): sending response (<Response 1244 bytes [200 OK]>) to 10.0.40.39
2022-01-06 14:55:11.619442 (Thread-212): handling status request
2022-01-06 14:55:11.619752 (Thread-212): 14:55:11  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780f6fd0>]}
2022-01-06 14:55:11.620208 (Thread-212): sending response (<Response 1244 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:57:51.170320 (Thread-213): handling status request
2022-01-06 14:57:51.171862 (Thread-213): 14:57:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78107280>]}
2022-01-06 14:57:51.172452 (Thread-213): sending response (<Response 1244 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:57:51.527507 (Thread-214): handling run_sql request
2022-01-06 14:57:51.527875 (Thread-214): 14:57:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781074f0>]}
2022-01-06 14:57:53.572412 (Thread-214): sending response (<Response 138 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:57:53.599786 (MainThread): 14:57:53  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '752659e6-c1ad-4564-be17-209857251944', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64ad1e9d90>]}
2022-01-06 14:57:53.600307 (MainThread): 14:57:53  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:57:53.600891 (Thread-1): 14:57:53  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:57:53.601020 (Thread-1): 14:57:53  Began compiling node rpc.my_new_project.request
2022-01-06 14:57:53.601112 (Thread-1): 14:57:53  Compiling rpc.my_new_project.request
2022-01-06 14:57:53.603657 (Thread-1): 14:57:53  finished collecting timing info
2022-01-06 14:57:53.603784 (Thread-1): 14:57:53  Began executing node rpc.my_new_project.request
2022-01-06 14:57:53.603881 (Thread-1): 14:57:53  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:57:53.603954 (Thread-1): 14:57:53  On rpc.my_new_project.request: 

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"

),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:57:53.604031 (Thread-1): 14:57:53  Opening a new connection, currently in state init
2022-01-06 14:57:53.604108 (Thread-1): 14:57:53  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:57:53.624010 (Thread-1): 14:57:53  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 14:57:53.624164 (Thread-1): 14:57:53  finished collecting timing info
2022-01-06 14:57:53.624279 (Thread-1): 14:57:53  On rpc.my_new_project.request: Close
2022-01-06 14:57:53.624531 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 14:57:53.625550 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\') }}\n\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\') }}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\') }}\n\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\') }}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 14:57:53.905066 (Thread-215): handling poll request
2022-01-06 14:57:53.905520 (Thread-215): 14:57:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78170940>]}
2022-01-06 14:57:53.906348 (Thread-215): sending response (<Response 14749 bytes [200 OK]>) to 10.0.40.39
2022-01-06 14:59:18.630347 (Thread-216): handling status request
2022-01-06 14:59:18.630729 (Thread-216): 14:59:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78104280>]}
2022-01-06 14:59:18.653886 (Thread-216): sending response (<Response 1244 bytes [200 OK]>) to 10.0.5.191
2022-01-06 14:59:18.968374 (Thread-217): handling run_sql request
2022-01-06 14:59:18.968710 (Thread-217): 14:59:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781045b0>]}
2022-01-06 14:59:21.035290 (Thread-217): sending response (<Response 138 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:59:21.061060 (MainThread): 14:59:21  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '75e06472-64b1-45e4-ba3f-8b33e271b1e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6983b46d0>]}
2022-01-06 14:59:21.061610 (MainThread): 14:59:21  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:59:21.062168 (Thread-1): 14:59:21  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:59:21.062298 (Thread-1): 14:59:21  Began compiling node rpc.my_new_project.request
2022-01-06 14:59:21.062398 (Thread-1): 14:59:21  Compiling rpc.my_new_project.request
2022-01-06 14:59:21.063551 (Thread-1): 14:59:21  finished collecting timing info
2022-01-06 14:59:21.063675 (Thread-1): 14:59:21  Began executing node rpc.my_new_project.request
2022-01-06 14:59:21.063773 (Thread-1): 14:59:21  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:59:21.063854 (Thread-1): 14:59:21  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from dev.jaffle_shop.customers

)
select * from customers
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:59:21.063929 (Thread-1): 14:59:21  Opening a new connection, currently in state init
2022-01-06 14:59:21.064015 (Thread-1): 14:59:21  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:59:21.087125 (Thread-1): 14:59:21  SQL status: SELECT in 0.02 seconds
2022-01-06 14:59:21.088943 (Thread-1): 14:59:21  finished collecting timing info
2022-01-06 14:59:21.089077 (Thread-1): 14:59:21  On rpc.my_new_project.request: Close
2022-01-06 14:59:21.440213 (Thread-218): handling poll request
2022-01-06 14:59:21.440657 (Thread-218): 14:59:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781192e0>]}
2022-01-06 14:59:21.442048 (Thread-218): sending response (<Response 10174 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:59:30.929755 (Thread-219): handling status request
2022-01-06 14:59:30.930123 (Thread-219): 14:59:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78119490>]}
2022-01-06 14:59:30.930627 (Thread-219): sending response (<Response 1244 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:59:31.330041 (Thread-220): handling run_sql request
2022-01-06 14:59:31.330412 (Thread-220): 14:59:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78119880>]}
2022-01-06 14:59:33.387115 (Thread-220): sending response (<Response 138 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:59:33.410869 (MainThread): 14:59:33  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '450d5133-2331-4364-aa83-8f1594fa730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a471ca640>]}
2022-01-06 14:59:33.411377 (MainThread): 14:59:33  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:59:33.411931 (Thread-1): 14:59:33  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:59:33.412061 (Thread-1): 14:59:33  Began compiling node rpc.my_new_project.request
2022-01-06 14:59:33.412160 (Thread-1): 14:59:33  Compiling rpc.my_new_project.request
2022-01-06 14:59:33.413340 (Thread-1): 14:59:33  finished collecting timing info
2022-01-06 14:59:33.413466 (Thread-1): 14:59:33  Began executing node rpc.my_new_project.request
2022-01-06 14:59:33.413561 (Thread-1): 14:59:33  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:59:33.413647 (Thread-1): 14:59:33  On rpc.my_new_project.request: with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from dev.jaffle_shop.orders

)
select * from orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:59:33.413722 (Thread-1): 14:59:33  Opening a new connection, currently in state init
2022-01-06 14:59:33.413804 (Thread-1): 14:59:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:59:33.434407 (Thread-1): 14:59:33  SQL status: SELECT in 0.02 seconds
2022-01-06 14:59:33.436852 (Thread-1): 14:59:33  finished collecting timing info
2022-01-06 14:59:33.436983 (Thread-1): 14:59:33  On rpc.my_new_project.request: Close
2022-01-06 14:59:33.950493 (Thread-221): handling poll request
2022-01-06 14:59:33.950950 (Thread-221): 14:59:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7811eca0>]}
2022-01-06 14:59:33.952476 (Thread-221): sending response (<Response 11872 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:59:43.768922 (Thread-222): handling status request
2022-01-06 14:59:43.769335 (Thread-222): 14:59:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7811ee20>]}
2022-01-06 14:59:43.769852 (Thread-222): sending response (<Response 1244 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:59:44.108975 (Thread-223): handling compile_sql request
2022-01-06 14:59:44.109360 (Thread-223): 14:59:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781191f0>]}
2022-01-06 14:59:46.187923 (Thread-223): sending response (<Response 138 bytes [200 OK]>) to 10.0.5.191
2022-01-06 14:59:46.215584 (MainThread): 14:59:46  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3b49f12f-12e0-4663-b9e6-ed498ee5926e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c955b4310>]}
2022-01-06 14:59:46.216099 (MainThread): 14:59:46  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:59:46.216664 (Thread-1): 14:59:46  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:59:46.216792 (Thread-1): 14:59:46  Began compiling node rpc.my_new_project.request
2022-01-06 14:59:46.216881 (Thread-1): 14:59:46  Compiling rpc.my_new_project.request
2022-01-06 14:59:46.219493 (Thread-1): 14:59:46  finished collecting timing info
2022-01-06 14:59:46.219620 (Thread-1): 14:59:46  Began executing node rpc.my_new_project.request
2022-01-06 14:59:46.219714 (Thread-1): 14:59:46  finished collecting timing info
2022-01-06 14:59:46.582732 (Thread-224): handling poll request
2022-01-06 14:59:46.583146 (Thread-224): 14:59:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780afa60>]}
2022-01-06 14:59:46.584214 (Thread-224): sending response (<Response 8504 bytes [200 OK]>) to 10.0.35.205
2022-01-06 15:00:06.379006 (Thread-225): handling status request
2022-01-06 15:00:06.379379 (Thread-225): 15:00:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780afc10>]}
2022-01-06 15:00:06.379900 (Thread-225): sending response (<Response 1244 bytes [200 OK]>) to 10.0.25.31
2022-01-06 15:00:06.536943 (Thread-226): handling status request
2022-01-06 15:00:06.537351 (Thread-226): 15:00:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780affa0>]}
2022-01-06 15:00:06.537822 (Thread-226): sending response (<Response 1244 bytes [200 OK]>) to 10.0.25.31
2022-01-06 15:00:06.702521 (Thread-227): handling cli_args request
2022-01-06 15:00:06.702868 (Thread-227): 15:00:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780b5280>]}
2022-01-06 15:00:08.771016 (Thread-227): sending response (<Response 138 bytes [200 OK]>) to 10.0.5.191
2022-01-06 15:00:08.856343 (MainThread): 15:00:08  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 15:00:08.856745 (MainThread): 15:00:08  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 15:00:08.862605 (MainThread): 15:00:08  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e8f8c20b-57fc-464d-819c-6d719cd3d82d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6b18d0c70>]}
2022-01-06 15:00:08.887174 (MainThread): 15:00:08  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e8f8c20b-57fc-464d-819c-6d719cd3d82d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6b1946c10>]}
2022-01-06 15:00:08.887418 (MainThread): 15:00:08  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:00:08.888491 (MainThread): 15:00:08  
2022-01-06 15:00:08.888760 (MainThread): 15:00:08  Acquiring new redshift connection "master"
2022-01-06 15:00:08.889671 (ThreadPoolExecutor-0_0): 15:00:08  Acquiring new redshift connection "list_dev"
2022-01-06 15:00:08.899325 (ThreadPoolExecutor-0_0): 15:00:08  Using redshift connection "list_dev"
2022-01-06 15:00:08.899635 (ThreadPoolExecutor-0_0): 15:00:08  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 15:00:08.899742 (ThreadPoolExecutor-0_0): 15:00:08  Opening a new connection, currently in state init
2022-01-06 15:00:08.899827 (ThreadPoolExecutor-0_0): 15:00:08  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:00:08.921730 (ThreadPoolExecutor-0_0): 15:00:08  SQL status: SELECT in 0.02 seconds
2022-01-06 15:00:08.922787 (ThreadPoolExecutor-0_0): 15:00:08  On list_dev: Close
2022-01-06 15:00:08.923959 (ThreadPoolExecutor-1_0): 15:00:08  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:00:08.930414 (ThreadPoolExecutor-1_0): 15:00:08  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:00:08.930513 (ThreadPoolExecutor-1_0): 15:00:08  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 15:00:08.930594 (ThreadPoolExecutor-1_0): 15:00:08  Opening a new connection, currently in state closed
2022-01-06 15:00:08.930670 (ThreadPoolExecutor-1_0): 15:00:08  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:00:08.951670 (ThreadPoolExecutor-1_0): 15:00:08  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:00:08.951783 (ThreadPoolExecutor-1_0): 15:00:08  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:00:08.951860 (ThreadPoolExecutor-1_0): 15:00:08  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 15:00:08.962916 (ThreadPoolExecutor-1_0): 15:00:08  SQL status: SELECT in 0.01 seconds
2022-01-06 15:00:08.963890 (ThreadPoolExecutor-1_0): 15:00:08  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 15:00:08.965764 (ThreadPoolExecutor-1_0): 15:00:08  On list_dev_dbt_nobodozie: Close
2022-01-06 15:00:08.969325 (MainThread): 15:00:08  Using redshift connection "master"
2022-01-06 15:00:08.969435 (MainThread): 15:00:08  On master: BEGIN
2022-01-06 15:00:08.969515 (MainThread): 15:00:08  Opening a new connection, currently in state init
2022-01-06 15:00:08.969590 (MainThread): 15:00:08  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:00:08.994158 (MainThread): 15:00:08  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:00:08.994265 (MainThread): 15:00:08  Using redshift connection "master"
2022-01-06 15:00:08.994341 (MainThread): 15:00:08  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 15:00:09.022998 (MainThread): 15:00:09  SQL status: SELECT in 0.03 seconds
2022-01-06 15:00:09.023925 (MainThread): 15:00:09  On master: ROLLBACK
2022-01-06 15:00:09.025799 (MainThread): 15:00:09  Using redshift connection "master"
2022-01-06 15:00:09.025895 (MainThread): 15:00:09  On master: BEGIN
2022-01-06 15:00:09.029352 (MainThread): 15:00:09  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:00:09.029452 (MainThread): 15:00:09  On master: COMMIT
2022-01-06 15:00:09.029523 (MainThread): 15:00:09  Using redshift connection "master"
2022-01-06 15:00:09.029589 (MainThread): 15:00:09  On master: COMMIT
2022-01-06 15:00:09.031321 (MainThread): 15:00:09  SQL status: COMMIT in 0.0 seconds
2022-01-06 15:00:09.031419 (MainThread): 15:00:09  On master: Close
2022-01-06 15:00:09.031760 (MainThread): 15:00:09  Concurrency: 4 threads (target='default')
2022-01-06 15:00:09.031869 (MainThread): 15:00:09  
2022-01-06 15:00:09.034007 (Thread-1): 15:00:09  Began running node model.my_new_project.dim_customers
2022-01-06 15:00:09.034243 (Thread-1): 15:00:09  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 15:00:09.034483 (Thread-1): 15:00:09  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:00:09.034576 (Thread-1): 15:00:09  Began compiling node model.my_new_project.dim_customers
2022-01-06 15:00:09.034668 (Thread-1): 15:00:09  Compiling model.my_new_project.dim_customers
2022-01-06 15:00:09.036626 (Thread-1): 15:00:09  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 15:00:09.036845 (Thread-2): 15:00:09  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 15:00:09.037064 (Thread-2): 15:00:09  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 15:00:09.037335 (Thread-2): 15:00:09  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:00:09.037423 (Thread-2): 15:00:09  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 15:00:09.037504 (Thread-2): 15:00:09  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 15:00:09.039443 (Thread-2): 15:00:09  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 15:00:09.051075 (Thread-1): 15:00:09  finished collecting timing info
2022-01-06 15:00:09.051213 (Thread-1): 15:00:09  Began executing node model.my_new_project.dim_customers
2022-01-06 15:00:09.056409 (Thread-2): 15:00:09  finished collecting timing info
2022-01-06 15:00:09.056538 (Thread-2): 15:00:09  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 15:00:09.110537 (Thread-1): 15:00:09  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 15:00:09.111796 (Thread-2): 15:00:09  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 15:00:09.128118 (Thread-2): 15:00:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:00:09.128230 (Thread-2): 15:00:09  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:00:09.128313 (Thread-2): 15:00:09  Opening a new connection, currently in state init
2022-01-06 15:00:09.128392 (Thread-2): 15:00:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:00:09.128636 (Thread-1): 15:00:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:00:09.128736 (Thread-1): 15:00:09  On model.my_new_project.dim_customers: BEGIN
2022-01-06 15:00:09.128814 (Thread-1): 15:00:09  Opening a new connection, currently in state closed
2022-01-06 15:00:09.128887 (Thread-1): 15:00:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:00:09.151895 (Thread-2): 15:00:09  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:00:09.152009 (Thread-2): 15:00:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:00:09.152086 (Thread-2): 15:00:09  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 15:00:09.154881 (Thread-1): 15:00:09  SQL status: BEGIN in 0.03 seconds
2022-01-06 15:00:09.155001 (Thread-1): 15:00:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:00:09.155078 (Thread-1): 15:00:09  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 15:00:09.225575 (Thread-2): 15:00:09  SQL status: SELECT in 0.07 seconds
2022-01-06 15:00:09.230977 (Thread-2): 15:00:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:00:09.231081 (Thread-2): 15:00:09  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 15:00:09.234977 (Thread-2): 15:00:09  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:00:09.236704 (Thread-2): 15:00:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:00:09.236802 (Thread-2): 15:00:09  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 15:00:09.240073 (Thread-2): 15:00:09  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:00:09.250219 (Thread-2): 15:00:09  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:00:09.250321 (Thread-2): 15:00:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:00:09.250496 (Thread-2): 15:00:09  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:00:09.283924 (Thread-1): 15:00:09  SQL status: SELECT in 0.13 seconds
2022-01-06 15:00:09.286552 (Thread-1): 15:00:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:00:09.286647 (Thread-1): 15:00:09  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 15:00:09.289774 (Thread-1): 15:00:09  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:00:09.291384 (Thread-1): 15:00:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:00:09.291478 (Thread-1): 15:00:09  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 15:00:09.294419 (Thread-1): 15:00:09  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:00:09.295477 (Thread-1): 15:00:09  On model.my_new_project.dim_customers: COMMIT
2022-01-06 15:00:09.295572 (Thread-1): 15:00:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:00:09.295645 (Thread-1): 15:00:09  On model.my_new_project.dim_customers: COMMIT
2022-01-06 15:00:09.335546 (Thread-2): 15:00:09  SQL status: COMMIT in 0.08 seconds
2022-01-06 15:00:09.335878 (Thread-2): 15:00:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:00:09.336268 (Thread-2): 15:00:09  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:00:09.336549 (Thread-1): 15:00:09  SQL status: COMMIT in 0.04 seconds
2022-01-06 15:00:09.338547 (Thread-2): 15:00:09  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:00:09.344891 (Thread-2): 15:00:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:00:09.345039 (Thread-2): 15:00:09  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 15:00:09.350022 (Thread-2): 15:00:09  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 15:00:09.351015 (Thread-2): 15:00:09  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:00:09.351157 (Thread-2): 15:00:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:00:09.351275 (Thread-2): 15:00:09  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:00:09.359789 (Thread-228): handling poll request
2022-01-06 15:00:09.360179 (Thread-228): 15:00:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780c34f0>]}
2022-01-06 15:00:09.361919 (Thread-228): sending response (<Response 42664 bytes [200 OK]>) to 10.0.15.67
2022-01-06 15:00:09.385330 (Thread-2): 15:00:09  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:00:09.385501 (Thread-2): 15:00:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:00:09.385582 (Thread-2): 15:00:09  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:00:09.387676 (Thread-2): 15:00:09  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:00:09.388179 (Thread-2): 15:00:09  finished collecting timing info
2022-01-06 15:00:09.388323 (Thread-2): 15:00:09  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 15:00:09.388557 (Thread-1): 15:00:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:00:09.388678 (Thread-1): 15:00:09  On model.my_new_project.dim_customers: BEGIN
2022-01-06 15:00:09.391072 (Thread-1): 15:00:09  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:00:09.392639 (Thread-1): 15:00:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:00:09.392737 (Thread-1): 15:00:09  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 15:00:09.392933 (Thread-2): 15:00:09  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 15:00:09.393494 (Thread-2): 15:00:09  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8f8c20b-57fc-464d-819c-6d719cd3d82d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a17e9af0>]}
2022-01-06 15:00:09.393844 (Thread-2): 15:00:09  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.36s]
2022-01-06 15:00:09.393964 (Thread-2): 15:00:09  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 15:00:09.394700 (Thread-4): 15:00:09  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 15:00:09.394948 (Thread-4): 15:00:09  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 15:00:09.395211 (Thread-4): 15:00:09  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:00:09.395300 (Thread-4): 15:00:09  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 15:00:09.395385 (Thread-4): 15:00:09  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 15:00:09.397674 (Thread-4): 15:00:09  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 15:00:09.397995 (Thread-1): 15:00:09  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 15:00:09.398706 (Thread-1): 15:00:09  On model.my_new_project.dim_customers: COMMIT
2022-01-06 15:00:09.398800 (Thread-1): 15:00:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:00:09.398874 (Thread-1): 15:00:09  On model.my_new_project.dim_customers: COMMIT
2022-01-06 15:00:09.412106 (Thread-4): 15:00:09  finished collecting timing info
2022-01-06 15:00:09.412251 (Thread-4): 15:00:09  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 15:00:09.427990 (Thread-4): 15:00:09  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 15:00:09.431587 (Thread-1): 15:00:09  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:00:09.431705 (Thread-1): 15:00:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:00:09.431780 (Thread-1): 15:00:09  On model.my_new_project.dim_customers: BEGIN
2022-01-06 15:00:09.433796 (Thread-1): 15:00:09  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:00:09.434170 (Thread-1): 15:00:09  finished collecting timing info
2022-01-06 15:00:09.434293 (Thread-1): 15:00:09  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 15:00:09.436008 (Thread-1): 15:00:09  On model.my_new_project.dim_customers: Close
2022-01-06 15:00:09.436433 (Thread-1): 15:00:09  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8f8c20b-57fc-464d-819c-6d719cd3d82d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a17c4070>]}
2022-01-06 15:00:09.436733 (Thread-1): 15:00:09  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.40s]
2022-01-06 15:00:09.436842 (Thread-1): 15:00:09  Finished running node model.my_new_project.dim_customers
2022-01-06 15:00:09.442319 (Thread-4): 15:00:09  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:00:09.442430 (Thread-4): 15:00:09  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:00:09.442517 (Thread-4): 15:00:09  Opening a new connection, currently in state init
2022-01-06 15:00:09.442597 (Thread-4): 15:00:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:00:09.464860 (Thread-4): 15:00:09  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:00:09.464973 (Thread-4): 15:00:09  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:00:09.465049 (Thread-4): 15:00:09  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 15:00:09.470014 (Thread-4): 15:00:09  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 15:00:09.471906 (Thread-4): 15:00:09  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:00:09.472001 (Thread-4): 15:00:09  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 15:00:09.474740 (Thread-4): 15:00:09  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:00:09.475694 (Thread-4): 15:00:09  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:00:09.475791 (Thread-4): 15:00:09  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:00:09.475864 (Thread-4): 15:00:09  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:00:09.508119 (Thread-4): 15:00:09  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:00:09.508326 (Thread-4): 15:00:09  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:00:09.508405 (Thread-4): 15:00:09  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:00:09.510424 (Thread-4): 15:00:09  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:00:09.511690 (Thread-4): 15:00:09  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:00:09.511785 (Thread-4): 15:00:09  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 15:00:09.513726 (Thread-4): 15:00:09  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 15:00:09.514411 (Thread-4): 15:00:09  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:00:09.514506 (Thread-4): 15:00:09  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:00:09.514579 (Thread-4): 15:00:09  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:00:09.544132 (Thread-4): 15:00:09  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:00:09.544241 (Thread-4): 15:00:09  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:00:09.544313 (Thread-4): 15:00:09  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:00:09.546289 (Thread-4): 15:00:09  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:00:09.546647 (Thread-4): 15:00:09  finished collecting timing info
2022-01-06 15:00:09.546768 (Thread-4): 15:00:09  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 15:00:09.548514 (Thread-4): 15:00:09  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 15:00:09.548913 (Thread-4): 15:00:09  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8f8c20b-57fc-464d-819c-6d719cd3d82d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6b0862430>]}
2022-01-06 15:00:09.549274 (Thread-4): 15:00:09  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.15s]
2022-01-06 15:00:09.549442 (Thread-4): 15:00:09  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 15:00:09.550869 (MainThread): 15:00:09  Acquiring new redshift connection "master"
2022-01-06 15:00:09.551079 (MainThread): 15:00:09  Using redshift connection "master"
2022-01-06 15:00:09.551209 (MainThread): 15:00:09  On master: BEGIN
2022-01-06 15:00:09.551344 (MainThread): 15:00:09  Opening a new connection, currently in state closed
2022-01-06 15:00:09.551472 (MainThread): 15:00:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:00:09.576294 (MainThread): 15:00:09  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:00:09.576470 (MainThread): 15:00:09  On master: COMMIT
2022-01-06 15:00:09.576608 (MainThread): 15:00:09  Using redshift connection "master"
2022-01-06 15:00:09.576737 (MainThread): 15:00:09  On master: COMMIT
2022-01-06 15:00:09.578488 (MainThread): 15:00:09  SQL status: COMMIT in 0.0 seconds
2022-01-06 15:00:09.578622 (MainThread): 15:00:09  On master: Close
2022-01-06 15:00:09.579164 (MainThread): 15:00:09  
2022-01-06 15:00:09.579343 (MainThread): 15:00:09  Finished running 2 table models, 1 view model in 0.69s.
2022-01-06 15:00:09.579488 (MainThread): 15:00:09  Connection 'master' was properly closed.
2022-01-06 15:00:09.579611 (MainThread): 15:00:09  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 15:00:09.579727 (MainThread): 15:00:09  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 15:00:09.579846 (MainThread): 15:00:09  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 15:00:09.630770 (MainThread): 15:00:09  
2022-01-06 15:00:09.630925 (MainThread): 15:00:09  Completed successfully
2022-01-06 15:00:09.631022 (MainThread): 15:00:09  
2022-01-06 15:00:09.631107 (MainThread): 15:00:09  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 15:00:10.824228 (Thread-229): handling poll request
2022-01-06 15:00:10.824591 (Thread-229): 15:00:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781979a0>]}
2022-01-06 15:00:10.826658 (Thread-229): sending response (<Response 44729 bytes [200 OK]>) to 10.0.2.195
2022-01-06 15:00:11.444449 (Thread-230): handling status request
2022-01-06 15:00:11.444824 (Thread-230): 15:00:11  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78175cd0>]}
2022-01-06 15:00:11.445378 (Thread-230): sending response (<Response 1244 bytes [200 OK]>) to 10.0.38.111
2022-01-06 15:00:11.488988 (Thread-231): handling status request
2022-01-06 15:00:11.489451 (Thread-231): 15:00:11  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780c3fa0>]}
2022-01-06 15:00:11.489873 (Thread-231): sending response (<Response 1244 bytes [200 OK]>) to 10.0.26.129
2022-01-06 15:06:03.439462 (Thread-232): handling status request
2022-01-06 15:06:03.440876 (Thread-232): 15:06:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7817e7c0>]}
2022-01-06 15:06:03.441471 (Thread-232): sending response (<Response 1244 bytes [200 OK]>) to 10.0.35.75
2022-01-06 15:06:03.881969 (Thread-233): handling run_sql request
2022-01-06 15:06:03.882333 (Thread-233): 15:06:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7817e430>]}
2022-01-06 15:06:05.938796 (Thread-233): sending response (<Response 138 bytes [200 OK]>) to 10.0.1.95
2022-01-06 15:06:05.965849 (MainThread): 15:06:05  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3d452219-487a-4d9e-9df0-8c326bc8a838', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6327e4f5e0>]}
2022-01-06 15:06:05.966374 (MainThread): 15:06:05  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:06:05.966927 (Thread-1): 15:06:05  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:06:05.967056 (Thread-1): 15:06:05  Began compiling node rpc.my_new_project.request
2022-01-06 15:06:05.967147 (Thread-1): 15:06:05  Compiling rpc.my_new_project.request
2022-01-06 15:06:05.969712 (Thread-1): 15:06:05  finished collecting timing info
2022-01-06 15:06:05.969838 (Thread-1): 15:06:05  Began executing node rpc.my_new_project.request
2022-01-06 15:06:05.969933 (Thread-1): 15:06:05  Using redshift connection "rpc.my_new_project.request"
2022-01-06 15:06:05.970007 (Thread-1): 15:06:05  On rpc.my_new_project.request: 

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"

),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 15:06:05.970080 (Thread-1): 15:06:05  Opening a new connection, currently in state init
2022-01-06 15:06:05.970158 (Thread-1): 15:06:05  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:06:05.990923 (Thread-1): 15:06:05  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 15:06:05.991077 (Thread-1): 15:06:05  finished collecting timing info
2022-01-06 15:06:05.991225 (Thread-1): 15:06:05  On rpc.my_new_project.request: Close
2022-01-06 15:06:05.991510 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 15:06:05.992484 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\') }}\n\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\') }}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\') }}\n\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\') }}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 15:06:06.354164 (Thread-234): handling poll request
2022-01-06 15:06:06.354608 (Thread-234): 15:06:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7817c880>]}
2022-01-06 15:06:06.355464 (Thread-234): sending response (<Response 14749 bytes [200 OK]>) to 10.0.21.176
2022-01-06 15:08:40.670251 (Thread-235): handling status request
2022-01-06 15:08:40.671877 (Thread-235): 15:08:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78202ac0>]}
2022-01-06 15:08:40.672410 (Thread-235): sending response (<Response 1244 bytes [200 OK]>) to 10.0.16.124
2022-01-06 15:08:40.826472 (Thread-236): handling status request
2022-01-06 15:08:40.826835 (Thread-236): 15:08:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782d9bb0>]}
2022-01-06 15:08:40.827324 (Thread-236): sending response (<Response 1244 bytes [200 OK]>) to 10.0.25.31
2022-01-06 15:08:41.006239 (Thread-237): handling cli_args request
2022-01-06 15:08:41.006589 (Thread-237): 15:08:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff781f4760>]}
2022-01-06 15:08:43.148146 (Thread-237): sending response (<Response 138 bytes [200 OK]>) to 10.0.35.75
2022-01-06 15:08:43.238920 (MainThread): 15:08:43  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 15:08:43.239336 (MainThread): 15:08:43  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 15:08:43.245488 (MainThread): 15:08:43  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '32798e5e-98e3-4dd1-b6ad-f64eb3252b85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff93adaab50>]}
2022-01-06 15:08:43.273840 (MainThread): 15:08:43  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '32798e5e-98e3-4dd1-b6ad-f64eb3252b85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff93ae20bb0>]}
2022-01-06 15:08:43.274131 (MainThread): 15:08:43  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:08:43.274562 (MainThread): 15:08:43  The selection criterion 'stg_customers' does not match any nodes
2022-01-06 15:08:43.275295 (MainThread): 15:08:43  
2022-01-06 15:08:43.275448 (MainThread): 15:08:43  [WARNING]: Nothing to do. Try checking your model configs and model specification args
2022-01-06 15:08:43.477004 (Thread-238): handling poll request
2022-01-06 15:08:43.477488 (Thread-238): 15:08:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7806ab20>]}
2022-01-06 15:08:43.478353 (Thread-238): sending response (<Response 3246 bytes [200 OK]>) to 10.0.8.130
2022-01-06 15:08:44.104612 (Thread-239): handling status request
2022-01-06 15:08:44.104991 (Thread-239): 15:08:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7806aca0>]}
2022-01-06 15:08:44.105524 (Thread-239): sending response (<Response 1244 bytes [200 OK]>) to 10.0.2.195
2022-01-06 15:08:44.272743 (Thread-240): handling status request
2022-01-06 15:08:44.273156 (Thread-240): 15:08:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7806a880>]}
2022-01-06 15:08:44.273678 (Thread-240): sending response (<Response 1244 bytes [200 OK]>) to 10.0.14.136
2022-01-06 15:11:43.321316 (Thread-241): handling status request
2022-01-06 15:11:43.322546 (Thread-241): 15:11:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78071370>]}
2022-01-06 15:11:43.323012 (Thread-241): sending response (<Response 1244 bytes [200 OK]>) to 10.0.15.67
2022-01-06 15:11:43.648992 (Thread-242): handling run_sql request
2022-01-06 15:11:43.649764 (Thread-242): 15:11:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7806aa00>]}
2022-01-06 15:11:45.734843 (Thread-242): sending response (<Response 138 bytes [200 OK]>) to 10.0.1.95
2022-01-06 15:11:45.760490 (MainThread): 15:11:45  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '63393924-c513-4525-8fc9-1e44109645bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f77fa7505e0>]}
2022-01-06 15:11:45.761019 (MainThread): 15:11:45  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:11:45.761697 (Thread-1): 15:11:45  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:11:45.761823 (Thread-1): 15:11:45  Began compiling node rpc.my_new_project.request
2022-01-06 15:11:45.761912 (Thread-1): 15:11:45  Compiling rpc.my_new_project.request
2022-01-06 15:11:45.763079 (Thread-1): 15:11:45  finished collecting timing info
2022-01-06 15:11:45.763203 (Thread-1): 15:11:45  Began executing node rpc.my_new_project.request
2022-01-06 15:11:45.763299 (Thread-1): 15:11:45  Using redshift connection "rpc.my_new_project.request"
2022-01-06 15:11:45.763380 (Thread-1): 15:11:45  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from dev.jaffle_shop.customers

)
select * from customers
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 15:11:45.763455 (Thread-1): 15:11:45  Opening a new connection, currently in state init
2022-01-06 15:11:45.763540 (Thread-1): 15:11:45  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:11:45.785093 (Thread-1): 15:11:45  SQL status: SELECT in 0.02 seconds
2022-01-06 15:11:45.786943 (Thread-1): 15:11:45  finished collecting timing info
2022-01-06 15:11:45.787095 (Thread-1): 15:11:45  On rpc.my_new_project.request: Close
2022-01-06 15:11:46.040927 (Thread-243): handling poll request
2022-01-06 15:11:46.041391 (Thread-243): 15:11:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78071670>]}
2022-01-06 15:11:46.042690 (Thread-243): sending response (<Response 10172 bytes [200 OK]>) to 10.0.2.195
2022-01-06 15:12:17.784982 (Thread-244): handling status request
2022-01-06 15:12:17.785431 (Thread-244): 15:12:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78071760>]}
2022-01-06 15:12:17.785959 (Thread-244): sending response (<Response 1244 bytes [200 OK]>) to 10.0.19.29
2022-01-06 15:12:18.152900 (Thread-245): handling run_sql request
2022-01-06 15:12:18.153342 (Thread-245): 15:12:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780c12e0>]}
2022-01-06 15:12:20.193071 (Thread-245): sending response (<Response 138 bytes [200 OK]>) to 10.0.19.29
2022-01-06 15:12:20.218030 (MainThread): 15:12:20  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '57683671-5bb0-49fd-be22-0cee9758070e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d8d302e50>]}
2022-01-06 15:12:20.218557 (MainThread): 15:12:20  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:12:20.219127 (Thread-1): 15:12:20  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:12:20.219259 (Thread-1): 15:12:20  Began compiling node rpc.my_new_project.request
2022-01-06 15:12:20.219366 (Thread-1): 15:12:20  Compiling rpc.my_new_project.request
2022-01-06 15:12:20.221903 (Thread-1): 15:12:20  finished collecting timing info
2022-01-06 15:12:20.222032 (Thread-1): 15:12:20  Began executing node rpc.my_new_project.request
2022-01-06 15:12:20.222130 (Thread-1): 15:12:20  Using redshift connection "rpc.my_new_project.request"
2022-01-06 15:12:20.222206 (Thread-1): 15:12:20  On rpc.my_new_project.request: 

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"

),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 15:12:20.222281 (Thread-1): 15:12:20  Opening a new connection, currently in state init
2022-01-06 15:12:20.222359 (Thread-1): 15:12:20  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:12:20.244973 (Thread-1): 15:12:20  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 15:12:20.245132 (Thread-1): 15:12:20  finished collecting timing info
2022-01-06 15:12:20.245281 (Thread-1): 15:12:20  On rpc.my_new_project.request: Close
2022-01-06 15:12:20.245545 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 15:12:20.246502 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\') }}\n\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\') }}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\') }}\n\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\') }}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 15:12:20.572103 (Thread-246): handling poll request
2022-01-06 15:12:20.572546 (Thread-246): 15:12:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7807bd60>]}
2022-01-06 15:12:20.599660 (Thread-246): sending response (<Response 14749 bytes [200 OK]>) to 10.0.35.75
2022-01-06 15:12:26.629345 (Thread-247): handling status request
2022-01-06 15:12:26.629715 (Thread-247): 15:12:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7806a940>]}
2022-01-06 15:12:26.630242 (Thread-247): sending response (<Response 1244 bytes [200 OK]>) to 10.0.26.21
2022-01-06 15:12:27.035450 (Thread-248): handling run_sql request
2022-01-06 15:12:27.035798 (Thread-248): 15:12:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780864c0>]}
2022-01-06 15:12:29.081941 (Thread-248): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.21
2022-01-06 15:12:29.106801 (MainThread): 15:12:29  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4cfe5a91-79b0-4d7a-9074-23340aded86f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e6a0bd130>]}
2022-01-06 15:12:29.107330 (MainThread): 15:12:29  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:12:29.107903 (Thread-1): 15:12:29  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:12:29.108033 (Thread-1): 15:12:29  Began compiling node rpc.my_new_project.request
2022-01-06 15:12:29.108122 (Thread-1): 15:12:29  Compiling rpc.my_new_project.request
2022-01-06 15:12:29.110618 (Thread-1): 15:12:29  finished collecting timing info
2022-01-06 15:12:29.110741 (Thread-1): 15:12:29  Began executing node rpc.my_new_project.request
2022-01-06 15:12:29.110837 (Thread-1): 15:12:29  Using redshift connection "rpc.my_new_project.request"
2022-01-06 15:12:29.110910 (Thread-1): 15:12:29  On rpc.my_new_project.request: 

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"

),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 15:12:29.110985 (Thread-1): 15:12:29  Opening a new connection, currently in state init
2022-01-06 15:12:29.111063 (Thread-1): 15:12:29  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:12:29.131597 (Thread-1): 15:12:29  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 15:12:29.131751 (Thread-1): 15:12:29  finished collecting timing info
2022-01-06 15:12:29.131862 (Thread-1): 15:12:29  On rpc.my_new_project.request: Close
2022-01-06 15:12:29.132077 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 15:12:29.133012 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\') }}\n\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\') }}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\') }}\n\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\') }}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 15:12:29.467107 (Thread-249): handling poll request
2022-01-06 15:12:29.467538 (Thread-249): 15:12:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780895e0>]}
2022-01-06 15:12:29.468463 (Thread-249): sending response (<Response 14749 bytes [200 OK]>) to 10.0.35.205
2022-01-06 15:12:31.677811 (Thread-250): handling status request
2022-01-06 15:12:31.678186 (Thread-250): 15:12:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78089af0>]}
2022-01-06 15:12:31.678714 (Thread-250): sending response (<Response 1244 bytes [200 OK]>) to 10.0.1.95
2022-01-06 15:12:32.086342 (Thread-251): handling compile_sql request
2022-01-06 15:12:32.086740 (Thread-251): 15:12:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78089df0>]}
2022-01-06 15:12:34.121207 (Thread-251): sending response (<Response 138 bytes [200 OK]>) to 10.0.40.39
2022-01-06 15:12:34.145804 (MainThread): 15:12:34  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1d8aa6b0-062d-4d99-ba07-bd6b27d57af4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe74724d100>]}
2022-01-06 15:12:34.146306 (MainThread): 15:12:34  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:12:34.146843 (Thread-1): 15:12:34  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:12:34.146971 (Thread-1): 15:12:34  Began compiling node rpc.my_new_project.request
2022-01-06 15:12:34.147070 (Thread-1): 15:12:34  Compiling rpc.my_new_project.request
2022-01-06 15:12:34.149697 (Thread-1): 15:12:34  finished collecting timing info
2022-01-06 15:12:34.149885 (Thread-1): 15:12:34  Began executing node rpc.my_new_project.request
2022-01-06 15:12:34.150035 (Thread-1): 15:12:34  finished collecting timing info
2022-01-06 15:12:34.588186 (Thread-252): handling poll request
2022-01-06 15:12:34.588628 (Thread-252): 15:12:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780a10a0>]}
2022-01-06 15:12:34.589787 (Thread-252): sending response (<Response 8504 bytes [200 OK]>) to 10.0.26.21
2022-01-06 15:13:05.146440 (Thread-253): handling status request
2022-01-06 15:13:05.146828 (Thread-253): 15:13:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780a1250>]}
2022-01-06 15:13:05.147375 (Thread-253): sending response (<Response 1244 bytes [200 OK]>) to 10.0.32.116
2022-01-06 15:13:05.334471 (Thread-254): handling status request
2022-01-06 15:13:05.334766 (Thread-254): 15:13:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780a1640>]}
2022-01-06 15:13:05.335192 (Thread-254): sending response (<Response 1244 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:13:05.477317 (Thread-255): handling cli_args request
2022-01-06 15:13:05.477659 (Thread-255): 15:13:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780a1880>]}
2022-01-06 15:13:07.529369 (Thread-255): sending response (<Response 138 bytes [200 OK]>) to 10.0.23.79
2022-01-06 15:13:07.617389 (MainThread): 15:13:07  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 15:13:07.617770 (MainThread): 15:13:07  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 15:13:07.623309 (MainThread): 15:13:07  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b5717dd3-ae14-4ff1-b96d-4e30746b43c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0e3502bb50>]}
2022-01-06 15:13:07.650737 (MainThread): 15:13:07  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b5717dd3-ae14-4ff1-b96d-4e30746b43c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0e350a1bb0>]}
2022-01-06 15:13:07.650980 (MainThread): 15:13:07  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:13:07.652043 (MainThread): 15:13:07  
2022-01-06 15:13:07.652313 (MainThread): 15:13:07  Acquiring new redshift connection "master"
2022-01-06 15:13:07.653283 (ThreadPoolExecutor-0_0): 15:13:07  Acquiring new redshift connection "list_dev"
2022-01-06 15:13:07.663092 (ThreadPoolExecutor-0_0): 15:13:07  Using redshift connection "list_dev"
2022-01-06 15:13:07.663207 (ThreadPoolExecutor-0_0): 15:13:07  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 15:13:07.663291 (ThreadPoolExecutor-0_0): 15:13:07  Opening a new connection, currently in state init
2022-01-06 15:13:07.663372 (ThreadPoolExecutor-0_0): 15:13:07  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:13:07.683946 (ThreadPoolExecutor-0_0): 15:13:07  SQL status: SELECT in 0.02 seconds
2022-01-06 15:13:07.684971 (ThreadPoolExecutor-0_0): 15:13:07  On list_dev: Close
2022-01-06 15:13:07.686119 (ThreadPoolExecutor-1_0): 15:13:07  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:13:07.692543 (ThreadPoolExecutor-1_0): 15:13:07  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:13:07.692642 (ThreadPoolExecutor-1_0): 15:13:07  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 15:13:07.692721 (ThreadPoolExecutor-1_0): 15:13:07  Opening a new connection, currently in state closed
2022-01-06 15:13:07.692796 (ThreadPoolExecutor-1_0): 15:13:07  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:13:07.714909 (ThreadPoolExecutor-1_0): 15:13:07  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:13:07.715019 (ThreadPoolExecutor-1_0): 15:13:07  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:13:07.715093 (ThreadPoolExecutor-1_0): 15:13:07  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 15:13:07.726326 (ThreadPoolExecutor-1_0): 15:13:07  SQL status: SELECT in 0.01 seconds
2022-01-06 15:13:07.727320 (ThreadPoolExecutor-1_0): 15:13:07  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 15:13:07.729143 (ThreadPoolExecutor-1_0): 15:13:07  On list_dev_dbt_nobodozie: Close
2022-01-06 15:13:07.732719 (MainThread): 15:13:07  Using redshift connection "master"
2022-01-06 15:13:07.732830 (MainThread): 15:13:07  On master: BEGIN
2022-01-06 15:13:07.732910 (MainThread): 15:13:07  Opening a new connection, currently in state init
2022-01-06 15:13:07.732984 (MainThread): 15:13:07  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:13:07.757122 (MainThread): 15:13:07  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:13:07.757270 (MainThread): 15:13:07  Using redshift connection "master"
2022-01-06 15:13:07.757357 (MainThread): 15:13:07  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 15:13:07.786103 (MainThread): 15:13:07  SQL status: SELECT in 0.03 seconds
2022-01-06 15:13:07.787061 (MainThread): 15:13:07  On master: ROLLBACK
2022-01-06 15:13:07.788952 (MainThread): 15:13:07  Using redshift connection "master"
2022-01-06 15:13:07.789051 (MainThread): 15:13:07  On master: BEGIN
2022-01-06 15:13:07.792682 (MainThread): 15:13:07  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:13:07.792793 (MainThread): 15:13:07  On master: COMMIT
2022-01-06 15:13:07.792862 (MainThread): 15:13:07  Using redshift connection "master"
2022-01-06 15:13:07.792928 (MainThread): 15:13:07  On master: COMMIT
2022-01-06 15:13:07.794699 (MainThread): 15:13:07  SQL status: COMMIT in 0.0 seconds
2022-01-06 15:13:07.794809 (MainThread): 15:13:07  On master: Close
2022-01-06 15:13:07.795186 (MainThread): 15:13:07  Concurrency: 4 threads (target='default')
2022-01-06 15:13:07.795298 (MainThread): 15:13:07  
2022-01-06 15:13:07.797500 (Thread-1): 15:13:07  Began running node model.my_new_project.dim_customers
2022-01-06 15:13:07.797731 (Thread-1): 15:13:07  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 15:13:07.797958 (Thread-1): 15:13:07  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:13:07.798048 (Thread-1): 15:13:07  Began compiling node model.my_new_project.dim_customers
2022-01-06 15:13:07.798142 (Thread-1): 15:13:07  Compiling model.my_new_project.dim_customers
2022-01-06 15:13:07.800154 (Thread-1): 15:13:07  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 15:13:07.800373 (Thread-2): 15:13:07  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 15:13:07.800594 (Thread-2): 15:13:07  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 15:13:07.800837 (Thread-2): 15:13:07  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:13:07.800920 (Thread-2): 15:13:07  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 15:13:07.800998 (Thread-2): 15:13:07  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 15:13:07.803037 (Thread-2): 15:13:07  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 15:13:07.815776 (Thread-1): 15:13:07  finished collecting timing info
2022-01-06 15:13:07.815913 (Thread-1): 15:13:07  Began executing node model.my_new_project.dim_customers
2022-01-06 15:13:07.821118 (Thread-2): 15:13:07  finished collecting timing info
2022-01-06 15:13:07.821274 (Thread-2): 15:13:07  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 15:13:07.870556 (Thread-2): 15:13:07  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 15:13:07.873064 (Thread-1): 15:13:07  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 15:13:07.887346 (Thread-1): 15:13:07  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:13:07.887452 (Thread-1): 15:13:07  On model.my_new_project.dim_customers: BEGIN
2022-01-06 15:13:07.887534 (Thread-1): 15:13:07  Opening a new connection, currently in state closed
2022-01-06 15:13:07.887614 (Thread-1): 15:13:07  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:13:07.887939 (Thread-2): 15:13:07  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:13:07.888041 (Thread-2): 15:13:07  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:13:07.888122 (Thread-2): 15:13:07  Opening a new connection, currently in state init
2022-01-06 15:13:07.888198 (Thread-2): 15:13:07  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:13:07.983678 (Thread-1): 15:13:07  SQL status: BEGIN in 0.1 seconds
2022-01-06 15:13:07.983831 (Thread-1): 15:13:07  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:13:07.983913 (Thread-1): 15:13:07  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 15:13:07.984650 (Thread-2): 15:13:07  SQL status: BEGIN in 0.1 seconds
2022-01-06 15:13:07.984786 (Thread-2): 15:13:07  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:13:07.984866 (Thread-2): 15:13:07  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 15:13:07.986801 (Thread-256): handling poll request
2022-01-06 15:13:07.987203 (Thread-256): 15:13:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78015c40>]}
2022-01-06 15:13:07.988687 (Thread-256): sending response (<Response 30644 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:13:08.074618 (Thread-2): 15:13:08  SQL status: SELECT in 0.09 seconds
2022-01-06 15:13:08.080920 (Thread-2): 15:13:08  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:13:08.081047 (Thread-2): 15:13:08  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 15:13:08.084144 (Thread-2): 15:13:08  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:13:08.086001 (Thread-2): 15:13:08  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:13:08.086102 (Thread-2): 15:13:08  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 15:13:08.089252 (Thread-2): 15:13:08  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:13:08.099451 (Thread-2): 15:13:08  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:13:08.099632 (Thread-2): 15:13:08  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:13:08.099713 (Thread-2): 15:13:08  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:13:08.099875 (Thread-1): 15:13:08  SQL status: SELECT in 0.12 seconds
2022-01-06 15:13:08.102681 (Thread-1): 15:13:08  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:13:08.102778 (Thread-1): 15:13:08  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 15:13:08.108471 (Thread-1): 15:13:08  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 15:13:08.110110 (Thread-1): 15:13:08  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:13:08.110203 (Thread-1): 15:13:08  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 15:13:08.113728 (Thread-1): 15:13:08  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:13:08.114786 (Thread-1): 15:13:08  On model.my_new_project.dim_customers: COMMIT
2022-01-06 15:13:08.114881 (Thread-1): 15:13:08  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:13:08.114952 (Thread-1): 15:13:08  On model.my_new_project.dim_customers: COMMIT
2022-01-06 15:13:08.160879 (Thread-2): 15:13:08  SQL status: COMMIT in 0.06 seconds
2022-01-06 15:13:08.161095 (Thread-2): 15:13:08  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:13:08.161175 (Thread-2): 15:13:08  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:13:08.161439 (Thread-1): 15:13:08  SQL status: COMMIT in 0.05 seconds
2022-01-06 15:13:08.163368 (Thread-2): 15:13:08  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:13:08.167361 (Thread-2): 15:13:08  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:13:08.167458 (Thread-2): 15:13:08  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 15:13:08.172469 (Thread-2): 15:13:08  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 15:13:08.173079 (Thread-2): 15:13:08  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:13:08.173172 (Thread-2): 15:13:08  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:13:08.173276 (Thread-2): 15:13:08  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:13:08.203081 (Thread-2): 15:13:08  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:13:08.203193 (Thread-2): 15:13:08  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:13:08.203264 (Thread-2): 15:13:08  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:13:08.205327 (Thread-2): 15:13:08  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:13:08.205712 (Thread-2): 15:13:08  finished collecting timing info
2022-01-06 15:13:08.205839 (Thread-2): 15:13:08  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 15:13:08.206056 (Thread-1): 15:13:08  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:13:08.206164 (Thread-1): 15:13:08  On model.my_new_project.dim_customers: BEGIN
2022-01-06 15:13:08.208645 (Thread-1): 15:13:08  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:13:08.209877 (Thread-1): 15:13:08  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:13:08.209970 (Thread-1): 15:13:08  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 15:13:08.210191 (Thread-2): 15:13:08  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 15:13:08.210661 (Thread-2): 15:13:08  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5717dd3-ae14-4ff1-b96d-4e30746b43c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0e3476fa60>]}
2022-01-06 15:13:08.211038 (Thread-2): 15:13:08  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.41s]
2022-01-06 15:13:08.211157 (Thread-2): 15:13:08  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 15:13:08.211669 (Thread-4): 15:13:08  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 15:13:08.211907 (Thread-4): 15:13:08  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 15:13:08.212161 (Thread-4): 15:13:08  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:13:08.212251 (Thread-4): 15:13:08  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 15:13:08.212336 (Thread-4): 15:13:08  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 15:13:08.215293 (Thread-4): 15:13:08  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 15:13:08.216078 (Thread-1): 15:13:08  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 15:13:08.216702 (Thread-1): 15:13:08  On model.my_new_project.dim_customers: COMMIT
2022-01-06 15:13:08.216798 (Thread-1): 15:13:08  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:13:08.216873 (Thread-1): 15:13:08  On model.my_new_project.dim_customers: COMMIT
2022-01-06 15:13:08.228283 (Thread-4): 15:13:08  finished collecting timing info
2022-01-06 15:13:08.228498 (Thread-4): 15:13:08  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 15:13:08.249816 (Thread-4): 15:13:08  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 15:13:08.250065 (Thread-1): 15:13:08  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:13:08.250178 (Thread-1): 15:13:08  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:13:08.250252 (Thread-1): 15:13:08  On model.my_new_project.dim_customers: BEGIN
2022-01-06 15:13:08.252360 (Thread-1): 15:13:08  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:13:08.252763 (Thread-1): 15:13:08  finished collecting timing info
2022-01-06 15:13:08.252956 (Thread-1): 15:13:08  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 15:13:08.254735 (Thread-1): 15:13:08  On model.my_new_project.dim_customers: Close
2022-01-06 15:13:08.255164 (Thread-1): 15:13:08  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5717dd3-ae14-4ff1-b96d-4e30746b43c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0e347792b0>]}
2022-01-06 15:13:08.255465 (Thread-1): 15:13:08  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.46s]
2022-01-06 15:13:08.255570 (Thread-1): 15:13:08  Finished running node model.my_new_project.dim_customers
2022-01-06 15:13:08.264700 (Thread-4): 15:13:08  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:13:08.264809 (Thread-4): 15:13:08  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:13:08.264893 (Thread-4): 15:13:08  Opening a new connection, currently in state init
2022-01-06 15:13:08.264973 (Thread-4): 15:13:08  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:13:08.285693 (Thread-4): 15:13:08  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:13:08.285806 (Thread-4): 15:13:08  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:13:08.285881 (Thread-4): 15:13:08  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 15:13:08.290756 (Thread-4): 15:13:08  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 15:13:08.292610 (Thread-4): 15:13:08  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:13:08.292704 (Thread-4): 15:13:08  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 15:13:08.294888 (Thread-4): 15:13:08  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:13:08.295831 (Thread-4): 15:13:08  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:13:08.295926 (Thread-4): 15:13:08  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:13:08.295998 (Thread-4): 15:13:08  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:13:08.325873 (Thread-4): 15:13:08  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:13:08.326117 (Thread-4): 15:13:08  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:13:08.326202 (Thread-4): 15:13:08  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:13:08.328425 (Thread-4): 15:13:08  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:13:08.330474 (Thread-4): 15:13:08  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:13:08.330613 (Thread-4): 15:13:08  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 15:13:08.332585 (Thread-4): 15:13:08  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 15:13:08.333316 (Thread-4): 15:13:08  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:13:08.333411 (Thread-4): 15:13:08  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:13:08.333484 (Thread-4): 15:13:08  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:13:08.358004 (Thread-4): 15:13:08  SQL status: COMMIT in 0.02 seconds
2022-01-06 15:13:08.358120 (Thread-4): 15:13:08  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:13:08.358194 (Thread-4): 15:13:08  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:13:08.360226 (Thread-4): 15:13:08  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:13:08.360620 (Thread-4): 15:13:08  finished collecting timing info
2022-01-06 15:13:08.360745 (Thread-4): 15:13:08  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 15:13:08.362452 (Thread-4): 15:13:08  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 15:13:08.362915 (Thread-4): 15:13:08  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5717dd3-ae14-4ff1-b96d-4e30746b43c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0e347e28e0>]}
2022-01-06 15:13:08.363218 (Thread-4): 15:13:08  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.15s]
2022-01-06 15:13:08.363328 (Thread-4): 15:13:08  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 15:13:08.364777 (MainThread): 15:13:08  Acquiring new redshift connection "master"
2022-01-06 15:13:08.364917 (MainThread): 15:13:08  Using redshift connection "master"
2022-01-06 15:13:08.364993 (MainThread): 15:13:08  On master: BEGIN
2022-01-06 15:13:08.365086 (MainThread): 15:13:08  Opening a new connection, currently in state closed
2022-01-06 15:13:08.365187 (MainThread): 15:13:08  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:13:08.389197 (MainThread): 15:13:08  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:13:08.389343 (MainThread): 15:13:08  On master: COMMIT
2022-01-06 15:13:08.389418 (MainThread): 15:13:08  Using redshift connection "master"
2022-01-06 15:13:08.389488 (MainThread): 15:13:08  On master: COMMIT
2022-01-06 15:13:08.391277 (MainThread): 15:13:08  SQL status: COMMIT in 0.0 seconds
2022-01-06 15:13:08.391380 (MainThread): 15:13:08  On master: Close
2022-01-06 15:13:08.391774 (MainThread): 15:13:08  
2022-01-06 15:13:08.391887 (MainThread): 15:13:08  Finished running 2 table models, 1 view model in 0.74s.
2022-01-06 15:13:08.391967 (MainThread): 15:13:08  Connection 'master' was properly closed.
2022-01-06 15:13:08.392033 (MainThread): 15:13:08  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 15:13:08.392125 (MainThread): 15:13:08  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 15:13:08.392188 (MainThread): 15:13:08  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 15:13:08.439646 (MainThread): 15:13:08  
2022-01-06 15:13:08.439801 (MainThread): 15:13:08  Completed successfully
2022-01-06 15:13:08.439900 (MainThread): 15:13:08  
2022-01-06 15:13:08.439987 (MainThread): 15:13:08  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 15:13:09.376148 (Thread-257): handling poll request
2022-01-06 15:13:09.376528 (Thread-257): 15:13:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfcfa30>]}
2022-01-06 15:13:09.378578 (Thread-257): sending response (<Response 56749 bytes [200 OK]>) to 10.0.26.21
2022-01-06 15:13:10.216398 (Thread-258): handling status request
2022-01-06 15:13:10.216765 (Thread-258): 15:13:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfcfbe0>]}
2022-01-06 15:13:10.217317 (Thread-258): sending response (<Response 1244 bytes [200 OK]>) to 10.0.32.116
2022-01-06 15:13:10.276916 (Thread-259): handling status request
2022-01-06 15:13:10.277196 (Thread-259): 15:13:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfcffa0>]}
2022-01-06 15:13:10.277597 (Thread-259): sending response (<Response 1244 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:16:15.208257 (Thread-260): handling status request
2022-01-06 15:16:15.208619 (Thread-260): 15:16:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfe31c0>]}
2022-01-06 15:16:15.209080 (Thread-260): sending response (<Response 1244 bytes [200 OK]>) to 10.0.2.97
2022-01-06 15:16:15.214406 (Thread-261): handling status request
2022-01-06 15:16:15.214648 (Thread-261): 15:16:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfe34c0>]}
2022-01-06 15:16:15.214994 (Thread-261): sending response (<Response 1244 bytes [200 OK]>) to 10.0.15.56
2022-01-06 15:16:15.333642 (Thread-262): handling ps request
2022-01-06 15:16:15.333903 (Thread-262): 15:16:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfe3730>]}
2022-01-06 15:16:15.335687 (Thread-262): sending response (<Response 21009 bytes [200 OK]>) to 10.0.29.240
2022-01-06 15:16:15.343715 (Thread-263): handling status request
2022-01-06 15:16:15.343939 (Thread-263): 15:16:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfe3a00>]}
2022-01-06 15:16:15.344266 (Thread-263): sending response (<Response 1244 bytes [200 OK]>) to 10.0.16.103
2022-01-06 15:16:16.555724 (Thread-264): handling poll request
2022-01-06 15:16:16.556102 (Thread-264): 15:16:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfe3d00>]}
2022-01-06 15:16:16.558685 (Thread-264): sending response (<Response 87109 bytes [200 OK]>) to 10.0.45.144
2022-01-06 15:16:17.196759 (Thread-265): handling status request
2022-01-06 15:16:17.197132 (Thread-265): 15:16:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfcfc10>]}
2022-01-06 15:16:17.197628 (Thread-265): sending response (<Response 1244 bytes [200 OK]>) to 10.0.0.136
2022-01-06 15:16:17.234894 (Thread-266): handling status request
2022-01-06 15:16:17.235192 (Thread-266): 15:16:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfc3be0>]}
2022-01-06 15:16:17.235560 (Thread-266): sending response (<Response 1244 bytes [200 OK]>) to 10.0.30.119
2022-01-06 15:16:54.698947 (Thread-267): handling status request
2022-01-06 15:16:54.699316 (Thread-267): 15:16:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfe3d60>]}
2022-01-06 15:16:54.699774 (Thread-267): sending response (<Response 1244 bytes [200 OK]>) to 10.0.10.175
2022-01-06 15:16:55.160528 (Thread-268): handling run_sql request
2022-01-06 15:16:55.160892 (Thread-268): 15:16:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfe37f0>]}
2022-01-06 15:16:57.225690 (Thread-268): sending response (<Response 138 bytes [200 OK]>) to 10.0.15.56
2022-01-06 15:16:57.250311 (MainThread): 15:16:57  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2616bf8c-91d9-4477-99d5-9f6339867f73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb718ea160>]}
2022-01-06 15:16:57.250833 (MainThread): 15:16:57  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:16:57.251405 (Thread-1): 15:16:57  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:16:57.251536 (Thread-1): 15:16:57  Began compiling node rpc.my_new_project.request
2022-01-06 15:16:57.251626 (Thread-1): 15:16:57  Compiling rpc.my_new_project.request
2022-01-06 15:16:57.253936 (Thread-1): 15:16:57  finished collecting timing info
2022-01-06 15:16:57.254063 (Thread-1): 15:16:57  Began executing node rpc.my_new_project.request
2022-01-06 15:16:57.254159 (Thread-1): 15:16:57  Using redshift connection "rpc.my_new_project.request"
2022-01-06 15:16:57.254232 (Thread-1): 15:16:57  On rpc.my_new_project.request: with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"

),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 15:16:57.254308 (Thread-1): 15:16:57  Opening a new connection, currently in state init
2022-01-06 15:16:57.254386 (Thread-1): 15:16:57  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:16:57.275198 (Thread-1): 15:16:57  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 15:16:57.275352 (Thread-1): 15:16:57  finished collecting timing info
2022-01-06 15:16:57.275466 (Thread-1): 15:16:57  On rpc.my_new_project.request: Close
2022-01-06 15:16:57.275644 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 15:16:57.276713 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': "with customers as (\n\n    select * from {{ ref('stg_customers') }}\n\n),\n\norders as (\n\n    select * from {{ ref('stg_orders') }}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': "with customers as (\n\n    select * from {{ ref('stg_customers') }}\n\n),\n\norders as (\n\n    select * from {{ ref('stg_orders') }}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 15:16:57.603037 (Thread-269): handling poll request
2022-01-06 15:16:57.603515 (Thread-269): 15:16:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfd9cd0>]}
2022-01-06 15:16:57.604364 (Thread-269): sending response (<Response 14565 bytes [200 OK]>) to 10.0.21.24
2022-01-06 15:18:47.468047 (Thread-270): handling status request
2022-01-06 15:18:47.469998 (Thread-270): 15:18:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfeb220>]}
2022-01-06 15:18:47.470512 (Thread-270): sending response (<Response 1244 bytes [200 OK]>) to 10.0.41.69
2022-01-06 15:18:47.881738 (Thread-271): handling run_sql request
2022-01-06 15:18:47.882109 (Thread-271): 15:18:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfeb520>]}
2022-01-06 15:18:49.943452 (Thread-271): sending response (<Response 138 bytes [200 OK]>) to 10.0.29.240
2022-01-06 15:18:49.971026 (MainThread): 15:18:49  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca58a801-4ae6-44cc-9c0d-21deae6eb91c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa24a1613d0>]}
2022-01-06 15:18:49.971533 (MainThread): 15:18:49  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:18:49.972083 (Thread-1): 15:18:49  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:18:49.972213 (Thread-1): 15:18:49  Began compiling node rpc.my_new_project.request
2022-01-06 15:18:49.972302 (Thread-1): 15:18:49  Compiling rpc.my_new_project.request
2022-01-06 15:18:49.974602 (Thread-1): 15:18:49  finished collecting timing info
2022-01-06 15:18:49.974727 (Thread-1): 15:18:49  Began executing node rpc.my_new_project.request
2022-01-06 15:18:49.974821 (Thread-1): 15:18:49  Using redshift connection "rpc.my_new_project.request"
2022-01-06 15:18:49.974894 (Thread-1): 15:18:49  On rpc.my_new_project.request: with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"

),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 15:18:49.974969 (Thread-1): 15:18:49  Opening a new connection, currently in state init
2022-01-06 15:18:49.975044 (Thread-1): 15:18:49  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:18:49.995383 (Thread-1): 15:18:49  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 15:18:49.995538 (Thread-1): 15:18:49  finished collecting timing info
2022-01-06 15:18:49.995652 (Thread-1): 15:18:49  On rpc.my_new_project.request: Close
2022-01-06 15:18:49.995879 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 15:18:49.996839 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': "with customers as (\n\n    select * from {{ ref('stg_customers')}}\n\n),\n\norders as (\n\n    select * from {{ ref('stg_orders') }}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': "with customers as (\n\n    select * from {{ ref('stg_customers')}}\n\n),\n\norders as (\n\n    select * from {{ ref('stg_orders') }}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 15:18:50.322311 (Thread-272): handling poll request
2022-01-06 15:18:50.322778 (Thread-272): 15:18:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bff1790>]}
2022-01-06 15:18:50.323614 (Thread-272): sending response (<Response 14562 bytes [200 OK]>) to 10.0.10.175
2022-01-06 15:19:15.692197 (Thread-273): handling status request
2022-01-06 15:19:15.692591 (Thread-273): 15:19:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfeb940>]}
2022-01-06 15:19:15.693116 (Thread-273): sending response (<Response 1244 bytes [200 OK]>) to 10.0.4.41
2022-01-06 15:19:16.051642 (Thread-274): handling run_sql request
2022-01-06 15:19:16.052023 (Thread-274): 15:19:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfcf9d0>]}
2022-01-06 15:19:18.090853 (Thread-274): sending response (<Response 138 bytes [200 OK]>) to 10.0.21.24
2022-01-06 15:19:18.105111 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/task_handler.py", line 102, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 164, in handle_request
    node = self._get_exec_node()
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 124, in _get_exec_node
    rpc_node = rpc_parser.parse_remote(sql, self.args.name)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/parser/rpc.py", line 47, in parse_remote
    return self.parse_node(contents)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 401, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 376, in render_update
    context = self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/parser/base.py", line 267, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 597, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 548, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 3, in top-level template code
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/context/providers.py", line 248, in __call__
    self.validate_args(name, package)
  File "/usr/local/lib/python3.8/dist-packages/dbt/context/providers.py", line 227, in validate_args
    raise CompilationException(
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  The name argument to ref() must be a string, got <class 'dbt.clients.jinja.create_undefined.<locals>.Undefined'>
2022-01-06 15:19:18.499560 (Thread-275): handling poll request
2022-01-06 15:19:18.500055 (Thread-275): 15:19:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bffe370>]}
2022-01-06 15:19:18.500806 (Thread-275): sending response (<Response 4105 bytes [200 OK]>) to 10.0.26.175
2022-01-06 15:21:07.614864 (Thread-276): handling status request
2022-01-06 15:21:07.616539 (Thread-276): 15:21:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bffe880>]}
2022-01-06 15:21:07.641134 (Thread-276): sending response (<Response 1244 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:21:08.028318 (Thread-277): handling run_sql request
2022-01-06 15:21:08.028662 (Thread-277): 15:21:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bffefa0>]}
2022-01-06 15:21:10.089817 (Thread-277): sending response (<Response 138 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:21:10.116669 (MainThread): 15:21:10  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c28533d1-6699-41d4-8633-d2487cc7eec8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58e1ff53a0>]}
2022-01-06 15:21:10.117196 (MainThread): 15:21:10  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:21:10.117776 (Thread-1): 15:21:10  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:21:10.117903 (Thread-1): 15:21:10  Began compiling node rpc.my_new_project.request
2022-01-06 15:21:10.117989 (Thread-1): 15:21:10  Compiling rpc.my_new_project.request
2022-01-06 15:21:10.120252 (Thread-1): 15:21:10  finished collecting timing info
2022-01-06 15:21:10.120378 (Thread-1): 15:21:10  Began executing node rpc.my_new_project.request
2022-01-06 15:21:10.120471 (Thread-1): 15:21:10  Using redshift connection "rpc.my_new_project.request"
2022-01-06 15:21:10.120543 (Thread-1): 15:21:10  On rpc.my_new_project.request: with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"

),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 15:21:10.120617 (Thread-1): 15:21:10  Opening a new connection, currently in state init
2022-01-06 15:21:10.120691 (Thread-1): 15:21:10  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:21:10.158707 (Thread-1): 15:21:10  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 15:21:10.158860 (Thread-1): 15:21:10  finished collecting timing info
2022-01-06 15:21:10.158973 (Thread-1): 15:21:10  On rpc.my_new_project.request: Close
2022-01-06 15:21:10.159211 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 15:21:10.160162 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': "with customers as (\n\n    select * from {{ ref('stg_customers')}}\n\n),\n\norders as (\n\n    select * from {{ ref('stg_orders') }}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': "with customers as (\n\n    select * from {{ ref('stg_customers')}}\n\n),\n\norders as (\n\n    select * from {{ ref('stg_orders') }}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 15:21:10.513188 (Thread-278): handling poll request
2022-01-06 15:21:10.513681 (Thread-278): 15:21:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf90040>]}
2022-01-06 15:21:10.514536 (Thread-278): sending response (<Response 14562 bytes [200 OK]>) to 10.0.30.119
2022-01-06 15:21:42.295604 (Thread-279): handling status request
2022-01-06 15:21:42.295986 (Thread-279): 15:21:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf90550>]}
2022-01-06 15:21:42.296518 (Thread-279): sending response (<Response 1244 bytes [200 OK]>) to 10.0.23.79
2022-01-06 15:21:42.774974 (Thread-280): handling compile_sql request
2022-01-06 15:21:42.775341 (Thread-280): 15:21:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf90850>]}
2022-01-06 15:21:44.837719 (Thread-280): sending response (<Response 138 bytes [200 OK]>) to 10.0.10.175
2022-01-06 15:21:44.861073 (MainThread): 15:21:44  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6ebb997b-4c99-44e6-847a-891daa2cdeb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c18a84670>]}
2022-01-06 15:21:44.861603 (MainThread): 15:21:44  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:21:44.862166 (Thread-1): 15:21:44  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:21:44.862296 (Thread-1): 15:21:44  Began compiling node rpc.my_new_project.request
2022-01-06 15:21:44.862387 (Thread-1): 15:21:44  Compiling rpc.my_new_project.request
2022-01-06 15:21:44.863555 (Thread-1): 15:21:44  finished collecting timing info
2022-01-06 15:21:44.863681 (Thread-1): 15:21:44  Began executing node rpc.my_new_project.request
2022-01-06 15:21:44.863782 (Thread-1): 15:21:44  finished collecting timing info
2022-01-06 15:21:45.232813 (Thread-281): handling poll request
2022-01-06 15:21:45.233251 (Thread-281): 15:21:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7802bfd0>]}
2022-01-06 15:21:45.234309 (Thread-281): sending response (<Response 5760 bytes [200 OK]>) to 10.0.40.96
2022-01-06 15:21:49.565780 (Thread-282): handling status request
2022-01-06 15:21:49.566149 (Thread-282): 15:21:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7802b430>]}
2022-01-06 15:21:49.566651 (Thread-282): sending response (<Response 1244 bytes [200 OK]>) to 10.0.26.175
2022-01-06 15:21:49.757609 (Thread-283): handling status request
2022-01-06 15:21:49.757892 (Thread-283): 15:21:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7802bc10>]}
2022-01-06 15:21:49.758310 (Thread-283): sending response (<Response 1244 bytes [200 OK]>) to 10.0.23.79
2022-01-06 15:21:50.101340 (Thread-284): handling cli_args request
2022-01-06 15:21:50.101709 (Thread-284): 15:21:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78015190>]}
2022-01-06 15:21:52.160745 (Thread-284): sending response (<Response 138 bytes [200 OK]>) to 10.0.41.69
2022-01-06 15:21:52.252675 (MainThread): 15:21:52  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 15:21:52.253075 (MainThread): 15:21:52  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 15:21:52.258957 (MainThread): 15:21:52  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b7535b00-bcc9-4267-b811-1244f43b0361', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c9ed1b50>]}
2022-01-06 15:21:52.297059 (MainThread): 15:21:52  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b7535b00-bcc9-4267-b811-1244f43b0361', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c9f49bb0>]}
2022-01-06 15:21:52.297316 (MainThread): 15:21:52  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:21:52.298357 (MainThread): 15:21:52  
2022-01-06 15:21:52.298621 (MainThread): 15:21:52  Acquiring new redshift connection "master"
2022-01-06 15:21:52.299592 (ThreadPoolExecutor-0_0): 15:21:52  Acquiring new redshift connection "list_dev"
2022-01-06 15:21:52.309504 (ThreadPoolExecutor-0_0): 15:21:52  Using redshift connection "list_dev"
2022-01-06 15:21:52.309621 (ThreadPoolExecutor-0_0): 15:21:52  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 15:21:52.309704 (ThreadPoolExecutor-0_0): 15:21:52  Opening a new connection, currently in state init
2022-01-06 15:21:52.309786 (ThreadPoolExecutor-0_0): 15:21:52  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:21:52.330848 (ThreadPoolExecutor-0_0): 15:21:52  SQL status: SELECT in 0.02 seconds
2022-01-06 15:21:52.331929 (ThreadPoolExecutor-0_0): 15:21:52  On list_dev: Close
2022-01-06 15:21:52.333167 (ThreadPoolExecutor-1_0): 15:21:52  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:21:52.339976 (ThreadPoolExecutor-1_0): 15:21:52  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:21:52.340077 (ThreadPoolExecutor-1_0): 15:21:52  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 15:21:52.340158 (ThreadPoolExecutor-1_0): 15:21:52  Opening a new connection, currently in state closed
2022-01-06 15:21:52.340237 (ThreadPoolExecutor-1_0): 15:21:52  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:21:52.505760 (ThreadPoolExecutor-1_0): 15:21:52  SQL status: BEGIN in 0.17 seconds
2022-01-06 15:21:52.505925 (ThreadPoolExecutor-1_0): 15:21:52  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:21:52.506009 (ThreadPoolExecutor-1_0): 15:21:52  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 15:21:52.517123 (ThreadPoolExecutor-1_0): 15:21:52  SQL status: SELECT in 0.01 seconds
2022-01-06 15:21:52.518336 (ThreadPoolExecutor-1_0): 15:21:52  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 15:21:52.520267 (ThreadPoolExecutor-1_0): 15:21:52  On list_dev_dbt_nobodozie: Close
2022-01-06 15:21:52.524435 (MainThread): 15:21:52  Using redshift connection "master"
2022-01-06 15:21:52.524551 (MainThread): 15:21:52  On master: BEGIN
2022-01-06 15:21:52.524633 (MainThread): 15:21:52  Opening a new connection, currently in state init
2022-01-06 15:21:52.524713 (MainThread): 15:21:52  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:21:52.547262 (MainThread): 15:21:52  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:21:52.547371 (MainThread): 15:21:52  Using redshift connection "master"
2022-01-06 15:21:52.547446 (MainThread): 15:21:52  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 15:21:52.576174 (MainThread): 15:21:52  SQL status: SELECT in 0.03 seconds
2022-01-06 15:21:52.577263 (MainThread): 15:21:52  On master: ROLLBACK
2022-01-06 15:21:52.579138 (MainThread): 15:21:52  Using redshift connection "master"
2022-01-06 15:21:52.579245 (MainThread): 15:21:52  On master: BEGIN
2022-01-06 15:21:52.581672 (Thread-285): handling poll request
2022-01-06 15:21:52.582042 (Thread-285): 15:21:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78019910>]}
2022-01-06 15:21:52.583171 (Thread-285): sending response (<Response 14265 bytes [200 OK]>) to 10.0.41.69
2022-01-06 15:21:52.582712 (MainThread): 15:21:52  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:21:52.582829 (MainThread): 15:21:52  On master: COMMIT
2022-01-06 15:21:52.582903 (MainThread): 15:21:52  Using redshift connection "master"
2022-01-06 15:21:52.582973 (MainThread): 15:21:52  On master: COMMIT
2022-01-06 15:21:52.584653 (MainThread): 15:21:52  SQL status: COMMIT in 0.0 seconds
2022-01-06 15:21:52.584777 (MainThread): 15:21:52  On master: Close
2022-01-06 15:21:52.585331 (MainThread): 15:21:52  Concurrency: 4 threads (target='default')
2022-01-06 15:21:52.585484 (MainThread): 15:21:52  
2022-01-06 15:21:52.587934 (Thread-1): 15:21:52  Began running node model.my_new_project.dim_customers
2022-01-06 15:21:52.588198 (Thread-1): 15:21:52  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 15:21:52.588463 (Thread-1): 15:21:52  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:21:52.588559 (Thread-1): 15:21:52  Began compiling node model.my_new_project.dim_customers
2022-01-06 15:21:52.588653 (Thread-1): 15:21:52  Compiling model.my_new_project.dim_customers
2022-01-06 15:21:52.591057 (Thread-1): 15:21:52  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 15:21:52.591284 (Thread-2): 15:21:52  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 15:21:52.591509 (Thread-2): 15:21:52  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 15:21:52.591774 (Thread-2): 15:21:52  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:21:52.591863 (Thread-2): 15:21:52  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 15:21:52.591944 (Thread-2): 15:21:52  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 15:21:52.594079 (Thread-2): 15:21:52  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 15:21:52.611531 (Thread-1): 15:21:52  finished collecting timing info
2022-01-06 15:21:52.611668 (Thread-1): 15:21:52  Began executing node model.my_new_project.dim_customers
2022-01-06 15:21:52.616876 (Thread-2): 15:21:52  finished collecting timing info
2022-01-06 15:21:52.617004 (Thread-2): 15:21:52  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 15:21:52.666395 (Thread-2): 15:21:52  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 15:21:52.668906 (Thread-1): 15:21:52  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 15:21:52.690026 (Thread-1): 15:21:52  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:21:52.690133 (Thread-1): 15:21:52  On model.my_new_project.dim_customers: BEGIN
2022-01-06 15:21:52.690215 (Thread-1): 15:21:52  Opening a new connection, currently in state closed
2022-01-06 15:21:52.690295 (Thread-1): 15:21:52  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:21:52.695284 (Thread-2): 15:21:52  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:21:52.695390 (Thread-2): 15:21:52  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:21:52.695469 (Thread-2): 15:21:52  Opening a new connection, currently in state init
2022-01-06 15:21:52.695544 (Thread-2): 15:21:52  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:21:52.717126 (Thread-1): 15:21:52  SQL status: BEGIN in 0.03 seconds
2022-01-06 15:21:52.717267 (Thread-1): 15:21:52  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:21:52.717352 (Thread-1): 15:21:52  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 15:21:52.718023 (Thread-2): 15:21:52  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:21:52.718121 (Thread-2): 15:21:52  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:21:52.718191 (Thread-2): 15:21:52  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 15:21:52.836557 (Thread-2): 15:21:52  SQL status: SELECT in 0.12 seconds
2022-01-06 15:21:52.842435 (Thread-2): 15:21:52  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:21:52.842545 (Thread-2): 15:21:52  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 15:21:52.847391 (Thread-2): 15:21:52  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:21:52.849202 (Thread-2): 15:21:52  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:21:52.849338 (Thread-2): 15:21:52  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 15:21:52.849637 (Thread-1): 15:21:52  SQL status: SELECT in 0.13 seconds
2022-01-06 15:21:52.851520 (Thread-1): 15:21:52  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:21:52.851623 (Thread-1): 15:21:52  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 15:21:52.851828 (Thread-2): 15:21:52  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:21:52.857136 (Thread-1): 15:21:52  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 15:21:52.858789 (Thread-1): 15:21:52  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:21:52.858886 (Thread-1): 15:21:52  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 15:21:52.864979 (Thread-2): 15:21:52  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:21:52.865098 (Thread-2): 15:21:52  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:21:52.865174 (Thread-2): 15:21:52  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:21:52.865331 (Thread-1): 15:21:52  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 15:21:52.866393 (Thread-1): 15:21:52  On model.my_new_project.dim_customers: COMMIT
2022-01-06 15:21:52.866489 (Thread-1): 15:21:52  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:21:52.866560 (Thread-1): 15:21:52  On model.my_new_project.dim_customers: COMMIT
2022-01-06 15:21:52.932459 (Thread-2): 15:21:52  SQL status: COMMIT in 0.07 seconds
2022-01-06 15:21:52.932673 (Thread-2): 15:21:52  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:21:52.932756 (Thread-2): 15:21:52  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:21:52.933058 (Thread-1): 15:21:52  SQL status: COMMIT in 0.07 seconds
2022-01-06 15:21:52.934920 (Thread-2): 15:21:52  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:21:52.938823 (Thread-2): 15:21:52  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:21:52.938921 (Thread-2): 15:21:52  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 15:21:52.943894 (Thread-2): 15:21:52  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 15:21:52.944507 (Thread-2): 15:21:52  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:21:52.944600 (Thread-2): 15:21:52  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:21:52.944673 (Thread-2): 15:21:52  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:21:52.973835 (Thread-2): 15:21:52  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:21:52.973943 (Thread-2): 15:21:52  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:21:52.974015 (Thread-2): 15:21:52  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:21:52.976114 (Thread-2): 15:21:52  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:21:52.976504 (Thread-2): 15:21:52  finished collecting timing info
2022-01-06 15:21:52.976633 (Thread-2): 15:21:52  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 15:21:52.976905 (Thread-1): 15:21:52  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:21:52.977003 (Thread-1): 15:21:52  On model.my_new_project.dim_customers: BEGIN
2022-01-06 15:21:52.979438 (Thread-2): 15:21:52  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 15:21:52.979597 (Thread-1): 15:21:52  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:21:52.980690 (Thread-1): 15:21:52  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:21:52.980785 (Thread-1): 15:21:52  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 15:21:52.981200 (Thread-2): 15:21:52  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7535b00-bcc9-4267-b811-1244f43b0361', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c8614af0>]}
2022-01-06 15:21:52.981543 (Thread-2): 15:21:52  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.39s]
2022-01-06 15:21:52.981656 (Thread-2): 15:21:52  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 15:21:52.982487 (Thread-4): 15:21:52  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 15:21:52.982733 (Thread-4): 15:21:52  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 15:21:52.983135 (Thread-4): 15:21:52  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:21:52.983231 (Thread-4): 15:21:52  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 15:21:52.983318 (Thread-4): 15:21:52  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 15:21:52.985144 (Thread-4): 15:21:52  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 15:21:52.985776 (Thread-1): 15:21:52  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 15:21:52.986402 (Thread-1): 15:21:52  On model.my_new_project.dim_customers: COMMIT
2022-01-06 15:21:52.986495 (Thread-1): 15:21:52  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:21:52.986570 (Thread-1): 15:21:52  On model.my_new_project.dim_customers: COMMIT
2022-01-06 15:21:53.002047 (Thread-4): 15:21:53  finished collecting timing info
2022-01-06 15:21:53.002177 (Thread-4): 15:21:53  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 15:21:53.017565 (Thread-4): 15:21:53  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 15:21:53.019117 (Thread-1): 15:21:53  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:21:53.019230 (Thread-1): 15:21:53  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:21:53.019304 (Thread-1): 15:21:53  On model.my_new_project.dim_customers: BEGIN
2022-01-06 15:21:53.021402 (Thread-1): 15:21:53  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:21:53.021759 (Thread-1): 15:21:53  finished collecting timing info
2022-01-06 15:21:53.021876 (Thread-1): 15:21:53  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 15:21:53.023687 (Thread-1): 15:21:53  On model.my_new_project.dim_customers: Close
2022-01-06 15:21:53.024083 (Thread-1): 15:21:53  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7535b00-bcc9-4267-b811-1244f43b0361', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c8e5a100>]}
2022-01-06 15:21:53.024368 (Thread-1): 15:21:53  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.44s]
2022-01-06 15:21:53.024473 (Thread-1): 15:21:53  Finished running node model.my_new_project.dim_customers
2022-01-06 15:21:53.035432 (Thread-4): 15:21:53  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:21:53.035535 (Thread-4): 15:21:53  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:21:53.035617 (Thread-4): 15:21:53  Opening a new connection, currently in state init
2022-01-06 15:21:53.035697 (Thread-4): 15:21:53  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:21:53.054481 (Thread-4): 15:21:53  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:21:53.054593 (Thread-4): 15:21:53  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:21:53.054670 (Thread-4): 15:21:53  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 15:21:53.059617 (Thread-4): 15:21:53  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 15:21:53.061396 (Thread-4): 15:21:53  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:21:53.061493 (Thread-4): 15:21:53  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 15:21:53.063927 (Thread-4): 15:21:53  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:21:53.064826 (Thread-4): 15:21:53  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:21:53.064919 (Thread-4): 15:21:53  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:21:53.064990 (Thread-4): 15:21:53  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:21:53.095960 (Thread-4): 15:21:53  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:21:53.096164 (Thread-4): 15:21:53  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:21:53.096255 (Thread-4): 15:21:53  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:21:53.098315 (Thread-4): 15:21:53  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:21:53.099528 (Thread-4): 15:21:53  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:21:53.099625 (Thread-4): 15:21:53  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 15:21:53.101756 (Thread-4): 15:21:53  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 15:21:53.102425 (Thread-4): 15:21:53  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:21:53.102518 (Thread-4): 15:21:53  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:21:53.102591 (Thread-4): 15:21:53  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:21:53.129789 (Thread-4): 15:21:53  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:21:53.129901 (Thread-4): 15:21:53  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:21:53.129974 (Thread-4): 15:21:53  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:21:53.132065 (Thread-4): 15:21:53  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:21:53.132422 (Thread-4): 15:21:53  finished collecting timing info
2022-01-06 15:21:53.132541 (Thread-4): 15:21:53  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 15:21:53.134268 (Thread-4): 15:21:53  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 15:21:53.134662 (Thread-4): 15:21:53  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7535b00-bcc9-4267-b811-1244f43b0361', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c8e5a4c0>]}
2022-01-06 15:21:53.134987 (Thread-4): 15:21:53  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.15s]
2022-01-06 15:21:53.135147 (Thread-4): 15:21:53  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 15:21:53.136585 (MainThread): 15:21:53  Acquiring new redshift connection "master"
2022-01-06 15:21:53.136735 (MainThread): 15:21:53  Using redshift connection "master"
2022-01-06 15:21:53.136812 (MainThread): 15:21:53  On master: BEGIN
2022-01-06 15:21:53.136889 (MainThread): 15:21:53  Opening a new connection, currently in state closed
2022-01-06 15:21:53.136965 (MainThread): 15:21:53  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:21:53.162099 (MainThread): 15:21:53  SQL status: BEGIN in 0.03 seconds
2022-01-06 15:21:53.162214 (MainThread): 15:21:53  On master: COMMIT
2022-01-06 15:21:53.162288 (MainThread): 15:21:53  Using redshift connection "master"
2022-01-06 15:21:53.162357 (MainThread): 15:21:53  On master: COMMIT
2022-01-06 15:21:53.164031 (MainThread): 15:21:53  SQL status: COMMIT in 0.0 seconds
2022-01-06 15:21:53.164132 (MainThread): 15:21:53  On master: Close
2022-01-06 15:21:53.164509 (MainThread): 15:21:53  
2022-01-06 15:21:53.164621 (MainThread): 15:21:53  Finished running 2 table models, 1 view model in 0.87s.
2022-01-06 15:21:53.164701 (MainThread): 15:21:53  Connection 'master' was properly closed.
2022-01-06 15:21:53.164766 (MainThread): 15:21:53  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 15:21:53.164827 (MainThread): 15:21:53  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 15:21:53.164887 (MainThread): 15:21:53  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 15:21:53.239227 (MainThread): 15:21:53  
2022-01-06 15:21:53.239374 (MainThread): 15:21:53  Completed successfully
2022-01-06 15:21:53.239468 (MainThread): 15:21:53  
2022-01-06 15:21:53.239551 (MainThread): 15:21:53  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 15:21:54.096622 (Thread-286): handling poll request
2022-01-06 15:21:54.097054 (Thread-286): 15:21:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfb32b0>]}
2022-01-06 15:21:54.099574 (Thread-286): sending response (<Response 73131 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:21:54.766198 (Thread-287): handling status request
2022-01-06 15:21:54.766572 (Thread-287): 15:21:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfb3460>]}
2022-01-06 15:21:54.767095 (Thread-287): sending response (<Response 1244 bytes [200 OK]>) to 10.0.4.41
2022-01-06 15:21:54.845352 (Thread-288): handling status request
2022-01-06 15:21:54.845635 (Thread-288): 15:21:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfb3850>]}
2022-01-06 15:21:54.846047 (Thread-288): sending response (<Response 1244 bytes [200 OK]>) to 10.0.4.41
2022-01-06 15:22:12.641798 (Thread-289): handling status request
2022-01-06 15:22:12.642168 (Thread-289): 15:22:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfb3a90>]}
2022-01-06 15:22:12.642634 (Thread-289): sending response (<Response 1244 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:22:12.893664 (Thread-290): handling status request
2022-01-06 15:22:12.894033 (Thread-290): 15:22:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfb3d00>]}
2022-01-06 15:22:12.894539 (Thread-290): sending response (<Response 1244 bytes [200 OK]>) to 10.0.32.116
2022-01-06 15:22:13.079885 (Thread-291): handling cli_args request
2022-01-06 15:22:13.080143 (Thread-291): 15:22:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bfb3f70>]}
2022-01-06 15:22:15.127587 (Thread-291): sending response (<Response 138 bytes [200 OK]>) to 10.0.16.103
2022-01-06 15:22:15.207056 (MainThread): 15:22:15  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 15:22:15.207447 (MainThread): 15:22:15  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 15:22:15.212954 (MainThread): 15:22:15  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cccb08c9-e5bb-48ba-bfb8-4002599290a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d03260b50>]}
2022-01-06 15:22:15.249378 (MainThread): 15:22:15  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cccb08c9-e5bb-48ba-bfb8-4002599290a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d032bfaf0>]}
2022-01-06 15:22:15.249617 (MainThread): 15:22:15  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:22:15.249937 (MainThread): 15:22:15  The selection criterion 'stg_customers' does not match any nodes
2022-01-06 15:22:15.250516 (MainThread): 15:22:15  
2022-01-06 15:22:15.250620 (MainThread): 15:22:15  [WARNING]: Nothing to do. Try checking your model configs and model specification args
2022-01-06 15:22:15.532476 (Thread-292): handling poll request
2022-01-06 15:22:15.532899 (Thread-292): 15:22:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf514f0>]}
2022-01-06 15:22:15.533769 (Thread-292): sending response (<Response 3246 bytes [200 OK]>) to 10.0.23.79
2022-01-06 15:22:16.260888 (Thread-293): handling status request
2022-01-06 15:22:16.261293 (Thread-293): 15:22:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf516a0>]}
2022-01-06 15:22:16.261800 (Thread-293): sending response (<Response 1244 bytes [200 OK]>) to 10.0.32.116
2022-01-06 15:22:16.353273 (Thread-294): handling status request
2022-01-06 15:22:16.353578 (Thread-294): 15:22:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf51a60>]}
2022-01-06 15:22:16.354001 (Thread-294): sending response (<Response 1244 bytes [200 OK]>) to 10.0.41.69
2022-01-06 15:22:48.876801 (Thread-295): handling status request
2022-01-06 15:22:48.877182 (Thread-295): 15:22:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf51cd0>]}
2022-01-06 15:22:48.877682 (Thread-295): sending response (<Response 1244 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:22:49.063648 (Thread-296): handling status request
2022-01-06 15:22:49.063982 (Thread-296): 15:22:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf51f40>]}
2022-01-06 15:22:49.064420 (Thread-296): sending response (<Response 1244 bytes [200 OK]>) to 10.0.29.240
2022-01-06 15:22:49.181207 (Thread-297): handling docs.generate request
2022-01-06 15:22:49.181622 (Thread-297): 15:22:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf60160>]}
2022-01-06 15:22:51.251297 (Thread-297): sending response (<Response 138 bytes [200 OK]>) to 10.0.10.175
2022-01-06 15:22:51.286744 (MainThread): 15:22:51  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6ebcbb30-a801-49a4-a394-4f11f9c676de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feff68613a0>]}
2022-01-06 15:22:51.287038 (MainThread): 15:22:51  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:22:51.288279 (MainThread): 15:22:51  
2022-01-06 15:22:51.288438 (MainThread): 15:22:51  Acquiring new redshift connection "master"
2022-01-06 15:22:51.289206 (ThreadPoolExecutor-0_0): 15:22:51  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:22:51.300557 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/catalog.sql
2022-01-06 15:22:51.314185 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/adapters.sql
2022-01-06 15:22:51.341259 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/relations.sql
2022-01-06 15:22:51.341963 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 15:22:51.342908 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/catalog.sql
2022-01-06 15:22:51.345095 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/adapters.sql
2022-01-06 15:22:51.365899 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/relations.sql
2022-01-06 15:22:51.367274 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 15:22:51.370192 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-06 15:22:51.371751 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-06 15:22:51.373385 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-06 15:22:51.375978 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-06 15:22:51.377450 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/generic_test_sql/not_null.sql
2022-01-06 15:22:51.378137 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/generic_test_sql/relationships.sql
2022-01-06 15:22:51.379101 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/generic_test_sql/unique.sql
2022-01-06 15:22:51.379909 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/configs.sql
2022-01-06 15:22:51.382315 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/hooks.sql
2022-01-06 15:22:51.386164 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/snapshots/strategies.sql
2022-01-06 15:22:51.402712 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-06 15:22:51.404436 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-06 15:22:51.415394 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/snapshots/helpers.sql
2022-01-06 15:22:51.426045 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/seeds/seed.sql
2022-01-06 15:22:51.431865 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/seeds/helpers.sql
2022-01-06 15:22:51.447529 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-06 15:22:51.449917 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/models/view/view.sql
2022-01-06 15:22:51.456564 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-06 15:22:51.459225 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/models/view/helpers.sql
2022-01-06 15:22:51.460626 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/models/table/table.sql
2022-01-06 15:22:51.467619 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-06 15:22:51.470569 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/models/incremental/merge.sql
2022-01-06 15:22:51.481964 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-06 15:22:51.496558 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-06 15:22:51.500999 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-06 15:22:51.510687 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-06 15:22:51.512247 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/tests/test.sql
2022-01-06 15:22:51.516539 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/tests/where_subquery.sql
2022-01-06 15:22:51.518458 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/materializations/tests/helpers.sql
2022-01-06 15:22:51.520261 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/etc/statement.sql
2022-01-06 15:22:51.524601 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/etc/datetime.sql
2022-01-06 15:22:51.532557 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/adapters/indexes.sql
2022-01-06 15:22:51.535294 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/adapters/persist_docs.sql
2022-01-06 15:22:51.539602 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/adapters/freshness.sql
2022-01-06 15:22:51.542574 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/adapters/relation.sql
2022-01-06 15:22:51.551797 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/adapters/metadata.sql
2022-01-06 15:22:51.558825 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/adapters/columns.sql
2022-01-06 15:22:51.568431 (ThreadPoolExecutor-0_0): 15:22:51  Parsing macros/adapters/schema.sql
2022-01-06 15:22:51.580358 (ThreadPoolExecutor-0_0): 15:22:51  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:22:51.580474 (ThreadPoolExecutor-0_0): 15:22:51  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 15:22:51.580555 (ThreadPoolExecutor-0_0): 15:22:51  Opening a new connection, currently in state init
2022-01-06 15:22:51.580635 (ThreadPoolExecutor-0_0): 15:22:51  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:22:51.600499 (ThreadPoolExecutor-0_0): 15:22:51  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:22:51.600610 (ThreadPoolExecutor-0_0): 15:22:51  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:22:51.600683 (ThreadPoolExecutor-0_0): 15:22:51  On list_dev_dbt_nobodozie: select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 15:22:51.611860 (ThreadPoolExecutor-0_0): 15:22:51  SQL status: SELECT in 0.01 seconds
2022-01-06 15:22:51.612905 (ThreadPoolExecutor-0_0): 15:22:51  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 15:22:51.614875 (ThreadPoolExecutor-0_0): 15:22:51  On list_dev_dbt_nobodozie: Close
2022-01-06 15:22:51.618461 (MainThread): 15:22:51  Using redshift connection "master"
2022-01-06 15:22:51.618573 (MainThread): 15:22:51  On master: BEGIN
2022-01-06 15:22:51.618653 (MainThread): 15:22:51  Opening a new connection, currently in state init
2022-01-06 15:22:51.618728 (MainThread): 15:22:51  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:22:51.644649 (MainThread): 15:22:51  SQL status: BEGIN in 0.03 seconds
2022-01-06 15:22:51.644755 (MainThread): 15:22:51  Using redshift connection "master"
2022-01-06 15:22:51.644828 (MainThread): 15:22:51  On master: with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 15:22:51.673698 (MainThread): 15:22:51  SQL status: SELECT in 0.03 seconds
2022-01-06 15:22:51.674666 (MainThread): 15:22:51  On master: ROLLBACK
2022-01-06 15:22:51.676625 (MainThread): 15:22:51  On master: Close
2022-01-06 15:22:51.676903 (MainThread): 15:22:51  Concurrency: 4 threads (target='default')
2022-01-06 15:22:51.677011 (MainThread): 15:22:51  
2022-01-06 15:22:51.679218 (Thread-1): 15:22:51  Began running node model.my_new_project.dim_customers
2022-01-06 15:22:51.679386 (Thread-1): 15:22:51  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:22:51.679474 (Thread-1): 15:22:51  Began compiling node model.my_new_project.dim_customers
2022-01-06 15:22:51.679559 (Thread-1): 15:22:51  Compiling model.my_new_project.dim_customers
2022-01-06 15:22:51.681619 (Thread-1): 15:22:51  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 15:22:51.681840 (Thread-2): 15:22:51  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 15:22:51.682005 (Thread-2): 15:22:51  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:22:51.682084 (Thread-2): 15:22:51  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 15:22:51.682160 (Thread-2): 15:22:51  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 15:22:51.684641 (Thread-2): 15:22:51  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 15:22:51.690434 (Thread-298): handling poll request
2022-01-06 15:22:51.690786 (Thread-298): 15:22:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf60e50>]}
2022-01-06 15:22:51.692148 (Thread-298): sending response (<Response 29041 bytes [200 OK]>) to 10.0.29.240
2022-01-06 15:22:51.699683 (Thread-1): 15:22:51  finished collecting timing info
2022-01-06 15:22:51.699821 (Thread-1): 15:22:51  Began executing node model.my_new_project.dim_customers
2022-01-06 15:22:51.699919 (Thread-1): 15:22:51  finished collecting timing info
2022-01-06 15:22:51.700056 (Thread-1): 15:22:51  Finished running node model.my_new_project.dim_customers
2022-01-06 15:22:51.700340 (Thread-2): 15:22:51  finished collecting timing info
2022-01-06 15:22:51.700472 (Thread-2): 15:22:51  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 15:22:51.700561 (Thread-2): 15:22:51  finished collecting timing info
2022-01-06 15:22:51.700686 (Thread-2): 15:22:51  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 15:22:51.701657 (Thread-4): 15:22:51  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 15:22:51.701826 (Thread-4): 15:22:51  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:22:51.701908 (Thread-4): 15:22:51  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 15:22:51.701983 (Thread-4): 15:22:51  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 15:22:51.703777 (Thread-4): 15:22:51  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 15:22:51.704103 (Thread-3): 15:22:51  Began running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 15:22:51.704266 (Thread-3): 15:22:51  Acquiring new redshift connection "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-06 15:22:51.704346 (Thread-3): 15:22:51  Began compiling node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 15:22:51.704421 (Thread-3): 15:22:51  Compiling test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 15:22:51.713345 (Thread-3): 15:22:51  Writing injected SQL for node "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-06 15:22:51.713530 (Thread-1): 15:22:51  Began running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 15:22:51.713677 (Thread-1): 15:22:51  Acquiring new redshift connection "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-06 15:22:51.713754 (Thread-1): 15:22:51  Began compiling node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 15:22:51.713827 (Thread-1): 15:22:51  Compiling test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 15:22:51.719292 (Thread-1): 15:22:51  Writing injected SQL for node "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-06 15:22:51.725416 (Thread-4): 15:22:51  finished collecting timing info
2022-01-06 15:22:51.725550 (Thread-4): 15:22:51  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 15:22:51.725642 (Thread-4): 15:22:51  finished collecting timing info
2022-01-06 15:22:51.725768 (Thread-4): 15:22:51  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 15:22:51.726360 (Thread-2): 15:22:51  Began running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 15:22:51.726519 (Thread-2): 15:22:51  Acquiring new redshift connection "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2022-01-06 15:22:51.726599 (Thread-2): 15:22:51  Began compiling node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 15:22:51.726685 (Thread-2): 15:22:51  Compiling test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 15:22:51.729682 (Thread-2): 15:22:51  Writing injected SQL for node "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2022-01-06 15:22:51.729865 (Thread-4): 15:22:51  Began running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 15:22:51.730006 (Thread-4): 15:22:51  Acquiring new redshift connection "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2022-01-06 15:22:51.730082 (Thread-4): 15:22:51  Began compiling node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 15:22:51.730153 (Thread-4): 15:22:51  Compiling test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 15:22:51.733047 (Thread-4): 15:22:51  Writing injected SQL for node "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2022-01-06 15:22:51.738910 (Thread-1): 15:22:51  finished collecting timing info
2022-01-06 15:22:51.739039 (Thread-1): 15:22:51  Began executing node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 15:22:51.739130 (Thread-1): 15:22:51  finished collecting timing info
2022-01-06 15:22:51.739253 (Thread-1): 15:22:51  Finished running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 15:22:51.739540 (Thread-3): 15:22:51  finished collecting timing info
2022-01-06 15:22:51.739700 (Thread-3): 15:22:51  Began executing node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 15:22:51.739836 (Thread-3): 15:22:51  finished collecting timing info
2022-01-06 15:22:51.740017 (Thread-3): 15:22:51  Finished running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 15:22:51.749725 (Thread-2): 15:22:51  finished collecting timing info
2022-01-06 15:22:51.749884 (Thread-2): 15:22:51  Began executing node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 15:22:51.749979 (Thread-2): 15:22:51  finished collecting timing info
2022-01-06 15:22:51.750100 (Thread-2): 15:22:51  Finished running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 15:22:51.750402 (Thread-4): 15:22:51  finished collecting timing info
2022-01-06 15:22:51.750523 (Thread-4): 15:22:51  Began executing node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 15:22:51.750611 (Thread-4): 15:22:51  finished collecting timing info
2022-01-06 15:22:51.750733 (Thread-4): 15:22:51  Finished running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 15:22:51.751921 (MainThread): 15:22:51  Connection 'master' was properly closed.
2022-01-06 15:22:51.752025 (MainThread): 15:22:51  Connection 'test.my_new_project.unique_my_first_dbt_model_id.16e066b321' was properly closed.
2022-01-06 15:22:51.752091 (MainThread): 15:22:51  Connection 'test.my_new_project.not_null_my_second_dbt_model_id.151b76d778' was properly closed.
2022-01-06 15:22:51.752151 (MainThread): 15:22:51  Connection 'test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
2022-01-06 15:22:51.752208 (MainThread): 15:22:51  Connection 'test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
2022-01-06 15:22:51.808876 (MainThread): 15:22:51  Done.
2022-01-06 15:22:51.887628 (MainThread): 15:22:51  Acquiring new redshift connection "generate_catalog"
2022-01-06 15:22:51.887763 (MainThread): 15:22:51  Building catalog
2022-01-06 15:22:51.889081 (ThreadPoolExecutor-1_0): 15:22:51  Acquiring new redshift connection "dev.information_schema"
2022-01-06 15:22:51.899657 (ThreadPoolExecutor-1_0): 15:22:51  Using redshift connection "dev.information_schema"
2022-01-06 15:22:51.899761 (ThreadPoolExecutor-1_0): 15:22:51  On dev.information_schema: BEGIN
2022-01-06 15:22:51.899843 (ThreadPoolExecutor-1_0): 15:22:51  Opening a new connection, currently in state init
2022-01-06 15:22:51.899920 (ThreadPoolExecutor-1_0): 15:22:51  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:22:51.919505 (ThreadPoolExecutor-1_0): 15:22:51  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:22:51.919620 (ThreadPoolExecutor-1_0): 15:22:51  Using redshift connection "dev.information_schema"
2022-01-06 15:22:51.919694 (ThreadPoolExecutor-1_0): 15:22:51  On dev.information_schema: 
    

    with late_binding as (
      select
        'dev'::varchar as table_database,
        table_schema,
        table_name,
        'LATE BINDING VIEW'::varchar as table_type,
        null::text as table_comment,

        column_name,
        column_index,
        column_type,
        null::text as column_comment
      from pg_get_late_binding_view_cols()
        cols(table_schema name, table_name name, column_name name,
             column_type varchar,
             column_index int)
        order by "column_index"
    ),

    early_binding as (
        select
            'dev'::varchar as table_database,
            sch.nspname as table_schema,
            tbl.relname as table_name,
            case tbl.relkind
                when 'v' then 'VIEW'
                else 'BASE TABLE'
            end as table_type,
            tbl_desc.description as table_comment,
            col.attname as column_name,
            col.attnum as column_index,
            pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
            col_desc.description as column_comment

        from pg_catalog.pg_namespace sch
        join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
        join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
        left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
        left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
        where (upper(sch.nspname) = upper('dbt_nobodozie'))
            and tbl.relkind in ('r', 'v', 'f', 'p')
            and col.attnum > 0
            and not col.attisdropped
    ),

    table_owners as (

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            tablename as table_name,
            tableowner as table_owner

        from pg_tables

        union all

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            viewname as table_name,
            viewowner as table_owner

        from pg_views

    ),

    unioned as (

        select *
        from early_binding

        union all

        select *
        from late_binding

    )

    select *,
        table_database || '.' || table_schema || '.' || table_name as table_id

    from unioned
    join table_owners using (table_database, table_schema, table_name)

    where (upper(table_schema) = upper('dbt_nobodozie'))

    order by "column_index"
2022-01-06 15:22:51.977451 (ThreadPoolExecutor-1_0): 15:22:51  SQL status: SELECT in 0.06 seconds
2022-01-06 15:22:51.980969 (ThreadPoolExecutor-1_0): 15:22:51  Using redshift connection "dev.information_schema"
2022-01-06 15:22:51.981079 (ThreadPoolExecutor-1_0): 15:22:51  On dev.information_schema: select has_table_privilege(current_user, 'svv_table_info', 'SELECT') as can_select
2022-01-06 15:22:51.983507 (ThreadPoolExecutor-1_0): 15:22:51  SQL status: SELECT in 0.0 seconds
2022-01-06 15:22:51.987346 (ThreadPoolExecutor-1_0): 15:22:51  Using redshift connection "dev.information_schema"
2022-01-06 15:22:51.987444 (ThreadPoolExecutor-1_0): 15:22:51  On dev.information_schema: select
        "database" || '.' || "schema" || '.' || "table" as table_id,

        'Encoded'::text as "stats:encoded:label",
        encoded as "stats:encoded:value",
        'Indicates whether any column in the table has compression encoding defined.'::text as "stats:encoded:description",
        true as "stats:encoded:include",

        'Dist Style' as "stats:diststyle:label",
        diststyle as "stats:diststyle:value",
        'Distribution style or distribution key column, if key distribution is defined.'::text as "stats:diststyle:description",
        true as "stats:diststyle:include",

        'Sort Key 1' as "stats:sortkey1:label",
        -- handle 0xFF byte in response for interleaved sort styles
        case
            when sortkey1 like 'INTERLEAVED%' then 'INTERLEAVED'::text
            else sortkey1
        end as "stats:sortkey1:value",
        'First column in the sort key.'::text as "stats:sortkey1:description",
        (sortkey1 is not null) as "stats:sortkey1:include",

        'Max Varchar' as "stats:max_varchar:label",
        max_varchar as "stats:max_varchar:value",
        'Size of the largest column that uses a VARCHAR data type.'::text as "stats:max_varchar:description",
        true as "stats:max_varchar:include",

        -- exclude this, as the data is strangely returned with null-byte characters
        'Sort Key 1 Encoding' as "stats:sortkey1_enc:label",
        sortkey1_enc as "stats:sortkey1_enc:value",
        'Compression encoding of the first column in the sort key.' as "stats:sortkey1_enc:description",
        false as "stats:sortkey1_enc:include",

        '# Sort Keys' as "stats:sortkey_num:label",
        sortkey_num as "stats:sortkey_num:value",
        'Number of columns defined as sort keys.' as "stats:sortkey_num:description",
        (sortkey_num > 0) as "stats:sortkey_num:include",

        'Approximate Size' as "stats:size:label",
        size * 1000000 as "stats:size:value",
        'Approximate size of the table, calculated from a count of 1MB blocks'::text as "stats:size:description",
        true as "stats:size:include",

        'Disk Utilization' as "stats:pct_used:label",
        pct_used / 100.0 as "stats:pct_used:value",
        'Percent of available space that is used by the table.'::text as "stats:pct_used:description",
        true as "stats:pct_used:include",

        'Unsorted %' as "stats:unsorted:label",
        unsorted / 100.0 as "stats:unsorted:value",
        'Percent of unsorted rows in the table.'::text as "stats:unsorted:description",
        (unsorted is not null) as "stats:unsorted:include",

        'Stats Off' as "stats:stats_off:label",
        stats_off as "stats:stats_off:value",
        'Number that indicates how stale the table statistics are; 0 is current, 100 is out of date.'::text as "stats:stats_off:description",
        true as "stats:stats_off:include",

        'Approximate Row Count' as "stats:rows:label",
        tbl_rows as "stats:rows:value",
        'Approximate number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed.'::text as "stats:rows:description",
        true as "stats:rows:include",

        'Sort Key Skew' as "stats:skew_sortkey1:label",
        skew_sortkey1 as "stats:skew_sortkey1:value",
        'Ratio of the size of the largest non-sort key column to the size of the first column of the sort key.'::text as "stats:skew_sortkey1:description",
        (skew_sortkey1 is not null) as "stats:skew_sortkey1:include",

        'Skew Rows' as "stats:skew_rows:label",
        skew_rows as "stats:skew_rows:value",
        'Ratio of the number of rows in the slice with the most rows to the number of rows in the slice with the fewest rows.'::text as "stats:skew_rows:description",
        (skew_rows is not null) as "stats:skew_rows:include"

    from svv_table_info
    where (upper(schema) = upper('dbt_nobodozie'))
2022-01-06 15:22:52.646790 (ThreadPoolExecutor-1_0): 15:22:52  SQL status: SELECT in 0.66 seconds
2022-01-06 15:22:52.655980 (ThreadPoolExecutor-1_0): 15:22:52  On dev.information_schema: ROLLBACK
2022-01-06 15:22:52.658304 (ThreadPoolExecutor-1_0): 15:22:52  On dev.information_schema: Close
2022-01-06 15:22:52.737460 (MainThread): 15:22:52  Catalog written to /usr/src/develop/user-52374/environment-57794/repository-46678/target/catalog.json
2022-01-06 15:22:53.034782 (Thread-299): handling poll request
2022-01-06 15:22:53.035141 (Thread-299): 15:22:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf11f70>]}
2022-01-06 15:22:53.036589 (Thread-299): sending response (<Response 44174 bytes [200 OK]>) to 10.0.30.119
2022-01-06 15:22:53.703549 (Thread-300): handling status request
2022-01-06 15:22:53.703903 (Thread-300): 15:22:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf174f0>]}
2022-01-06 15:22:53.704408 (Thread-300): sending response (<Response 1244 bytes [200 OK]>) to 10.0.26.175
2022-01-06 15:22:53.767054 (Thread-301): handling status request
2022-01-06 15:22:53.767425 (Thread-301): 15:22:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf178b0>]}
2022-01-06 15:22:53.767905 (Thread-301): sending response (<Response 1244 bytes [200 OK]>) to 10.0.4.41
2022-01-06 15:22:53.867958 (Thread-302): handling status request
2022-01-06 15:22:53.868314 (Thread-302): 15:22:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf17b20>]}
2022-01-06 15:22:53.868765 (Thread-302): sending response (<Response 1244 bytes [200 OK]>) to 10.0.41.69
2022-01-06 15:28:01.662941 (Thread-303): handling status request
2022-01-06 15:28:01.664603 (Thread-303): 15:28:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf17f10>]}
2022-01-06 15:28:01.665082 (Thread-303): sending response (<Response 1244 bytes [200 OK]>) to 10.0.2.97
2022-01-06 15:28:01.984026 (Thread-304): handling compile_sql request
2022-01-06 15:28:01.984426 (Thread-304): 15:28:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf21310>]}
2022-01-06 15:28:04.122546 (Thread-304): sending response (<Response 138 bytes [200 OK]>) to 10.0.30.119
2022-01-06 15:28:04.149655 (MainThread): 15:28:04  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '809126ef-4dbd-4ef1-b729-e625771ecfbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc25f1c430>]}
2022-01-06 15:28:04.150178 (MainThread): 15:28:04  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:28:04.150754 (Thread-1): 15:28:04  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:28:04.150902 (Thread-1): 15:28:04  Began compiling node rpc.my_new_project.request
2022-01-06 15:28:04.150995 (Thread-1): 15:28:04  Compiling rpc.my_new_project.request
2022-01-06 15:28:04.153413 (Thread-1): 15:28:04  finished collecting timing info
2022-01-06 15:28:04.153542 (Thread-1): 15:28:04  Began executing node rpc.my_new_project.request
2022-01-06 15:28:04.153639 (Thread-1): 15:28:04  finished collecting timing info
2022-01-06 15:28:04.621954 (Thread-305): handling poll request
2022-01-06 15:28:04.622375 (Thread-305): 15:28:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf2b580>]}
2022-01-06 15:28:04.623449 (Thread-305): sending response (<Response 8349 bytes [200 OK]>) to 10.0.21.24
2022-01-06 15:28:20.490216 (Thread-306): handling status request
2022-01-06 15:28:20.490596 (Thread-306): 15:28:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf2b730>]}
2022-01-06 15:28:20.515093 (Thread-306): sending response (<Response 1244 bytes [200 OK]>) to 10.0.0.136
2022-01-06 15:28:20.839263 (Thread-307): handling run_sql request
2022-01-06 15:28:20.839653 (Thread-307): 15:28:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf2b910>]}
2022-01-06 15:28:22.888343 (Thread-307): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.97
2022-01-06 15:28:22.911739 (MainThread): 15:28:22  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd335fc04-75da-48dd-904e-99da08aea222', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ed6948700>]}
2022-01-06 15:28:22.912266 (MainThread): 15:28:22  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:28:22.912838 (Thread-1): 15:28:22  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:28:22.912969 (Thread-1): 15:28:22  Began compiling node rpc.my_new_project.request
2022-01-06 15:28:22.913061 (Thread-1): 15:28:22  Compiling rpc.my_new_project.request
2022-01-06 15:28:22.914255 (Thread-1): 15:28:22  finished collecting timing info
2022-01-06 15:28:22.914382 (Thread-1): 15:28:22  Began executing node rpc.my_new_project.request
2022-01-06 15:28:22.914482 (Thread-1): 15:28:22  Using redshift connection "rpc.my_new_project.request"
2022-01-06 15:28:22.914562 (Thread-1): 15:28:22  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from dev.jaffle_shop.customers

)
select * from customers
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 15:28:22.914639 (Thread-1): 15:28:22  Opening a new connection, currently in state init
2022-01-06 15:28:22.914725 (Thread-1): 15:28:22  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:28:22.935613 (Thread-1): 15:28:22  SQL status: SELECT in 0.02 seconds
2022-01-06 15:28:22.937462 (Thread-1): 15:28:22  finished collecting timing info
2022-01-06 15:28:22.937599 (Thread-1): 15:28:22  On rpc.my_new_project.request: Close
2022-01-06 15:28:23.343075 (Thread-308): handling poll request
2022-01-06 15:28:23.343602 (Thread-308): 15:28:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf357f0>]}
2022-01-06 15:28:23.345011 (Thread-308): sending response (<Response 10174 bytes [200 OK]>) to 10.0.15.56
2022-01-06 15:28:27.255694 (Thread-309): handling status request
2022-01-06 15:28:27.256082 (Thread-309): 15:28:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf359a0>]}
2022-01-06 15:28:27.256629 (Thread-309): sending response (<Response 1244 bytes [200 OK]>) to 10.0.26.175
2022-01-06 15:28:27.682864 (Thread-310): handling run_sql request
2022-01-06 15:28:27.683167 (Thread-310): 15:28:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf35d90>]}
2022-01-06 15:28:29.723344 (Thread-310): sending response (<Response 138 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:28:29.746624 (MainThread): 15:28:29  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd76bff4f-d1b9-4d00-affb-3c95f08a727a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e9e53c670>]}
2022-01-06 15:28:29.747149 (MainThread): 15:28:29  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:28:29.747711 (Thread-1): 15:28:29  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:28:29.747823 (Thread-1): 15:28:29  Began compiling node rpc.my_new_project.request
2022-01-06 15:28:29.747908 (Thread-1): 15:28:29  Compiling rpc.my_new_project.request
2022-01-06 15:28:29.749019 (Thread-1): 15:28:29  finished collecting timing info
2022-01-06 15:28:29.749146 (Thread-1): 15:28:29  Began executing node rpc.my_new_project.request
2022-01-06 15:28:29.749285 (Thread-1): 15:28:29  Using redshift connection "rpc.my_new_project.request"
2022-01-06 15:28:29.749377 (Thread-1): 15:28:29  On rpc.my_new_project.request: with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from dev.jaffle_shop.orders

)
select * from orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 15:28:29.749456 (Thread-1): 15:28:29  Opening a new connection, currently in state init
2022-01-06 15:28:29.749539 (Thread-1): 15:28:29  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:28:29.770188 (Thread-1): 15:28:29  SQL status: SELECT in 0.02 seconds
2022-01-06 15:28:29.772816 (Thread-1): 15:28:29  finished collecting timing info
2022-01-06 15:28:29.772956 (Thread-1): 15:28:29  On rpc.my_new_project.request: Close
2022-01-06 15:28:30.120544 (Thread-311): handling poll request
2022-01-06 15:28:30.121008 (Thread-311): 15:28:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bec0250>]}
2022-01-06 15:28:30.122878 (Thread-311): sending response (<Response 11872 bytes [200 OK]>) to 10.0.0.136
2022-01-06 15:28:35.163472 (Thread-312): handling status request
2022-01-06 15:28:35.163860 (Thread-312): 15:28:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf35700>]}
2022-01-06 15:28:35.164402 (Thread-312): sending response (<Response 1244 bytes [200 OK]>) to 10.0.0.136
2022-01-06 15:28:35.526059 (Thread-313): handling run_sql request
2022-01-06 15:28:35.526401 (Thread-313): 15:28:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bec0070>]}
2022-01-06 15:28:37.581831 (Thread-313): sending response (<Response 138 bytes [200 OK]>) to 10.0.32.116
2022-01-06 15:28:37.606278 (MainThread): 15:28:37  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6aa01e48-3452-42bd-b355-274e36c4309d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2712130d0>]}
2022-01-06 15:28:37.606800 (MainThread): 15:28:37  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:28:37.607369 (Thread-1): 15:28:37  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:28:37.607498 (Thread-1): 15:28:37  Began compiling node rpc.my_new_project.request
2022-01-06 15:28:37.607589 (Thread-1): 15:28:37  Compiling rpc.my_new_project.request
2022-01-06 15:28:37.609970 (Thread-1): 15:28:37  finished collecting timing info
2022-01-06 15:28:37.610098 (Thread-1): 15:28:37  Began executing node rpc.my_new_project.request
2022-01-06 15:28:37.610193 (Thread-1): 15:28:37  Using redshift connection "rpc.my_new_project.request"
2022-01-06 15:28:37.610267 (Thread-1): 15:28:37  On rpc.my_new_project.request: with customers as (
    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"
),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 15:28:37.610343 (Thread-1): 15:28:37  Opening a new connection, currently in state init
2022-01-06 15:28:37.610422 (Thread-1): 15:28:37  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:28:37.631229 (Thread-1): 15:28:37  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 15:28:37.631384 (Thread-1): 15:28:37  finished collecting timing info
2022-01-06 15:28:37.631498 (Thread-1): 15:28:37  On rpc.my_new_project.request: Close
2022-01-06 15:28:37.631747 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 15:28:37.632695 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': "with customers as (\n    select * from {{ ref('stg_customers')}}\n),\n\norders as (\n\n    select * from {{ ref('stg_orders') }}\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': "with customers as (\n    select * from {{ ref('stg_customers')}}\n),\n\norders as (\n\n    select * from {{ ref('stg_orders') }}\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 15:28:37.986097 (Thread-314): handling poll request
2022-01-06 15:28:37.986545 (Thread-314): 15:28:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bec7520>]}
2022-01-06 15:28:37.987394 (Thread-314): sending response (<Response 14508 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:29:46.787474 (Thread-315): handling ps request
2022-01-06 15:29:46.787996 (Thread-315): 15:29:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bec7a60>]}
2022-01-06 15:29:46.788591 (Thread-316): handling status request
2022-01-06 15:29:46.791288 (Thread-315): sending response (<Response 26758 bytes [200 OK]>) to 10.0.10.175
2022-01-06 15:29:46.791645 (Thread-316): 15:29:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2becd340>]}
2022-01-06 15:29:46.792398 (Thread-316): sending response (<Response 1244 bytes [200 OK]>) to 10.0.45.144
2022-01-06 15:29:46.830181 (Thread-317): handling status request
2022-01-06 15:29:46.830423 (Thread-317): 15:29:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2becd910>]}
2022-01-06 15:29:46.830803 (Thread-317): sending response (<Response 1244 bytes [200 OK]>) to 10.0.26.175
2022-01-06 15:29:46.861682 (Thread-318): handling status request
2022-01-06 15:29:46.861952 (Thread-318): 15:29:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2becdc10>]}
2022-01-06 15:29:46.862372 (Thread-318): sending response (<Response 1244 bytes [200 OK]>) to 10.0.23.79
2022-01-06 15:29:47.879260 (Thread-319): handling poll request
2022-01-06 15:29:47.879615 (Thread-319): 15:29:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2becde80>]}
2022-01-06 15:29:47.882064 (Thread-319): sending response (<Response 72921 bytes [200 OK]>) to 10.0.33.128
2022-01-06 15:29:48.509284 (Thread-320): handling status request
2022-01-06 15:29:48.509650 (Thread-320): 15:29:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bec7c40>]}
2022-01-06 15:29:48.510107 (Thread-320): sending response (<Response 1244 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:29:48.547730 (Thread-321): handling status request
2022-01-06 15:29:48.548002 (Thread-321): 15:29:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bec7fd0>]}
2022-01-06 15:29:48.555474 (Thread-321): sending response (<Response 1244 bytes [200 OK]>) to 10.0.2.170
2022-01-06 15:29:57.485294 (Thread-322): handling status request
2022-01-06 15:29:57.485672 (Thread-322): 15:29:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bec7a60>]}
2022-01-06 15:29:57.486150 (Thread-322): sending response (<Response 1244 bytes [200 OK]>) to 10.0.15.56
2022-01-06 15:29:57.798860 (Thread-323): handling run_sql request
2022-01-06 15:29:57.799220 (Thread-323): 15:29:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bec0fa0>]}
2022-01-06 15:29:59.821898 (Thread-323): sending response (<Response 138 bytes [200 OK]>) to 10.0.10.175
2022-01-06 15:29:59.846128 (MainThread): 15:29:59  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f765dc36-cc44-43fe-8898-7a372aca91c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c952a1400>]}
2022-01-06 15:29:59.846679 (MainThread): 15:29:59  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:29:59.847245 (Thread-1): 15:29:59  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:29:59.847379 (Thread-1): 15:29:59  Began compiling node rpc.my_new_project.request
2022-01-06 15:29:59.847469 (Thread-1): 15:29:59  Compiling rpc.my_new_project.request
2022-01-06 15:29:59.849441 (Thread-1): 15:29:59  finished collecting timing info
2022-01-06 15:29:59.849569 (Thread-1): 15:29:59  Began executing node rpc.my_new_project.request
2022-01-06 15:29:59.849663 (Thread-1): 15:29:59  Using redshift connection "rpc.my_new_project.request"
2022-01-06 15:29:59.849735 (Thread-1): 15:29:59  On rpc.my_new_project.request: with customers as (
    select * from "dev"."dbt_nobodozie"."stg_customers"
)
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 15:29:59.849812 (Thread-1): 15:29:59  Opening a new connection, currently in state init
2022-01-06 15:29:59.849887 (Thread-1): 15:29:59  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:29:59.869711 (Thread-1): 15:29:59  Postgres adapter: Postgres error: syntax error at or near "limit"
LINE 4: limit 500
        ^

2022-01-06 15:29:59.869871 (Thread-1): 15:29:59  finished collecting timing info
2022-01-06 15:29:59.869989 (Thread-1): 15:29:59  On rpc.my_new_project.request: Close
2022-01-06 15:29:59.870271 (Thread-1): Got an exception: Database Error
  syntax error at or near "limit"
  LINE 4: limit 500
          ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "limit"
LINE 4: limit 500
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "limit"
  LINE 4: limit 500
          ^
2022-01-06 15:29:59.871217 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "limit"\n  LINE 4: limit 500\n          ^', 'raw_sql': "with customers as (\n    select * from {{ ref('stg_customers')}}\n)\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n)\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "limit"\n  LINE 4: limit 500\n          ^', 'raw_sql': "with customers as (\n    select * from {{ ref('stg_customers')}}\n)\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n)\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 15:30:00.217431 (Thread-324): handling poll request
2022-01-06 15:30:00.217851 (Thread-324): 15:30:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bed7e50>]}
2022-01-06 15:30:00.218631 (Thread-324): sending response (<Response 9434 bytes [200 OK]>) to 10.0.0.136
2022-01-06 15:31:28.997643 (Thread-325): handling status request
2022-01-06 15:31:28.999608 (Thread-325): 15:31:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bed79a0>]}
2022-01-06 15:31:29.000136 (Thread-325): sending response (<Response 1244 bytes [200 OK]>) to 10.0.10.175
2022-01-06 15:31:29.402905 (Thread-326): handling run_sql request
2022-01-06 15:31:29.403270 (Thread-326): 15:31:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bee66a0>]}
2022-01-06 15:31:31.467380 (Thread-326): sending response (<Response 138 bytes [200 OK]>) to 10.0.29.240
2022-01-06 15:31:31.503266 (MainThread): 15:31:31  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7bb556b0-3933-4dea-8df8-7d67049bab56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef345f3700>]}
2022-01-06 15:31:31.503860 (MainThread): 15:31:31  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:31:31.504480 (Thread-1): 15:31:31  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:31:31.504613 (Thread-1): 15:31:31  Began compiling node rpc.my_new_project.request
2022-01-06 15:31:31.504705 (Thread-1): 15:31:31  Compiling rpc.my_new_project.request
2022-01-06 15:31:31.505990 (Thread-1): 15:31:31  finished collecting timing info
2022-01-06 15:31:31.506121 (Thread-1): 15:31:31  Began executing node rpc.my_new_project.request
2022-01-06 15:31:31.506223 (Thread-1): 15:31:31  Using redshift connection "rpc.my_new_project.request"
2022-01-06 15:31:31.506306 (Thread-1): 15:31:31  On rpc.my_new_project.request: create schema if not exists jaffle_shop;
	
create schema if not exists stripe;

create table jaffle_shop.customers(
  id integer,
  first_name varchar(50),
  last_name varchar(50)
);
	
create table jaffle_shop.orders(
  id integer,
  user_id integer,
  order_date date,
  status varchar(50),
  _etl_loaded_at timestamp default current_timestamp
);
	
create table stripe.payment(
  id integer,
  orderid integer,
  paymentmethod varchar(50),
  status varchar(50),
  amount integer,
  created date,
  _batched_at timestamp default current_timestamp
);


copy jaffle_shop.orders(id, user_id, order_date, status)
from 's3://dbt-tutorial-public/jaffle_shop_orders.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;

copy stripe.payment(id, orderid, paymentmethod, status, amount, created)
from 's3://dbt-tutorial-public/stripe_payments.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;

copy jaffle_shop.customers( id, first_name, last_name)
from 's3://dbt-tutorial-public/jaffle_shop_customers.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 15:31:31.506389 (Thread-1): 15:31:31  Opening a new connection, currently in state init
2022-01-06 15:31:31.506491 (Thread-1): 15:31:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:31:31.528073 (Thread-1): 15:31:31  Postgres adapter: Postgres error: syntax error at or near "limit"
LINE 53: limit 500
         ^

2022-01-06 15:31:31.528234 (Thread-1): 15:31:31  finished collecting timing info
2022-01-06 15:31:31.528360 (Thread-1): 15:31:31  On rpc.my_new_project.request: Close
2022-01-06 15:31:31.528643 (Thread-1): Got an exception: Database Error
  syntax error at or near "limit"
  LINE 53: limit 500
           ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "limit"
LINE 53: limit 500
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "limit"
  LINE 53: limit 500
           ^
2022-01-06 15:31:31.529650 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "limit"\n  LINE 53: limit 500\n           ^', 'raw_sql': "create schema if not exists jaffle_shop;\n\t\ncreate schema if not exists stripe;\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create schema if not exists jaffle_shop;\n\t\ncreate schema if not exists stripe;\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "limit"\n  LINE 53: limit 500\n           ^', 'raw_sql': "create schema if not exists jaffle_shop;\n\t\ncreate schema if not exists stripe;\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create schema if not exists jaffle_shop;\n\t\ncreate schema if not exists stripe;\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-01-06 15:31:31.807175 (Thread-327): handling poll request
2022-01-06 15:31:31.807609 (Thread-327): 15:31:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2becdac0>]}
2022-01-06 15:31:31.808456 (Thread-327): sending response (<Response 19331 bytes [200 OK]>) to 10.0.45.144
2022-01-06 15:33:40.625718 (Thread-328): 15:33:40  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 15:33:40.629189 (Thread-328): 15:33:40  Partial parsing: updated file: my_new_project://models/stg_customers.sql
2022-01-06 15:33:40.633473 (Thread-328): 15:33:40  1699: static parser successfully parsed stg_customers.sql
2022-01-06 15:33:40.706648 (Thread-328): 15:33:40  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bdf0040>]}
2022-01-06 15:33:41.238667 (Thread-329): handling status request
2022-01-06 15:33:41.239043 (Thread-329): 15:33:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2be63ac0>]}
2022-01-06 15:33:41.239555 (Thread-329): sending response (<Response 1556 bytes [200 OK]>) to 10.0.32.116
2022-01-06 15:33:41.976338 (Thread-330): handling status request
2022-01-06 15:33:41.976733 (Thread-330): 15:33:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2be63ca0>]}
2022-01-06 15:33:41.977250 (Thread-330): sending response (<Response 1556 bytes [200 OK]>) to 10.0.0.136
2022-01-06 15:33:44.753017 (Thread-331): handling status request
2022-01-06 15:33:44.753414 (Thread-331): 15:33:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2be63820>]}
2022-01-06 15:33:44.753898 (Thread-331): sending response (<Response 1556 bytes [200 OK]>) to 10.0.4.41
2022-01-06 15:33:45.158506 (Thread-332): handling run_sql request
2022-01-06 15:33:45.158895 (Thread-332): 15:33:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2be73400>]}
2022-01-06 15:33:47.234368 (Thread-332): sending response (<Response 138 bytes [200 OK]>) to 10.0.21.24
2022-01-06 15:33:47.258503 (MainThread): 15:33:47  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b43c9d21-bd85-47c0-adb0-89c4918b33c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faae8f81820>]}
2022-01-06 15:33:47.259002 (MainThread): 15:33:47  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:33:47.259568 (Thread-1): 15:33:47  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:33:47.259697 (Thread-1): 15:33:47  Began compiling node rpc.my_new_project.request
2022-01-06 15:33:47.259785 (Thread-1): 15:33:47  Compiling rpc.my_new_project.request
2022-01-06 15:33:47.260906 (Thread-1): 15:33:47  finished collecting timing info
2022-01-06 15:33:47.261031 (Thread-1): 15:33:47  Began executing node rpc.my_new_project.request
2022-01-06 15:33:47.261131 (Thread-1): 15:33:47  Using redshift connection "rpc.my_new_project.request"
2022-01-06 15:33:47.261208 (Thread-1): 15:33:47  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 15:33:47.261316 (Thread-1): 15:33:47  Opening a new connection, currently in state init
2022-01-06 15:33:47.261402 (Thread-1): 15:33:47  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:33:47.282212 (Thread-1): 15:33:47  SQL status: SELECT in 0.02 seconds
2022-01-06 15:33:47.283993 (Thread-1): 15:33:47  finished collecting timing info
2022-01-06 15:33:47.284122 (Thread-1): 15:33:47  On rpc.my_new_project.request: Close
2022-01-06 15:33:47.592580 (Thread-333): handling poll request
2022-01-06 15:33:47.593024 (Thread-333): 15:33:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bdee2e0>]}
2022-01-06 15:33:47.594493 (Thread-333): sending response (<Response 10152 bytes [200 OK]>) to 10.0.26.175
2022-01-06 15:34:10.192906 (Thread-334): 15:34:10  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 15:34:10.193333 (Thread-334): 15:34:10  Partial parsing: updated file: my_new_project://models/stg_orders.sql
2022-01-06 15:34:10.197907 (Thread-334): 15:34:10  1699: static parser successfully parsed stg_orders.sql
2022-01-06 15:34:10.249468 (Thread-334): 15:34:10  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bd9fe80>]}
2022-01-06 15:34:10.876227 (Thread-335): handling status request
2022-01-06 15:34:10.876618 (Thread-335): 15:34:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bd8bdf0>]}
2022-01-06 15:34:10.877123 (Thread-335): sending response (<Response 1550 bytes [200 OK]>) to 10.0.40.96
2022-01-06 15:34:10.923788 (Thread-336): handling status request
2022-01-06 15:34:10.924042 (Thread-336): 15:34:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bd8ba00>]}
2022-01-06 15:34:10.948366 (Thread-336): sending response (<Response 1550 bytes [200 OK]>) to 10.0.30.119
2022-01-06 15:35:33.181679 (Thread-337): handling status request
2022-01-06 15:35:33.183387 (Thread-337): 15:35:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bd8bb20>]}
2022-01-06 15:35:33.183888 (Thread-337): sending response (<Response 1550 bytes [200 OK]>) to 10.0.40.96
2022-01-06 15:35:33.550513 (Thread-338): handling run_sql request
2022-01-06 15:35:33.550872 (Thread-338): 15:35:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bd8b310>]}
2022-01-06 15:35:35.616705 (Thread-338): sending response (<Response 138 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:35:35.644778 (MainThread): 15:35:35  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '70e26f58-ae8e-44f1-a0ae-65ab4be4bf63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6f0a97a90>]}
2022-01-06 15:35:35.645361 (MainThread): 15:35:35  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:35:35.645904 (Thread-1): 15:35:35  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:35:35.646035 (Thread-1): 15:35:35  Began compiling node rpc.my_new_project.request
2022-01-06 15:35:35.646125 (Thread-1): 15:35:35  Compiling rpc.my_new_project.request
2022-01-06 15:35:35.648643 (Thread-1): 15:35:35  finished collecting timing info
2022-01-06 15:35:35.648769 (Thread-1): 15:35:35  Began executing node rpc.my_new_project.request
2022-01-06 15:35:35.648866 (Thread-1): 15:35:35  Using redshift connection "rpc.my_new_project.request"
2022-01-06 15:35:35.648942 (Thread-1): 15:35:35  On rpc.my_new_project.request: 

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"


),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 15:35:35.649017 (Thread-1): 15:35:35  Opening a new connection, currently in state init
2022-01-06 15:35:35.649095 (Thread-1): 15:35:35  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:35:35.670946 (Thread-1): 15:35:35  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 15:35:35.671102 (Thread-1): 15:35:35  finished collecting timing info
2022-01-06 15:35:35.671219 (Thread-1): 15:35:35  On rpc.my_new_project.request: Close
2022-01-06 15:35:35.671397 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 15:35:35.672547 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 15:35:35.983225 (Thread-339): handling poll request
2022-01-06 15:35:35.983658 (Thread-339): 15:35:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2be23640>]}
2022-01-06 15:35:35.984586 (Thread-339): sending response (<Response 14743 bytes [200 OK]>) to 10.0.45.144
2022-01-06 15:35:45.206656 (Thread-340): handling status request
2022-01-06 15:35:45.207037 (Thread-340): 15:35:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bd9e190>]}
2022-01-06 15:35:45.207575 (Thread-340): sending response (<Response 1550 bytes [200 OK]>) to 10.0.21.24
2022-01-06 15:35:45.552137 (Thread-341): handling compile_sql request
2022-01-06 15:35:45.552446 (Thread-341): 15:35:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bd9edc0>]}
2022-01-06 15:35:46.599410 (Thread-342): 15:35:46  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 15:35:46.599895 (Thread-342): 15:35:46  Partial parsing: updated file: my_new_project://models/dim_customers.sql
2022-01-06 15:35:46.604268 (Thread-342): 15:35:46  1699: static parser successfully parsed dim_customers.sql
2022-01-06 15:35:46.652636 (Thread-342): 15:35:46  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bcd5430>]}
2022-01-06 15:35:47.134308 (Thread-343): handling status request
2022-01-06 15:35:47.134708 (Thread-343): 15:35:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bcb7d30>]}
2022-01-06 15:35:47.135342 (Thread-343): sending response (<Response 1556 bytes [200 OK]>) to 10.0.21.24
2022-01-06 15:35:47.159717 (Thread-344): handling status request
2022-01-06 15:35:47.159981 (Thread-344): 15:35:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bcb7a60>]}
2022-01-06 15:35:47.160406 (Thread-344): sending response (<Response 1556 bytes [200 OK]>) to 10.0.4.41
2022-01-06 15:35:47.592693 (Thread-341): sending response (<Response 138 bytes [200 OK]>) to 10.0.45.144
2022-01-06 15:35:47.618116 (MainThread): 15:35:47  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6ea3eac0-b4a8-42cd-81ee-d73edaa4fd1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8bd874a30>]}
2022-01-06 15:35:47.618624 (MainThread): 15:35:47  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:35:47.619190 (Thread-1): 15:35:47  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:35:47.619323 (Thread-1): 15:35:47  Began compiling node rpc.my_new_project.request
2022-01-06 15:35:47.619412 (Thread-1): 15:35:47  Compiling rpc.my_new_project.request
2022-01-06 15:35:47.621920 (Thread-1): 15:35:47  finished collecting timing info
2022-01-06 15:35:47.622045 (Thread-1): 15:35:47  Began executing node rpc.my_new_project.request
2022-01-06 15:35:47.622141 (Thread-1): 15:35:47  finished collecting timing info
2022-01-06 15:35:47.944055 (Thread-345): handling poll request
2022-01-06 15:35:47.944410 (Thread-345): 15:35:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bcb7130>]}
2022-01-06 15:35:47.945279 (Thread-345): sending response (<Response 8498 bytes [200 OK]>) to 10.0.26.175
2022-01-06 15:35:56.538166 (Thread-346): handling status request
2022-01-06 15:35:56.538534 (Thread-346): 15:35:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bd9e610>]}
2022-01-06 15:35:56.539044 (Thread-346): sending response (<Response 1556 bytes [200 OK]>) to 10.0.45.144
2022-01-06 15:35:56.722218 (Thread-347): handling status request
2022-01-06 15:35:56.722543 (Thread-347): 15:35:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bd9ff40>]}
2022-01-06 15:35:56.722990 (Thread-347): sending response (<Response 1556 bytes [200 OK]>) to 10.0.30.119
2022-01-06 15:35:56.861891 (Thread-348): handling cli_args request
2022-01-06 15:35:56.862162 (Thread-348): 15:35:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bcff610>]}
2022-01-06 15:35:58.912266 (Thread-348): sending response (<Response 138 bytes [200 OK]>) to 10.0.33.128
2022-01-06 15:35:58.991760 (MainThread): 15:35:58  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 15:35:58.992139 (MainThread): 15:35:58  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 15:35:58.997695 (MainThread): 15:35:58  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '57630187-f2e4-4ce3-8587-346942a50533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b85ad9d90>]}
2022-01-06 15:35:59.030707 (MainThread): 15:35:59  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '57630187-f2e4-4ce3-8587-346942a50533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b85b7c5e0>]}
2022-01-06 15:35:59.030939 (MainThread): 15:35:59  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:35:59.031990 (MainThread): 15:35:59  
2022-01-06 15:35:59.032253 (MainThread): 15:35:59  Acquiring new redshift connection "master"
2022-01-06 15:35:59.033304 (ThreadPoolExecutor-0_0): 15:35:59  Acquiring new redshift connection "list_dev"
2022-01-06 15:35:59.042896 (ThreadPoolExecutor-0_0): 15:35:59  Using redshift connection "list_dev"
2022-01-06 15:35:59.042998 (ThreadPoolExecutor-0_0): 15:35:59  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 15:35:59.043241 (ThreadPoolExecutor-0_0): 15:35:59  Opening a new connection, currently in state init
2022-01-06 15:35:59.043338 (ThreadPoolExecutor-0_0): 15:35:59  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:35:59.065099 (ThreadPoolExecutor-0_0): 15:35:59  SQL status: SELECT in 0.02 seconds
2022-01-06 15:35:59.066137 (ThreadPoolExecutor-0_0): 15:35:59  On list_dev: Close
2022-01-06 15:35:59.067313 (ThreadPoolExecutor-1_0): 15:35:59  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:35:59.073719 (ThreadPoolExecutor-1_0): 15:35:59  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:35:59.073821 (ThreadPoolExecutor-1_0): 15:35:59  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 15:35:59.073901 (ThreadPoolExecutor-1_0): 15:35:59  Opening a new connection, currently in state closed
2022-01-06 15:35:59.073977 (ThreadPoolExecutor-1_0): 15:35:59  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:35:59.097582 (ThreadPoolExecutor-1_0): 15:35:59  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:35:59.097692 (ThreadPoolExecutor-1_0): 15:35:59  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:35:59.097768 (ThreadPoolExecutor-1_0): 15:35:59  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 15:35:59.109305 (ThreadPoolExecutor-1_0): 15:35:59  SQL status: SELECT in 0.01 seconds
2022-01-06 15:35:59.110316 (ThreadPoolExecutor-1_0): 15:35:59  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 15:35:59.112389 (ThreadPoolExecutor-1_0): 15:35:59  On list_dev_dbt_nobodozie: Close
2022-01-06 15:35:59.115984 (MainThread): 15:35:59  Using redshift connection "master"
2022-01-06 15:35:59.116096 (MainThread): 15:35:59  On master: BEGIN
2022-01-06 15:35:59.116176 (MainThread): 15:35:59  Opening a new connection, currently in state init
2022-01-06 15:35:59.116249 (MainThread): 15:35:59  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:35:59.141240 (MainThread): 15:35:59  SQL status: BEGIN in 0.03 seconds
2022-01-06 15:35:59.141349 (MainThread): 15:35:59  Using redshift connection "master"
2022-01-06 15:35:59.141425 (MainThread): 15:35:59  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 15:35:59.170488 (MainThread): 15:35:59  SQL status: SELECT in 0.03 seconds
2022-01-06 15:35:59.171430 (MainThread): 15:35:59  On master: ROLLBACK
2022-01-06 15:35:59.173411 (MainThread): 15:35:59  Using redshift connection "master"
2022-01-06 15:35:59.173521 (MainThread): 15:35:59  On master: BEGIN
2022-01-06 15:35:59.177142 (MainThread): 15:35:59  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:35:59.177271 (MainThread): 15:35:59  On master: COMMIT
2022-01-06 15:35:59.177345 (MainThread): 15:35:59  Using redshift connection "master"
2022-01-06 15:35:59.177411 (MainThread): 15:35:59  On master: COMMIT
2022-01-06 15:35:59.179294 (MainThread): 15:35:59  SQL status: COMMIT in 0.0 seconds
2022-01-06 15:35:59.179402 (MainThread): 15:35:59  On master: Close
2022-01-06 15:35:59.179761 (MainThread): 15:35:59  Concurrency: 4 threads (target='default')
2022-01-06 15:35:59.179876 (MainThread): 15:35:59  
2022-01-06 15:35:59.182064 (Thread-1): 15:35:59  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 15:35:59.182301 (Thread-1): 15:35:59  1 of 5 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 15:35:59.182539 (Thread-1): 15:35:59  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:35:59.182633 (Thread-1): 15:35:59  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 15:35:59.182729 (Thread-1): 15:35:59  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 15:35:59.184796 (Thread-1): 15:35:59  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 15:35:59.185026 (Thread-2): 15:35:59  Began running node model.my_new_project.stg_customers
2022-01-06 15:35:59.185277 (Thread-2): 15:35:59  2 of 5 START view model dbt_nobodozie.stg_customers............................. [RUN]
2022-01-06 15:35:59.185525 (Thread-2): 15:35:59  Acquiring new redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:35:59.185662 (Thread-2): 15:35:59  Began compiling node model.my_new_project.stg_customers
2022-01-06 15:35:59.185752 (Thread-2): 15:35:59  Compiling model.my_new_project.stg_customers
2022-01-06 15:35:59.186865 (Thread-2): 15:35:59  Writing injected SQL for node "model.my_new_project.stg_customers"
2022-01-06 15:35:59.187245 (Thread-3): 15:35:59  Began running node model.my_new_project.stg_orders
2022-01-06 15:35:59.187500 (Thread-3): 15:35:59  3 of 5 START view model dbt_nobodozie.stg_orders................................ [RUN]
2022-01-06 15:35:59.187739 (Thread-3): 15:35:59  Acquiring new redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:35:59.187828 (Thread-3): 15:35:59  Began compiling node model.my_new_project.stg_orders
2022-01-06 15:35:59.187907 (Thread-3): 15:35:59  Compiling model.my_new_project.stg_orders
2022-01-06 15:35:59.189003 (Thread-3): 15:35:59  Writing injected SQL for node "model.my_new_project.stg_orders"
2022-01-06 15:35:59.204030 (Thread-2): 15:35:59  finished collecting timing info
2022-01-06 15:35:59.204172 (Thread-2): 15:35:59  Began executing node model.my_new_project.stg_customers
2022-01-06 15:35:59.209302 (Thread-3): 15:35:59  finished collecting timing info
2022-01-06 15:35:59.209429 (Thread-3): 15:35:59  Began executing node model.my_new_project.stg_orders
2022-01-06 15:35:59.227012 (Thread-1): 15:35:59  finished collecting timing info
2022-01-06 15:35:59.227144 (Thread-1): 15:35:59  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 15:35:59.257270 (Thread-3): 15:35:59  Writing runtime SQL for node "model.my_new_project.stg_orders"
2022-01-06 15:35:59.258028 (Thread-2): 15:35:59  Writing runtime SQL for node "model.my_new_project.stg_customers"
2022-01-06 15:35:59.267527 (Thread-1): 15:35:59  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 15:35:59.274406 (Thread-2): 15:35:59  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:35:59.274522 (Thread-2): 15:35:59  On model.my_new_project.stg_customers: BEGIN
2022-01-06 15:35:59.274606 (Thread-2): 15:35:59  Opening a new connection, currently in state init
2022-01-06 15:35:59.274685 (Thread-2): 15:35:59  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:35:59.278222 (Thread-3): 15:35:59  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:35:59.278335 (Thread-3): 15:35:59  On model.my_new_project.stg_orders: BEGIN
2022-01-06 15:35:59.278416 (Thread-3): 15:35:59  Opening a new connection, currently in state init
2022-01-06 15:35:59.278492 (Thread-3): 15:35:59  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:35:59.281589 (Thread-1): 15:35:59  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:35:59.281695 (Thread-1): 15:35:59  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:35:59.281774 (Thread-1): 15:35:59  Opening a new connection, currently in state closed
2022-01-06 15:35:59.281846 (Thread-1): 15:35:59  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:35:59.289734 (Thread-349): handling poll request
2022-01-06 15:35:59.290102 (Thread-349): 15:35:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bc5c880>]}
2022-01-06 15:35:59.291593 (Thread-349): sending response (<Response 31538 bytes [200 OK]>) to 10.0.0.136
2022-01-06 15:35:59.302823 (Thread-2): 15:35:59  SQL status: BEGIN in 0.03 seconds
2022-01-06 15:35:59.302933 (Thread-2): 15:35:59  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:35:59.303009 (Thread-2): 15:35:59  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */


  create view "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
  ) ;

2022-01-06 15:35:59.306088 (Thread-3): 15:35:59  SQL status: BEGIN in 0.03 seconds
2022-01-06 15:35:59.306209 (Thread-3): 15:35:59  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:35:59.306287 (Thread-3): 15:35:59  On model.my_new_project.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_orders"} */


  create view "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" as (
    orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
  ) ;

2022-01-06 15:35:59.309975 (Thread-2): 15:35:59  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 15:35:59.315311 (Thread-3): 15:35:59  Postgres adapter: Postgres error: syntax error at or near "orders"
LINE 5:     orders as (
            ^

2022-01-06 15:35:59.315423 (Thread-3): 15:35:59  On model.my_new_project.stg_orders: ROLLBACK
2022-01-06 15:35:59.316214 (Thread-2): 15:35:59  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:35:59.316318 (Thread-2): 15:35:59  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" rename to "stg_customers"
2022-01-06 15:35:59.317377 (Thread-3): 15:35:59  finished collecting timing info
2022-01-06 15:35:59.317522 (Thread-3): 15:35:59  On model.my_new_project.stg_orders: Close
2022-01-06 15:35:59.317957 (Thread-3): 15:35:59  Database Error in model stg_orders (models/stg_orders.sql)
  syntax error at or near "orders"
  LINE 5:     orders as (
              ^
  compiled SQL at target/run/my_new_project/models/stg_orders.sql
2022-01-06 15:35:59.318149 (Thread-3): 15:35:59  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57630187-f2e4-4ce3-8587-346942a50533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b841eca60>]}
2022-01-06 15:35:59.318432 (Thread-3): 15:35:59  3 of 5 ERROR creating view model dbt_nobodozie.stg_orders....................... [ERROR in 0.13s]
2022-01-06 15:35:59.318541 (Thread-3): 15:35:59  Finished running node model.my_new_project.stg_orders
2022-01-06 15:35:59.321641 (Thread-2): 15:35:59  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 15:35:59.328212 (Thread-2): 15:35:59  On model.my_new_project.stg_customers: COMMIT
2022-01-06 15:35:59.328361 (Thread-2): 15:35:59  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:35:59.328471 (Thread-2): 15:35:59  On model.my_new_project.stg_customers: COMMIT
2022-01-06 15:35:59.328643 (Thread-1): 15:35:59  SQL status: BEGIN in 0.05 seconds
2022-01-06 15:35:59.328746 (Thread-1): 15:35:59  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:35:59.328820 (Thread-1): 15:35:59  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 15:35:59.380360 (Thread-2): 15:35:59  SQL status: COMMIT in 0.05 seconds
2022-01-06 15:35:59.380576 (Thread-2): 15:35:59  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:35:59.380712 (Thread-2): 15:35:59  On model.my_new_project.stg_customers: BEGIN
2022-01-06 15:35:59.384289 (Thread-2): 15:35:59  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:35:59.388237 (Thread-2): 15:35:59  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:35:59.388335 (Thread-2): 15:35:59  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */
drop view if exists "dev"."dbt_nobodozie"."stg_customers__dbt_backup" cascade
2022-01-06 15:35:59.393497 (Thread-2): 15:35:59  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 15:35:59.394125 (Thread-2): 15:35:59  On model.my_new_project.stg_customers: COMMIT
2022-01-06 15:35:59.394220 (Thread-2): 15:35:59  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:35:59.394294 (Thread-2): 15:35:59  On model.my_new_project.stg_customers: COMMIT
2022-01-06 15:35:59.405187 (Thread-1): 15:35:59  SQL status: SELECT in 0.08 seconds
2022-01-06 15:35:59.407123 (Thread-1): 15:35:59  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:35:59.407222 (Thread-1): 15:35:59  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 15:35:59.411013 (Thread-1): 15:35:59  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:35:59.412676 (Thread-1): 15:35:59  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:35:59.412774 (Thread-1): 15:35:59  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 15:35:59.417058 (Thread-1): 15:35:59  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:35:59.421705 (Thread-1): 15:35:59  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:35:59.421807 (Thread-1): 15:35:59  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:35:59.421881 (Thread-1): 15:35:59  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:35:59.428121 (Thread-2): 15:35:59  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:35:59.428240 (Thread-2): 15:35:59  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:35:59.428313 (Thread-2): 15:35:59  On model.my_new_project.stg_customers: BEGIN
2022-01-06 15:35:59.434701 (Thread-2): 15:35:59  SQL status: BEGIN in 0.01 seconds
2022-01-06 15:35:59.435072 (Thread-2): 15:35:59  finished collecting timing info
2022-01-06 15:35:59.435191 (Thread-2): 15:35:59  On model.my_new_project.stg_customers: ROLLBACK
2022-01-06 15:35:59.437280 (Thread-2): 15:35:59  On model.my_new_project.stg_customers: Close
2022-01-06 15:35:59.437675 (Thread-2): 15:35:59  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57630187-f2e4-4ce3-8587-346942a50533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b841bdf10>]}
2022-01-06 15:35:59.437968 (Thread-2): 15:35:59  2 of 5 OK created view model dbt_nobodozie.stg_customers........................ [CREATE VIEW in 0.25s]
2022-01-06 15:35:59.438074 (Thread-2): 15:35:59  Finished running node model.my_new_project.stg_customers
2022-01-06 15:35:59.438612 (Thread-4): 15:35:59  Began running node model.my_new_project.dim_customers
2022-01-06 15:35:59.438755 (Thread-4): 15:35:59  4 of 5 SKIP relation dbt_nobodozie.dim_customers................................ [SKIP]
2022-01-06 15:35:59.438850 (Thread-4): 15:35:59  Finished running node model.my_new_project.dim_customers
2022-01-06 15:35:59.465541 (Thread-1): 15:35:59  SQL status: COMMIT in 0.04 seconds
2022-01-06 15:35:59.465754 (Thread-1): 15:35:59  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:35:59.465836 (Thread-1): 15:35:59  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:35:59.468009 (Thread-1): 15:35:59  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:35:59.469900 (Thread-1): 15:35:59  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:35:59.470045 (Thread-1): 15:35:59  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 15:35:59.475437 (Thread-1): 15:35:59  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 15:35:59.476404 (Thread-1): 15:35:59  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:35:59.476535 (Thread-1): 15:35:59  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:35:59.476649 (Thread-1): 15:35:59  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:35:59.506953 (Thread-1): 15:35:59  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:35:59.507075 (Thread-1): 15:35:59  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:35:59.507152 (Thread-1): 15:35:59  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:35:59.509272 (Thread-1): 15:35:59  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:35:59.509635 (Thread-1): 15:35:59  finished collecting timing info
2022-01-06 15:35:59.509754 (Thread-1): 15:35:59  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 15:35:59.511618 (Thread-1): 15:35:59  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 15:35:59.512016 (Thread-1): 15:35:59  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57630187-f2e4-4ce3-8587-346942a50533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b841cfd60>]}
2022-01-06 15:35:59.512303 (Thread-1): 15:35:59  1 of 5 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.33s]
2022-01-06 15:35:59.512444 (Thread-1): 15:35:59  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 15:35:59.513282 (Thread-2): 15:35:59  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 15:35:59.513518 (Thread-2): 15:35:59  5 of 5 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 15:35:59.513738 (Thread-2): 15:35:59  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:35:59.513828 (Thread-2): 15:35:59  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 15:35:59.513912 (Thread-2): 15:35:59  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 15:35:59.515683 (Thread-2): 15:35:59  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 15:35:59.530178 (Thread-2): 15:35:59  finished collecting timing info
2022-01-06 15:35:59.530309 (Thread-2): 15:35:59  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 15:35:59.532076 (Thread-2): 15:35:59  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 15:35:59.546663 (Thread-2): 15:35:59  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:35:59.546770 (Thread-2): 15:35:59  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:35:59.546852 (Thread-2): 15:35:59  Opening a new connection, currently in state closed
2022-01-06 15:35:59.546930 (Thread-2): 15:35:59  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:35:59.645940 (Thread-2): 15:35:59  SQL status: BEGIN in 0.1 seconds
2022-01-06 15:35:59.646049 (Thread-2): 15:35:59  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:35:59.646124 (Thread-2): 15:35:59  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 15:35:59.650764 (Thread-2): 15:35:59  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 15:35:59.652514 (Thread-2): 15:35:59  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:35:59.652607 (Thread-2): 15:35:59  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 15:35:59.654772 (Thread-2): 15:35:59  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:35:59.655672 (Thread-2): 15:35:59  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:35:59.655765 (Thread-2): 15:35:59  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:35:59.655836 (Thread-2): 15:35:59  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:35:59.684807 (Thread-2): 15:35:59  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:35:59.685015 (Thread-2): 15:35:59  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:35:59.685095 (Thread-2): 15:35:59  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:35:59.687060 (Thread-2): 15:35:59  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:35:59.688264 (Thread-2): 15:35:59  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:35:59.688362 (Thread-2): 15:35:59  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 15:35:59.690208 (Thread-2): 15:35:59  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 15:35:59.690816 (Thread-2): 15:35:59  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:35:59.690909 (Thread-2): 15:35:59  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:35:59.690981 (Thread-2): 15:35:59  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:35:59.715353 (Thread-2): 15:35:59  SQL status: COMMIT in 0.02 seconds
2022-01-06 15:35:59.715463 (Thread-2): 15:35:59  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:35:59.715535 (Thread-2): 15:35:59  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:35:59.717509 (Thread-2): 15:35:59  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:35:59.717865 (Thread-2): 15:35:59  finished collecting timing info
2022-01-06 15:35:59.717981 (Thread-2): 15:35:59  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 15:35:59.719623 (Thread-2): 15:35:59  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 15:35:59.720006 (Thread-2): 15:35:59  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57630187-f2e4-4ce3-8587-346942a50533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b84186130>]}
2022-01-06 15:35:59.720290 (Thread-2): 15:35:59  5 of 5 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.21s]
2022-01-06 15:35:59.720394 (Thread-2): 15:35:59  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 15:35:59.721730 (MainThread): 15:35:59  Acquiring new redshift connection "master"
2022-01-06 15:35:59.721876 (MainThread): 15:35:59  Using redshift connection "master"
2022-01-06 15:35:59.721971 (MainThread): 15:35:59  On master: BEGIN
2022-01-06 15:35:59.722055 (MainThread): 15:35:59  Opening a new connection, currently in state closed
2022-01-06 15:35:59.722130 (MainThread): 15:35:59  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:35:59.745709 (MainThread): 15:35:59  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:35:59.745828 (MainThread): 15:35:59  On master: COMMIT
2022-01-06 15:35:59.745903 (MainThread): 15:35:59  Using redshift connection "master"
2022-01-06 15:35:59.745972 (MainThread): 15:35:59  On master: COMMIT
2022-01-06 15:35:59.747676 (MainThread): 15:35:59  SQL status: COMMIT in 0.0 seconds
2022-01-06 15:35:59.747802 (MainThread): 15:35:59  On master: Close
2022-01-06 15:35:59.748312 (MainThread): 15:35:59  
2022-01-06 15:35:59.748429 (MainThread): 15:35:59  Finished running 3 view models, 2 table models in 0.72s.
2022-01-06 15:35:59.748514 (MainThread): 15:35:59  Connection 'master' was properly closed.
2022-01-06 15:35:59.748581 (MainThread): 15:35:59  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 15:35:59.748642 (MainThread): 15:35:59  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 15:35:59.748703 (MainThread): 15:35:59  Connection 'model.my_new_project.stg_orders' was properly closed.
2022-01-06 15:35:59.820451 (MainThread): 15:35:59  
2022-01-06 15:35:59.820604 (MainThread): 15:35:59  Completed with 1 error and 0 warnings:
2022-01-06 15:35:59.820692 (MainThread): 15:35:59  
2022-01-06 15:35:59.820780 (MainThread): 15:35:59  Database Error in model stg_orders (models/stg_orders.sql)
2022-01-06 15:35:59.820856 (MainThread): 15:35:59    syntax error at or near "orders"
2022-01-06 15:35:59.820923 (MainThread): 15:35:59    LINE 5:     orders as (
2022-01-06 15:35:59.820987 (MainThread): 15:35:59                ^
2022-01-06 15:35:59.821050 (MainThread): 15:35:59    compiled SQL at target/run/my_new_project/models/stg_orders.sql
2022-01-06 15:35:59.821127 (MainThread): 15:35:59  
2022-01-06 15:35:59.821204 (MainThread): 15:35:59  Done. PASS=3 WARN=0 ERROR=1 SKIP=1 TOTAL=5
2022-01-06 15:36:00.632536 (Thread-350): handling poll request
2022-01-06 15:36:00.632912 (Thread-350): 15:36:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bc17790>]}
2022-01-06 15:36:00.635604 (Thread-350): sending response (<Response 70518 bytes [200 OK]>) to 10.0.23.79
2022-01-06 15:36:01.275340 (Thread-351): handling status request
2022-01-06 15:36:01.275689 (Thread-351): 15:36:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bc17940>]}
2022-01-06 15:36:01.276202 (Thread-351): sending response (<Response 1556 bytes [200 OK]>) to 10.0.0.136
2022-01-06 15:36:01.362765 (Thread-352): handling status request
2022-01-06 15:36:01.363117 (Thread-352): 15:36:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bc17d30>]}
2022-01-06 15:36:01.363581 (Thread-352): sending response (<Response 1556 bytes [200 OK]>) to 10.0.32.116
2022-01-06 15:36:17.977980 (Thread-353): handling status request
2022-01-06 15:36:17.978394 (Thread-353): 15:36:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bc17f70>]}
2022-01-06 15:36:17.978877 (Thread-353): sending response (<Response 1556 bytes [200 OK]>) to 10.0.21.24
2022-01-06 15:36:18.237800 (Thread-354): handling status request
2022-01-06 15:36:18.238159 (Thread-354): 15:36:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bc29190>]}
2022-01-06 15:36:18.238628 (Thread-354): sending response (<Response 1556 bytes [200 OK]>) to 10.0.21.24
2022-01-06 15:36:18.380456 (Thread-355): handling docs.generate request
2022-01-06 15:36:18.380707 (Thread-355): 15:36:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bc29490>]}
2022-01-06 15:36:20.429958 (Thread-355): sending response (<Response 138 bytes [200 OK]>) to 10.0.30.119
2022-01-06 15:36:20.457961 (MainThread): 15:36:20  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dc529549-dc06-4817-8f72-190914e1fe02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a05172580>]}
2022-01-06 15:36:20.458242 (MainThread): 15:36:20  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:36:20.459492 (MainThread): 15:36:20  
2022-01-06 15:36:20.459645 (MainThread): 15:36:20  Acquiring new redshift connection "master"
2022-01-06 15:36:20.460412 (ThreadPoolExecutor-0_0): 15:36:20  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:36:20.472558 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/catalog.sql
2022-01-06 15:36:20.486044 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/adapters.sql
2022-01-06 15:36:20.513050 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/relations.sql
2022-01-06 15:36:20.513768 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 15:36:20.514705 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/catalog.sql
2022-01-06 15:36:20.516927 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/adapters.sql
2022-01-06 15:36:20.537847 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/relations.sql
2022-01-06 15:36:20.539221 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 15:36:20.542114 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-06 15:36:20.543657 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-06 15:36:20.545301 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-06 15:36:20.547931 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-06 15:36:20.549380 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/generic_test_sql/not_null.sql
2022-01-06 15:36:20.550057 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/generic_test_sql/relationships.sql
2022-01-06 15:36:20.551012 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/generic_test_sql/unique.sql
2022-01-06 15:36:20.551807 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/configs.sql
2022-01-06 15:36:20.554181 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/hooks.sql
2022-01-06 15:36:20.558009 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/snapshots/strategies.sql
2022-01-06 15:36:20.574403 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-06 15:36:20.576099 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-06 15:36:20.587032 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/snapshots/helpers.sql
2022-01-06 15:36:20.597699 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/seeds/seed.sql
2022-01-06 15:36:20.603559 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/seeds/helpers.sql
2022-01-06 15:36:20.619065 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-06 15:36:20.621446 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/models/view/view.sql
2022-01-06 15:36:20.628190 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-06 15:36:20.630908 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/models/view/helpers.sql
2022-01-06 15:36:20.632327 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/models/table/table.sql
2022-01-06 15:36:20.639534 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-06 15:36:20.642473 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/models/incremental/merge.sql
2022-01-06 15:36:20.653250 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-06 15:36:20.667984 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-06 15:36:20.672385 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-06 15:36:20.682165 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-06 15:36:20.683778 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/tests/test.sql
2022-01-06 15:36:20.688134 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/tests/where_subquery.sql
2022-01-06 15:36:20.690096 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/materializations/tests/helpers.sql
2022-01-06 15:36:20.691953 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/etc/statement.sql
2022-01-06 15:36:20.696440 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/etc/datetime.sql
2022-01-06 15:36:20.704661 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/adapters/indexes.sql
2022-01-06 15:36:20.707428 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/adapters/persist_docs.sql
2022-01-06 15:36:20.712069 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/adapters/freshness.sql
2022-01-06 15:36:20.715073 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/adapters/relation.sql
2022-01-06 15:36:20.724481 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/adapters/metadata.sql
2022-01-06 15:36:20.731714 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/adapters/columns.sql
2022-01-06 15:36:20.741439 (ThreadPoolExecutor-0_0): 15:36:20  Parsing macros/adapters/schema.sql
2022-01-06 15:36:20.753507 (ThreadPoolExecutor-0_0): 15:36:20  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:36:20.753623 (ThreadPoolExecutor-0_0): 15:36:20  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 15:36:20.753710 (ThreadPoolExecutor-0_0): 15:36:20  Opening a new connection, currently in state init
2022-01-06 15:36:20.753790 (ThreadPoolExecutor-0_0): 15:36:20  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:36:20.774961 (ThreadPoolExecutor-0_0): 15:36:20  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:36:20.775072 (ThreadPoolExecutor-0_0): 15:36:20  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:36:20.775147 (ThreadPoolExecutor-0_0): 15:36:20  On list_dev_dbt_nobodozie: select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 15:36:20.786599 (ThreadPoolExecutor-0_0): 15:36:20  SQL status: SELECT in 0.01 seconds
2022-01-06 15:36:20.787717 (ThreadPoolExecutor-0_0): 15:36:20  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 15:36:20.789522 (ThreadPoolExecutor-0_0): 15:36:20  On list_dev_dbt_nobodozie: Close
2022-01-06 15:36:20.793246 (MainThread): 15:36:20  Using redshift connection "master"
2022-01-06 15:36:20.793365 (MainThread): 15:36:20  On master: BEGIN
2022-01-06 15:36:20.793450 (MainThread): 15:36:20  Opening a new connection, currently in state init
2022-01-06 15:36:20.793527 (MainThread): 15:36:20  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:36:20.820836 (Thread-356): handling poll request
2022-01-06 15:36:20.819851 (MainThread): 15:36:20  SQL status: BEGIN in 0.03 seconds
2022-01-06 15:36:20.821476 (Thread-356): 15:36:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bc1ba00>]}
2022-01-06 15:36:20.819966 (MainThread): 15:36:20  Using redshift connection "master"
2022-01-06 15:36:20.822920 (Thread-356): sending response (<Response 20991 bytes [200 OK]>) to 10.0.29.240
2022-01-06 15:36:20.820042 (MainThread): 15:36:20  On master: with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 15:36:20.848654 (MainThread): 15:36:20  SQL status: SELECT in 0.03 seconds
2022-01-06 15:36:20.849742 (MainThread): 15:36:20  On master: ROLLBACK
2022-01-06 15:36:20.851666 (MainThread): 15:36:20  On master: Close
2022-01-06 15:36:20.851974 (MainThread): 15:36:20  Concurrency: 4 threads (target='default')
2022-01-06 15:36:20.852092 (MainThread): 15:36:20  
2022-01-06 15:36:20.854506 (Thread-1): 15:36:20  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 15:36:20.854677 (Thread-1): 15:36:20  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:36:20.854769 (Thread-1): 15:36:20  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 15:36:20.854856 (Thread-1): 15:36:20  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 15:36:20.857065 (Thread-1): 15:36:20  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 15:36:20.857301 (Thread-2): 15:36:20  Began running node model.my_new_project.stg_customers
2022-01-06 15:36:20.857466 (Thread-2): 15:36:20  Acquiring new redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:36:20.857546 (Thread-2): 15:36:20  Began compiling node model.my_new_project.stg_customers
2022-01-06 15:36:20.857622 (Thread-2): 15:36:20  Compiling model.my_new_project.stg_customers
2022-01-06 15:36:20.859369 (Thread-2): 15:36:20  Writing injected SQL for node "model.my_new_project.stg_customers"
2022-01-06 15:36:20.859721 (Thread-3): 15:36:20  Began running node model.my_new_project.stg_orders
2022-01-06 15:36:20.859897 (Thread-3): 15:36:20  Acquiring new redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:36:20.859978 (Thread-3): 15:36:20  Began compiling node model.my_new_project.stg_orders
2022-01-06 15:36:20.860056 (Thread-3): 15:36:20  Compiling model.my_new_project.stg_orders
2022-01-06 15:36:20.861087 (Thread-3): 15:36:20  Writing injected SQL for node "model.my_new_project.stg_orders"
2022-01-06 15:36:20.875377 (Thread-1): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.875519 (Thread-1): 15:36:20  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 15:36:20.875620 (Thread-1): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.875762 (Thread-1): 15:36:20  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 15:36:20.876071 (Thread-3): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.876261 (Thread-3): 15:36:20  Began executing node model.my_new_project.stg_orders
2022-01-06 15:36:20.876406 (Thread-3): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.876594 (Thread-3): 15:36:20  Finished running node model.my_new_project.stg_orders
2022-01-06 15:36:20.876816 (Thread-2): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.876942 (Thread-2): 15:36:20  Began executing node model.my_new_project.stg_customers
2022-01-06 15:36:20.877028 (Thread-2): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.877152 (Thread-2): 15:36:20  Finished running node model.my_new_project.stg_customers
2022-01-06 15:36:20.877633 (Thread-4): 15:36:20  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 15:36:20.877793 (Thread-4): 15:36:20  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:36:20.877869 (Thread-4): 15:36:20  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 15:36:20.877941 (Thread-4): 15:36:20  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 15:36:20.879928 (Thread-4): 15:36:20  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 15:36:20.880214 (Thread-1): 15:36:20  Began running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 15:36:20.880347 (Thread-1): 15:36:20  Acquiring new redshift connection "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-06 15:36:20.880423 (Thread-1): 15:36:20  Began compiling node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 15:36:20.880494 (Thread-1): 15:36:20  Compiling test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 15:36:20.885327 (Thread-3): 15:36:20  Began running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 15:36:20.885461 (Thread-3): 15:36:20  Acquiring new redshift connection "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-06 15:36:20.885538 (Thread-3): 15:36:20  Began compiling node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 15:36:20.885612 (Thread-3): 15:36:20  Compiling test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 15:36:20.890656 (Thread-2): 15:36:20  Began running node model.my_new_project.dim_customers
2022-01-06 15:36:20.890802 (Thread-2): 15:36:20  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:36:20.890882 (Thread-2): 15:36:20  Began compiling node model.my_new_project.dim_customers
2022-01-06 15:36:20.890956 (Thread-2): 15:36:20  Compiling model.my_new_project.dim_customers
2022-01-06 15:36:20.893337 (Thread-2): 15:36:20  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 15:36:20.897507 (Thread-1): 15:36:20  Writing injected SQL for node "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-06 15:36:20.900396 (Thread-3): 15:36:20  Writing injected SQL for node "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-06 15:36:20.906862 (Thread-4): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.906992 (Thread-4): 15:36:20  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 15:36:20.907082 (Thread-4): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.907211 (Thread-4): 15:36:20  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 15:36:20.907811 (Thread-4): 15:36:20  Began running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 15:36:20.907935 (Thread-4): 15:36:20  Acquiring new redshift connection "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2022-01-06 15:36:20.908007 (Thread-4): 15:36:20  Began compiling node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 15:36:20.908077 (Thread-4): 15:36:20  Compiling test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 15:36:20.911030 (Thread-4): 15:36:20  Writing injected SQL for node "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2022-01-06 15:36:20.911680 (Thread-2): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.911822 (Thread-2): 15:36:20  Began executing node model.my_new_project.dim_customers
2022-01-06 15:36:20.911913 (Thread-2): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.912043 (Thread-2): 15:36:20  Finished running node model.my_new_project.dim_customers
2022-01-06 15:36:20.912157 (Thread-2): 15:36:20  Began running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 15:36:20.912305 (Thread-2): 15:36:20  Acquiring new redshift connection "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2022-01-06 15:36:20.912389 (Thread-2): 15:36:20  Began compiling node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 15:36:20.912460 (Thread-2): 15:36:20  Compiling test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 15:36:20.915445 (Thread-2): 15:36:20  Writing injected SQL for node "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2022-01-06 15:36:20.920732 (Thread-3): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.920863 (Thread-3): 15:36:20  Began executing node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 15:36:20.920967 (Thread-3): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.921098 (Thread-3): 15:36:20  Finished running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 15:36:20.921368 (Thread-1): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.921495 (Thread-1): 15:36:20  Began executing node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 15:36:20.921585 (Thread-1): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.921710 (Thread-1): 15:36:20  Finished running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 15:36:20.928546 (Thread-4): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.928674 (Thread-4): 15:36:20  Began executing node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 15:36:20.928762 (Thread-4): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.928885 (Thread-4): 15:36:20  Finished running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 15:36:20.930626 (Thread-2): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.930761 (Thread-2): 15:36:20  Began executing node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 15:36:20.930851 (Thread-2): 15:36:20  finished collecting timing info
2022-01-06 15:36:20.930977 (Thread-2): 15:36:20  Finished running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 15:36:20.932142 (MainThread): 15:36:20  Connection 'master' was properly closed.
2022-01-06 15:36:20.932247 (MainThread): 15:36:20  Connection 'test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
2022-01-06 15:36:20.932315 (MainThread): 15:36:20  Connection 'test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
2022-01-06 15:36:20.932377 (MainThread): 15:36:20  Connection 'test.my_new_project.unique_my_first_dbt_model_id.16e066b321' was properly closed.
2022-01-06 15:36:20.932436 (MainThread): 15:36:20  Connection 'test.my_new_project.not_null_my_second_dbt_model_id.151b76d778' was properly closed.
2022-01-06 15:36:20.993430 (MainThread): 15:36:20  Done.
2022-01-06 15:36:21.069403 (MainThread): 15:36:21  Acquiring new redshift connection "generate_catalog"
2022-01-06 15:36:21.069522 (MainThread): 15:36:21  Building catalog
2022-01-06 15:36:21.070669 (ThreadPoolExecutor-1_0): 15:36:21  Acquiring new redshift connection "dev.information_schema"
2022-01-06 15:36:21.080836 (ThreadPoolExecutor-1_0): 15:36:21  Using redshift connection "dev.information_schema"
2022-01-06 15:36:21.080938 (ThreadPoolExecutor-1_0): 15:36:21  On dev.information_schema: BEGIN
2022-01-06 15:36:21.081019 (ThreadPoolExecutor-1_0): 15:36:21  Opening a new connection, currently in state init
2022-01-06 15:36:21.081095 (ThreadPoolExecutor-1_0): 15:36:21  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:36:21.099784 (ThreadPoolExecutor-1_0): 15:36:21  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:36:21.099897 (ThreadPoolExecutor-1_0): 15:36:21  Using redshift connection "dev.information_schema"
2022-01-06 15:36:21.099971 (ThreadPoolExecutor-1_0): 15:36:21  On dev.information_schema: 
    

    with late_binding as (
      select
        'dev'::varchar as table_database,
        table_schema,
        table_name,
        'LATE BINDING VIEW'::varchar as table_type,
        null::text as table_comment,

        column_name,
        column_index,
        column_type,
        null::text as column_comment
      from pg_get_late_binding_view_cols()
        cols(table_schema name, table_name name, column_name name,
             column_type varchar,
             column_index int)
        order by "column_index"
    ),

    early_binding as (
        select
            'dev'::varchar as table_database,
            sch.nspname as table_schema,
            tbl.relname as table_name,
            case tbl.relkind
                when 'v' then 'VIEW'
                else 'BASE TABLE'
            end as table_type,
            tbl_desc.description as table_comment,
            col.attname as column_name,
            col.attnum as column_index,
            pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
            col_desc.description as column_comment

        from pg_catalog.pg_namespace sch
        join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
        join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
        left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
        left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
        where (upper(sch.nspname) = upper('dbt_nobodozie'))
            and tbl.relkind in ('r', 'v', 'f', 'p')
            and col.attnum > 0
            and not col.attisdropped
    ),

    table_owners as (

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            tablename as table_name,
            tableowner as table_owner

        from pg_tables

        union all

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            viewname as table_name,
            viewowner as table_owner

        from pg_views

    ),

    unioned as (

        select *
        from early_binding

        union all

        select *
        from late_binding

    )

    select *,
        table_database || '.' || table_schema || '.' || table_name as table_id

    from unioned
    join table_owners using (table_database, table_schema, table_name)

    where (upper(table_schema) = upper('dbt_nobodozie'))

    order by "column_index"
2022-01-06 15:36:21.156530 (ThreadPoolExecutor-1_0): 15:36:21  SQL status: SELECT in 0.06 seconds
2022-01-06 15:36:21.161550 (ThreadPoolExecutor-1_0): 15:36:21  Using redshift connection "dev.information_schema"
2022-01-06 15:36:21.161656 (ThreadPoolExecutor-1_0): 15:36:21  On dev.information_schema: select has_table_privilege(current_user, 'svv_table_info', 'SELECT') as can_select
2022-01-06 15:36:21.164357 (ThreadPoolExecutor-1_0): 15:36:21  SQL status: SELECT in 0.0 seconds
2022-01-06 15:36:21.168132 (ThreadPoolExecutor-1_0): 15:36:21  Using redshift connection "dev.information_schema"
2022-01-06 15:36:21.168227 (ThreadPoolExecutor-1_0): 15:36:21  On dev.information_schema: select
        "database" || '.' || "schema" || '.' || "table" as table_id,

        'Encoded'::text as "stats:encoded:label",
        encoded as "stats:encoded:value",
        'Indicates whether any column in the table has compression encoding defined.'::text as "stats:encoded:description",
        true as "stats:encoded:include",

        'Dist Style' as "stats:diststyle:label",
        diststyle as "stats:diststyle:value",
        'Distribution style or distribution key column, if key distribution is defined.'::text as "stats:diststyle:description",
        true as "stats:diststyle:include",

        'Sort Key 1' as "stats:sortkey1:label",
        -- handle 0xFF byte in response for interleaved sort styles
        case
            when sortkey1 like 'INTERLEAVED%' then 'INTERLEAVED'::text
            else sortkey1
        end as "stats:sortkey1:value",
        'First column in the sort key.'::text as "stats:sortkey1:description",
        (sortkey1 is not null) as "stats:sortkey1:include",

        'Max Varchar' as "stats:max_varchar:label",
        max_varchar as "stats:max_varchar:value",
        'Size of the largest column that uses a VARCHAR data type.'::text as "stats:max_varchar:description",
        true as "stats:max_varchar:include",

        -- exclude this, as the data is strangely returned with null-byte characters
        'Sort Key 1 Encoding' as "stats:sortkey1_enc:label",
        sortkey1_enc as "stats:sortkey1_enc:value",
        'Compression encoding of the first column in the sort key.' as "stats:sortkey1_enc:description",
        false as "stats:sortkey1_enc:include",

        '# Sort Keys' as "stats:sortkey_num:label",
        sortkey_num as "stats:sortkey_num:value",
        'Number of columns defined as sort keys.' as "stats:sortkey_num:description",
        (sortkey_num > 0) as "stats:sortkey_num:include",

        'Approximate Size' as "stats:size:label",
        size * 1000000 as "stats:size:value",
        'Approximate size of the table, calculated from a count of 1MB blocks'::text as "stats:size:description",
        true as "stats:size:include",

        'Disk Utilization' as "stats:pct_used:label",
        pct_used / 100.0 as "stats:pct_used:value",
        'Percent of available space that is used by the table.'::text as "stats:pct_used:description",
        true as "stats:pct_used:include",

        'Unsorted %' as "stats:unsorted:label",
        unsorted / 100.0 as "stats:unsorted:value",
        'Percent of unsorted rows in the table.'::text as "stats:unsorted:description",
        (unsorted is not null) as "stats:unsorted:include",

        'Stats Off' as "stats:stats_off:label",
        stats_off as "stats:stats_off:value",
        'Number that indicates how stale the table statistics are; 0 is current, 100 is out of date.'::text as "stats:stats_off:description",
        true as "stats:stats_off:include",

        'Approximate Row Count' as "stats:rows:label",
        tbl_rows as "stats:rows:value",
        'Approximate number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed.'::text as "stats:rows:description",
        true as "stats:rows:include",

        'Sort Key Skew' as "stats:skew_sortkey1:label",
        skew_sortkey1 as "stats:skew_sortkey1:value",
        'Ratio of the size of the largest non-sort key column to the size of the first column of the sort key.'::text as "stats:skew_sortkey1:description",
        (skew_sortkey1 is not null) as "stats:skew_sortkey1:include",

        'Skew Rows' as "stats:skew_rows:label",
        skew_rows as "stats:skew_rows:value",
        'Ratio of the number of rows in the slice with the most rows to the number of rows in the slice with the fewest rows.'::text as "stats:skew_rows:description",
        (skew_rows is not null) as "stats:skew_rows:include"

    from svv_table_info
    where (upper(schema) = upper('dbt_nobodozie'))
2022-01-06 15:36:21.793561 (ThreadPoolExecutor-1_0): 15:36:21  SQL status: SELECT in 0.63 seconds
2022-01-06 15:36:21.803025 (ThreadPoolExecutor-1_0): 15:36:21  On dev.information_schema: ROLLBACK
2022-01-06 15:36:21.805044 (ThreadPoolExecutor-1_0): 15:36:21  On dev.information_schema: Close
2022-01-06 15:36:21.888418 (MainThread): 15:36:21  Catalog written to /usr/src/develop/user-52374/environment-57794/repository-46678/target/catalog.json
2022-01-06 15:36:22.234184 (Thread-357): handling poll request
2022-01-06 15:36:22.234571 (Thread-357): 15:36:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bcbf130>]}
2022-01-06 15:36:22.236451 (Thread-357): sending response (<Response 60466 bytes [200 OK]>) to 10.0.16.103
2022-01-06 15:36:22.874155 (Thread-358): handling status request
2022-01-06 15:36:22.874522 (Thread-358): 15:36:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bcbf700>]}
2022-01-06 15:36:22.875017 (Thread-358): sending response (<Response 1556 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:36:22.959656 (Thread-359): handling status request
2022-01-06 15:36:22.959978 (Thread-359): 15:36:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bcc3970>]}
2022-01-06 15:36:22.960459 (Thread-359): sending response (<Response 1556 bytes [200 OK]>) to 10.0.41.69
2022-01-06 15:36:23.002110 (Thread-360): handling status request
2022-01-06 15:36:23.002412 (Thread-360): 15:36:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bcc3730>]}
2022-01-06 15:36:23.002845 (Thread-360): sending response (<Response 1556 bytes [200 OK]>) to 10.0.26.175
2022-01-06 15:48:22.092463 (Thread-361): 15:48:22  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 15:48:22.094173 (Thread-361): 15:48:22  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 15:48:22.099295 (Thread-361): 15:48:22  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bb6a8b0>]}
2022-01-06 15:48:22.681597 (Thread-362): handling status request
2022-01-06 15:48:22.681955 (Thread-362): 15:48:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bbf11c0>]}
2022-01-06 15:48:22.682417 (Thread-362): sending response (<Response 1244 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:48:22.733840 (Thread-363): handling status request
2022-01-06 15:48:22.734153 (Thread-363): 15:48:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bb63d90>]}
2022-01-06 15:48:22.734578 (Thread-363): sending response (<Response 1244 bytes [200 OK]>) to 10.0.2.97
2022-01-06 15:48:26.207421 (Thread-364): 15:48:26  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 15:48:26.207616 (Thread-364): 15:48:26  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 15:48:26.212695 (Thread-364): 15:48:26  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff783f0400>]}
2022-01-06 15:48:26.718606 (Thread-365): handling status request
2022-01-06 15:48:26.718964 (Thread-365): 15:48:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bb600d0>]}
2022-01-06 15:48:26.719428 (Thread-365): sending response (<Response 1244 bytes [200 OK]>) to 10.0.41.69
2022-01-06 15:48:27.113188 (Thread-366): handling status request
2022-01-06 15:48:27.113592 (Thread-366): 15:48:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bf030a0>]}
2022-01-06 15:48:27.137291 (Thread-366): sending response (<Response 1244 bytes [200 OK]>) to 10.0.23.79
2022-01-06 15:48:28.929047 (Thread-367): 15:48:28  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 15:48:28.929267 (Thread-367): 15:48:28  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 15:48:28.933980 (Thread-367): 15:48:28  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bbb2bb0>]}
2022-01-06 15:48:29.570635 (Thread-368): handling status request
2022-01-06 15:48:29.570995 (Thread-368): 15:48:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bcc4430>]}
2022-01-06 15:48:29.571451 (Thread-368): sending response (<Response 1244 bytes [200 OK]>) to 10.0.15.56
2022-01-06 15:48:29.572973 (Thread-369): handling status request
2022-01-06 15:48:29.573253 (Thread-369): 15:48:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bcc4b20>]}
2022-01-06 15:48:29.573615 (Thread-369): sending response (<Response 1244 bytes [200 OK]>) to 10.0.40.96
2022-01-06 15:51:24.082331 (Thread-370): handling status request
2022-01-06 15:51:24.083897 (Thread-370): 15:51:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bcc4910>]}
2022-01-06 15:51:24.084359 (Thread-370): sending response (<Response 1244 bytes [200 OK]>) to 10.0.2.170
2022-01-06 15:51:24.253635 (Thread-371): handling status request
2022-01-06 15:51:24.253954 (Thread-371): 15:51:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bcc4e80>]}
2022-01-06 15:51:24.254399 (Thread-371): sending response (<Response 1244 bytes [200 OK]>) to 10.0.41.69
2022-01-06 15:51:24.571276 (Thread-372): handling cli_args request
2022-01-06 15:51:24.571559 (Thread-372): 15:51:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bcc46d0>]}
2022-01-06 15:51:26.614612 (Thread-372): sending response (<Response 138 bytes [200 OK]>) to 10.0.29.240
2022-01-06 15:51:26.707214 (MainThread): 15:51:26  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 15:51:26.707602 (MainThread): 15:51:26  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 15:51:26.713143 (MainThread): 15:51:26  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cb3e4201-1f29-478e-97ce-833901dab724', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b347ab50>]}
2022-01-06 15:51:26.749562 (MainThread): 15:51:26  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cb3e4201-1f29-478e-97ce-833901dab724', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b34dbbb0>]}
2022-01-06 15:51:26.749797 (MainThread): 15:51:26  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:51:26.750874 (MainThread): 15:51:26  
2022-01-06 15:51:26.751136 (MainThread): 15:51:26  Acquiring new redshift connection "master"
2022-01-06 15:51:26.752182 (ThreadPoolExecutor-0_0): 15:51:26  Acquiring new redshift connection "list_dev"
2022-01-06 15:51:26.761970 (ThreadPoolExecutor-0_0): 15:51:26  Using redshift connection "list_dev"
2022-01-06 15:51:26.762174 (ThreadPoolExecutor-0_0): 15:51:26  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 15:51:26.762265 (ThreadPoolExecutor-0_0): 15:51:26  Opening a new connection, currently in state init
2022-01-06 15:51:26.762348 (ThreadPoolExecutor-0_0): 15:51:26  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:51:26.782592 (ThreadPoolExecutor-0_0): 15:51:26  SQL status: SELECT in 0.02 seconds
2022-01-06 15:51:26.783661 (ThreadPoolExecutor-0_0): 15:51:26  On list_dev: Close
2022-01-06 15:51:26.784877 (ThreadPoolExecutor-1_0): 15:51:26  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:51:26.791324 (ThreadPoolExecutor-1_0): 15:51:26  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:51:26.791424 (ThreadPoolExecutor-1_0): 15:51:26  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 15:51:26.791504 (ThreadPoolExecutor-1_0): 15:51:26  Opening a new connection, currently in state closed
2022-01-06 15:51:26.791579 (ThreadPoolExecutor-1_0): 15:51:26  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:51:26.814036 (ThreadPoolExecutor-1_0): 15:51:26  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:51:26.814147 (ThreadPoolExecutor-1_0): 15:51:26  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:51:26.814222 (ThreadPoolExecutor-1_0): 15:51:26  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 15:51:26.825286 (ThreadPoolExecutor-1_0): 15:51:26  SQL status: SELECT in 0.01 seconds
2022-01-06 15:51:26.826411 (ThreadPoolExecutor-1_0): 15:51:26  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 15:51:26.828281 (ThreadPoolExecutor-1_0): 15:51:26  On list_dev_dbt_nobodozie: Close
2022-01-06 15:51:26.831886 (MainThread): 15:51:26  Using redshift connection "master"
2022-01-06 15:51:26.831998 (MainThread): 15:51:26  On master: BEGIN
2022-01-06 15:51:26.832078 (MainThread): 15:51:26  Opening a new connection, currently in state init
2022-01-06 15:51:26.832154 (MainThread): 15:51:26  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:51:26.855857 (MainThread): 15:51:26  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:51:26.855978 (MainThread): 15:51:26  Using redshift connection "master"
2022-01-06 15:51:26.856055 (MainThread): 15:51:26  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 15:51:26.885124 (MainThread): 15:51:26  SQL status: SELECT in 0.03 seconds
2022-01-06 15:51:26.886142 (MainThread): 15:51:26  On master: ROLLBACK
2022-01-06 15:51:26.888032 (MainThread): 15:51:26  Using redshift connection "master"
2022-01-06 15:51:26.888131 (MainThread): 15:51:26  On master: BEGIN
2022-01-06 15:51:26.891544 (MainThread): 15:51:26  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:51:26.891645 (MainThread): 15:51:26  On master: COMMIT
2022-01-06 15:51:26.891717 (MainThread): 15:51:26  Using redshift connection "master"
2022-01-06 15:51:26.891784 (MainThread): 15:51:26  On master: COMMIT
2022-01-06 15:51:26.893471 (MainThread): 15:51:26  SQL status: COMMIT in 0.0 seconds
2022-01-06 15:51:26.893572 (MainThread): 15:51:26  On master: Close
2022-01-06 15:51:26.893971 (MainThread): 15:51:26  Concurrency: 4 threads (target='default')
2022-01-06 15:51:26.894085 (MainThread): 15:51:26  
2022-01-06 15:51:26.896338 (Thread-1): 15:51:26  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 15:51:26.896580 (Thread-1): 15:51:26  1 of 5 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 15:51:26.896822 (Thread-1): 15:51:26  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:51:26.896916 (Thread-1): 15:51:26  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 15:51:26.897013 (Thread-1): 15:51:26  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 15:51:26.899108 (Thread-1): 15:51:26  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 15:51:26.899332 (Thread-2): 15:51:26  Began running node model.my_new_project.stg_customers
2022-01-06 15:51:26.899552 (Thread-2): 15:51:26  2 of 5 START view model dbt_nobodozie.stg_customers............................. [RUN]
2022-01-06 15:51:26.899794 (Thread-2): 15:51:26  Acquiring new redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:51:26.899878 (Thread-2): 15:51:26  Began compiling node model.my_new_project.stg_customers
2022-01-06 15:51:26.899985 (Thread-2): 15:51:26  Compiling model.my_new_project.stg_customers
2022-01-06 15:51:26.901091 (Thread-2): 15:51:26  Writing injected SQL for node "model.my_new_project.stg_customers"
2022-01-06 15:51:26.901440 (Thread-3): 15:51:26  Began running node model.my_new_project.stg_orders
2022-01-06 15:51:26.901659 (Thread-3): 15:51:26  3 of 5 START view model dbt_nobodozie.stg_orders................................ [RUN]
2022-01-06 15:51:26.901905 (Thread-3): 15:51:26  Acquiring new redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:51:26.901993 (Thread-3): 15:51:26  Began compiling node model.my_new_project.stg_orders
2022-01-06 15:51:26.902073 (Thread-3): 15:51:26  Compiling model.my_new_project.stg_orders
2022-01-06 15:51:26.903149 (Thread-3): 15:51:26  Writing injected SQL for node "model.my_new_project.stg_orders"
2022-01-06 15:51:26.917553 (Thread-2): 15:51:26  finished collecting timing info
2022-01-06 15:51:26.917705 (Thread-2): 15:51:26  Began executing node model.my_new_project.stg_customers
2022-01-06 15:51:26.922921 (Thread-3): 15:51:26  finished collecting timing info
2022-01-06 15:51:26.923052 (Thread-3): 15:51:26  Began executing node model.my_new_project.stg_orders
2022-01-06 15:51:26.940480 (Thread-1): 15:51:26  finished collecting timing info
2022-01-06 15:51:26.940613 (Thread-1): 15:51:26  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 15:51:26.977028 (Thread-373): handling poll request
2022-01-06 15:51:26.977391 (Thread-373): 15:51:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc003a2b0>]}
2022-01-06 15:51:26.959234 (Thread-3): 15:51:26  Writing runtime SQL for node "model.my_new_project.stg_orders"
2022-01-06 15:51:26.979265 (Thread-373): sending response (<Response 26601 bytes [200 OK]>) to 10.0.16.103
2022-01-06 15:51:26.966838 (Thread-2): 15:51:26  Writing runtime SQL for node "model.my_new_project.stg_customers"
2022-01-06 15:51:26.982876 (Thread-1): 15:51:26  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 15:51:26.988534 (Thread-3): 15:51:26  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:51:26.988649 (Thread-3): 15:51:26  On model.my_new_project.stg_orders: BEGIN
2022-01-06 15:51:26.988740 (Thread-3): 15:51:26  Opening a new connection, currently in state init
2022-01-06 15:51:26.988824 (Thread-3): 15:51:26  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:51:26.989124 (Thread-2): 15:51:26  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:51:26.989251 (Thread-2): 15:51:26  On model.my_new_project.stg_customers: BEGIN
2022-01-06 15:51:26.989337 (Thread-2): 15:51:26  Opening a new connection, currently in state init
2022-01-06 15:51:26.989414 (Thread-2): 15:51:26  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:51:26.997997 (Thread-1): 15:51:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:51:26.998108 (Thread-1): 15:51:26  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:51:26.998188 (Thread-1): 15:51:26  Opening a new connection, currently in state closed
2022-01-06 15:51:26.998262 (Thread-1): 15:51:26  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:51:27.030308 (Thread-2): 15:51:27  SQL status: BEGIN in 0.04 seconds
2022-01-06 15:51:27.030428 (Thread-2): 15:51:27  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:51:27.030506 (Thread-2): 15:51:27  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */


  create view "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
  ) ;

2022-01-06 15:51:27.034536 (Thread-3): 15:51:27  SQL status: BEGIN in 0.05 seconds
2022-01-06 15:51:27.034652 (Thread-3): 15:51:27  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:51:27.034728 (Thread-3): 15:51:27  On model.my_new_project.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_orders"} */


  create view "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" as (
    orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
  ) ;

2022-01-06 15:51:27.038520 (Thread-3): 15:51:27  Postgres adapter: Postgres error: syntax error at or near "orders"
LINE 5:     orders as (
            ^

2022-01-06 15:51:27.038630 (Thread-3): 15:51:27  On model.my_new_project.stg_orders: ROLLBACK
2022-01-06 15:51:27.040330 (Thread-2): 15:51:27  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 15:51:27.045807 (Thread-3): 15:51:27  finished collecting timing info
2022-01-06 15:51:27.045942 (Thread-3): 15:51:27  On model.my_new_project.stg_orders: Close
2022-01-06 15:51:27.046491 (Thread-2): 15:51:27  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:51:27.046603 (Thread-2): 15:51:27  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers" rename to "stg_customers__dbt_backup"
2022-01-06 15:51:27.046757 (Thread-1): 15:51:27  SQL status: BEGIN in 0.05 seconds
2022-01-06 15:51:27.046866 (Thread-1): 15:51:27  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:51:27.046942 (Thread-1): 15:51:27  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 15:51:27.047241 (Thread-3): 15:51:27  Database Error in model stg_orders (models/stg_orders.sql)
  syntax error at or near "orders"
  LINE 5:     orders as (
              ^
  compiled SQL at target/run/my_new_project/models/stg_orders.sql
2022-01-06 15:51:27.047422 (Thread-3): 15:51:27  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cb3e4201-1f29-478e-97ce-833901dab724', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b23ec4c0>]}
2022-01-06 15:51:27.047715 (Thread-3): 15:51:27  3 of 5 ERROR creating view model dbt_nobodozie.stg_orders....................... [ERROR in 0.15s]
2022-01-06 15:51:27.047826 (Thread-3): 15:51:27  Finished running node model.my_new_project.stg_orders
2022-01-06 15:51:27.049694 (Thread-2): 15:51:27  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:51:27.051460 (Thread-2): 15:51:27  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:51:27.051558 (Thread-2): 15:51:27  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" rename to "stg_customers"
2022-01-06 15:51:27.054327 (Thread-2): 15:51:27  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:51:27.061000 (Thread-2): 15:51:27  On model.my_new_project.stg_customers: COMMIT
2022-01-06 15:51:27.061106 (Thread-2): 15:51:27  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:51:27.061180 (Thread-2): 15:51:27  On model.my_new_project.stg_customers: COMMIT
2022-01-06 15:51:27.104739 (Thread-2): 15:51:27  SQL status: COMMIT in 0.04 seconds
2022-01-06 15:51:27.104954 (Thread-2): 15:51:27  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:51:27.105036 (Thread-2): 15:51:27  On model.my_new_project.stg_customers: BEGIN
2022-01-06 15:51:27.108105 (Thread-2): 15:51:27  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:51:27.112016 (Thread-2): 15:51:27  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:51:27.112114 (Thread-2): 15:51:27  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */
drop view if exists "dev"."dbt_nobodozie"."stg_customers__dbt_backup" cascade
2022-01-06 15:51:27.121105 (Thread-2): 15:51:27  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 15:51:27.121752 (Thread-2): 15:51:27  On model.my_new_project.stg_customers: COMMIT
2022-01-06 15:51:27.121848 (Thread-2): 15:51:27  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:51:27.121922 (Thread-2): 15:51:27  On model.my_new_project.stg_customers: COMMIT
2022-01-06 15:51:27.126740 (Thread-1): 15:51:27  SQL status: SELECT in 0.08 seconds
2022-01-06 15:51:27.129472 (Thread-1): 15:51:27  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:51:27.129623 (Thread-1): 15:51:27  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 15:51:27.134557 (Thread-1): 15:51:27  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:51:27.136960 (Thread-1): 15:51:27  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:51:27.137111 (Thread-1): 15:51:27  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 15:51:27.140270 (Thread-1): 15:51:27  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:51:27.147395 (Thread-1): 15:51:27  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:51:27.147552 (Thread-1): 15:51:27  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:51:27.147685 (Thread-1): 15:51:27  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:51:27.155725 (Thread-2): 15:51:27  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:51:27.155843 (Thread-2): 15:51:27  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:51:27.155919 (Thread-2): 15:51:27  On model.my_new_project.stg_customers: BEGIN
2022-01-06 15:51:27.158510 (Thread-2): 15:51:27  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:51:27.158940 (Thread-2): 15:51:27  finished collecting timing info
2022-01-06 15:51:27.159069 (Thread-2): 15:51:27  On model.my_new_project.stg_customers: ROLLBACK
2022-01-06 15:51:27.162495 (Thread-2): 15:51:27  On model.my_new_project.stg_customers: Close
2022-01-06 15:51:27.162919 (Thread-2): 15:51:27  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cb3e4201-1f29-478e-97ce-833901dab724', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b03972b0>]}
2022-01-06 15:51:27.163307 (Thread-2): 15:51:27  2 of 5 OK created view model dbt_nobodozie.stg_customers........................ [CREATE VIEW in 0.26s]
2022-01-06 15:51:27.163469 (Thread-2): 15:51:27  Finished running node model.my_new_project.stg_customers
2022-01-06 15:51:27.163991 (Thread-4): 15:51:27  Began running node model.my_new_project.dim_customers
2022-01-06 15:51:27.164140 (Thread-4): 15:51:27  4 of 5 SKIP relation dbt_nobodozie.dim_customers................................ [SKIP]
2022-01-06 15:51:27.164239 (Thread-4): 15:51:27  Finished running node model.my_new_project.dim_customers
2022-01-06 15:51:27.193348 (Thread-1): 15:51:27  SQL status: COMMIT in 0.05 seconds
2022-01-06 15:51:27.193571 (Thread-1): 15:51:27  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:51:27.193657 (Thread-1): 15:51:27  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:51:27.195832 (Thread-1): 15:51:27  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:51:27.196980 (Thread-1): 15:51:27  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:51:27.197073 (Thread-1): 15:51:27  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 15:51:27.202058 (Thread-1): 15:51:27  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 15:51:27.202682 (Thread-1): 15:51:27  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:51:27.202775 (Thread-1): 15:51:27  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:51:27.202847 (Thread-1): 15:51:27  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:51:27.236610 (Thread-1): 15:51:27  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:51:27.236717 (Thread-1): 15:51:27  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:51:27.236787 (Thread-1): 15:51:27  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:51:27.238838 (Thread-1): 15:51:27  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:51:27.239202 (Thread-1): 15:51:27  finished collecting timing info
2022-01-06 15:51:27.239320 (Thread-1): 15:51:27  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 15:51:27.241053 (Thread-1): 15:51:27  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 15:51:27.241470 (Thread-1): 15:51:27  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cb3e4201-1f29-478e-97ce-833901dab724', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b3482130>]}
2022-01-06 15:51:27.241750 (Thread-1): 15:51:27  1 of 5 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.34s]
2022-01-06 15:51:27.241850 (Thread-1): 15:51:27  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 15:51:27.242608 (Thread-2): 15:51:27  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 15:51:27.242820 (Thread-2): 15:51:27  5 of 5 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 15:51:27.243048 (Thread-2): 15:51:27  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:51:27.243137 (Thread-2): 15:51:27  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 15:51:27.243220 (Thread-2): 15:51:27  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 15:51:27.245196 (Thread-2): 15:51:27  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 15:51:27.259443 (Thread-2): 15:51:27  finished collecting timing info
2022-01-06 15:51:27.259576 (Thread-2): 15:51:27  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 15:51:27.261386 (Thread-2): 15:51:27  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 15:51:27.274885 (Thread-2): 15:51:27  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:51:27.274993 (Thread-2): 15:51:27  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:51:27.275075 (Thread-2): 15:51:27  Opening a new connection, currently in state closed
2022-01-06 15:51:27.275153 (Thread-2): 15:51:27  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:51:27.293920 (Thread-2): 15:51:27  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:51:27.294035 (Thread-2): 15:51:27  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:51:27.294111 (Thread-2): 15:51:27  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 15:51:27.299763 (Thread-2): 15:51:27  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 15:51:27.301547 (Thread-2): 15:51:27  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:51:27.301649 (Thread-2): 15:51:27  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 15:51:27.304044 (Thread-2): 15:51:27  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:51:27.304960 (Thread-2): 15:51:27  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:51:27.305055 (Thread-2): 15:51:27  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:51:27.305128 (Thread-2): 15:51:27  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:51:27.335381 (Thread-2): 15:51:27  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:51:27.335596 (Thread-2): 15:51:27  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:51:27.335679 (Thread-2): 15:51:27  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:51:27.337858 (Thread-2): 15:51:27  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:51:27.339065 (Thread-2): 15:51:27  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:51:27.339160 (Thread-2): 15:51:27  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 15:51:27.341088 (Thread-2): 15:51:27  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 15:51:27.341799 (Thread-2): 15:51:27  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:51:27.341894 (Thread-2): 15:51:27  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:51:27.341966 (Thread-2): 15:51:27  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:51:27.367393 (Thread-2): 15:51:27  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:51:27.367511 (Thread-2): 15:51:27  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:51:27.367584 (Thread-2): 15:51:27  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:51:27.369688 (Thread-2): 15:51:27  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:51:27.370056 (Thread-2): 15:51:27  finished collecting timing info
2022-01-06 15:51:27.370179 (Thread-2): 15:51:27  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 15:51:27.372021 (Thread-2): 15:51:27  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 15:51:27.372422 (Thread-2): 15:51:27  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cb3e4201-1f29-478e-97ce-833901dab724', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b0336b20>]}
2022-01-06 15:51:27.372708 (Thread-2): 15:51:27  5 of 5 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.13s]
2022-01-06 15:51:27.372847 (Thread-2): 15:51:27  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 15:51:27.374193 (MainThread): 15:51:27  Acquiring new redshift connection "master"
2022-01-06 15:51:27.374334 (MainThread): 15:51:27  Using redshift connection "master"
2022-01-06 15:51:27.374409 (MainThread): 15:51:27  On master: BEGIN
2022-01-06 15:51:27.374484 (MainThread): 15:51:27  Opening a new connection, currently in state closed
2022-01-06 15:51:27.374558 (MainThread): 15:51:27  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:51:27.400171 (MainThread): 15:51:27  SQL status: BEGIN in 0.03 seconds
2022-01-06 15:51:27.400288 (MainThread): 15:51:27  On master: COMMIT
2022-01-06 15:51:27.400363 (MainThread): 15:51:27  Using redshift connection "master"
2022-01-06 15:51:27.400433 (MainThread): 15:51:27  On master: COMMIT
2022-01-06 15:51:27.402208 (MainThread): 15:51:27  SQL status: COMMIT in 0.0 seconds
2022-01-06 15:51:27.402315 (MainThread): 15:51:27  On master: Close
2022-01-06 15:51:27.402723 (MainThread): 15:51:27  
2022-01-06 15:51:27.402834 (MainThread): 15:51:27  Finished running 3 view models, 2 table models in 0.65s.
2022-01-06 15:51:27.402915 (MainThread): 15:51:27  Connection 'master' was properly closed.
2022-01-06 15:51:27.402981 (MainThread): 15:51:27  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 15:51:27.403042 (MainThread): 15:51:27  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 15:51:27.403102 (MainThread): 15:51:27  Connection 'model.my_new_project.stg_orders' was properly closed.
2022-01-06 15:51:27.475098 (MainThread): 15:51:27  
2022-01-06 15:51:27.475246 (MainThread): 15:51:27  Completed with 1 error and 0 warnings:
2022-01-06 15:51:27.475333 (MainThread): 15:51:27  
2022-01-06 15:51:27.475420 (MainThread): 15:51:27  Database Error in model stg_orders (models/stg_orders.sql)
2022-01-06 15:51:27.475496 (MainThread): 15:51:27    syntax error at or near "orders"
2022-01-06 15:51:27.475563 (MainThread): 15:51:27    LINE 5:     orders as (
2022-01-06 15:51:27.475627 (MainThread): 15:51:27                ^
2022-01-06 15:51:27.475689 (MainThread): 15:51:27    compiled SQL at target/run/my_new_project/models/stg_orders.sql
2022-01-06 15:51:27.475766 (MainThread): 15:51:27  
2022-01-06 15:51:27.475843 (MainThread): 15:51:27  Done. PASS=3 WARN=0 ERROR=1 SKIP=1 TOTAL=5
2022-01-06 15:51:28.407988 (Thread-374): handling poll request
2022-01-06 15:51:28.408350 (Thread-374): 15:51:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc0022970>]}
2022-01-06 15:51:28.411455 (Thread-374): sending response (<Response 76731 bytes [200 OK]>) to 10.0.45.144
2022-01-06 15:51:29.033975 (Thread-375): handling status request
2022-01-06 15:51:29.034340 (Thread-375): 15:51:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc0022790>]}
2022-01-06 15:51:29.034821 (Thread-375): sending response (<Response 1244 bytes [200 OK]>) to 10.0.41.69
2022-01-06 15:51:29.167129 (Thread-376): handling status request
2022-01-06 15:51:29.167536 (Thread-376): 15:51:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc002f340>]}
2022-01-06 15:51:29.167994 (Thread-376): sending response (<Response 1244 bytes [200 OK]>) to 10.0.29.240
2022-01-06 15:52:03.148568 (Thread-377): handling status request
2022-01-06 15:52:03.148942 (Thread-377): 15:52:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc0022130>]}
2022-01-06 15:52:03.149449 (Thread-377): sending response (<Response 1244 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:52:03.547257 (Thread-378): handling run_sql request
2022-01-06 15:52:03.547641 (Thread-378): 15:52:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc001ae80>]}
2022-01-06 15:52:05.622720 (Thread-378): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.170
2022-01-06 15:52:05.646746 (MainThread): 15:52:05  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bd8d4244-8298-45b2-9857-89483c708f22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb174be97c0>]}
2022-01-06 15:52:05.647306 (MainThread): 15:52:05  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:52:05.647889 (Thread-1): 15:52:05  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 15:52:05.648019 (Thread-1): 15:52:05  Began compiling node rpc.my_new_project.request
2022-01-06 15:52:05.648111 (Thread-1): 15:52:05  Compiling rpc.my_new_project.request
2022-01-06 15:52:05.649402 (Thread-1): 15:52:05  finished collecting timing info
2022-01-06 15:52:05.649535 (Thread-1): 15:52:05  Began executing node rpc.my_new_project.request
2022-01-06 15:52:05.649637 (Thread-1): 15:52:05  Using redshift connection "rpc.my_new_project.request"
2022-01-06 15:52:05.649736 (Thread-1): 15:52:05  On rpc.my_new_project.request: orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 15:52:05.649822 (Thread-1): 15:52:05  Opening a new connection, currently in state init
2022-01-06 15:52:05.649909 (Thread-1): 15:52:05  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:52:05.669994 (Thread-1): 15:52:05  Postgres adapter: Postgres error: syntax error at or near "orders"
LINE 1: orders as (
        ^

2022-01-06 15:52:05.670216 (Thread-1): 15:52:05  finished collecting timing info
2022-01-06 15:52:05.670349 (Thread-1): 15:52:05  On rpc.my_new_project.request: Close
2022-01-06 15:52:05.670589 (Thread-1): Got an exception: Database Error
  syntax error at or near "orders"
  LINE 1: orders as (
          ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "orders"
LINE 1: orders as (
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "orders"
  LINE 1: orders as (
          ^
2022-01-06 15:52:05.671771 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "orders"\n  LINE 1: orders as (\n          ^', 'raw_sql': 'orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from jaffle_shop.orders\n\n)\nselect * from orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from jaffle_shop.orders\n\n)\nselect * from orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "orders"\n  LINE 1: orders as (\n          ^', 'raw_sql': 'orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from jaffle_shop.orders\n\n)\nselect * from orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from jaffle_shop.orders\n\n)\nselect * from orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 15:52:06.117210 (Thread-379): handling poll request
2022-01-06 15:52:06.117698 (Thread-379): 15:52:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc001ca30>]}
2022-01-06 15:52:06.118579 (Thread-379): sending response (<Response 10174 bytes [200 OK]>) to 10.0.30.119
2022-01-06 15:52:17.618099 (Thread-380): 15:52:17  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 15:52:17.618502 (Thread-380): 15:52:17  Partial parsing: updated file: my_new_project://models/stg_orders.sql
2022-01-06 15:52:17.622406 (Thread-380): 15:52:17  1699: static parser successfully parsed stg_orders.sql
2022-01-06 15:52:17.686924 (Thread-380): 15:52:17  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bb4bc70>]}
2022-01-06 15:52:18.313195 (Thread-381): handling status request
2022-01-06 15:52:18.313598 (Thread-381): 15:52:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bb20a90>]}
2022-01-06 15:52:18.314096 (Thread-381): sending response (<Response 1550 bytes [200 OK]>) to 10.0.41.69
2022-01-06 15:52:18.477073 (Thread-382): handling status request
2022-01-06 15:52:18.477508 (Thread-382): 15:52:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bb20790>]}
2022-01-06 15:52:18.478000 (Thread-382): sending response (<Response 1550 bytes [200 OK]>) to 10.0.2.170
2022-01-06 15:52:25.456888 (Thread-383): handling status request
2022-01-06 15:52:25.457286 (Thread-383): 15:52:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78104af0>]}
2022-01-06 15:52:25.457769 (Thread-383): sending response (<Response 1550 bytes [200 OK]>) to 10.0.21.24
2022-01-06 15:52:25.648190 (Thread-384): handling status request
2022-01-06 15:52:25.648454 (Thread-384): 15:52:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bb1df70>]}
2022-01-06 15:52:25.648847 (Thread-384): sending response (<Response 1550 bytes [200 OK]>) to 10.0.2.97
2022-01-06 15:52:25.780874 (Thread-385): handling cli_args request
2022-01-06 15:52:25.781263 (Thread-385): 15:52:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bb1d760>]}
2022-01-06 15:52:27.863434 (Thread-385): sending response (<Response 138 bytes [200 OK]>) to 10.0.33.128
2022-01-06 15:52:27.945917 (MainThread): 15:52:27  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 15:52:27.946329 (MainThread): 15:52:27  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 15:52:27.951891 (MainThread): 15:52:27  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b3c1a348-0206-465c-990f-87e41f0ee1ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b34decd0>]}
2022-01-06 15:52:27.982099 (MainThread): 15:52:27  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b3c1a348-0206-465c-990f-87e41f0ee1ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b353cd30>]}
2022-01-06 15:52:27.982334 (MainThread): 15:52:27  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:52:27.983401 (MainThread): 15:52:27  
2022-01-06 15:52:27.983664 (MainThread): 15:52:27  Acquiring new redshift connection "master"
2022-01-06 15:52:27.984675 (ThreadPoolExecutor-0_0): 15:52:27  Acquiring new redshift connection "list_dev"
2022-01-06 15:52:27.994354 (ThreadPoolExecutor-0_0): 15:52:27  Using redshift connection "list_dev"
2022-01-06 15:52:27.994454 (ThreadPoolExecutor-0_0): 15:52:27  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 15:52:27.994619 (ThreadPoolExecutor-0_0): 15:52:27  Opening a new connection, currently in state init
2022-01-06 15:52:27.994709 (ThreadPoolExecutor-0_0): 15:52:27  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:52:28.016986 (ThreadPoolExecutor-0_0): 15:52:28  SQL status: SELECT in 0.02 seconds
2022-01-06 15:52:28.018058 (ThreadPoolExecutor-0_0): 15:52:28  On list_dev: Close
2022-01-06 15:52:28.019235 (ThreadPoolExecutor-1_0): 15:52:28  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:52:28.025583 (ThreadPoolExecutor-1_0): 15:52:28  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:52:28.025683 (ThreadPoolExecutor-1_0): 15:52:28  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 15:52:28.025762 (ThreadPoolExecutor-1_0): 15:52:28  Opening a new connection, currently in state closed
2022-01-06 15:52:28.025837 (ThreadPoolExecutor-1_0): 15:52:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:52:28.047770 (ThreadPoolExecutor-1_0): 15:52:28  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:52:28.047882 (ThreadPoolExecutor-1_0): 15:52:28  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:52:28.047959 (ThreadPoolExecutor-1_0): 15:52:28  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 15:52:28.058974 (ThreadPoolExecutor-1_0): 15:52:28  SQL status: SELECT in 0.01 seconds
2022-01-06 15:52:28.059966 (ThreadPoolExecutor-1_0): 15:52:28  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 15:52:28.061755 (ThreadPoolExecutor-1_0): 15:52:28  On list_dev_dbt_nobodozie: Close
2022-01-06 15:52:28.065339 (MainThread): 15:52:28  Using redshift connection "master"
2022-01-06 15:52:28.065449 (MainThread): 15:52:28  On master: BEGIN
2022-01-06 15:52:28.065529 (MainThread): 15:52:28  Opening a new connection, currently in state init
2022-01-06 15:52:28.065604 (MainThread): 15:52:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:52:28.089157 (MainThread): 15:52:28  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:52:28.089353 (MainThread): 15:52:28  Using redshift connection "master"
2022-01-06 15:52:28.089478 (MainThread): 15:52:28  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 15:52:28.118169 (MainThread): 15:52:28  SQL status: SELECT in 0.03 seconds
2022-01-06 15:52:28.119736 (MainThread): 15:52:28  On master: ROLLBACK
2022-01-06 15:52:28.121705 (MainThread): 15:52:28  Using redshift connection "master"
2022-01-06 15:52:28.121866 (MainThread): 15:52:28  On master: BEGIN
2022-01-06 15:52:28.125517 (MainThread): 15:52:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:52:28.125686 (MainThread): 15:52:28  On master: COMMIT
2022-01-06 15:52:28.125803 (MainThread): 15:52:28  Using redshift connection "master"
2022-01-06 15:52:28.125910 (MainThread): 15:52:28  On master: COMMIT
2022-01-06 15:52:28.127774 (MainThread): 15:52:28  SQL status: COMMIT in 0.0 seconds
2022-01-06 15:52:28.127950 (MainThread): 15:52:28  On master: Close
2022-01-06 15:52:28.128489 (MainThread): 15:52:28  Concurrency: 4 threads (target='default')
2022-01-06 15:52:28.128658 (MainThread): 15:52:28  
2022-01-06 15:52:28.131578 (Thread-1): 15:52:28  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 15:52:28.131822 (Thread-1): 15:52:28  1 of 5 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 15:52:28.132062 (Thread-1): 15:52:28  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:52:28.132158 (Thread-1): 15:52:28  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 15:52:28.132251 (Thread-1): 15:52:28  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 15:52:28.134468 (Thread-1): 15:52:28  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 15:52:28.134700 (Thread-2): 15:52:28  Began running node model.my_new_project.stg_customers
2022-01-06 15:52:28.134927 (Thread-2): 15:52:28  2 of 5 START view model dbt_nobodozie.stg_customers............................. [RUN]
2022-01-06 15:52:28.135180 (Thread-2): 15:52:28  Acquiring new redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:52:28.135279 (Thread-2): 15:52:28  Began compiling node model.my_new_project.stg_customers
2022-01-06 15:52:28.135362 (Thread-2): 15:52:28  Compiling model.my_new_project.stg_customers
2022-01-06 15:52:28.136518 (Thread-2): 15:52:28  Writing injected SQL for node "model.my_new_project.stg_customers"
2022-01-06 15:52:28.136843 (Thread-3): 15:52:28  Began running node model.my_new_project.stg_orders
2022-01-06 15:52:28.137054 (Thread-3): 15:52:28  3 of 5 START view model dbt_nobodozie.stg_orders................................ [RUN]
2022-01-06 15:52:28.137349 (Thread-3): 15:52:28  Acquiring new redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:52:28.137442 (Thread-3): 15:52:28  Began compiling node model.my_new_project.stg_orders
2022-01-06 15:52:28.137526 (Thread-3): 15:52:28  Compiling model.my_new_project.stg_orders
2022-01-06 15:52:28.138615 (Thread-3): 15:52:28  Writing injected SQL for node "model.my_new_project.stg_orders"
2022-01-06 15:52:28.153650 (Thread-1): 15:52:28  finished collecting timing info
2022-01-06 15:52:28.153794 (Thread-1): 15:52:28  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 15:52:28.158719 (Thread-3): 15:52:28  finished collecting timing info
2022-01-06 15:52:28.158857 (Thread-3): 15:52:28  Began executing node model.my_new_project.stg_orders
2022-01-06 15:52:28.176666 (Thread-2): 15:52:28  finished collecting timing info
2022-01-06 15:52:28.176794 (Thread-2): 15:52:28  Began executing node model.my_new_project.stg_customers
2022-01-06 15:52:28.203316 (Thread-3): 15:52:28  Writing runtime SQL for node "model.my_new_project.stg_orders"
2022-01-06 15:52:28.204261 (Thread-2): 15:52:28  Writing runtime SQL for node "model.my_new_project.stg_customers"
2022-01-06 15:52:28.215555 (Thread-1): 15:52:28  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 15:52:28.220957 (Thread-3): 15:52:28  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:52:28.221069 (Thread-3): 15:52:28  On model.my_new_project.stg_orders: BEGIN
2022-01-06 15:52:28.221153 (Thread-3): 15:52:28  Opening a new connection, currently in state init
2022-01-06 15:52:28.221262 (Thread-3): 15:52:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:52:28.225234 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:52:28.225351 (Thread-2): 15:52:28  On model.my_new_project.stg_customers: BEGIN
2022-01-06 15:52:28.225445 (Thread-2): 15:52:28  Opening a new connection, currently in state init
2022-01-06 15:52:28.225523 (Thread-2): 15:52:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:52:28.228945 (Thread-1): 15:52:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:52:28.229053 (Thread-1): 15:52:28  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:52:28.229133 (Thread-1): 15:52:28  Opening a new connection, currently in state closed
2022-01-06 15:52:28.229207 (Thread-1): 15:52:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:52:28.353837 (Thread-386): handling poll request
2022-01-06 15:52:28.354179 (Thread-386): 15:52:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bb25790>]}
2022-01-06 15:52:28.355680 (Thread-386): sending response (<Response 31538 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:52:28.523493 (Thread-3): 15:52:28  SQL status: BEGIN in 0.3 seconds
2022-01-06 15:52:28.523626 (Thread-3): 15:52:28  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:52:28.523707 (Thread-3): 15:52:28  On model.my_new_project.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_orders"} */


  create view "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" as (
    with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
  ) ;

2022-01-06 15:52:28.524419 (Thread-2): 15:52:28  SQL status: BEGIN in 0.3 seconds
2022-01-06 15:52:28.524544 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:52:28.524620 (Thread-2): 15:52:28  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */


  create view "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
  ) ;

2022-01-06 15:52:28.531527 (Thread-1): 15:52:28  SQL status: BEGIN in 0.3 seconds
2022-01-06 15:52:28.531638 (Thread-1): 15:52:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:52:28.531714 (Thread-1): 15:52:28  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 15:52:28.532049 (Thread-3): 15:52:28  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 15:52:28.538414 (Thread-3): 15:52:28  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:52:28.538527 (Thread-3): 15:52:28  On model.my_new_project.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" rename to "stg_orders"
2022-01-06 15:52:28.538694 (Thread-2): 15:52:28  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 15:52:28.540512 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:52:28.540609 (Thread-2): 15:52:28  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers" rename to "stg_customers__dbt_backup"
2022-01-06 15:52:28.541508 (Thread-3): 15:52:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:52:28.546833 (Thread-2): 15:52:28  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 15:52:28.548661 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:52:28.548756 (Thread-2): 15:52:28  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" rename to "stg_customers"
2022-01-06 15:52:28.550291 (Thread-3): 15:52:28  On model.my_new_project.stg_orders: COMMIT
2022-01-06 15:52:28.550388 (Thread-3): 15:52:28  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:52:28.550461 (Thread-3): 15:52:28  On model.my_new_project.stg_orders: COMMIT
2022-01-06 15:52:28.567921 (Thread-2): 15:52:28  SQL status: ALTER TABLE in 0.02 seconds
2022-01-06 15:52:28.568857 (Thread-2): 15:52:28  On model.my_new_project.stg_customers: COMMIT
2022-01-06 15:52:28.568965 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:52:28.569039 (Thread-2): 15:52:28  On model.my_new_project.stg_customers: COMMIT
2022-01-06 15:52:28.619426 (Thread-3): 15:52:28  SQL status: COMMIT in 0.07 seconds
2022-01-06 15:52:28.619643 (Thread-3): 15:52:28  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:52:28.619725 (Thread-3): 15:52:28  On model.my_new_project.stg_orders: BEGIN
2022-01-06 15:52:28.620974 (Thread-2): 15:52:28  SQL status: COMMIT in 0.05 seconds
2022-01-06 15:52:28.622862 (Thread-3): 15:52:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:52:28.626761 (Thread-3): 15:52:28  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:52:28.626857 (Thread-3): 15:52:28  On model.my_new_project.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_orders"} */
drop view if exists "dev"."dbt_nobodozie"."stg_orders__dbt_backup" cascade
2022-01-06 15:52:28.630059 (Thread-3): 15:52:28  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 15:52:28.630668 (Thread-3): 15:52:28  On model.my_new_project.stg_orders: COMMIT
2022-01-06 15:52:28.630761 (Thread-3): 15:52:28  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:52:28.630833 (Thread-3): 15:52:28  On model.my_new_project.stg_orders: COMMIT
2022-01-06 15:52:28.657739 (Thread-1): 15:52:28  SQL status: SELECT in 0.13 seconds
2022-01-06 15:52:28.659442 (Thread-1): 15:52:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:52:28.659536 (Thread-1): 15:52:28  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 15:52:28.662727 (Thread-1): 15:52:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:52:28.664454 (Thread-1): 15:52:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:52:28.664550 (Thread-1): 15:52:28  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 15:52:28.666962 (Thread-1): 15:52:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:52:28.671332 (Thread-1): 15:52:28  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:52:28.671429 (Thread-1): 15:52:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:52:28.671501 (Thread-1): 15:52:28  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:52:28.673738 (Thread-3): 15:52:28  SQL status: COMMIT in 0.04 seconds
2022-01-06 15:52:28.673857 (Thread-3): 15:52:28  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:52:28.673930 (Thread-3): 15:52:28  On model.my_new_project.stg_orders: BEGIN
2022-01-06 15:52:28.677058 (Thread-3): 15:52:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:52:28.677469 (Thread-3): 15:52:28  finished collecting timing info
2022-01-06 15:52:28.677595 (Thread-3): 15:52:28  On model.my_new_project.stg_orders: ROLLBACK
2022-01-06 15:52:28.677821 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:52:28.677952 (Thread-2): 15:52:28  On model.my_new_project.stg_customers: BEGIN
2022-01-06 15:52:28.680340 (Thread-3): 15:52:28  On model.my_new_project.stg_orders: Close
2022-01-06 15:52:28.680758 (Thread-3): 15:52:28  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3c1a348-0206-465c-990f-87e41f0ee1ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b0416d60>]}
2022-01-06 15:52:28.681076 (Thread-3): 15:52:28  3 of 5 OK created view model dbt_nobodozie.stg_orders........................... [CREATE VIEW in 0.54s]
2022-01-06 15:52:28.681189 (Thread-3): 15:52:28  Finished running node model.my_new_project.stg_orders
2022-01-06 15:52:28.681479 (Thread-2): 15:52:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:52:28.682763 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:52:28.682863 (Thread-2): 15:52:28  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */
drop view if exists "dev"."dbt_nobodozie"."stg_customers__dbt_backup" cascade
2022-01-06 15:52:28.715904 (Thread-2): 15:52:28  SQL status: DROP VIEW in 0.03 seconds
2022-01-06 15:52:28.716574 (Thread-2): 15:52:28  On model.my_new_project.stg_customers: COMMIT
2022-01-06 15:52:28.716667 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:52:28.716741 (Thread-2): 15:52:28  On model.my_new_project.stg_customers: COMMIT
2022-01-06 15:52:28.719855 (Thread-1): 15:52:28  SQL status: COMMIT in 0.05 seconds
2022-01-06 15:52:28.743777 (Thread-2): 15:52:28  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:52:28.743895 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:52:28.743970 (Thread-2): 15:52:28  On model.my_new_project.stg_customers: BEGIN
2022-01-06 15:52:28.745994 (Thread-2): 15:52:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:52:28.746377 (Thread-2): 15:52:28  finished collecting timing info
2022-01-06 15:52:28.746502 (Thread-2): 15:52:28  On model.my_new_project.stg_customers: ROLLBACK
2022-01-06 15:52:28.746690 (Thread-1): 15:52:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:52:28.746792 (Thread-1): 15:52:28  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:52:28.748834 (Thread-1): 15:52:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:52:28.750056 (Thread-1): 15:52:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:52:28.750150 (Thread-1): 15:52:28  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 15:52:28.750362 (Thread-2): 15:52:28  On model.my_new_project.stg_customers: Close
2022-01-06 15:52:28.750954 (Thread-2): 15:52:28  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3c1a348-0206-465c-990f-87e41f0ee1ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b04168b0>]}
2022-01-06 15:52:28.751306 (Thread-2): 15:52:28  2 of 5 OK created view model dbt_nobodozie.stg_customers........................ [CREATE VIEW in 0.62s]
2022-01-06 15:52:28.751417 (Thread-2): 15:52:28  Finished running node model.my_new_project.stg_customers
2022-01-06 15:52:28.752010 (Thread-4): 15:52:28  Began running node model.my_new_project.dim_customers
2022-01-06 15:52:28.752238 (Thread-4): 15:52:28  4 of 5 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 15:52:28.752487 (Thread-4): 15:52:28  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:52:28.752575 (Thread-4): 15:52:28  Began compiling node model.my_new_project.dim_customers
2022-01-06 15:52:28.752659 (Thread-4): 15:52:28  Compiling model.my_new_project.dim_customers
2022-01-06 15:52:28.755148 (Thread-4): 15:52:28  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 15:52:28.757716 (Thread-1): 15:52:28  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 15:52:28.758396 (Thread-1): 15:52:28  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:52:28.758489 (Thread-1): 15:52:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:52:28.758563 (Thread-1): 15:52:28  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 15:52:28.768788 (Thread-4): 15:52:28  finished collecting timing info
2022-01-06 15:52:28.768931 (Thread-4): 15:52:28  Began executing node model.my_new_project.dim_customers
2022-01-06 15:52:28.771057 (Thread-4): 15:52:28  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 15:52:28.784884 (Thread-4): 15:52:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:52:28.784997 (Thread-4): 15:52:28  On model.my_new_project.dim_customers: BEGIN
2022-01-06 15:52:28.785080 (Thread-4): 15:52:28  Opening a new connection, currently in state init
2022-01-06 15:52:28.785158 (Thread-4): 15:52:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:52:28.795587 (Thread-1): 15:52:28  SQL status: COMMIT in 0.04 seconds
2022-01-06 15:52:28.795692 (Thread-1): 15:52:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:52:28.795763 (Thread-1): 15:52:28  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 15:52:28.797909 (Thread-1): 15:52:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:52:28.798257 (Thread-1): 15:52:28  finished collecting timing info
2022-01-06 15:52:28.798375 (Thread-1): 15:52:28  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 15:52:28.800288 (Thread-1): 15:52:28  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 15:52:28.800687 (Thread-1): 15:52:28  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3c1a348-0206-465c-990f-87e41f0ee1ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b03f75e0>]}
2022-01-06 15:52:28.800971 (Thread-1): 15:52:28  1 of 5 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.67s]
2022-01-06 15:52:28.801076 (Thread-1): 15:52:28  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 15:52:28.801633 (Thread-2): 15:52:28  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 15:52:28.801967 (Thread-2): 15:52:28  5 of 5 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 15:52:28.802242 (Thread-2): 15:52:28  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:52:28.802340 (Thread-2): 15:52:28  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 15:52:28.802429 (Thread-2): 15:52:28  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 15:52:28.804322 (Thread-2): 15:52:28  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 15:52:28.812202 (Thread-4): 15:52:28  SQL status: BEGIN in 0.03 seconds
2022-01-06 15:52:28.812319 (Thread-4): 15:52:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:52:28.812396 (Thread-4): 15:52:28  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"


),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 15:52:28.817751 (Thread-2): 15:52:28  finished collecting timing info
2022-01-06 15:52:28.817882 (Thread-2): 15:52:28  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 15:52:28.819692 (Thread-2): 15:52:28  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 15:52:28.834019 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:52:28.834132 (Thread-2): 15:52:28  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:52:28.834217 (Thread-2): 15:52:28  Opening a new connection, currently in state closed
2022-01-06 15:52:28.834294 (Thread-2): 15:52:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:52:28.864282 (Thread-2): 15:52:28  SQL status: BEGIN in 0.03 seconds
2022-01-06 15:52:28.864396 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:52:28.864471 (Thread-2): 15:52:28  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 15:52:28.873183 (Thread-2): 15:52:28  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 15:52:28.875086 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:52:28.875182 (Thread-2): 15:52:28  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 15:52:28.883066 (Thread-2): 15:52:28  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 15:52:28.883993 (Thread-2): 15:52:28  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:52:28.884088 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:52:28.884182 (Thread-2): 15:52:28  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:52:28.913170 (Thread-4): 15:52:28  SQL status: SELECT in 0.1 seconds
2022-01-06 15:52:28.914971 (Thread-4): 15:52:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:52:28.915066 (Thread-4): 15:52:28  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 15:52:28.918555 (Thread-4): 15:52:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:52:28.921486 (Thread-4): 15:52:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:52:28.921580 (Thread-4): 15:52:28  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 15:52:28.925453 (Thread-2): 15:52:28  SQL status: COMMIT in 0.04 seconds
2022-01-06 15:52:28.925669 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:52:28.925750 (Thread-2): 15:52:28  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:52:28.926400 (Thread-4): 15:52:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 15:52:28.927475 (Thread-4): 15:52:28  On model.my_new_project.dim_customers: COMMIT
2022-01-06 15:52:28.927570 (Thread-4): 15:52:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:52:28.927642 (Thread-4): 15:52:28  On model.my_new_project.dim_customers: COMMIT
2022-01-06 15:52:28.927816 (Thread-2): 15:52:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:52:28.929028 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:52:28.929122 (Thread-2): 15:52:28  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 15:52:28.932651 (Thread-2): 15:52:28  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 15:52:28.933298 (Thread-2): 15:52:28  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:52:28.933392 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:52:28.933465 (Thread-2): 15:52:28  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 15:52:28.996666 (Thread-4): 15:52:28  SQL status: COMMIT in 0.07 seconds
2022-01-06 15:52:28.997585 (Thread-2): 15:52:28  SQL status: COMMIT in 0.06 seconds
2022-01-06 15:52:28.997705 (Thread-2): 15:52:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:52:28.997779 (Thread-2): 15:52:28  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 15:52:28.999936 (Thread-2): 15:52:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:52:29.000320 (Thread-2): 15:52:29  finished collecting timing info
2022-01-06 15:52:29.000445 (Thread-2): 15:52:29  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 15:52:29.000663 (Thread-4): 15:52:29  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:52:29.000766 (Thread-4): 15:52:29  On model.my_new_project.dim_customers: BEGIN
2022-01-06 15:52:29.003038 (Thread-2): 15:52:29  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 15:52:29.003190 (Thread-4): 15:52:29  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:52:29.004373 (Thread-4): 15:52:29  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:52:29.004467 (Thread-4): 15:52:29  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 15:52:29.004845 (Thread-2): 15:52:29  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3c1a348-0206-465c-990f-87e41f0ee1ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b03327f0>]}
2022-01-06 15:52:29.005208 (Thread-2): 15:52:29  5 of 5 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.20s]
2022-01-06 15:52:29.005360 (Thread-2): 15:52:29  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 15:52:29.009326 (Thread-4): 15:52:29  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 15:52:29.009949 (Thread-4): 15:52:29  On model.my_new_project.dim_customers: COMMIT
2022-01-06 15:52:29.010043 (Thread-4): 15:52:29  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:52:29.010117 (Thread-4): 15:52:29  On model.my_new_project.dim_customers: COMMIT
2022-01-06 15:52:29.042406 (Thread-4): 15:52:29  SQL status: COMMIT in 0.03 seconds
2022-01-06 15:52:29.042522 (Thread-4): 15:52:29  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:52:29.042596 (Thread-4): 15:52:29  On model.my_new_project.dim_customers: BEGIN
2022-01-06 15:52:29.044775 (Thread-4): 15:52:29  SQL status: BEGIN in 0.0 seconds
2022-01-06 15:52:29.045136 (Thread-4): 15:52:29  finished collecting timing info
2022-01-06 15:52:29.045298 (Thread-4): 15:52:29  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 15:52:29.047116 (Thread-4): 15:52:29  On model.my_new_project.dim_customers: Close
2022-01-06 15:52:29.047603 (Thread-4): 15:52:29  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3c1a348-0206-465c-990f-87e41f0ee1ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4b0332490>]}
2022-01-06 15:52:29.047884 (Thread-4): 15:52:29  4 of 5 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.30s]
2022-01-06 15:52:29.047989 (Thread-4): 15:52:29  Finished running node model.my_new_project.dim_customers
2022-01-06 15:52:29.049276 (MainThread): 15:52:29  Acquiring new redshift connection "master"
2022-01-06 15:52:29.049419 (MainThread): 15:52:29  Using redshift connection "master"
2022-01-06 15:52:29.049498 (MainThread): 15:52:29  On master: BEGIN
2022-01-06 15:52:29.049574 (MainThread): 15:52:29  Opening a new connection, currently in state closed
2022-01-06 15:52:29.049649 (MainThread): 15:52:29  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:52:29.071835 (MainThread): 15:52:29  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:52:29.071951 (MainThread): 15:52:29  On master: COMMIT
2022-01-06 15:52:29.072024 (MainThread): 15:52:29  Using redshift connection "master"
2022-01-06 15:52:29.072093 (MainThread): 15:52:29  On master: COMMIT
2022-01-06 15:52:29.073856 (MainThread): 15:52:29  SQL status: COMMIT in 0.0 seconds
2022-01-06 15:52:29.074013 (MainThread): 15:52:29  On master: Close
2022-01-06 15:52:29.074616 (MainThread): 15:52:29  
2022-01-06 15:52:29.074796 (MainThread): 15:52:29  Finished running 3 view models, 2 table models in 1.09s.
2022-01-06 15:52:29.074933 (MainThread): 15:52:29  Connection 'master' was properly closed.
2022-01-06 15:52:29.075048 (MainThread): 15:52:29  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 15:52:29.075156 (MainThread): 15:52:29  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 15:52:29.075263 (MainThread): 15:52:29  Connection 'model.my_new_project.stg_orders' was properly closed.
2022-01-06 15:52:29.075369 (MainThread): 15:52:29  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 15:52:29.127303 (MainThread): 15:52:29  
2022-01-06 15:52:29.127453 (MainThread): 15:52:29  Completed successfully
2022-01-06 15:52:29.127550 (MainThread): 15:52:29  
2022-01-06 15:52:29.127635 (MainThread): 15:52:29  Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2022-01-06 15:52:29.675113 (Thread-387): handling poll request
2022-01-06 15:52:29.675495 (Thread-387): 15:52:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2baef610>]}
2022-01-06 15:52:29.678599 (Thread-387): sending response (<Response 94643 bytes [200 OK]>) to 10.0.21.24
2022-01-06 15:52:30.369446 (Thread-388): handling status request
2022-01-06 15:52:30.369813 (Thread-388): 15:52:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2baef7c0>]}
2022-01-06 15:52:30.370312 (Thread-388): sending response (<Response 1550 bytes [200 OK]>) to 10.0.2.97
2022-01-06 15:52:30.396500 (Thread-389): handling status request
2022-01-06 15:52:30.400116 (Thread-389): 15:52:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2baefbb0>]}
2022-01-06 15:52:30.400518 (Thread-389): sending response (<Response 1550 bytes [200 OK]>) to 10.0.21.24
2022-01-06 15:52:41.048966 (Thread-390): 15:52:41  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 15:52:41.049170 (Thread-390): 15:52:41  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 15:52:41.054941 (Thread-390): 15:52:41  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2ba5efa0>]}
2022-01-06 15:52:41.686416 (Thread-391): handling status request
2022-01-06 15:52:41.686791 (Thread-391): 15:52:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2ba30fa0>]}
2022-01-06 15:52:41.687270 (Thread-391): sending response (<Response 1244 bytes [200 OK]>) to 10.0.29.240
2022-01-06 15:52:41.706113 (Thread-392): handling status request
2022-01-06 15:52:41.706363 (Thread-392): 15:52:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2ba30ca0>]}
2022-01-06 15:52:41.706761 (Thread-392): sending response (<Response 1244 bytes [200 OK]>) to 10.0.21.24
2022-01-06 15:52:52.085001 (Thread-393): handling status request
2022-01-06 15:52:52.085400 (Thread-393): 15:52:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2ba30880>]}
2022-01-06 15:52:52.085870 (Thread-393): sending response (<Response 1244 bytes [200 OK]>) to 10.0.23.79
2022-01-06 15:52:52.241356 (Thread-394): handling status request
2022-01-06 15:52:52.241646 (Thread-394): 15:52:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2ba30910>]}
2022-01-06 15:52:52.242044 (Thread-394): sending response (<Response 1244 bytes [200 OK]>) to 10.0.45.144
2022-01-06 15:52:52.503615 (Thread-395): handling docs.generate request
2022-01-06 15:52:52.503881 (Thread-395): 15:52:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2ba305b0>]}
2022-01-06 15:52:54.553098 (Thread-395): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.170
2022-01-06 15:52:54.584286 (MainThread): 15:52:54  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aa03b345-211c-4155-ab8d-0ad15397b444', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7cdec4550>]}
2022-01-06 15:52:54.584603 (MainThread): 15:52:54  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 15:52:54.586035 (MainThread): 15:52:54  
2022-01-06 15:52:54.586206 (MainThread): 15:52:54  Acquiring new redshift connection "master"
2022-01-06 15:52:54.587036 (ThreadPoolExecutor-0_0): 15:52:54  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:52:54.599238 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/catalog.sql
2022-01-06 15:52:54.612878 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/adapters.sql
2022-01-06 15:52:54.639999 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/relations.sql
2022-01-06 15:52:54.640718 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 15:52:54.641687 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/catalog.sql
2022-01-06 15:52:54.643912 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/adapters.sql
2022-01-06 15:52:54.664878 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/relations.sql
2022-01-06 15:52:54.666313 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 15:52:54.669268 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-06 15:52:54.670812 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-06 15:52:54.672449 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-06 15:52:54.675069 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-06 15:52:54.676510 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/generic_test_sql/not_null.sql
2022-01-06 15:52:54.677182 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/generic_test_sql/relationships.sql
2022-01-06 15:52:54.678164 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/generic_test_sql/unique.sql
2022-01-06 15:52:54.678982 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/configs.sql
2022-01-06 15:52:54.681342 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/hooks.sql
2022-01-06 15:52:54.685175 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/snapshots/strategies.sql
2022-01-06 15:52:54.702158 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-06 15:52:54.703890 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-06 15:52:54.715108 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/snapshots/helpers.sql
2022-01-06 15:52:54.725766 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/seeds/seed.sql
2022-01-06 15:52:54.731603 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/seeds/helpers.sql
2022-01-06 15:52:54.747140 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-06 15:52:54.749732 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/models/view/view.sql
2022-01-06 15:52:54.756479 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-06 15:52:54.759199 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/models/view/helpers.sql
2022-01-06 15:52:54.760625 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/models/table/table.sql
2022-01-06 15:52:54.767602 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-06 15:52:54.770558 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/models/incremental/merge.sql
2022-01-06 15:52:54.781370 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-06 15:52:54.795988 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-06 15:52:54.800387 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-06 15:52:54.810051 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-06 15:52:54.811612 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/tests/test.sql
2022-01-06 15:52:54.816006 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/tests/where_subquery.sql
2022-01-06 15:52:54.817906 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/materializations/tests/helpers.sql
2022-01-06 15:52:54.819718 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/etc/statement.sql
2022-01-06 15:52:54.824025 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/etc/datetime.sql
2022-01-06 15:52:54.831979 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/adapters/indexes.sql
2022-01-06 15:52:54.834686 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/adapters/persist_docs.sql
2022-01-06 15:52:54.838986 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/adapters/freshness.sql
2022-01-06 15:52:54.841902 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/adapters/relation.sql
2022-01-06 15:52:54.851099 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/adapters/metadata.sql
2022-01-06 15:52:54.858142 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/adapters/columns.sql
2022-01-06 15:52:54.867693 (ThreadPoolExecutor-0_0): 15:52:54  Parsing macros/adapters/schema.sql
2022-01-06 15:52:54.879700 (ThreadPoolExecutor-0_0): 15:52:54  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:52:54.879819 (ThreadPoolExecutor-0_0): 15:52:54  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 15:52:54.879906 (ThreadPoolExecutor-0_0): 15:52:54  Opening a new connection, currently in state init
2022-01-06 15:52:54.879989 (ThreadPoolExecutor-0_0): 15:52:54  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:52:54.900159 (ThreadPoolExecutor-0_0): 15:52:54  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:52:54.900271 (ThreadPoolExecutor-0_0): 15:52:54  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 15:52:54.900345 (ThreadPoolExecutor-0_0): 15:52:54  On list_dev_dbt_nobodozie: select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 15:52:54.911451 (ThreadPoolExecutor-0_0): 15:52:54  SQL status: SELECT in 0.01 seconds
2022-01-06 15:52:54.912581 (ThreadPoolExecutor-0_0): 15:52:54  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 15:52:54.914435 (ThreadPoolExecutor-0_0): 15:52:54  On list_dev_dbt_nobodozie: Close
2022-01-06 15:52:54.918176 (MainThread): 15:52:54  Using redshift connection "master"
2022-01-06 15:52:54.918288 (MainThread): 15:52:54  On master: BEGIN
2022-01-06 15:52:54.918370 (MainThread): 15:52:54  Opening a new connection, currently in state init
2022-01-06 15:52:54.918446 (MainThread): 15:52:54  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:52:54.942509 (MainThread): 15:52:54  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:52:54.942617 (MainThread): 15:52:54  Using redshift connection "master"
2022-01-06 15:52:54.942690 (MainThread): 15:52:54  On master: with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 15:52:54.964503 (Thread-396): handling poll request
2022-01-06 15:52:54.964878 (Thread-396): 15:52:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2ba33490>]}
2022-01-06 15:52:54.971167 (MainThread): 15:52:54  SQL status: SELECT in 0.03 seconds
2022-01-06 15:52:54.972237 (MainThread): 15:52:54  On master: ROLLBACK
2022-01-06 15:52:54.974149 (MainThread): 15:52:54  On master: Close
2022-01-06 15:52:54.974441 (MainThread): 15:52:54  Concurrency: 4 threads (target='default')
2022-01-06 15:52:54.974550 (MainThread): 15:52:54  
2022-01-06 15:52:54.976837 (Thread-1): 15:52:54  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 15:52:54.977013 (Thread-1): 15:52:54  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 15:52:54.977104 (Thread-1): 15:52:54  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 15:52:54.977191 (Thread-1): 15:52:54  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 15:52:54.979400 (Thread-1): 15:52:54  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 15:52:54.979627 (Thread-2): 15:52:54  Began running node model.my_new_project.stg_customers
2022-01-06 15:52:54.979799 (Thread-2): 15:52:54  Acquiring new redshift connection "model.my_new_project.stg_customers"
2022-01-06 15:52:54.979880 (Thread-2): 15:52:54  Began compiling node model.my_new_project.stg_customers
2022-01-06 15:52:54.979955 (Thread-2): 15:52:54  Compiling model.my_new_project.stg_customers
2022-01-06 15:52:54.981746 (Thread-2): 15:52:54  Writing injected SQL for node "model.my_new_project.stg_customers"
2022-01-06 15:52:54.982360 (Thread-3): 15:52:54  Began running node model.my_new_project.stg_orders
2022-01-06 15:52:54.982525 (Thread-3): 15:52:54  Acquiring new redshift connection "model.my_new_project.stg_orders"
2022-01-06 15:52:54.982607 (Thread-3): 15:52:54  Began compiling node model.my_new_project.stg_orders
2022-01-06 15:52:54.982684 (Thread-3): 15:52:54  Compiling model.my_new_project.stg_orders
2022-01-06 15:52:54.983703 (Thread-3): 15:52:54  Writing injected SQL for node "model.my_new_project.stg_orders"
2022-01-06 15:52:54.992400 (Thread-396): sending response (<Response 31055 bytes [200 OK]>) to 10.0.4.41
2022-01-06 15:52:54.995874 (Thread-1): 15:52:54  finished collecting timing info
2022-01-06 15:52:54.996025 (Thread-1): 15:52:54  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 15:52:54.996124 (Thread-1): 15:52:54  finished collecting timing info
2022-01-06 15:52:54.996261 (Thread-1): 15:52:54  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 15:52:54.996876 (Thread-4): 15:52:54  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 15:52:54.997058 (Thread-4): 15:52:54  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 15:52:54.997139 (Thread-4): 15:52:54  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 15:52:54.997243 (Thread-4): 15:52:54  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 15:52:54.999233 (Thread-4): 15:52:54  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 15:52:54.999394 (Thread-1): 15:52:54  Began running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 15:52:54.999528 (Thread-1): 15:52:54  Acquiring new redshift connection "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-06 15:52:54.999603 (Thread-1): 15:52:54  Began compiling node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 15:52:54.999676 (Thread-1): 15:52:54  Compiling test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 15:52:55.004495 (Thread-2): 15:52:55  finished collecting timing info
2022-01-06 15:52:55.004626 (Thread-2): 15:52:55  Began executing node model.my_new_project.stg_customers
2022-01-06 15:52:55.004720 (Thread-2): 15:52:55  finished collecting timing info
2022-01-06 15:52:55.004855 (Thread-2): 15:52:55  Finished running node model.my_new_project.stg_customers
2022-01-06 15:52:55.004969 (Thread-2): 15:52:55  Began running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 15:52:55.005077 (Thread-2): 15:52:55  Acquiring new redshift connection "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-06 15:52:55.005150 (Thread-2): 15:52:55  Began compiling node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 15:52:55.005261 (Thread-2): 15:52:55  Compiling test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 15:52:55.013584 (Thread-1): 15:52:55  Writing injected SQL for node "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-06 15:52:55.016987 (Thread-2): 15:52:55  Writing injected SQL for node "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-06 15:52:55.017172 (Thread-3): 15:52:55  finished collecting timing info
2022-01-06 15:52:55.017354 (Thread-3): 15:52:55  Began executing node model.my_new_project.stg_orders
2022-01-06 15:52:55.017449 (Thread-3): 15:52:55  finished collecting timing info
2022-01-06 15:52:55.017581 (Thread-3): 15:52:55  Finished running node model.my_new_project.stg_orders
2022-01-06 15:52:55.018362 (Thread-3): 15:52:55  Began running node model.my_new_project.dim_customers
2022-01-06 15:52:55.018489 (Thread-3): 15:52:55  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 15:52:55.018567 (Thread-3): 15:52:55  Began compiling node model.my_new_project.dim_customers
2022-01-06 15:52:55.018640 (Thread-3): 15:52:55  Compiling model.my_new_project.dim_customers
2022-01-06 15:52:55.020992 (Thread-3): 15:52:55  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 15:52:55.027870 (Thread-4): 15:52:55  finished collecting timing info
2022-01-06 15:52:55.028002 (Thread-4): 15:52:55  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 15:52:55.028094 (Thread-4): 15:52:55  finished collecting timing info
2022-01-06 15:52:55.028221 (Thread-4): 15:52:55  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 15:52:55.028735 (Thread-4): 15:52:55  Began running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 15:52:55.028855 (Thread-4): 15:52:55  Acquiring new redshift connection "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2022-01-06 15:52:55.028929 (Thread-4): 15:52:55  Began compiling node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 15:52:55.029001 (Thread-4): 15:52:55  Compiling test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 15:52:55.031933 (Thread-4): 15:52:55  Writing injected SQL for node "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2022-01-06 15:52:55.033349 (Thread-1): 15:52:55  finished collecting timing info
2022-01-06 15:52:55.033479 (Thread-1): 15:52:55  Began executing node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 15:52:55.033569 (Thread-1): 15:52:55  finished collecting timing info
2022-01-06 15:52:55.033695 (Thread-1): 15:52:55  Finished running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 15:52:55.033804 (Thread-1): 15:52:55  Began running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 15:52:55.033906 (Thread-1): 15:52:55  Acquiring new redshift connection "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2022-01-06 15:52:55.033977 (Thread-1): 15:52:55  Began compiling node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 15:52:55.034046 (Thread-1): 15:52:55  Compiling test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 15:52:55.036842 (Thread-1): 15:52:55  Writing injected SQL for node "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2022-01-06 15:52:55.037014 (Thread-2): 15:52:55  finished collecting timing info
2022-01-06 15:52:55.037138 (Thread-2): 15:52:55  Began executing node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 15:52:55.037256 (Thread-2): 15:52:55  finished collecting timing info
2022-01-06 15:52:55.037390 (Thread-2): 15:52:55  Finished running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 15:52:55.037716 (Thread-3): 15:52:55  finished collecting timing info
2022-01-06 15:52:55.037836 (Thread-3): 15:52:55  Began executing node model.my_new_project.dim_customers
2022-01-06 15:52:55.037925 (Thread-3): 15:52:55  finished collecting timing info
2022-01-06 15:52:55.038048 (Thread-3): 15:52:55  Finished running node model.my_new_project.dim_customers
2022-01-06 15:52:55.045502 (Thread-4): 15:52:55  finished collecting timing info
2022-01-06 15:52:55.045629 (Thread-4): 15:52:55  Began executing node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 15:52:55.045718 (Thread-4): 15:52:55  finished collecting timing info
2022-01-06 15:52:55.045839 (Thread-4): 15:52:55  Finished running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 15:52:55.052328 (Thread-1): 15:52:55  finished collecting timing info
2022-01-06 15:52:55.052454 (Thread-1): 15:52:55  Began executing node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 15:52:55.052542 (Thread-1): 15:52:55  finished collecting timing info
2022-01-06 15:52:55.052662 (Thread-1): 15:52:55  Finished running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 15:52:55.053753 (MainThread): 15:52:55  Connection 'master' was properly closed.
2022-01-06 15:52:55.053862 (MainThread): 15:52:55  Connection 'test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
2022-01-06 15:52:55.053930 (MainThread): 15:52:55  Connection 'test.my_new_project.unique_my_first_dbt_model_id.16e066b321' was properly closed.
2022-01-06 15:52:55.053993 (MainThread): 15:52:55  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 15:52:55.054053 (MainThread): 15:52:55  Connection 'test.my_new_project.not_null_my_second_dbt_model_id.151b76d778' was properly closed.
2022-01-06 15:52:55.117444 (MainThread): 15:52:55  Done.
2022-01-06 15:52:55.191955 (MainThread): 15:52:55  Acquiring new redshift connection "generate_catalog"
2022-01-06 15:52:55.192061 (MainThread): 15:52:55  Building catalog
2022-01-06 15:52:55.193164 (ThreadPoolExecutor-1_0): 15:52:55  Acquiring new redshift connection "dev.information_schema"
2022-01-06 15:52:55.202961 (ThreadPoolExecutor-1_0): 15:52:55  Using redshift connection "dev.information_schema"
2022-01-06 15:52:55.203059 (ThreadPoolExecutor-1_0): 15:52:55  On dev.information_schema: BEGIN
2022-01-06 15:52:55.203139 (ThreadPoolExecutor-1_0): 15:52:55  Opening a new connection, currently in state init
2022-01-06 15:52:55.203216 (ThreadPoolExecutor-1_0): 15:52:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 15:52:55.221150 (ThreadPoolExecutor-1_0): 15:52:55  SQL status: BEGIN in 0.02 seconds
2022-01-06 15:52:55.221279 (ThreadPoolExecutor-1_0): 15:52:55  Using redshift connection "dev.information_schema"
2022-01-06 15:52:55.221355 (ThreadPoolExecutor-1_0): 15:52:55  On dev.information_schema: 
    

    with late_binding as (
      select
        'dev'::varchar as table_database,
        table_schema,
        table_name,
        'LATE BINDING VIEW'::varchar as table_type,
        null::text as table_comment,

        column_name,
        column_index,
        column_type,
        null::text as column_comment
      from pg_get_late_binding_view_cols()
        cols(table_schema name, table_name name, column_name name,
             column_type varchar,
             column_index int)
        order by "column_index"
    ),

    early_binding as (
        select
            'dev'::varchar as table_database,
            sch.nspname as table_schema,
            tbl.relname as table_name,
            case tbl.relkind
                when 'v' then 'VIEW'
                else 'BASE TABLE'
            end as table_type,
            tbl_desc.description as table_comment,
            col.attname as column_name,
            col.attnum as column_index,
            pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
            col_desc.description as column_comment

        from pg_catalog.pg_namespace sch
        join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
        join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
        left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
        left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
        where (upper(sch.nspname) = upper('dbt_nobodozie'))
            and tbl.relkind in ('r', 'v', 'f', 'p')
            and col.attnum > 0
            and not col.attisdropped
    ),

    table_owners as (

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            tablename as table_name,
            tableowner as table_owner

        from pg_tables

        union all

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            viewname as table_name,
            viewowner as table_owner

        from pg_views

    ),

    unioned as (

        select *
        from early_binding

        union all

        select *
        from late_binding

    )

    select *,
        table_database || '.' || table_schema || '.' || table_name as table_id

    from unioned
    join table_owners using (table_database, table_schema, table_name)

    where (upper(table_schema) = upper('dbt_nobodozie'))

    order by "column_index"
2022-01-06 15:52:55.281952 (ThreadPoolExecutor-1_0): 15:52:55  SQL status: SELECT in 0.06 seconds
2022-01-06 15:52:55.285407 (ThreadPoolExecutor-1_0): 15:52:55  Using redshift connection "dev.information_schema"
2022-01-06 15:52:55.285500 (ThreadPoolExecutor-1_0): 15:52:55  On dev.information_schema: select has_table_privilege(current_user, 'svv_table_info', 'SELECT') as can_select
2022-01-06 15:52:55.287731 (ThreadPoolExecutor-1_0): 15:52:55  SQL status: SELECT in 0.0 seconds
2022-01-06 15:52:55.291370 (ThreadPoolExecutor-1_0): 15:52:55  Using redshift connection "dev.information_schema"
2022-01-06 15:52:55.291463 (ThreadPoolExecutor-1_0): 15:52:55  On dev.information_schema: select
        "database" || '.' || "schema" || '.' || "table" as table_id,

        'Encoded'::text as "stats:encoded:label",
        encoded as "stats:encoded:value",
        'Indicates whether any column in the table has compression encoding defined.'::text as "stats:encoded:description",
        true as "stats:encoded:include",

        'Dist Style' as "stats:diststyle:label",
        diststyle as "stats:diststyle:value",
        'Distribution style or distribution key column, if key distribution is defined.'::text as "stats:diststyle:description",
        true as "stats:diststyle:include",

        'Sort Key 1' as "stats:sortkey1:label",
        -- handle 0xFF byte in response for interleaved sort styles
        case
            when sortkey1 like 'INTERLEAVED%' then 'INTERLEAVED'::text
            else sortkey1
        end as "stats:sortkey1:value",
        'First column in the sort key.'::text as "stats:sortkey1:description",
        (sortkey1 is not null) as "stats:sortkey1:include",

        'Max Varchar' as "stats:max_varchar:label",
        max_varchar as "stats:max_varchar:value",
        'Size of the largest column that uses a VARCHAR data type.'::text as "stats:max_varchar:description",
        true as "stats:max_varchar:include",

        -- exclude this, as the data is strangely returned with null-byte characters
        'Sort Key 1 Encoding' as "stats:sortkey1_enc:label",
        sortkey1_enc as "stats:sortkey1_enc:value",
        'Compression encoding of the first column in the sort key.' as "stats:sortkey1_enc:description",
        false as "stats:sortkey1_enc:include",

        '# Sort Keys' as "stats:sortkey_num:label",
        sortkey_num as "stats:sortkey_num:value",
        'Number of columns defined as sort keys.' as "stats:sortkey_num:description",
        (sortkey_num > 0) as "stats:sortkey_num:include",

        'Approximate Size' as "stats:size:label",
        size * 1000000 as "stats:size:value",
        'Approximate size of the table, calculated from a count of 1MB blocks'::text as "stats:size:description",
        true as "stats:size:include",

        'Disk Utilization' as "stats:pct_used:label",
        pct_used / 100.0 as "stats:pct_used:value",
        'Percent of available space that is used by the table.'::text as "stats:pct_used:description",
        true as "stats:pct_used:include",

        'Unsorted %' as "stats:unsorted:label",
        unsorted / 100.0 as "stats:unsorted:value",
        'Percent of unsorted rows in the table.'::text as "stats:unsorted:description",
        (unsorted is not null) as "stats:unsorted:include",

        'Stats Off' as "stats:stats_off:label",
        stats_off as "stats:stats_off:value",
        'Number that indicates how stale the table statistics are; 0 is current, 100 is out of date.'::text as "stats:stats_off:description",
        true as "stats:stats_off:include",

        'Approximate Row Count' as "stats:rows:label",
        tbl_rows as "stats:rows:value",
        'Approximate number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed.'::text as "stats:rows:description",
        true as "stats:rows:include",

        'Sort Key Skew' as "stats:skew_sortkey1:label",
        skew_sortkey1 as "stats:skew_sortkey1:value",
        'Ratio of the size of the largest non-sort key column to the size of the first column of the sort key.'::text as "stats:skew_sortkey1:description",
        (skew_sortkey1 is not null) as "stats:skew_sortkey1:include",

        'Skew Rows' as "stats:skew_rows:label",
        skew_rows as "stats:skew_rows:value",
        'Ratio of the number of rows in the slice with the most rows to the number of rows in the slice with the fewest rows.'::text as "stats:skew_rows:description",
        (skew_rows is not null) as "stats:skew_rows:include"

    from svv_table_info
    where (upper(schema) = upper('dbt_nobodozie'))
2022-01-06 15:52:55.945730 (ThreadPoolExecutor-1_0): 15:52:55  SQL status: SELECT in 0.65 seconds
2022-01-06 15:52:55.956541 (ThreadPoolExecutor-1_0): 15:52:55  On dev.information_schema: ROLLBACK
2022-01-06 15:52:55.958595 (ThreadPoolExecutor-1_0): 15:52:55  On dev.information_schema: Close
2022-01-06 15:52:56.045332 (MainThread): 15:52:56  Catalog written to /usr/src/develop/user-52374/environment-57794/repository-46678/target/catalog.json
2022-01-06 15:52:56.465611 (Thread-397): handling poll request
2022-01-06 15:52:56.466002 (Thread-397): 15:52:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9c9070>]}
2022-01-06 15:52:56.467722 (Thread-397): sending response (<Response 51125 bytes [200 OK]>) to 10.0.21.24
2022-01-06 15:52:57.063872 (Thread-398): handling status request
2022-01-06 15:52:57.064278 (Thread-398): 15:52:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9c9ac0>]}
2022-01-06 15:52:57.064808 (Thread-398): sending response (<Response 1244 bytes [200 OK]>) to 10.0.38.186
2022-01-06 15:52:57.105910 (Thread-399): handling status request
2022-01-06 15:52:57.106179 (Thread-399): 15:52:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9d8280>]}
2022-01-06 15:52:57.106546 (Thread-399): sending response (<Response 1244 bytes [200 OK]>) to 10.0.23.79
2022-01-06 15:52:57.169283 (Thread-400): handling status request
2022-01-06 15:52:57.169531 (Thread-400): 15:52:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9d84f0>]}
2022-01-06 15:52:57.169879 (Thread-400): sending response (<Response 1244 bytes [200 OK]>) to 10.0.41.69
2022-01-06 18:41:51.770699 (Thread-401): handling ps request
2022-01-06 18:41:51.771202 (Thread-401): 18:41:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9d18b0>]}
2022-01-06 18:41:51.775406 (Thread-401): sending response (<Response 31797 bytes [200 OK]>) to 10.0.5.108
2022-01-06 18:41:51.833327 (Thread-402): handling status request
2022-01-06 18:41:51.833682 (Thread-402): 18:41:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2ba45730>]}
2022-01-06 18:41:51.834129 (Thread-402): sending response (<Response 1244 bytes [200 OK]>) to 10.0.47.45
2022-01-06 18:41:52.096536 (Thread-403): handling status request
2022-01-06 18:41:52.096900 (Thread-403): 18:41:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9d1040>]}
2022-01-06 18:41:52.097391 (Thread-403): sending response (<Response 1244 bytes [200 OK]>) to 10.0.31.30
2022-01-06 18:41:52.848009 (Thread-404): handling status request
2022-01-06 18:41:52.848375 (Thread-404): 18:41:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9d19d0>]}
2022-01-06 18:41:52.848847 (Thread-404): sending response (<Response 1244 bytes [200 OK]>) to 10.0.31.30
2022-01-06 18:41:52.978323 (Thread-405): handling poll request
2022-01-06 18:41:52.978645 (Thread-405): 18:41:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9d1e50>]}
2022-01-06 18:41:52.980823 (Thread-405): sending response (<Response 81886 bytes [200 OK]>) to 10.0.39.67
2022-01-06 18:41:53.727486 (Thread-406): handling status request
2022-01-06 18:41:53.727867 (Thread-406): 18:41:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9d1fd0>]}
2022-01-06 18:41:53.728340 (Thread-406): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:41:53.729323 (Thread-407): handling status request
2022-01-06 18:41:53.729666 (Thread-407): 18:41:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9def10>]}
2022-01-06 18:41:53.730082 (Thread-407): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:41:53.735160 (Thread-408): handling list request
2022-01-06 18:41:53.735392 (Thread-408): 18:41:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9d1880>]}
2022-01-06 18:41:53.805883 (Thread-413): sending response (<Response 214 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:41:53.885959 (Thread-414): handling status request
2022-01-06 18:41:53.886297 (Thread-414): 18:41:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9d89d0>]}
2022-01-06 18:41:53.886732 (Thread-414): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:41:53.892205 (Thread-415): handling list request
2022-01-06 18:41:53.892437 (Thread-415): 18:41:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9d16d0>]}
2022-01-06 18:41:53.976759 (Thread-417): sending response (<Response 214 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:41:54.307172 (Thread-418): handling status request
2022-01-06 18:41:54.307523 (Thread-418): 18:41:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9bc070>]}
2022-01-06 18:41:54.307971 (Thread-418): sending response (<Response 1244 bytes [200 OK]>) to 10.0.28.223
2022-01-06 18:41:54.312229 (Thread-419): handling status request
2022-01-06 18:41:54.312472 (Thread-419): 18:41:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9b4ac0>]}
2022-01-06 18:41:54.312815 (Thread-419): sending response (<Response 1244 bytes [200 OK]>) to 10.0.5.108
2022-01-06 18:41:54.925680 (Thread-420): handling status request
2022-01-06 18:41:54.926077 (Thread-420): 18:41:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2ba40430>]}
2022-01-06 18:41:54.947123 (Thread-420): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:41:54.952952 (Thread-421): handling list request
2022-01-06 18:41:54.953288 (Thread-421): 18:41:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b99aeb0>]}
2022-01-06 18:41:54.981666 (Thread-421): 18:41:54  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9c3250>]}
2022-01-06 18:41:54.981980 (Thread-421): 18:41:54  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:41:54.984260 (Thread-421): sending response (<Response 2813 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:42:12.828292 (Thread-422): handling status request
2022-01-06 18:42:12.828664 (Thread-422): 18:42:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2912f370>]}
2022-01-06 18:42:12.829122 (Thread-422): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:42:12.837200 (Thread-423): handling list request
2022-01-06 18:42:12.837520 (Thread-423): 18:42:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9c3520>]}
2022-01-06 18:42:12.866825 (Thread-423): 18:42:12  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2912f220>]}
2022-01-06 18:42:12.867111 (Thread-423): 18:42:12  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:42:12.867470 (Thread-423): 18:42:12  The selection criterion '+schema.sql+' does not match any nodes
2022-01-06 18:42:12.867596 (Thread-423): 18:42:12  No nodes selected!
2022-01-06 18:42:12.868944 (Thread-423): sending response (<Response 1923 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:42:16.227299 (Thread-424): 18:42:16  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 18:42:16.227502 (Thread-424): 18:42:16  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 18:42:16.232504 (Thread-424): 18:42:16  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff288cadf0>]}
2022-01-06 18:42:16.907356 (Thread-425): handling status request
2022-01-06 18:42:16.907721 (Thread-425): 18:42:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2bd264f0>]}
2022-01-06 18:42:16.908187 (Thread-425): sending response (<Response 1244 bytes [200 OK]>) to 10.0.17.11
2022-01-06 18:42:16.957210 (Thread-426): handling status request
2022-01-06 18:42:16.957530 (Thread-426): 18:42:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff288c4ac0>]}
2022-01-06 18:42:16.957948 (Thread-426): sending response (<Response 1244 bytes [200 OK]>) to 10.0.1.28
2022-01-06 18:42:17.508266 (Thread-427): handling status request
2022-01-06 18:42:17.508651 (Thread-427): 18:42:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff288c4cd0>]}
2022-01-06 18:42:17.509129 (Thread-427): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:42:17.516246 (Thread-428): handling list request
2022-01-06 18:42:17.516480 (Thread-428): 18:42:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff288c4a60>]}
2022-01-06 18:42:17.545509 (Thread-428): 18:42:17  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9b4a60>]}
2022-01-06 18:42:17.545793 (Thread-428): 18:42:17  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:42:17.546163 (Thread-428): 18:42:17  The selection criterion '+schema.sql+' does not match any nodes
2022-01-06 18:42:17.546289 (Thread-428): 18:42:17  No nodes selected!
2022-01-06 18:42:17.547658 (Thread-428): sending response (<Response 1923 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:43:15.932487 (Thread-429): handling status request
2022-01-06 18:43:15.932846 (Thread-429): 18:43:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff288cae80>]}
2022-01-06 18:43:15.933352 (Thread-429): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:43:15.944616 (Thread-430): handling list request
2022-01-06 18:43:15.944855 (Thread-430): 18:43:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff288cb0a0>]}
2022-01-06 18:43:15.975332 (Thread-430): 18:43:15  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9bcaf0>]}
2022-01-06 18:43:15.975626 (Thread-430): 18:43:15  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:43:15.975988 (Thread-430): 18:43:15  The selection criterion '+schema.sql+' does not match any nodes
2022-01-06 18:43:15.976119 (Thread-430): 18:43:15  No nodes selected!
2022-01-06 18:43:15.977579 (Thread-430): sending response (<Response 1923 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:50:24.563343 (Thread-431): handling status request
2022-01-06 18:50:24.565089 (Thread-431): 18:50:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff288caca0>]}
2022-01-06 18:50:24.565584 (Thread-431): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:50:24.575450 (Thread-432): handling list request
2022-01-06 18:50:24.575683 (Thread-432): 18:50:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff288cbc40>]}
2022-01-06 18:50:24.608278 (Thread-432): 18:50:24  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff288ee910>]}
2022-01-06 18:50:24.608795 (Thread-432): 18:50:24  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:50:24.609171 (Thread-432): 18:50:24  The selection criterion '+schema.sql+' does not match any nodes
2022-01-06 18:50:24.609342 (Thread-432): 18:50:24  No nodes selected!
2022-01-06 18:50:24.610658 (Thread-432): sending response (<Response 1923 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:50:29.329897 (Thread-433): 18:50:29  Partial parsing enabled: 3 files deleted, 0 files added, 0 files changed.
2022-01-06 18:50:29.330225 (Thread-433): 18:50:29  Partial parsing: deleted file: my_new_project://models/example/my_first_dbt_model.sql
2022-01-06 18:50:29.330351 (Thread-433): 18:50:29  Partial parsing: deleted file: my_new_project://models/example/my_second_dbt_model.sql
2022-01-06 18:50:29.389827 (Thread-433): 18:50:29  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 18:50:29.394710 (Thread-433): 18:50:29  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff06fc9580>]}
2022-01-06 18:50:30.014817 (Thread-434): handling status request
2022-01-06 18:50:30.015176 (Thread-434): 18:50:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9de070>]}
2022-01-06 18:50:30.015660 (Thread-434): sending response (<Response 2039 bytes [200 OK]>) to 10.0.28.223
2022-01-06 18:50:30.606020 (Thread-435): handling status request
2022-01-06 18:50:30.606406 (Thread-435): 18:50:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff28085c10>]}
2022-01-06 18:50:30.606904 (Thread-435): sending response (<Response 2017 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:50:30.612619 (Thread-436): handling list request
2022-01-06 18:50:30.612857 (Thread-436): 18:50:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff28085970>]}
2022-01-06 18:50:30.616936 (Thread-437): handling status request
2022-01-06 18:50:30.617312 (Thread-437): 18:50:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff288ccd60>]}
2022-01-06 18:50:30.617835 (Thread-437): sending response (<Response 2039 bytes [200 OK]>) to 10.0.36.155
2022-01-06 18:50:30.631717 (Thread-436): 18:50:30  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff06fc2f70>]}
2022-01-06 18:50:30.631974 (Thread-436): 18:50:30  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:50:30.632300 (Thread-436): 18:50:30  The selection criterion '+schema.sql+' does not match any nodes
2022-01-06 18:50:30.632424 (Thread-436): 18:50:30  No nodes selected!
2022-01-06 18:50:30.634183 (Thread-436): sending response (<Response 3248 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:50:53.096632 (Thread-438): 18:50:53  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 18:50:53.096837 (Thread-438): 18:50:53  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 18:50:53.097155 (Thread-438): 18:50:53  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 18:50:53.102067 (Thread-438): 18:50:53  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05f41d60>]}
2022-01-06 18:50:53.811029 (Thread-439): handling status request
2022-01-06 18:50:53.811507 (Thread-439): 18:50:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff288fa5b0>]}
2022-01-06 18:50:53.812190 (Thread-439): sending response (<Response 1685 bytes [200 OK]>) to 10.0.47.45
2022-01-06 18:50:53.920477 (Thread-440): handling status request
2022-01-06 18:50:53.920835 (Thread-440): 18:50:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff06ff4190>]}
2022-01-06 18:50:53.921334 (Thread-440): sending response (<Response 1685 bytes [200 OK]>) to 10.0.47.45
2022-01-06 18:50:54.293483 (Thread-441): handling status request
2022-01-06 18:50:54.293968 (Thread-441): 18:50:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff28085df0>]}
2022-01-06 18:50:54.294498 (Thread-441): sending response (<Response 1663 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:50:54.300383 (Thread-442): handling list request
2022-01-06 18:50:54.300659 (Thread-442): 18:50:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05f3cd90>]}
2022-01-06 18:50:54.317631 (Thread-442): 18:50:54  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff288d8280>]}
2022-01-06 18:50:54.317908 (Thread-442): 18:50:54  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:50:54.318273 (Thread-442): 18:50:54  The selection criterion '+schema.sql+' does not match any nodes
2022-01-06 18:50:54.318425 (Thread-442): 18:50:54  No nodes selected!
2022-01-06 18:50:54.319772 (Thread-442): sending response (<Response 1923 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:51:04.992655 (Thread-443): 18:51:04  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 18:51:04.992851 (Thread-443): 18:51:04  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 18:51:04.993153 (Thread-443): 18:51:04  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 18:51:04.997772 (Thread-443): 18:51:04  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05ec6e80>]}
2022-01-06 18:51:05.660116 (Thread-444): handling status request
2022-01-06 18:51:05.660587 (Thread-444): 18:51:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05f12670>]}
2022-01-06 18:51:05.661146 (Thread-444): sending response (<Response 1685 bytes [200 OK]>) to 10.0.44.76
2022-01-06 18:51:05.685627 (Thread-445): handling status request
2022-01-06 18:51:05.686012 (Thread-445): 18:51:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05f12400>]}
2022-01-06 18:51:05.686530 (Thread-445): sending response (<Response 1685 bytes [200 OK]>) to 10.0.14.28
2022-01-06 18:51:06.225439 (Thread-446): handling status request
2022-01-06 18:51:06.225800 (Thread-446): 18:51:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff288c4dc0>]}
2022-01-06 18:51:06.226294 (Thread-446): sending response (<Response 1663 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:51:06.232228 (Thread-447): handling list request
2022-01-06 18:51:06.232499 (Thread-447): 18:51:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2913c550>]}
2022-01-06 18:51:06.249640 (Thread-447): 18:51:06  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05f43790>]}
2022-01-06 18:51:06.249939 (Thread-447): 18:51:06  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:51:06.250308 (Thread-447): 18:51:06  The selection criterion '+schema.sql+' does not match any nodes
2022-01-06 18:51:06.250439 (Thread-447): 18:51:06  No nodes selected!
2022-01-06 18:51:06.251844 (Thread-447): sending response (<Response 1923 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:51:56.535602 (Thread-448): handling status request
2022-01-06 18:51:56.535979 (Thread-448): 18:51:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05ec8730>]}
2022-01-06 18:51:56.536470 (Thread-448): sending response (<Response 1663 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:51:56.545925 (Thread-449): handling list request
2022-01-06 18:51:56.546154 (Thread-449): 18:51:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05ec8970>]}
2022-01-06 18:51:56.563134 (Thread-449): 18:51:56  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05ec95b0>]}
2022-01-06 18:51:56.563397 (Thread-449): 18:51:56  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:51:56.564257 (Thread-449): 18:51:56  The selection criterion '+schema.sql+' does not match any nodes
2022-01-06 18:51:56.564416 (Thread-449): 18:51:56  No nodes selected!
2022-01-06 18:51:56.565665 (Thread-449): sending response (<Response 1923 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:52:01.391783 (Thread-450): handling status request
2022-01-06 18:52:01.392162 (Thread-450): 18:52:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff288cf190>]}
2022-01-06 18:52:01.392638 (Thread-450): sending response (<Response 1663 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:52:01.405760 (Thread-451): handling list request
2022-01-06 18:52:01.406012 (Thread-451): 18:52:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05f12940>]}
2022-01-06 18:52:01.423817 (Thread-451): 18:52:01  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05ec9ee0>]}
2022-01-06 18:52:01.424258 (Thread-451): 18:52:01  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:52:01.424725 (Thread-451): 18:52:01  The selection criterion '+schema.sql+' does not match any nodes
2022-01-06 18:52:01.424917 (Thread-451): 18:52:01  No nodes selected!
2022-01-06 18:52:01.426930 (Thread-451): sending response (<Response 1923 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:52:27.169322 (Thread-452): 18:52:27  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 18:52:27.169534 (Thread-452): 18:52:27  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 18:52:27.169843 (Thread-452): 18:52:27  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 18:52:27.176536 (Thread-452): 18:52:27  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05eeaa30>]}
2022-01-06 18:52:27.850591 (Thread-453): handling status request
2022-01-06 18:52:27.850969 (Thread-453): 18:52:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff06ff4400>]}
2022-01-06 18:52:27.851490 (Thread-453): sending response (<Response 1685 bytes [200 OK]>) to 10.0.28.223
2022-01-06 18:52:27.854921 (Thread-454): handling status request
2022-01-06 18:52:27.855160 (Thread-454): 18:52:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04698070>]}
2022-01-06 18:52:27.855518 (Thread-454): sending response (<Response 1685 bytes [200 OK]>) to 10.0.24.171
2022-01-06 18:52:28.493561 (Thread-455): handling status request
2022-01-06 18:52:28.493923 (Thread-455): 18:52:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0465dc70>]}
2022-01-06 18:52:28.494395 (Thread-455): sending response (<Response 1663 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:52:28.499679 (Thread-456): handling list request
2022-01-06 18:52:28.499914 (Thread-456): 18:52:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0465dd00>]}
2022-01-06 18:52:28.516533 (Thread-456): 18:52:28  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff2b9951c0>]}
2022-01-06 18:52:28.516806 (Thread-456): 18:52:28  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:52:28.517162 (Thread-456): 18:52:28  The selection criterion '+schema.sql+' does not match any nodes
2022-01-06 18:52:28.517330 (Thread-456): 18:52:28  No nodes selected!
2022-01-06 18:52:28.518694 (Thread-456): sending response (<Response 1923 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:52:39.363011 (Thread-457): handling status request
2022-01-06 18:52:39.363369 (Thread-457): 18:52:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05eead00>]}
2022-01-06 18:52:39.363844 (Thread-457): sending response (<Response 1663 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:52:39.369614 (Thread-458): handling list request
2022-01-06 18:52:39.369864 (Thread-458): 18:52:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05ec3640>]}
2022-01-06 18:52:39.385343 (Thread-458): 18:52:39  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05ec3130>]}
2022-01-06 18:52:39.386057 (Thread-458): 18:52:39  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:52:39.388389 (Thread-458): sending response (<Response 2290 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:53:04.431439 (Thread-459): 18:53:04  Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
2022-01-06 18:53:04.431767 (Thread-459): 18:53:04  Partial parsing: added file: my_new_project://models/staging/jaffle_shop/stg_customers.sql
2022-01-06 18:53:04.431984 (Thread-459): 18:53:04  Partial parsing: deleted file: my_new_project://models/stg_customers.sql
2022-01-06 18:53:04.436530 (Thread-459): 18:53:04  1699: static parser successfully parsed staging/jaffle_shop/stg_customers.sql
2022-01-06 18:53:04.439001 (Thread-459): 18:53:04  1699: static parser successfully parsed dim_customers.sql
2022-01-06 18:53:04.478305 (Thread-459): 18:53:04  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 18:53:04.483165 (Thread-459): 18:53:04  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04595760>]}
2022-01-06 18:53:05.031631 (Thread-460): handling status request
2022-01-06 18:53:05.032005 (Thread-460): 18:53:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05f121f0>]}
2022-01-06 18:53:05.032513 (Thread-460): sending response (<Response 2648 bytes [200 OK]>) to 10.0.44.31
2022-01-06 18:53:05.817910 (Thread-461): handling status request
2022-01-06 18:53:05.818322 (Thread-461): 18:53:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05f12190>]}
2022-01-06 18:53:05.818849 (Thread-461): sending response (<Response 2626 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:53:05.841750 (Thread-462): handling list request
2022-01-06 18:53:05.842114 (Thread-462): 18:53:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04620460>]}
2022-01-06 18:53:05.850186 (Thread-463): handling status request
2022-01-06 18:53:05.850568 (Thread-463): 18:53:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04667340>]}
2022-01-06 18:53:05.851187 (Thread-463): sending response (<Response 2648 bytes [200 OK]>) to 10.0.39.207
2022-01-06 18:53:05.862244 (Thread-462): 18:53:05  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff06ff47f0>]}
2022-01-06 18:53:05.862571 (Thread-462): 18:53:05  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:53:05.863380 (Thread-462): 18:53:05  The selection criterion '+models/stg_customers.sql+' does not match any nodes
2022-01-06 18:53:05.863556 (Thread-462): 18:53:05  No nodes selected!
2022-01-06 18:53:05.865467 (Thread-462): sending response (<Response 3262 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:53:06.015521 (Thread-464): handling status request
2022-01-06 18:53:06.015891 (Thread-464): 18:53:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff045951f0>]}
2022-01-06 18:53:06.016551 (Thread-464): sending response (<Response 2626 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:53:06.022579 (Thread-465): handling list request
2022-01-06 18:53:06.022828 (Thread-465): 18:53:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04595910>]}
2022-01-06 18:53:06.040099 (Thread-465): 18:53:06  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04661a60>]}
2022-01-06 18:53:06.040511 (Thread-465): 18:53:06  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:53:06.042562 (Thread-465): sending response (<Response 2310 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:53:27.666567 (Thread-466): 18:53:27  Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
2022-01-06 18:53:27.666885 (Thread-466): 18:53:27  Partial parsing: added file: my_new_project://models/staging/jaffle_shop/stg_orders.sql
2022-01-06 18:53:27.667086 (Thread-466): 18:53:27  Partial parsing: deleted file: my_new_project://models/stg_orders.sql
2022-01-06 18:53:27.671283 (Thread-466): 18:53:27  1699: static parser successfully parsed staging/jaffle_shop/stg_orders.sql
2022-01-06 18:53:27.673941 (Thread-466): 18:53:27  1699: static parser successfully parsed dim_customers.sql
2022-01-06 18:53:27.714585 (Thread-466): 18:53:27  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 18:53:27.719432 (Thread-466): 18:53:27  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff044cc700>]}
2022-01-06 18:53:28.305260 (Thread-467): handling status request
2022-01-06 18:53:28.305624 (Thread-467): 18:53:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff046984f0>]}
2022-01-06 18:53:28.306123 (Thread-467): sending response (<Response 2639 bytes [200 OK]>) to 10.0.47.45
2022-01-06 18:53:28.371236 (Thread-468): handling status request
2022-01-06 18:53:28.371578 (Thread-468): 18:53:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff046981f0>]}
2022-01-06 18:53:28.372082 (Thread-468): sending response (<Response 2639 bytes [200 OK]>) to 10.0.31.30
2022-01-06 18:53:28.963561 (Thread-469): handling status request
2022-01-06 18:53:28.963923 (Thread-469): 18:53:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05f12790>]}
2022-01-06 18:53:28.964418 (Thread-469): sending response (<Response 2617 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:53:28.970379 (Thread-470): handling list request
2022-01-06 18:53:28.970614 (Thread-470): 18:53:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04521fd0>]}
2022-01-06 18:53:28.987325 (Thread-470): 18:53:28  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04620d30>]}
2022-01-06 18:53:28.987596 (Thread-470): 18:53:28  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:53:28.989559 (Thread-470): sending response (<Response 2310 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:54:18.325713 (Thread-471): handling status request
2022-01-06 18:54:18.326079 (Thread-471): 18:54:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff044cc340>]}
2022-01-06 18:54:18.326587 (Thread-471): sending response (<Response 2617 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:54:18.336500 (Thread-472): handling list request
2022-01-06 18:54:18.336734 (Thread-472): 18:54:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff044cce80>]}
2022-01-06 18:54:18.354348 (Thread-472): 18:54:18  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0458bd90>]}
2022-01-06 18:54:18.354615 (Thread-472): 18:54:18  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:54:18.356601 (Thread-472): sending response (<Response 2310 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:54:28.623604 (Thread-473): 18:54:28  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 18:54:28.623800 (Thread-473): 18:54:28  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 18:54:28.624108 (Thread-473): 18:54:28  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 18:54:28.628621 (Thread-473): 18:54:28  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff044452b0>]}
2022-01-06 18:54:29.272783 (Thread-474): handling status request
2022-01-06 18:54:29.273161 (Thread-474): 18:54:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0454c520>]}
2022-01-06 18:54:29.273732 (Thread-474): sending response (<Response 1685 bytes [200 OK]>) to 10.0.36.155
2022-01-06 18:54:29.412991 (Thread-475): handling status request
2022-01-06 18:54:29.413427 (Thread-475): 18:54:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04698490>]}
2022-01-06 18:54:29.413912 (Thread-475): sending response (<Response 1685 bytes [200 OK]>) to 10.0.31.2
2022-01-06 18:54:29.987167 (Thread-476): handling status request
2022-01-06 18:54:29.987589 (Thread-476): 18:54:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff044cc670>]}
2022-01-06 18:54:29.988069 (Thread-476): sending response (<Response 1663 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:54:29.994585 (Thread-477): handling list request
2022-01-06 18:54:29.994832 (Thread-477): 18:54:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0449a430>]}
2022-01-06 18:54:30.011115 (Thread-477): 18:54:30  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff044e79d0>]}
2022-01-06 18:54:30.011386 (Thread-477): 18:54:30  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:54:30.013438 (Thread-477): sending response (<Response 2310 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:54:36.774684 (Thread-478): 18:54:36  Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
2022-01-06 18:54:36.774990 (Thread-478): 18:54:36  Partial parsing: added file: my_new_project://models/marts/core/dim_customers.sql
2022-01-06 18:54:36.775118 (Thread-478): 18:54:36  Partial parsing: deleted file: my_new_project://models/dim_customers.sql
2022-01-06 18:54:36.779501 (Thread-478): 18:54:36  1699: static parser successfully parsed marts/core/dim_customers.sql
2022-01-06 18:54:36.823869 (Thread-478): 18:54:36  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 18:54:36.828404 (Thread-478): 18:54:36  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff043e4b20>]}
2022-01-06 18:54:37.421958 (Thread-479): handling status request
2022-01-06 18:54:37.422320 (Thread-479): 18:54:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff043d2bb0>]}
2022-01-06 18:54:37.422813 (Thread-479): sending response (<Response 2331 bytes [200 OK]>) to 10.0.44.76
2022-01-06 18:54:37.485476 (Thread-480): handling status request
2022-01-06 18:54:37.485810 (Thread-480): 18:54:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff043d2a00>]}
2022-01-06 18:54:37.486281 (Thread-480): sending response (<Response 2331 bytes [200 OK]>) to 10.0.31.30
2022-01-06 18:54:38.089405 (Thread-481): handling status request
2022-01-06 18:54:38.089749 (Thread-481): 18:54:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0449a8b0>]}
2022-01-06 18:54:38.090224 (Thread-481): sending response (<Response 2309 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:54:38.095655 (Thread-482): handling list request
2022-01-06 18:54:38.095890 (Thread-482): 18:54:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff043cff40>]}
2022-01-06 18:54:38.111871 (Thread-482): 18:54:38  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04445550>]}
2022-01-06 18:54:38.112137 (Thread-482): 18:54:38  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:54:38.114083 (Thread-482): sending response (<Response 2321 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:57:38.742381 (Thread-483): handling status request
2022-01-06 18:57:38.744025 (Thread-483): 18:57:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff043e2c70>]}
2022-01-06 18:57:38.744523 (Thread-483): sending response (<Response 2309 bytes [200 OK]>) to 10.0.7.144
2022-01-06 18:57:38.757324 (Thread-484): handling list request
2022-01-06 18:57:38.757554 (Thread-484): 18:57:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff043e28e0>]}
2022-01-06 18:57:38.778425 (Thread-484): 18:57:38  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04445d30>]}
2022-01-06 18:57:38.778689 (Thread-484): 18:57:38  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 18:57:38.787607 (Thread-484): sending response (<Response 2321 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:01:02.466285 (Thread-485): handling status request
2022-01-06 19:01:02.467899 (Thread-485): 19:01:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff043e4b50>]}
2022-01-06 19:01:02.468512 (Thread-485): sending response (<Response 2331 bytes [200 OK]>) to 10.0.6.251
2022-01-06 19:01:02.679628 (Thread-486): handling status request
2022-01-06 19:01:02.680011 (Thread-486): 19:01:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff043e2c40>]}
2022-01-06 19:01:02.680505 (Thread-486): sending response (<Response 2331 bytes [200 OK]>) to 10.0.28.223
2022-01-06 19:01:02.789247 (Thread-487): handling cli_args request
2022-01-06 19:01:02.789612 (Thread-487): 19:01:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff043e2f10>]}
2022-01-06 19:01:04.889993 (Thread-487): sending response (<Response 138 bytes [200 OK]>) to 10.0.14.28
2022-01-06 19:01:04.982457 (MainThread): 19:01:04  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 19:01:04.982853 (MainThread): 19:01:04  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 19:01:04.983372 (MainThread): 19:01:04  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 19:01:04.988523 (MainThread): 19:01:04  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e6fbdd2c-0e13-488a-bbb9-117ea915bde6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2c88c3520>]}
2022-01-06 19:01:05.005636 (MainThread): 19:01:05  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e6fbdd2c-0e13-488a-bbb9-117ea915bde6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2c9160cd0>]}
2022-01-06 19:01:05.005866 (MainThread): 19:01:05  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:01:05.006736 (MainThread): 19:01:05  
2022-01-06 19:01:05.006992 (MainThread): 19:01:05  Acquiring new redshift connection "master"
2022-01-06 19:01:05.007823 (ThreadPoolExecutor-0_0): 19:01:05  Acquiring new redshift connection "list_dev"
2022-01-06 19:01:05.017504 (ThreadPoolExecutor-0_0): 19:01:05  Using redshift connection "list_dev"
2022-01-06 19:01:05.017604 (ThreadPoolExecutor-0_0): 19:01:05  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 19:01:05.017687 (ThreadPoolExecutor-0_0): 19:01:05  Opening a new connection, currently in state init
2022-01-06 19:01:05.017919 (ThreadPoolExecutor-0_0): 19:01:05  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:01:05.040306 (ThreadPoolExecutor-0_0): 19:01:05  SQL status: SELECT in 0.02 seconds
2022-01-06 19:01:05.041354 (ThreadPoolExecutor-0_0): 19:01:05  On list_dev: Close
2022-01-06 19:01:05.042436 (ThreadPoolExecutor-1_0): 19:01:05  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 19:01:05.048478 (ThreadPoolExecutor-1_0): 19:01:05  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 19:01:05.048578 (ThreadPoolExecutor-1_0): 19:01:05  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 19:01:05.048659 (ThreadPoolExecutor-1_0): 19:01:05  Opening a new connection, currently in state closed
2022-01-06 19:01:05.048736 (ThreadPoolExecutor-1_0): 19:01:05  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:01:05.071347 (ThreadPoolExecutor-1_0): 19:01:05  SQL status: BEGIN in 0.02 seconds
2022-01-06 19:01:05.071462 (ThreadPoolExecutor-1_0): 19:01:05  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 19:01:05.071538 (ThreadPoolExecutor-1_0): 19:01:05  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 19:01:05.082644 (ThreadPoolExecutor-1_0): 19:01:05  SQL status: SELECT in 0.01 seconds
2022-01-06 19:01:05.083695 (ThreadPoolExecutor-1_0): 19:01:05  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 19:01:05.085510 (ThreadPoolExecutor-1_0): 19:01:05  On list_dev_dbt_nobodozie: Close
2022-01-06 19:01:05.089566 (MainThread): 19:01:05  Using redshift connection "master"
2022-01-06 19:01:05.089677 (MainThread): 19:01:05  On master: BEGIN
2022-01-06 19:01:05.089758 (MainThread): 19:01:05  Opening a new connection, currently in state init
2022-01-06 19:01:05.089834 (MainThread): 19:01:05  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:01:05.113367 (MainThread): 19:01:05  SQL status: BEGIN in 0.02 seconds
2022-01-06 19:01:05.113477 (MainThread): 19:01:05  Using redshift connection "master"
2022-01-06 19:01:05.113554 (MainThread): 19:01:05  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 19:01:05.143676 (MainThread): 19:01:05  SQL status: SELECT in 0.03 seconds
2022-01-06 19:01:05.144771 (MainThread): 19:01:05  On master: ROLLBACK
2022-01-06 19:01:05.146649 (MainThread): 19:01:05  Using redshift connection "master"
2022-01-06 19:01:05.146768 (MainThread): 19:01:05  On master: BEGIN
2022-01-06 19:01:05.150225 (MainThread): 19:01:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 19:01:05.150334 (MainThread): 19:01:05  On master: COMMIT
2022-01-06 19:01:05.150408 (MainThread): 19:01:05  Using redshift connection "master"
2022-01-06 19:01:05.150488 (MainThread): 19:01:05  On master: COMMIT
2022-01-06 19:01:05.152282 (MainThread): 19:01:05  SQL status: COMMIT in 0.0 seconds
2022-01-06 19:01:05.152392 (MainThread): 19:01:05  On master: Close
2022-01-06 19:01:05.152782 (MainThread): 19:01:05  Concurrency: 4 threads (target='default')
2022-01-06 19:01:05.152899 (MainThread): 19:01:05  
2022-01-06 19:01:05.154966 (Thread-1): 19:01:05  Began running node model.my_new_project.stg_customers
2022-01-06 19:01:05.155200 (Thread-1): 19:01:05  1 of 3 START view model dbt_nobodozie.stg_customers............................. [RUN]
2022-01-06 19:01:05.155580 (Thread-1): 19:01:05  Acquiring new redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:05.155680 (Thread-1): 19:01:05  Began compiling node model.my_new_project.stg_customers
2022-01-06 19:01:05.155772 (Thread-1): 19:01:05  Compiling model.my_new_project.stg_customers
2022-01-06 19:01:05.156845 (Thread-1): 19:01:05  Writing injected SQL for node "model.my_new_project.stg_customers"
2022-01-06 19:01:05.157073 (Thread-2): 19:01:05  Began running node model.my_new_project.stg_orders
2022-01-06 19:01:05.157436 (Thread-2): 19:01:05  2 of 3 START view model dbt_nobodozie.stg_orders................................ [RUN]
2022-01-06 19:01:05.157839 (Thread-2): 19:01:05  Acquiring new redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:05.157934 (Thread-2): 19:01:05  Began compiling node model.my_new_project.stg_orders
2022-01-06 19:01:05.158016 (Thread-2): 19:01:05  Compiling model.my_new_project.stg_orders
2022-01-06 19:01:05.159023 (Thread-2): 19:01:05  Writing injected SQL for node "model.my_new_project.stg_orders"
2022-01-06 19:01:05.182746 (Thread-2): 19:01:05  finished collecting timing info
2022-01-06 19:01:05.182887 (Thread-2): 19:01:05  Began executing node model.my_new_project.stg_orders
2022-01-06 19:01:05.188081 (Thread-1): 19:01:05  finished collecting timing info
2022-01-06 19:01:05.188218 (Thread-1): 19:01:05  Began executing node model.my_new_project.stg_customers
2022-01-06 19:01:05.219696 (Thread-2): 19:01:05  Writing runtime SQL for node "model.my_new_project.stg_orders"
2022-01-06 19:01:05.220700 (Thread-1): 19:01:05  Writing runtime SQL for node "model.my_new_project.stg_customers"
2022-01-06 19:01:05.245710 (Thread-2): 19:01:05  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:05.245825 (Thread-2): 19:01:05  On model.my_new_project.stg_orders: BEGIN
2022-01-06 19:01:05.245913 (Thread-2): 19:01:05  Opening a new connection, currently in state init
2022-01-06 19:01:05.245993 (Thread-2): 19:01:05  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:01:05.251073 (Thread-1): 19:01:05  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:05.251203 (Thread-1): 19:01:05  On model.my_new_project.stg_customers: BEGIN
2022-01-06 19:01:05.251288 (Thread-1): 19:01:05  Opening a new connection, currently in state closed
2022-01-06 19:01:05.251364 (Thread-1): 19:01:05  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:01:05.269303 (Thread-2): 19:01:05  SQL status: BEGIN in 0.02 seconds
2022-01-06 19:01:05.269419 (Thread-2): 19:01:05  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:05.269497 (Thread-2): 19:01:05  On model.my_new_project.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_orders"} */


  create view "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" as (
    with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
  ) ;

2022-01-06 19:01:05.272533 (Thread-1): 19:01:05  SQL status: BEGIN in 0.02 seconds
2022-01-06 19:01:05.272653 (Thread-1): 19:01:05  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:05.272731 (Thread-1): 19:01:05  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */


  create view "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
  ) ;

2022-01-06 19:01:05.276252 (Thread-2): 19:01:05  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 19:01:05.281499 (Thread-1): 19:01:05  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 19:01:05.283397 (Thread-1): 19:01:05  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:05.283494 (Thread-1): 19:01:05  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers" rename to "stg_customers__dbt_backup"
2022-01-06 19:01:05.283974 (Thread-2): 19:01:05  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:05.284075 (Thread-2): 19:01:05  On model.my_new_project.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders" rename to "stg_orders__dbt_backup"
2022-01-06 19:01:05.286207 (Thread-1): 19:01:05  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 19:01:05.287949 (Thread-1): 19:01:05  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:05.288043 (Thread-1): 19:01:05  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" rename to "stg_customers"
2022-01-06 19:01:05.288248 (Thread-2): 19:01:05  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 19:01:05.290053 (Thread-2): 19:01:05  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:05.290149 (Thread-2): 19:01:05  On model.my_new_project.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" rename to "stg_orders"
2022-01-06 19:01:05.290359 (Thread-1): 19:01:05  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 19:01:05.297266 (Thread-1): 19:01:05  On model.my_new_project.stg_customers: COMMIT
2022-01-06 19:01:05.297371 (Thread-1): 19:01:05  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:05.297445 (Thread-1): 19:01:05  On model.my_new_project.stg_customers: COMMIT
2022-01-06 19:01:05.297586 (Thread-2): 19:01:05  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 19:01:05.298522 (Thread-2): 19:01:05  On model.my_new_project.stg_orders: COMMIT
2022-01-06 19:01:05.298619 (Thread-2): 19:01:05  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:05.298695 (Thread-2): 19:01:05  On model.my_new_project.stg_orders: COMMIT
2022-01-06 19:01:05.346454 (Thread-488): handling poll request
2022-01-06 19:01:05.346821 (Thread-488): 19:01:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04389ac0>]}
2022-01-06 19:01:05.348524 (Thread-488): sending response (<Response 37522 bytes [200 OK]>) to 10.0.31.2
2022-01-06 19:01:05.382258 (Thread-1): 19:01:05  SQL status: COMMIT in 0.08 seconds
2022-01-06 19:01:05.382592 (Thread-1): 19:01:05  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:05.382689 (Thread-1): 19:01:05  On model.my_new_project.stg_customers: BEGIN
2022-01-06 19:01:05.382966 (Thread-2): 19:01:05  SQL status: COMMIT in 0.08 seconds
2022-01-06 19:01:05.384929 (Thread-1): 19:01:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 19:01:05.389523 (Thread-1): 19:01:05  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:05.389623 (Thread-1): 19:01:05  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */
drop view if exists "dev"."dbt_nobodozie"."stg_customers__dbt_backup" cascade
2022-01-06 19:01:05.393838 (Thread-1): 19:01:05  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 19:01:05.394536 (Thread-1): 19:01:05  On model.my_new_project.stg_customers: COMMIT
2022-01-06 19:01:05.394632 (Thread-1): 19:01:05  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:05.394706 (Thread-1): 19:01:05  On model.my_new_project.stg_customers: COMMIT
2022-01-06 19:01:05.421145 (Thread-1): 19:01:05  SQL status: COMMIT in 0.03 seconds
2022-01-06 19:01:05.421295 (Thread-1): 19:01:05  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:05.421375 (Thread-1): 19:01:05  On model.my_new_project.stg_customers: BEGIN
2022-01-06 19:01:05.423513 (Thread-1): 19:01:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 19:01:05.423987 (Thread-1): 19:01:05  finished collecting timing info
2022-01-06 19:01:05.424120 (Thread-1): 19:01:05  On model.my_new_project.stg_customers: ROLLBACK
2022-01-06 19:01:05.424328 (Thread-2): 19:01:05  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:05.424438 (Thread-2): 19:01:05  On model.my_new_project.stg_orders: BEGIN
2022-01-06 19:01:05.426916 (Thread-2): 19:01:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 19:01:05.428195 (Thread-2): 19:01:05  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:05.428290 (Thread-2): 19:01:05  On model.my_new_project.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_orders"} */
drop view if exists "dev"."dbt_nobodozie"."stg_orders__dbt_backup" cascade
2022-01-06 19:01:05.428433 (Thread-1): 19:01:05  On model.my_new_project.stg_customers: Close
2022-01-06 19:01:05.428975 (Thread-1): 19:01:05  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6fbdd2c-0e13-488a-bbb9-117ea915bde6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2c8067460>]}
2022-01-06 19:01:05.429350 (Thread-1): 19:01:05  1 of 3 OK created view model dbt_nobodozie.stg_customers........................ [CREATE VIEW in 0.27s]
2022-01-06 19:01:05.429476 (Thread-1): 19:01:05  Finished running node model.my_new_project.stg_customers
2022-01-06 19:01:05.433716 (Thread-2): 19:01:05  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 19:01:05.434396 (Thread-2): 19:01:05  On model.my_new_project.stg_orders: COMMIT
2022-01-06 19:01:05.434490 (Thread-2): 19:01:05  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:05.434565 (Thread-2): 19:01:05  On model.my_new_project.stg_orders: COMMIT
2022-01-06 19:01:05.464673 (Thread-2): 19:01:05  SQL status: COMMIT in 0.03 seconds
2022-01-06 19:01:05.464855 (Thread-2): 19:01:05  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:05.464976 (Thread-2): 19:01:05  On model.my_new_project.stg_orders: BEGIN
2022-01-06 19:01:05.467180 (Thread-2): 19:01:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 19:01:05.467619 (Thread-2): 19:01:05  finished collecting timing info
2022-01-06 19:01:05.467744 (Thread-2): 19:01:05  On model.my_new_project.stg_orders: ROLLBACK
2022-01-06 19:01:05.469496 (Thread-2): 19:01:05  On model.my_new_project.stg_orders: Close
2022-01-06 19:01:05.469949 (Thread-2): 19:01:05  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6fbdd2c-0e13-488a-bbb9-117ea915bde6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2c80a4ca0>]}
2022-01-06 19:01:05.470282 (Thread-2): 19:01:05  2 of 3 OK created view model dbt_nobodozie.stg_orders........................... [CREATE VIEW in 0.31s]
2022-01-06 19:01:05.470398 (Thread-2): 19:01:05  Finished running node model.my_new_project.stg_orders
2022-01-06 19:01:05.471310 (Thread-4): 19:01:05  Began running node model.my_new_project.dim_customers
2022-01-06 19:01:05.471550 (Thread-4): 19:01:05  3 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 19:01:05.471829 (Thread-4): 19:01:05  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:05.471923 (Thread-4): 19:01:05  Began compiling node model.my_new_project.dim_customers
2022-01-06 19:01:05.472008 (Thread-4): 19:01:05  Compiling model.my_new_project.dim_customers
2022-01-06 19:01:05.475943 (Thread-4): 19:01:05  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 19:01:05.499007 (Thread-4): 19:01:05  finished collecting timing info
2022-01-06 19:01:05.499194 (Thread-4): 19:01:05  Began executing node model.my_new_project.dim_customers
2022-01-06 19:01:05.538744 (Thread-4): 19:01:05  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 19:01:05.561329 (Thread-4): 19:01:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:05.561496 (Thread-4): 19:01:05  On model.my_new_project.dim_customers: BEGIN
2022-01-06 19:01:05.561623 (Thread-4): 19:01:05  Opening a new connection, currently in state init
2022-01-06 19:01:05.561756 (Thread-4): 19:01:05  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:01:05.581128 (Thread-4): 19:01:05  SQL status: BEGIN in 0.02 seconds
2022-01-06 19:01:05.581347 (Thread-4): 19:01:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:05.581473 (Thread-4): 19:01:05  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"


),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 19:01:05.651084 (Thread-4): 19:01:05  SQL status: SELECT in 0.07 seconds
2022-01-06 19:01:05.654434 (Thread-4): 19:01:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:05.654588 (Thread-4): 19:01:05  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 19:01:05.657284 (Thread-4): 19:01:05  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 19:01:05.659993 (Thread-4): 19:01:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:05.660125 (Thread-4): 19:01:05  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 19:01:05.662467 (Thread-4): 19:01:05  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 19:01:05.669359 (Thread-4): 19:01:05  On model.my_new_project.dim_customers: COMMIT
2022-01-06 19:01:05.669500 (Thread-4): 19:01:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:05.669611 (Thread-4): 19:01:05  On model.my_new_project.dim_customers: COMMIT
2022-01-06 19:01:05.720190 (Thread-4): 19:01:05  SQL status: COMMIT in 0.05 seconds
2022-01-06 19:01:05.720667 (Thread-4): 19:01:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:05.720831 (Thread-4): 19:01:05  On model.my_new_project.dim_customers: BEGIN
2022-01-06 19:01:05.723078 (Thread-4): 19:01:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 19:01:05.724659 (Thread-4): 19:01:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:05.724809 (Thread-4): 19:01:05  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 19:01:05.728639 (Thread-4): 19:01:05  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 19:01:05.729433 (Thread-4): 19:01:05  On model.my_new_project.dim_customers: COMMIT
2022-01-06 19:01:05.729541 (Thread-4): 19:01:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:05.729659 (Thread-4): 19:01:05  On model.my_new_project.dim_customers: COMMIT
2022-01-06 19:01:05.759766 (Thread-4): 19:01:05  SQL status: COMMIT in 0.03 seconds
2022-01-06 19:01:05.760035 (Thread-4): 19:01:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:05.760188 (Thread-4): 19:01:05  On model.my_new_project.dim_customers: BEGIN
2022-01-06 19:01:05.762426 (Thread-4): 19:01:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 19:01:05.762994 (Thread-4): 19:01:05  finished collecting timing info
2022-01-06 19:01:05.763164 (Thread-4): 19:01:05  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 19:01:05.765057 (Thread-4): 19:01:05  On model.my_new_project.dim_customers: Close
2022-01-06 19:01:05.765662 (Thread-4): 19:01:05  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6fbdd2c-0e13-488a-bbb9-117ea915bde6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2c9181af0>]}
2022-01-06 19:01:05.766098 (Thread-4): 19:01:05  3 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.29s]
2022-01-06 19:01:05.766254 (Thread-4): 19:01:05  Finished running node model.my_new_project.dim_customers
2022-01-06 19:01:05.767781 (MainThread): 19:01:05  Acquiring new redshift connection "master"
2022-01-06 19:01:05.767973 (MainThread): 19:01:05  Using redshift connection "master"
2022-01-06 19:01:05.768059 (MainThread): 19:01:05  On master: BEGIN
2022-01-06 19:01:05.768139 (MainThread): 19:01:05  Opening a new connection, currently in state closed
2022-01-06 19:01:05.768217 (MainThread): 19:01:05  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:01:05.791443 (MainThread): 19:01:05  SQL status: BEGIN in 0.02 seconds
2022-01-06 19:01:05.791595 (MainThread): 19:01:05  On master: COMMIT
2022-01-06 19:01:05.791679 (MainThread): 19:01:05  Using redshift connection "master"
2022-01-06 19:01:05.791764 (MainThread): 19:01:05  On master: COMMIT
2022-01-06 19:01:05.794866 (MainThread): 19:01:05  SQL status: COMMIT in 0.0 seconds
2022-01-06 19:01:05.794996 (MainThread): 19:01:05  On master: Close
2022-01-06 19:01:05.795496 (MainThread): 19:01:05  
2022-01-06 19:01:05.795602 (MainThread): 19:01:05  Finished running 2 view models, 1 table model in 0.79s.
2022-01-06 19:01:05.795686 (MainThread): 19:01:05  Connection 'master' was properly closed.
2022-01-06 19:01:05.795753 (MainThread): 19:01:05  Connection 'model.my_new_project.stg_customers' was properly closed.
2022-01-06 19:01:05.795848 (MainThread): 19:01:05  Connection 'model.my_new_project.stg_orders' was properly closed.
2022-01-06 19:01:05.795980 (MainThread): 19:01:05  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 19:01:05.874558 (MainThread): 19:01:05  
2022-01-06 19:01:05.874841 (MainThread): 19:01:05  Completed successfully
2022-01-06 19:01:05.875021 (MainThread): 19:01:05  
2022-01-06 19:01:05.875169 (MainThread): 19:01:05  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 19:01:06.785250 (Thread-489): handling poll request
2022-01-06 19:01:06.785623 (Thread-489): 19:01:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04328790>]}
2022-01-06 19:01:06.787583 (Thread-489): sending response (<Response 48900 bytes [200 OK]>) to 10.0.39.67
2022-01-06 19:01:07.506362 (Thread-490): handling status request
2022-01-06 19:01:07.506716 (Thread-490): 19:01:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04328940>]}
2022-01-06 19:01:07.507246 (Thread-490): sending response (<Response 2331 bytes [200 OK]>) to 10.0.13.109
2022-01-06 19:01:07.594474 (Thread-491): handling status request
2022-01-06 19:01:07.594757 (Thread-491): 19:01:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04328d30>]}
2022-01-06 19:01:07.620337 (Thread-491): sending response (<Response 2331 bytes [200 OK]>) to 10.0.23.128
2022-01-06 19:01:16.785488 (Thread-492): handling status request
2022-01-06 19:01:16.785849 (Thread-492): 19:01:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff043da130>]}
2022-01-06 19:01:16.786334 (Thread-492): sending response (<Response 2309 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:01:16.819805 (Thread-493): handling list request
2022-01-06 19:01:16.820100 (Thread-493): 19:01:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0433b130>]}
2022-01-06 19:01:16.838563 (Thread-493): 19:01:16  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0432e130>]}
2022-01-06 19:01:16.838866 (Thread-493): 19:01:16  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:01:16.841102 (Thread-493): sending response (<Response 2321 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:01:18.231884 (Thread-494): handling status request
2022-01-06 19:01:18.232295 (Thread-494): 19:01:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff043d2670>]}
2022-01-06 19:01:18.232771 (Thread-494): sending response (<Response 2309 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:01:18.238948 (Thread-495): handling list request
2022-01-06 19:01:18.239256 (Thread-495): 19:01:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0432ef40>]}
2022-01-06 19:01:18.255931 (Thread-495): 19:01:18  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0432e8e0>]}
2022-01-06 19:01:18.256216 (Thread-495): 19:01:18  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:01:18.258251 (Thread-495): sending response (<Response 2309 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:01:19.347045 (Thread-496): handling status request
2022-01-06 19:01:19.347405 (Thread-496): 19:01:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0433bdc0>]}
2022-01-06 19:01:19.347891 (Thread-496): sending response (<Response 2309 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:01:19.353489 (Thread-497): handling list request
2022-01-06 19:01:19.353788 (Thread-497): 19:01:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0433b9a0>]}
2022-01-06 19:01:19.369828 (Thread-497): 19:01:19  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04343340>]}
2022-01-06 19:01:19.370129 (Thread-497): 19:01:19  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:01:19.372418 (Thread-497): sending response (<Response 2864 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:01:24.076599 (Thread-498): 19:01:24  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 19:01:24.076977 (Thread-498): 19:01:24  Partial parsing: updated file: my_new_project://models/marts/core/dim_customers.sql
2022-01-06 19:01:24.080992 (Thread-498): 19:01:24  1699: static parser successfully parsed marts/core/dim_customers.sql
2022-01-06 19:01:24.115126 (Thread-498): 19:01:24  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 19:01:24.119588 (Thread-498): 19:01:24  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042f7520>]}
2022-01-06 19:01:24.532827 (Thread-499): handling status request
2022-01-06 19:01:24.533193 (Thread-499): 19:01:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042bab20>]}
2022-01-06 19:01:24.533718 (Thread-499): sending response (<Response 1997 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:01:24.539468 (Thread-500): handling list request
2022-01-06 19:01:24.539713 (Thread-500): 19:01:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042ba430>]}
2022-01-06 19:01:24.557370 (Thread-500): 19:01:24  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042bd250>]}
2022-01-06 19:01:24.557673 (Thread-500): 19:01:24  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:01:24.559836 (Thread-500): sending response (<Response 2863 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:01:24.775339 (Thread-501): handling status request
2022-01-06 19:01:24.775690 (Thread-501): 19:01:24  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042f79a0>]}
2022-01-06 19:01:24.776176 (Thread-501): sending response (<Response 2019 bytes [200 OK]>) to 10.0.31.2
2022-01-06 19:01:25.462695 (Thread-502): handling status request
2022-01-06 19:01:25.463061 (Thread-502): 19:01:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff043d2a90>]}
2022-01-06 19:01:25.463542 (Thread-502): sending response (<Response 1997 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:01:25.469173 (Thread-503): handling list request
2022-01-06 19:01:25.469449 (Thread-503): 19:01:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff043d2790>]}
2022-01-06 19:01:25.485453 (Thread-503): 19:01:25  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042cc0d0>]}
2022-01-06 19:01:25.486118 (Thread-503): 19:01:25  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:01:25.488117 (Thread-503): sending response (<Response 2863 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:01:25.583972 (Thread-504): handling status request
2022-01-06 19:01:25.584217 (Thread-504): 19:01:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042bd340>]}
2022-01-06 19:01:25.584592 (Thread-504): sending response (<Response 2019 bytes [200 OK]>) to 10.0.31.2
2022-01-06 19:01:27.534323 (Thread-505): handling status request
2022-01-06 19:01:27.534683 (Thread-505): 19:01:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042ba4c0>]}
2022-01-06 19:01:27.535153 (Thread-505): sending response (<Response 2019 bytes [200 OK]>) to 10.0.36.155
2022-01-06 19:01:27.717496 (Thread-506): handling status request
2022-01-06 19:01:27.717782 (Thread-506): 19:01:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042ba3d0>]}
2022-01-06 19:01:27.718206 (Thread-506): sending response (<Response 2019 bytes [200 OK]>) to 10.0.10.3
2022-01-06 19:01:27.959096 (Thread-507): handling cli_args request
2022-01-06 19:01:27.959455 (Thread-507): 19:01:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042f76a0>]}
2022-01-06 19:01:30.013080 (Thread-507): sending response (<Response 138 bytes [200 OK]>) to 10.0.28.223
2022-01-06 19:01:30.097988 (MainThread): 19:01:30  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 19:01:30.098376 (MainThread): 19:01:30  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 19:01:30.098898 (MainThread): 19:01:30  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 19:01:30.104002 (MainThread): 19:01:30  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b5de993e-4185-4338-9f91-334d10dd379d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc10fe4a550>]}
2022-01-06 19:01:30.119088 (MainThread): 19:01:30  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b5de993e-4185-4338-9f91-334d10dd379d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1106daca0>]}
2022-01-06 19:01:30.119322 (MainThread): 19:01:30  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:01:30.120188 (MainThread): 19:01:30  
2022-01-06 19:01:30.120459 (MainThread): 19:01:30  Acquiring new redshift connection "master"
2022-01-06 19:01:30.121321 (ThreadPoolExecutor-0_0): 19:01:30  Acquiring new redshift connection "list_dev"
2022-01-06 19:01:30.131035 (ThreadPoolExecutor-0_0): 19:01:30  Using redshift connection "list_dev"
2022-01-06 19:01:30.131137 (ThreadPoolExecutor-0_0): 19:01:30  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 19:01:30.131385 (ThreadPoolExecutor-0_0): 19:01:30  Opening a new connection, currently in state init
2022-01-06 19:01:30.131477 (ThreadPoolExecutor-0_0): 19:01:30  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:01:30.152203 (ThreadPoolExecutor-0_0): 19:01:30  SQL status: SELECT in 0.02 seconds
2022-01-06 19:01:30.153249 (ThreadPoolExecutor-0_0): 19:01:30  On list_dev: Close
2022-01-06 19:01:30.154278 (ThreadPoolExecutor-1_0): 19:01:30  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 19:01:30.160226 (ThreadPoolExecutor-1_0): 19:01:30  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 19:01:30.160349 (ThreadPoolExecutor-1_0): 19:01:30  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 19:01:30.160444 (ThreadPoolExecutor-1_0): 19:01:30  Opening a new connection, currently in state closed
2022-01-06 19:01:30.160532 (ThreadPoolExecutor-1_0): 19:01:30  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:01:30.181868 (ThreadPoolExecutor-1_0): 19:01:30  SQL status: BEGIN in 0.02 seconds
2022-01-06 19:01:30.181979 (ThreadPoolExecutor-1_0): 19:01:30  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 19:01:30.182055 (ThreadPoolExecutor-1_0): 19:01:30  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 19:01:30.193802 (ThreadPoolExecutor-1_0): 19:01:30  SQL status: SELECT in 0.01 seconds
2022-01-06 19:01:30.194795 (ThreadPoolExecutor-1_0): 19:01:30  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 19:01:30.196862 (ThreadPoolExecutor-1_0): 19:01:30  On list_dev_dbt_nobodozie: Close
2022-01-06 19:01:30.200826 (MainThread): 19:01:30  Using redshift connection "master"
2022-01-06 19:01:30.200938 (MainThread): 19:01:30  On master: BEGIN
2022-01-06 19:01:30.201019 (MainThread): 19:01:30  Opening a new connection, currently in state init
2022-01-06 19:01:30.201095 (MainThread): 19:01:30  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:01:30.223614 (MainThread): 19:01:30  SQL status: BEGIN in 0.02 seconds
2022-01-06 19:01:30.223724 (MainThread): 19:01:30  Using redshift connection "master"
2022-01-06 19:01:30.223802 (MainThread): 19:01:30  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 19:01:30.252603 (MainThread): 19:01:30  SQL status: SELECT in 0.03 seconds
2022-01-06 19:01:30.253595 (MainThread): 19:01:30  On master: ROLLBACK
2022-01-06 19:01:30.255499 (MainThread): 19:01:30  Using redshift connection "master"
2022-01-06 19:01:30.255603 (MainThread): 19:01:30  On master: BEGIN
2022-01-06 19:01:30.259251 (MainThread): 19:01:30  SQL status: BEGIN in 0.0 seconds
2022-01-06 19:01:30.259359 (MainThread): 19:01:30  On master: COMMIT
2022-01-06 19:01:30.259433 (MainThread): 19:01:30  Using redshift connection "master"
2022-01-06 19:01:30.259500 (MainThread): 19:01:30  On master: COMMIT
2022-01-06 19:01:30.261199 (MainThread): 19:01:30  SQL status: COMMIT in 0.0 seconds
2022-01-06 19:01:30.261322 (MainThread): 19:01:30  On master: Close
2022-01-06 19:01:30.261678 (MainThread): 19:01:30  Concurrency: 4 threads (target='default')
2022-01-06 19:01:30.261806 (MainThread): 19:01:30  
2022-01-06 19:01:30.263844 (Thread-1): 19:01:30  Began running node model.my_new_project.stg_customers
2022-01-06 19:01:30.264082 (Thread-1): 19:01:30  1 of 3 START view model dbt_nobodozie.stg_customers............................. [RUN]
2022-01-06 19:01:30.264486 (Thread-1): 19:01:30  Acquiring new redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:30.264589 (Thread-1): 19:01:30  Began compiling node model.my_new_project.stg_customers
2022-01-06 19:01:30.264682 (Thread-1): 19:01:30  Compiling model.my_new_project.stg_customers
2022-01-06 19:01:30.265790 (Thread-1): 19:01:30  Writing injected SQL for node "model.my_new_project.stg_customers"
2022-01-06 19:01:30.265995 (Thread-2): 19:01:30  Began running node model.my_new_project.stg_orders
2022-01-06 19:01:30.266186 (Thread-2): 19:01:30  2 of 3 START view model dbt_nobodozie.stg_orders................................ [RUN]
2022-01-06 19:01:30.266592 (Thread-2): 19:01:30  Acquiring new redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:30.266687 (Thread-2): 19:01:30  Began compiling node model.my_new_project.stg_orders
2022-01-06 19:01:30.266768 (Thread-2): 19:01:30  Compiling model.my_new_project.stg_orders
2022-01-06 19:01:30.267792 (Thread-2): 19:01:30  Writing injected SQL for node "model.my_new_project.stg_orders"
2022-01-06 19:01:30.282329 (Thread-2): 19:01:30  finished collecting timing info
2022-01-06 19:01:30.282468 (Thread-2): 19:01:30  Began executing node model.my_new_project.stg_orders
2022-01-06 19:01:30.294245 (Thread-1): 19:01:30  finished collecting timing info
2022-01-06 19:01:30.294374 (Thread-1): 19:01:30  Began executing node model.my_new_project.stg_customers
2022-01-06 19:01:30.315339 (Thread-2): 19:01:30  Writing runtime SQL for node "model.my_new_project.stg_orders"
2022-01-06 19:01:30.316310 (Thread-1): 19:01:30  Writing runtime SQL for node "model.my_new_project.stg_customers"
2022-01-06 19:01:30.329932 (Thread-1): 19:01:30  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:30.330041 (Thread-1): 19:01:30  On model.my_new_project.stg_customers: BEGIN
2022-01-06 19:01:30.330123 (Thread-1): 19:01:30  Opening a new connection, currently in state closed
2022-01-06 19:01:30.330214 (Thread-1): 19:01:30  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:01:30.330762 (Thread-2): 19:01:30  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:30.330871 (Thread-2): 19:01:30  On model.my_new_project.stg_orders: BEGIN
2022-01-06 19:01:30.330950 (Thread-2): 19:01:30  Opening a new connection, currently in state init
2022-01-06 19:01:30.331025 (Thread-2): 19:01:30  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:01:30.337829 (Thread-508): handling poll request
2022-01-06 19:01:30.338164 (Thread-508): 19:01:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042d1490>]}
2022-01-06 19:01:30.339573 (Thread-508): sending response (<Response 26879 bytes [200 OK]>) to 10.0.1.28
2022-01-06 19:01:30.356588 (Thread-2): 19:01:30  SQL status: BEGIN in 0.03 seconds
2022-01-06 19:01:30.356701 (Thread-2): 19:01:30  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:30.356778 (Thread-2): 19:01:30  On model.my_new_project.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_orders"} */


  create view "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" as (
    with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
  ) ;

2022-01-06 19:01:30.357106 (Thread-1): 19:01:30  SQL status: BEGIN in 0.03 seconds
2022-01-06 19:01:30.357260 (Thread-1): 19:01:30  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:30.357347 (Thread-1): 19:01:30  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */


  create view "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
  ) ;

2022-01-06 19:01:30.365005 (Thread-2): 19:01:30  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 19:01:30.370128 (Thread-1): 19:01:30  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 19:01:30.371966 (Thread-1): 19:01:30  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:30.372063 (Thread-1): 19:01:30  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers" rename to "stg_customers__dbt_backup"
2022-01-06 19:01:30.372326 (Thread-2): 19:01:30  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:30.372448 (Thread-2): 19:01:30  On model.my_new_project.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders" rename to "stg_orders__dbt_backup"
2022-01-06 19:01:30.375265 (Thread-1): 19:01:30  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 19:01:30.376961 (Thread-1): 19:01:30  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:30.377058 (Thread-1): 19:01:30  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" rename to "stg_customers"
2022-01-06 19:01:30.377201 (Thread-2): 19:01:30  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 19:01:30.378937 (Thread-2): 19:01:30  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:30.379034 (Thread-2): 19:01:30  On model.my_new_project.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" rename to "stg_orders"
2022-01-06 19:01:30.379225 (Thread-1): 19:01:30  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 19:01:30.384315 (Thread-2): 19:01:30  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 19:01:30.389467 (Thread-2): 19:01:30  On model.my_new_project.stg_orders: COMMIT
2022-01-06 19:01:30.389569 (Thread-2): 19:01:30  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:30.389646 (Thread-2): 19:01:30  On model.my_new_project.stg_orders: COMMIT
2022-01-06 19:01:30.391248 (Thread-1): 19:01:30  On model.my_new_project.stg_customers: COMMIT
2022-01-06 19:01:30.391356 (Thread-1): 19:01:30  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:30.391430 (Thread-1): 19:01:30  On model.my_new_project.stg_customers: COMMIT
2022-01-06 19:01:30.445407 (Thread-2): 19:01:30  SQL status: COMMIT in 0.06 seconds
2022-01-06 19:01:30.445746 (Thread-2): 19:01:30  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:30.445842 (Thread-2): 19:01:30  On model.my_new_project.stg_orders: BEGIN
2022-01-06 19:01:30.446125 (Thread-1): 19:01:30  SQL status: COMMIT in 0.05 seconds
2022-01-06 19:01:30.447979 (Thread-2): 19:01:30  SQL status: BEGIN in 0.0 seconds
2022-01-06 19:01:30.452482 (Thread-2): 19:01:30  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:30.452590 (Thread-2): 19:01:30  On model.my_new_project.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_orders"} */
drop view if exists "dev"."dbt_nobodozie"."stg_orders__dbt_backup" cascade
2022-01-06 19:01:30.456541 (Thread-2): 19:01:30  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 19:01:30.457291 (Thread-2): 19:01:30  On model.my_new_project.stg_orders: COMMIT
2022-01-06 19:01:30.457393 (Thread-2): 19:01:30  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:30.457468 (Thread-2): 19:01:30  On model.my_new_project.stg_orders: COMMIT
2022-01-06 19:01:30.485357 (Thread-2): 19:01:30  SQL status: COMMIT in 0.03 seconds
2022-01-06 19:01:30.485475 (Thread-2): 19:01:30  Using redshift connection "model.my_new_project.stg_orders"
2022-01-06 19:01:30.485549 (Thread-2): 19:01:30  On model.my_new_project.stg_orders: BEGIN
2022-01-06 19:01:30.487584 (Thread-2): 19:01:30  SQL status: BEGIN in 0.0 seconds
2022-01-06 19:01:30.488078 (Thread-2): 19:01:30  finished collecting timing info
2022-01-06 19:01:30.488214 (Thread-2): 19:01:30  On model.my_new_project.stg_orders: ROLLBACK
2022-01-06 19:01:30.488433 (Thread-1): 19:01:30  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:30.488546 (Thread-1): 19:01:30  On model.my_new_project.stg_customers: BEGIN
2022-01-06 19:01:30.490967 (Thread-1): 19:01:30  SQL status: BEGIN in 0.0 seconds
2022-01-06 19:01:30.492316 (Thread-1): 19:01:30  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:30.492413 (Thread-1): 19:01:30  On model.my_new_project.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.stg_customers"} */
drop view if exists "dev"."dbt_nobodozie"."stg_customers__dbt_backup" cascade
2022-01-06 19:01:30.492546 (Thread-2): 19:01:30  On model.my_new_project.stg_orders: Close
2022-01-06 19:01:30.493067 (Thread-2): 19:01:30  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5de993e-4185-4338-9f91-334d10dd379d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc10f5de310>]}
2022-01-06 19:01:30.493446 (Thread-2): 19:01:30  2 of 3 OK created view model dbt_nobodozie.stg_orders........................... [CREATE VIEW in 0.23s]
2022-01-06 19:01:30.493569 (Thread-2): 19:01:30  Finished running node model.my_new_project.stg_orders
2022-01-06 19:01:30.497501 (Thread-1): 19:01:30  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 19:01:30.498218 (Thread-1): 19:01:30  On model.my_new_project.stg_customers: COMMIT
2022-01-06 19:01:30.498315 (Thread-1): 19:01:30  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:30.498390 (Thread-1): 19:01:30  On model.my_new_project.stg_customers: COMMIT
2022-01-06 19:01:30.528094 (Thread-1): 19:01:30  SQL status: COMMIT in 0.03 seconds
2022-01-06 19:01:30.528224 (Thread-1): 19:01:30  Using redshift connection "model.my_new_project.stg_customers"
2022-01-06 19:01:30.528297 (Thread-1): 19:01:30  On model.my_new_project.stg_customers: BEGIN
2022-01-06 19:01:30.530345 (Thread-1): 19:01:30  SQL status: BEGIN in 0.0 seconds
2022-01-06 19:01:30.530830 (Thread-1): 19:01:30  finished collecting timing info
2022-01-06 19:01:30.530963 (Thread-1): 19:01:30  On model.my_new_project.stg_customers: ROLLBACK
2022-01-06 19:01:30.532777 (Thread-1): 19:01:30  On model.my_new_project.stg_customers: Close
2022-01-06 19:01:30.533316 (Thread-1): 19:01:30  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5de993e-4185-4338-9f91-334d10dd379d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc10f5c5e50>]}
2022-01-06 19:01:30.533653 (Thread-1): 19:01:30  1 of 3 OK created view model dbt_nobodozie.stg_customers........................ [CREATE VIEW in 0.27s]
2022-01-06 19:01:30.533763 (Thread-1): 19:01:30  Finished running node model.my_new_project.stg_customers
2022-01-06 19:01:30.534591 (Thread-4): 19:01:30  Began running node model.my_new_project.dim_customers
2022-01-06 19:01:30.534843 (Thread-4): 19:01:30  3 of 3 START view model dbt_nobodozie.dim_customers............................. [RUN]
2022-01-06 19:01:30.535123 (Thread-4): 19:01:30  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:30.535216 (Thread-4): 19:01:30  Began compiling node model.my_new_project.dim_customers
2022-01-06 19:01:30.535303 (Thread-4): 19:01:30  Compiling model.my_new_project.dim_customers
2022-01-06 19:01:30.538929 (Thread-4): 19:01:30  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 19:01:30.553675 (Thread-4): 19:01:30  finished collecting timing info
2022-01-06 19:01:30.553816 (Thread-4): 19:01:30  Began executing node model.my_new_project.dim_customers
2022-01-06 19:01:30.555766 (Thread-4): 19:01:30  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 19:01:30.571637 (Thread-4): 19:01:30  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:30.571765 (Thread-4): 19:01:30  On model.my_new_project.dim_customers: BEGIN
2022-01-06 19:01:30.571853 (Thread-4): 19:01:30  Opening a new connection, currently in state init
2022-01-06 19:01:30.571937 (Thread-4): 19:01:30  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:01:30.590019 (Thread-4): 19:01:30  SQL status: BEGIN in 0.02 seconds
2022-01-06 19:01:30.590162 (Thread-4): 19:01:30  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:30.590242 (Thread-4): 19:01:30  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create view "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" as (
    with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"


),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  ) ;

2022-01-06 19:01:30.597357 (Thread-4): 19:01:30  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 19:01:30.599574 (Thread-4): 19:01:30  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:30.599678 (Thread-4): 19:01:30  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 19:01:30.602196 (Thread-4): 19:01:30  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 19:01:30.604088 (Thread-4): 19:01:30  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:30.604188 (Thread-4): 19:01:30  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 19:01:30.606414 (Thread-4): 19:01:30  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 19:01:30.607439 (Thread-4): 19:01:30  On model.my_new_project.dim_customers: COMMIT
2022-01-06 19:01:30.607538 (Thread-4): 19:01:30  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:30.607612 (Thread-4): 19:01:30  On model.my_new_project.dim_customers: COMMIT
2022-01-06 19:01:30.642269 (Thread-4): 19:01:30  SQL status: COMMIT in 0.03 seconds
2022-01-06 19:01:30.642501 (Thread-4): 19:01:30  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:30.642586 (Thread-4): 19:01:30  On model.my_new_project.dim_customers: BEGIN
2022-01-06 19:01:30.644754 (Thread-4): 19:01:30  SQL status: BEGIN in 0.0 seconds
2022-01-06 19:01:30.646056 (Thread-4): 19:01:30  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:30.646158 (Thread-4): 19:01:30  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 19:01:30.649858 (Thread-4): 19:01:30  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 19:01:30.650464 (Thread-4): 19:01:30  On model.my_new_project.dim_customers: COMMIT
2022-01-06 19:01:30.650558 (Thread-4): 19:01:30  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:30.650633 (Thread-4): 19:01:30  On model.my_new_project.dim_customers: COMMIT
2022-01-06 19:01:30.679107 (Thread-4): 19:01:30  SQL status: COMMIT in 0.03 seconds
2022-01-06 19:01:30.679215 (Thread-4): 19:01:30  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 19:01:30.679287 (Thread-4): 19:01:30  On model.my_new_project.dim_customers: BEGIN
2022-01-06 19:01:30.681321 (Thread-4): 19:01:30  SQL status: BEGIN in 0.0 seconds
2022-01-06 19:01:30.681718 (Thread-4): 19:01:30  finished collecting timing info
2022-01-06 19:01:30.681853 (Thread-4): 19:01:30  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 19:01:30.683581 (Thread-4): 19:01:30  On model.my_new_project.dim_customers: Close
2022-01-06 19:01:30.684027 (Thread-4): 19:01:30  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5de993e-4185-4338-9f91-334d10dd379d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc10c557e80>]}
2022-01-06 19:01:30.684353 (Thread-4): 19:01:30  3 of 3 OK created view model dbt_nobodozie.dim_customers........................ [CREATE VIEW in 0.15s]
2022-01-06 19:01:30.684469 (Thread-4): 19:01:30  Finished running node model.my_new_project.dim_customers
2022-01-06 19:01:30.685843 (MainThread): 19:01:30  Acquiring new redshift connection "master"
2022-01-06 19:01:30.685989 (MainThread): 19:01:30  Using redshift connection "master"
2022-01-06 19:01:30.686068 (MainThread): 19:01:30  On master: BEGIN
2022-01-06 19:01:30.686147 (MainThread): 19:01:30  Opening a new connection, currently in state closed
2022-01-06 19:01:30.686224 (MainThread): 19:01:30  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:01:30.710532 (MainThread): 19:01:30  SQL status: BEGIN in 0.02 seconds
2022-01-06 19:01:30.710690 (MainThread): 19:01:30  On master: COMMIT
2022-01-06 19:01:30.710810 (MainThread): 19:01:30  Using redshift connection "master"
2022-01-06 19:01:30.710930 (MainThread): 19:01:30  On master: COMMIT
2022-01-06 19:01:30.712711 (MainThread): 19:01:30  SQL status: COMMIT in 0.0 seconds
2022-01-06 19:01:30.712838 (MainThread): 19:01:30  On master: Close
2022-01-06 19:01:30.713292 (MainThread): 19:01:30  
2022-01-06 19:01:30.713408 (MainThread): 19:01:30  Finished running 3 view models in 0.59s.
2022-01-06 19:01:30.713491 (MainThread): 19:01:30  Connection 'master' was properly closed.
2022-01-06 19:01:30.713558 (MainThread): 19:01:30  Connection 'model.my_new_project.stg_customers' was properly closed.
2022-01-06 19:01:30.713621 (MainThread): 19:01:30  Connection 'model.my_new_project.stg_orders' was properly closed.
2022-01-06 19:01:30.713681 (MainThread): 19:01:30  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 19:01:30.765291 (MainThread): 19:01:30  
2022-01-06 19:01:30.765452 (MainThread): 19:01:30  Completed successfully
2022-01-06 19:01:30.765552 (MainThread): 19:01:30  
2022-01-06 19:01:30.765640 (MainThread): 19:01:30  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 19:01:31.706123 (Thread-509): handling poll request
2022-01-06 19:01:31.706494 (Thread-509): 19:01:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04273af0>]}
2022-01-06 19:01:31.708621 (Thread-509): sending response (<Response 59419 bytes [200 OK]>) to 10.0.5.108
2022-01-06 19:01:32.399390 (Thread-510): handling status request
2022-01-06 19:01:32.399746 (Thread-510): 19:01:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04273ca0>]}
2022-01-06 19:01:32.400246 (Thread-510): sending response (<Response 2019 bytes [200 OK]>) to 10.0.28.223
2022-01-06 19:01:32.442590 (Thread-511): handling status request
2022-01-06 19:01:32.442840 (Thread-511): 19:01:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04273f70>]}
2022-01-06 19:01:32.443208 (Thread-511): sending response (<Response 2019 bytes [200 OK]>) to 10.0.44.31
2022-01-06 19:01:33.163435 (Thread-512): handling status request
2022-01-06 19:01:33.163788 (Thread-512): 19:01:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04277310>]}
2022-01-06 19:01:33.164251 (Thread-512): sending response (<Response 1997 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:01:33.169406 (Thread-513): handling list request
2022-01-06 19:01:33.169655 (Thread-513): 19:01:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04277580>]}
2022-01-06 19:01:33.192267 (Thread-513): 19:01:33  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0427b220>]}
2022-01-06 19:01:33.192560 (Thread-513): 19:01:33  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:01:33.194785 (Thread-513): sending response (<Response 2863 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:02:22.844438 (Thread-514): handling status request
2022-01-06 19:02:22.844790 (Thread-514): 19:02:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0427bc10>]}
2022-01-06 19:02:22.845573 (Thread-514): sending response (<Response 1997 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:02:22.856077 (Thread-515): handling list request
2022-01-06 19:02:22.856333 (Thread-515): 19:02:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042d31f0>]}
2022-01-06 19:02:22.895675 (Thread-515): 19:02:22  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0427b9a0>]}
2022-01-06 19:02:22.895939 (Thread-515): 19:02:22  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:02:22.901412 (Thread-515): sending response (<Response 2863 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:04:27.651276 (Thread-516): 19:04:27  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 19:04:27.653078 (Thread-516): 19:04:27  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 19:04:27.653707 (Thread-516): 19:04:27  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 19:04:27.661289 (Thread-516): 19:04:27  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff041ebd30>]}
2022-01-06 19:04:28.278449 (Thread-517): handling status request
2022-01-06 19:04:28.278831 (Thread-517): 19:04:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042f7b20>]}
2022-01-06 19:04:28.279318 (Thread-517): sending response (<Response 1685 bytes [200 OK]>) to 10.0.10.3
2022-01-06 19:04:28.363736 (Thread-518): handling status request
2022-01-06 19:04:28.364040 (Thread-518): 19:04:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04202040>]}
2022-01-06 19:04:28.364476 (Thread-518): sending response (<Response 1685 bytes [200 OK]>) to 10.0.23.128
2022-01-06 19:04:28.992655 (Thread-519): handling status request
2022-01-06 19:04:28.993011 (Thread-519): 19:04:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff041a0e80>]}
2022-01-06 19:04:28.993516 (Thread-519): sending response (<Response 1663 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:04:29.000624 (Thread-520): handling list request
2022-01-06 19:04:29.000920 (Thread-520): 19:04:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff041a0b50>]}
2022-01-06 19:04:29.016311 (Thread-520): 19:04:29  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042223a0>]}
2022-01-06 19:04:29.016597 (Thread-520): 19:04:29  Found 3 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:04:29.018727 (Thread-520): sending response (<Response 2863 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:04:46.518131 (Thread-521): 19:04:46  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-01-06 19:04:46.518471 (Thread-521): 19:04:46  Partial parsing: added file: my_new_project://models/staging/stripe/fct_orders.sql
2022-01-06 19:04:46.523251 (Thread-521): 19:04:46  1699: static parser successfully parsed staging/stripe/fct_orders.sql
2022-01-06 19:04:46.571619 (Thread-521): 19:04:46  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 19:04:46.576306 (Thread-521): 19:04:46  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0412dac0>]}
2022-01-06 19:04:46.945501 (Thread-522): handling status request
2022-01-06 19:04:46.945855 (Thread-522): 19:04:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042d3730>]}
2022-01-06 19:04:46.946337 (Thread-522): sending response (<Response 1997 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:04:46.953496 (Thread-523): handling list request
2022-01-06 19:04:46.953742 (Thread-523): 19:04:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0414f730>]}
2022-01-06 19:04:46.971926 (Thread-523): 19:04:46  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0411d9a0>]}
2022-01-06 19:04:46.972207 (Thread-523): 19:04:46  Found 4 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:04:46.974453 (Thread-523): sending response (<Response 2863 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:04:47.412343 (Thread-524): handling status request
2022-01-06 19:04:47.412705 (Thread-524): 19:04:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0422f910>]}
2022-01-06 19:04:47.413188 (Thread-524): sending response (<Response 2019 bytes [200 OK]>) to 10.0.1.28
2022-01-06 19:04:47.747343 (Thread-525): handling status request
2022-01-06 19:04:47.747694 (Thread-525): 19:04:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0412d7f0>]}
2022-01-06 19:04:47.748165 (Thread-525): sending response (<Response 2019 bytes [200 OK]>) to 10.0.5.108
2022-01-06 19:04:49.969916 (Thread-526): handling status request
2022-01-06 19:04:49.970278 (Thread-526): 19:04:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0412d760>]}
2022-01-06 19:04:49.970754 (Thread-526): sending response (<Response 1997 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:04:49.979769 (Thread-527): handling list request
2022-01-06 19:04:49.980037 (Thread-527): 19:04:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0413a1c0>]}
2022-01-06 19:04:49.996061 (Thread-527): 19:04:49  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0422fd90>]}
2022-01-06 19:04:49.996354 (Thread-527): 19:04:49  Found 4 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:04:49.998654 (Thread-527): sending response (<Response 2863 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:04:50.096874 (Thread-528): handling status request
2022-01-06 19:04:50.097275 (Thread-528): 19:04:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042ba9d0>]}
2022-01-06 19:04:50.097758 (Thread-528): sending response (<Response 1997 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:04:50.103611 (Thread-529): handling list request
2022-01-06 19:04:50.103837 (Thread-529): 19:04:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0413a8b0>]}
2022-01-06 19:04:50.126340 (Thread-529): 19:04:50  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04137610>]}
2022-01-06 19:04:50.126641 (Thread-529): 19:04:50  Found 4 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:04:50.128583 (Thread-529): 19:04:50  The selection criterion '+models/staging/stripe/fct_orders.sql+' does not match any nodes
2022-01-06 19:04:50.128738 (Thread-529): 19:04:50  No nodes selected!
2022-01-06 19:04:50.130028 (Thread-529): sending response (<Response 1949 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:06:35.238856 (Thread-530): 19:06:35  Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
2022-01-06 19:06:35.240527 (Thread-530): 19:06:35  Partial parsing: added file: my_new_project://models/mart/core/fct_orders.sql
2022-01-06 19:06:35.240676 (Thread-530): 19:06:35  Partial parsing: deleted file: my_new_project://models/staging/stripe/fct_orders.sql
2022-01-06 19:06:35.244241 (Thread-530): 19:06:35  1699: static parser successfully parsed mart/core/fct_orders.sql
2022-01-06 19:06:35.285516 (Thread-530): 19:06:35  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 19:06:35.289944 (Thread-530): 19:06:35  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0406dc10>]}
2022-01-06 19:06:35.912087 (Thread-531): handling status request
2022-01-06 19:06:35.912547 (Thread-531): 19:06:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0409d760>]}
2022-01-06 19:06:35.913488 (Thread-531): sending response (<Response 2335 bytes [200 OK]>) to 10.0.23.128
2022-01-06 19:06:35.936414 (Thread-532): handling status request
2022-01-06 19:06:35.936800 (Thread-532): 19:06:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff042026d0>]}
2022-01-06 19:06:35.937345 (Thread-532): sending response (<Response 2335 bytes [200 OK]>) to 10.0.44.31
2022-01-06 19:06:36.451621 (Thread-533): handling status request
2022-01-06 19:06:36.452105 (Thread-533): 19:06:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff041361c0>]}
2022-01-06 19:06:36.452651 (Thread-533): sending response (<Response 2313 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:06:36.476798 (Thread-534): handling list request
2022-01-06 19:06:36.477142 (Thread-534): 19:06:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0414fb80>]}
2022-01-06 19:06:36.493441 (Thread-534): 19:06:36  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0433b550>]}
2022-01-06 19:06:36.493731 (Thread-534): 19:06:36  Found 4 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:06:36.495661 (Thread-534): 19:06:36  The selection criterion '+models/staging/stripe/fct_orders.sql+' does not match any nodes
2022-01-06 19:06:36.495820 (Thread-534): 19:06:36  No nodes selected!
2022-01-06 19:06:36.497078 (Thread-534): sending response (<Response 1949 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:06:36.644881 (Thread-535): handling status request
2022-01-06 19:06:36.645332 (Thread-535): 19:06:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04136190>]}
2022-01-06 19:06:36.645853 (Thread-535): sending response (<Response 2313 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:06:36.652031 (Thread-536): handling list request
2022-01-06 19:06:36.652270 (Thread-536): 19:06:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0406d8e0>]}
2022-01-06 19:06:36.669011 (Thread-536): 19:06:36  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0422fbb0>]}
2022-01-06 19:06:36.669313 (Thread-536): 19:06:36  Found 4 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:06:36.670056 (Thread-536): 19:06:36  The selection criterion '+models/mart/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:06:36.670211 (Thread-536): 19:06:36  No nodes selected!
2022-01-06 19:06:36.671426 (Thread-536): sending response (<Response 1944 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:06:56.151160 (Thread-537): 19:06:56  Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
2022-01-06 19:06:56.151506 (Thread-537): 19:06:56  Partial parsing: added file: my_new_project://models/marts/core/fct_orders.sql
2022-01-06 19:06:56.151652 (Thread-537): 19:06:56  Partial parsing: deleted file: my_new_project://models/mart/core/fct_orders.sql
2022-01-06 19:06:56.155542 (Thread-537): 19:06:56  1699: static parser successfully parsed marts/core/fct_orders.sql
2022-01-06 19:06:56.197274 (Thread-537): 19:06:56  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 19:06:56.206090 (Thread-537): 19:06:56  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04043370>]}
2022-01-06 19:06:56.602276 (Thread-538): handling status request
2022-01-06 19:06:56.602637 (Thread-538): 19:06:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04527940>]}
2022-01-06 19:06:56.624165 (Thread-538): sending response (<Response 2332 bytes [200 OK]>) to 10.0.36.155
2022-01-06 19:06:56.696267 (Thread-539): handling status request
2022-01-06 19:06:56.696631 (Thread-539): 19:06:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04527250>]}
2022-01-06 19:06:56.697145 (Thread-539): sending response (<Response 2332 bytes [200 OK]>) to 10.0.39.67
2022-01-06 19:06:57.239342 (Thread-540): handling status request
2022-01-06 19:06:57.239729 (Thread-540): 19:06:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0458bd30>]}
2022-01-06 19:06:57.240229 (Thread-540): sending response (<Response 2310 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:06:57.245515 (Thread-541): handling list request
2022-01-06 19:06:57.245765 (Thread-541): 19:06:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04592700>]}
2022-01-06 19:06:57.262012 (Thread-541): 19:06:57  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff044b4a30>]}
2022-01-06 19:06:57.262290 (Thread-541): 19:06:57  Found 4 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:06:57.264283 (Thread-541): 19:06:57  The selection criterion '+models/mart/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:06:57.264444 (Thread-541): 19:06:57  No nodes selected!
2022-01-06 19:06:57.265702 (Thread-541): sending response (<Response 1944 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:06:57.485761 (Thread-542): handling status request
2022-01-06 19:06:57.486166 (Thread-542): 19:06:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff044b4340>]}
2022-01-06 19:06:57.486676 (Thread-542): sending response (<Response 2310 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:06:57.491951 (Thread-543): handling list request
2022-01-06 19:06:57.492188 (Thread-543): 19:06:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04482df0>]}
2022-01-06 19:06:57.509609 (Thread-543): 19:06:57  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0404e7c0>]}
2022-01-06 19:06:57.509877 (Thread-543): 19:06:57  Found 4 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:06:57.510566 (Thread-543): 19:06:57  The selection criterion '+models/marts/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:06:57.510721 (Thread-543): 19:06:57  No nodes selected!
2022-01-06 19:06:57.511937 (Thread-543): sending response (<Response 1945 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:07:03.036733 (Thread-544): 19:07:03  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 19:07:03.036946 (Thread-544): 19:07:03  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 19:07:03.037349 (Thread-544): 19:07:03  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 19:07:03.042324 (Thread-544): 19:07:03  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee477eeb0>]}
2022-01-06 19:07:03.609395 (Thread-545): handling status request
2022-01-06 19:07:03.609758 (Thread-545): 19:07:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04069cd0>]}
2022-01-06 19:07:03.610235 (Thread-545): sending response (<Response 1685 bytes [200 OK]>) to 10.0.23.128
2022-01-06 19:07:04.054056 (Thread-546): handling status request
2022-01-06 19:07:04.054429 (Thread-546): 19:07:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0409dc40>]}
2022-01-06 19:07:04.054904 (Thread-546): sending response (<Response 1685 bytes [200 OK]>) to 10.0.39.207
2022-01-06 19:07:04.290218 (Thread-547): handling status request
2022-01-06 19:07:04.290627 (Thread-547): 19:07:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff0409d850>]}
2022-01-06 19:07:04.291200 (Thread-547): sending response (<Response 1663 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:07:04.297193 (Thread-548): handling list request
2022-01-06 19:07:04.297489 (Thread-548): 19:07:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff045249a0>]}
2022-01-06 19:07:04.313957 (Thread-548): 19:07:04  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04087640>]}
2022-01-06 19:07:04.314264 (Thread-548): 19:07:04  Found 4 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:07:04.315151 (Thread-548): 19:07:04  The selection criterion '+models/marts/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:07:04.315307 (Thread-548): 19:07:04  No nodes selected!
2022-01-06 19:07:04.316811 (Thread-548): sending response (<Response 1945 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:07:07.624464 (Thread-549): 19:07:07  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 19:07:07.624665 (Thread-549): 19:07:07  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 19:07:07.624996 (Thread-549): 19:07:07  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 19:07:07.629612 (Thread-549): 19:07:07  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4700460>]}
2022-01-06 19:07:08.236228 (Thread-550): handling status request
2022-01-06 19:07:08.236626 (Thread-550): 19:07:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04527c10>]}
2022-01-06 19:07:08.237126 (Thread-550): sending response (<Response 1685 bytes [200 OK]>) to 10.0.31.2
2022-01-06 19:07:08.255390 (Thread-551): handling status request
2022-01-06 19:07:08.255628 (Thread-551): 19:07:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff045272e0>]}
2022-01-06 19:07:08.255996 (Thread-551): sending response (<Response 1685 bytes [200 OK]>) to 10.0.36.155
2022-01-06 19:07:08.867749 (Thread-552): handling status request
2022-01-06 19:07:08.868113 (Thread-552): 19:07:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4739790>]}
2022-01-06 19:07:08.868595 (Thread-552): sending response (<Response 1663 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:07:08.878858 (Thread-553): handling list request
2022-01-06 19:07:08.879122 (Thread-553): 19:07:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee47394c0>]}
2022-01-06 19:07:08.894683 (Thread-553): 19:07:08  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04055190>]}
2022-01-06 19:07:08.894985 (Thread-553): 19:07:08  Found 4 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:07:08.895734 (Thread-553): 19:07:08  The selection criterion '+models/marts/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:07:08.895892 (Thread-553): 19:07:08  No nodes selected!
2022-01-06 19:07:08.897088 (Thread-553): sending response (<Response 1945 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:07:49.057708 (Thread-554): 19:07:49  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-01-06 19:07:49.058042 (Thread-554): 19:07:49  Partial parsing: added file: my_new_project://models/staging/stripe/stg_payments.sql
2022-01-06 19:07:49.062821 (Thread-554): 19:07:49  1699: static parser successfully parsed staging/stripe/stg_payments.sql
2022-01-06 19:07:49.099146 (Thread-554): 19:07:49  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.example

2022-01-06 19:07:49.104123 (Thread-554): 19:07:49  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4693520>]}
2022-01-06 19:07:49.529014 (Thread-555): handling status request
2022-01-06 19:07:49.529421 (Thread-555): 19:07:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4687970>]}
2022-01-06 19:07:49.529925 (Thread-555): sending response (<Response 2001 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:07:49.536275 (Thread-556): handling list request
2022-01-06 19:07:49.536566 (Thread-556): 19:07:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff05f41c40>]}
2022-01-06 19:07:49.562860 (Thread-556): 19:07:49  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee46b90d0>]}
2022-01-06 19:07:49.563157 (Thread-556): 19:07:49  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:07:49.563933 (Thread-556): 19:07:49  The selection criterion '+models/marts/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:07:49.564101 (Thread-556): 19:07:49  No nodes selected!
2022-01-06 19:07:49.565481 (Thread-556): sending response (<Response 1945 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:07:49.798011 (Thread-557): handling status request
2022-01-06 19:07:49.798375 (Thread-557): 19:07:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4693910>]}
2022-01-06 19:07:49.798871 (Thread-557): sending response (<Response 2023 bytes [200 OK]>) to 10.0.13.109
2022-01-06 19:07:49.841942 (Thread-558): handling status request
2022-01-06 19:07:49.842328 (Thread-558): 19:07:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4693670>]}
2022-01-06 19:07:49.842874 (Thread-558): sending response (<Response 2023 bytes [200 OK]>) to 10.0.23.128
2022-01-06 19:07:50.422182 (Thread-559): handling status request
2022-01-06 19:07:50.422551 (Thread-559): 19:07:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff040691f0>]}
2022-01-06 19:07:50.423031 (Thread-559): sending response (<Response 2001 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:07:50.428682 (Thread-560): handling list request
2022-01-06 19:07:50.428930 (Thread-560): 19:07:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04069e80>]}
2022-01-06 19:07:50.460241 (Thread-560): 19:07:50  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff04527790>]}
2022-01-06 19:07:50.460529 (Thread-560): 19:07:50  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:07:50.461310 (Thread-560): 19:07:50  The selection criterion '+models/marts/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:07:50.461475 (Thread-560): 19:07:50  No nodes selected!
2022-01-06 19:07:50.462722 (Thread-560): sending response (<Response 1945 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:07:50.580272 (Thread-561): handling status request
2022-01-06 19:07:50.580634 (Thread-561): 19:07:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff045279a0>]}
2022-01-06 19:07:50.581144 (Thread-561): sending response (<Response 2001 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:07:50.586563 (Thread-562): handling list request
2022-01-06 19:07:50.586856 (Thread-562): 19:07:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4700e80>]}
2022-01-06 19:07:50.636580 (Thread-562): 19:07:50  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee46a5670>]}
2022-01-06 19:07:50.636924 (Thread-562): 19:07:50  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:07:50.637797 (Thread-562): 19:07:50  The selection criterion '+models/staging/stripe/stg_payments.sql+' does not match any nodes
2022-01-06 19:07:50.637951 (Thread-562): 19:07:50  No nodes selected!
2022-01-06 19:07:50.639494 (Thread-562): sending response (<Response 1951 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:11.485782 (Thread-563): handling status request
2022-01-06 19:08:11.486156 (Thread-563): 19:08:11  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee46959a0>]}
2022-01-06 19:08:11.486650 (Thread-563): sending response (<Response 2001 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:11.492576 (Thread-564): handling list request
2022-01-06 19:08:11.492830 (Thread-564): 19:08:11  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee46a14c0>]}
2022-01-06 19:08:11.524871 (Thread-564): 19:08:11  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4695dc0>]}
2022-01-06 19:08:11.525168 (Thread-564): 19:08:11  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:08:11.525954 (Thread-564): 19:08:11  The selection criterion '+models/marts/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:08:11.526120 (Thread-564): 19:08:11  No nodes selected!
2022-01-06 19:08:11.527429 (Thread-564): sending response (<Response 1945 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:17.553348 (Thread-565): handling status request
2022-01-06 19:08:17.553718 (Thread-565): 19:08:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee46a59a0>]}
2022-01-06 19:08:17.554201 (Thread-565): sending response (<Response 2001 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:17.560730 (Thread-566): handling list request
2022-01-06 19:08:17.561019 (Thread-566): 19:08:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee47399d0>]}
2022-01-06 19:08:17.591360 (Thread-566): 19:08:17  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee469ba60>]}
2022-01-06 19:08:17.591645 (Thread-566): 19:08:17  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:08:17.592345 (Thread-566): 19:08:17  The selection criterion '+1641483140394/__unsaved/Statement' does not match any nodes
2022-01-06 19:08:17.592540 (Thread-566): 19:08:17  The selection criterion '2.sql+' does not match any nodes
2022-01-06 19:08:17.592655 (Thread-566): 19:08:17  No nodes selected!
2022-01-06 19:08:17.594050 (Thread-566): sending response (<Response 2348 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:19.407483 (Thread-567): handling status request
2022-01-06 19:08:19.407838 (Thread-567): 19:08:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee46972b0>]}
2022-01-06 19:08:19.408313 (Thread-567): sending response (<Response 2001 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:19.421326 (Thread-568): handling list request
2022-01-06 19:08:19.421629 (Thread-568): 19:08:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4697850>]}
2022-01-06 19:08:19.452581 (Thread-568): 19:08:19  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee46a15e0>]}
2022-01-06 19:08:19.452914 (Thread-568): 19:08:19  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:08:19.455054 (Thread-568): sending response (<Response 2308 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:20.629115 (Thread-569): handling status request
2022-01-06 19:08:20.629539 (Thread-569): 19:08:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee46b4340>]}
2022-01-06 19:08:20.630024 (Thread-569): sending response (<Response 2001 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:20.645097 (Thread-570): handling list request
2022-01-06 19:08:20.645437 (Thread-570): 19:08:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee46b4670>]}
2022-01-06 19:08:20.675228 (Thread-570): 19:08:20  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee463c1c0>]}
2022-01-06 19:08:20.675575 (Thread-570): 19:08:20  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:08:20.677973 (Thread-570): sending response (<Response 2320 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:21.578801 (Thread-571): handling status request
2022-01-06 19:08:21.579159 (Thread-571): 19:08:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee46978b0>]}
2022-01-06 19:08:21.579634 (Thread-571): sending response (<Response 2001 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:21.585064 (Thread-572): handling list request
2022-01-06 19:08:21.585336 (Thread-572): 19:08:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee46937c0>]}
2022-01-06 19:08:21.615601 (Thread-572): 19:08:21  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee463cf40>]}
2022-01-06 19:08:21.615870 (Thread-572): 19:08:21  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:08:21.617892 (Thread-572): sending response (<Response 2863 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:27.927324 (Thread-573): 19:08:27  Unable to do partial parsing because a project dependency has been added
2022-01-06 19:08:27.927631 (Thread-573): 19:08:27  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee46b4e80>]}
2022-01-06 19:08:27.967411 (Thread-573): 19:08:27  Parsing macros/catalog.sql
2022-01-06 19:08:27.979301 (Thread-573): 19:08:27  Parsing macros/adapters.sql
2022-01-06 19:08:28.006121 (Thread-573): 19:08:28  Parsing macros/relations.sql
2022-01-06 19:08:28.006701 (Thread-573): 19:08:28  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 19:08:28.007332 (Thread-573): 19:08:28  Parsing macros/catalog.sql
2022-01-06 19:08:28.009405 (Thread-573): 19:08:28  Parsing macros/adapters.sql
2022-01-06 19:08:28.029921 (Thread-573): 19:08:28  Parsing macros/relations.sql
2022-01-06 19:08:28.031165 (Thread-573): 19:08:28  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 19:08:28.032772 (Thread-573): 19:08:28  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-06 19:08:28.034226 (Thread-573): 19:08:28  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-06 19:08:28.035740 (Thread-573): 19:08:28  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-06 19:08:28.038096 (Thread-573): 19:08:28  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-06 19:08:28.039431 (Thread-573): 19:08:28  Parsing macros/generic_test_sql/not_null.sql
2022-01-06 19:08:28.039996 (Thread-573): 19:08:28  Parsing macros/generic_test_sql/relationships.sql
2022-01-06 19:08:28.040842 (Thread-573): 19:08:28  Parsing macros/generic_test_sql/unique.sql
2022-01-06 19:08:28.041581 (Thread-573): 19:08:28  Parsing macros/materializations/configs.sql
2022-01-06 19:08:28.043791 (Thread-573): 19:08:28  Parsing macros/materializations/hooks.sql
2022-01-06 19:08:28.047579 (Thread-573): 19:08:28  Parsing macros/materializations/snapshots/strategies.sql
2022-01-06 19:08:28.063362 (Thread-573): 19:08:28  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-06 19:08:28.064940 (Thread-573): 19:08:28  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-06 19:08:28.075611 (Thread-573): 19:08:28  Parsing macros/materializations/snapshots/helpers.sql
2022-01-06 19:08:28.086271 (Thread-573): 19:08:28  Parsing macros/materializations/seeds/seed.sql
2022-01-06 19:08:28.092004 (Thread-573): 19:08:28  Parsing macros/materializations/seeds/helpers.sql
2022-01-06 19:08:28.107598 (Thread-573): 19:08:28  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-06 19:08:28.109866 (Thread-573): 19:08:28  Parsing macros/materializations/models/view/view.sql
2022-01-06 19:08:28.116399 (Thread-573): 19:08:28  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-06 19:08:28.118972 (Thread-573): 19:08:28  Parsing macros/materializations/models/view/helpers.sql
2022-01-06 19:08:28.120282 (Thread-573): 19:08:28  Parsing macros/materializations/models/table/table.sql
2022-01-06 19:08:28.127132 (Thread-573): 19:08:28  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-06 19:08:28.129924 (Thread-573): 19:08:28  Parsing macros/materializations/models/incremental/merge.sql
2022-01-06 19:08:28.144209 (Thread-573): 19:08:28  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-06 19:08:28.163107 (Thread-573): 19:08:28  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-06 19:08:28.167318 (Thread-573): 19:08:28  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-06 19:08:28.176673 (Thread-573): 19:08:28  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-06 19:08:28.185805 (Thread-573): 19:08:28  Parsing macros/materializations/tests/test.sql
2022-01-06 19:08:28.195783 (Thread-573): 19:08:28  Parsing macros/materializations/tests/where_subquery.sql
2022-01-06 19:08:28.197718 (Thread-573): 19:08:28  Parsing macros/materializations/tests/helpers.sql
2022-01-06 19:08:28.199565 (Thread-573): 19:08:28  Parsing macros/etc/statement.sql
2022-01-06 19:08:28.208921 (Thread-573): 19:08:28  Parsing macros/etc/datetime.sql
2022-01-06 19:08:28.220602 (Thread-573): 19:08:28  Parsing macros/adapters/indexes.sql
2022-01-06 19:08:28.223478 (Thread-573): 19:08:28  Parsing macros/adapters/persist_docs.sql
2022-01-06 19:08:28.227877 (Thread-573): 19:08:28  Parsing macros/adapters/freshness.sql
2022-01-06 19:08:28.230916 (Thread-573): 19:08:28  Parsing macros/adapters/relation.sql
2022-01-06 19:08:28.240764 (Thread-573): 19:08:28  Parsing macros/adapters/metadata.sql
2022-01-06 19:08:28.254987 (Thread-573): 19:08:28  Parsing macros/adapters/columns.sql
2022-01-06 19:08:28.264844 (Thread-573): 19:08:28  Parsing macros/adapters/schema.sql
2022-01-06 19:08:28.269067 (Thread-573): 19:08:28  Parsing tests/generic/builtin.sql
2022-01-06 19:08:28.453880 (Thread-573): 19:08:28  1699: static parser successfully parsed staging/jaffle_shop/stg_customers.sql
2022-01-06 19:08:28.456053 (Thread-573): 19:08:28  1699: static parser successfully parsed staging/jaffle_shop/stg_orders.sql
2022-01-06 19:08:28.458089 (Thread-573): 19:08:28  1699: static parser successfully parsed staging/stripe/stg_payments.sql
2022-01-06 19:08:28.460400 (Thread-573): 19:08:28  1699: static parser successfully parsed marts/core/dim_customers.sql
2022-01-06 19:08:28.462715 (Thread-573): 19:08:28  1699: static parser successfully parsed marts/core/fct_orders.sql
2022-01-06 19:08:28.531151 (Thread-573): 19:08:28  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45b6070>]}
2022-01-06 19:08:28.579125 (Thread-574): handling status request
2022-01-06 19:08:28.579424 (Thread-574): 19:08:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45b6430>]}
2022-01-06 19:08:28.580226 (Thread-574): sending response (<Response 16530 bytes [200 OK]>) to 10.0.10.3
2022-01-06 19:08:28.634858 (Thread-575): handling status request
2022-01-06 19:08:28.635127 (Thread-575): 19:08:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45b64c0>]}
2022-01-06 19:08:28.636007 (Thread-575): sending response (<Response 16530 bytes [200 OK]>) to 10.0.31.30
2022-01-06 19:08:29.053260 (Thread-576): handling status request
2022-01-06 19:08:29.053631 (Thread-576): 19:08:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee46a59d0>]}
2022-01-06 19:08:29.054465 (Thread-576): sending response (<Response 16508 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:29.060050 (Thread-577): handling list request
2022-01-06 19:08:29.060293 (Thread-577): 19:08:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45b6730>]}
2022-01-06 19:08:29.086475 (Thread-577): 19:08:29  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45b56a0>]}
2022-01-06 19:08:29.086860 (Thread-577): 19:08:29  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:08:29.087843 (Thread-577): 19:08:29  The selection criterion '+models/marts/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:08:29.088068 (Thread-577): 19:08:29  No nodes selected!
2022-01-06 19:08:29.089583 (Thread-577): sending response (<Response 1945 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:29.313353 (Thread-578): handling status request
2022-01-06 19:08:29.313739 (Thread-578): 19:08:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45b59a0>]}
2022-01-06 19:08:29.314555 (Thread-578): sending response (<Response 16508 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:29.319924 (Thread-579): handling list request
2022-01-06 19:08:29.320186 (Thread-579): 19:08:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45af2b0>]}
2022-01-06 19:08:29.349057 (Thread-579): 19:08:29  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45b5f70>]}
2022-01-06 19:08:29.349395 (Thread-579): 19:08:29  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:08:29.350162 (Thread-579): 19:08:29  The selection criterion '+models/marts/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:08:29.350324 (Thread-579): 19:08:29  No nodes selected!
2022-01-06 19:08:29.351661 (Thread-579): sending response (<Response 1945 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:31.156914 (Thread-580): handling status request
2022-01-06 19:08:31.157303 (Thread-580): 19:08:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45cc8b0>]}
2022-01-06 19:08:31.158174 (Thread-580): sending response (<Response 16508 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:31.164373 (Thread-581): handling list request
2022-01-06 19:08:31.164609 (Thread-581): 19:08:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45d3a60>]}
2022-01-06 19:08:31.192535 (Thread-581): 19:08:31  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45d3910>]}
2022-01-06 19:08:31.192828 (Thread-581): 19:08:31  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:08:31.194964 (Thread-581): sending response (<Response 2911 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:49.564364 (Thread-582): handling status request
2022-01-06 19:08:49.564737 (Thread-582): 19:08:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45e6c10>]}
2022-01-06 19:08:49.588810 (Thread-582): sending response (<Response 16508 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:08:49.611170 (Thread-583): handling list request
2022-01-06 19:08:49.611423 (Thread-583): 19:08:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45f2850>]}
2022-01-06 19:08:49.647582 (Thread-583): 19:08:49  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45e6d30>]}
2022-01-06 19:08:49.647855 (Thread-583): 19:08:49  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:08:49.650975 (Thread-583): 19:08:49  The selection criterion '+models/marts/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:08:49.651135 (Thread-583): 19:08:49  No nodes selected!
2022-01-06 19:08:49.652365 (Thread-583): sending response (<Response 1945 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:09:03.949580 (Thread-584): handling status request
2022-01-06 19:09:03.949983 (Thread-584): 19:09:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee465b9d0>]}
2022-01-06 19:09:03.950945 (Thread-584): sending response (<Response 16508 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:09:03.957115 (Thread-585): handling list request
2022-01-06 19:09:03.957397 (Thread-585): 19:09:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45f33d0>]}
2022-01-06 19:09:03.987865 (Thread-585): 19:09:03  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45f3cd0>]}
2022-01-06 19:09:03.988159 (Thread-585): 19:09:03  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:09:03.990514 (Thread-585): sending response (<Response 2350 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:09:09.885332 (Thread-586): handling status request
2022-01-06 19:09:09.885886 (Thread-586): 19:09:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45e69a0>]}
2022-01-06 19:09:09.886992 (Thread-586): sending response (<Response 16508 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:09:09.909360 (Thread-587): handling list request
2022-01-06 19:09:09.909622 (Thread-587): 19:09:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45f2850>]}
2022-01-06 19:09:09.941021 (Thread-587): 19:09:09  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45fb070>]}
2022-01-06 19:09:09.941377 (Thread-587): 19:09:09  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:09:09.942174 (Thread-587): 19:09:09  The selection criterion '+models/marts/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:09:09.942337 (Thread-587): 19:09:09  No nodes selected!
2022-01-06 19:09:09.943568 (Thread-587): sending response (<Response 1945 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:13:00.841897 (Thread-588): handling status request
2022-01-06 19:13:00.843870 (Thread-588): 19:13:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45fb130>]}
2022-01-06 19:13:00.844715 (Thread-588): sending response (<Response 16508 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:13:00.850598 (Thread-589): handling list request
2022-01-06 19:13:00.850826 (Thread-589): 19:13:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45cf4f0>]}
2022-01-06 19:13:00.882913 (Thread-589): 19:13:00  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45cf460>]}
2022-01-06 19:13:00.883204 (Thread-589): 19:13:00  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:13:00.891403 (Thread-589): 19:13:00  The selection criterion '+models/marts/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:13:00.891577 (Thread-589): 19:13:00  No nodes selected!
2022-01-06 19:13:00.892800 (Thread-589): sending response (<Response 1945 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:14:18.567478 (Thread-590): handling status request
2022-01-06 19:14:18.569046 (Thread-590): 19:14:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45cfdc0>]}
2022-01-06 19:14:18.569961 (Thread-590): sending response (<Response 16508 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:14:18.578813 (Thread-591): handling list request
2022-01-06 19:14:18.579042 (Thread-591): 19:14:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45e6a60>]}
2022-01-06 19:14:18.610044 (Thread-591): 19:14:18  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee462c160>]}
2022-01-06 19:14:18.610308 (Thread-591): 19:14:18  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:14:18.617938 (Thread-591): 19:14:18  The selection criterion '+models/marts/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:14:18.618097 (Thread-591): 19:14:18  No nodes selected!
2022-01-06 19:14:18.619275 (Thread-591): sending response (<Response 1945 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:14:26.792022 (Thread-592): handling status request
2022-01-06 19:14:26.792378 (Thread-592): 19:14:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4622550>]}
2022-01-06 19:14:26.793345 (Thread-592): sending response (<Response 16508 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:14:26.799352 (Thread-593): handling list request
2022-01-06 19:14:26.799591 (Thread-593): 19:14:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4622850>]}
2022-01-06 19:14:26.826960 (Thread-593): 19:14:26  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee462c1f0>]}
2022-01-06 19:14:26.827295 (Thread-593): 19:14:26  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:14:26.828166 (Thread-593): 19:14:26  The selection criterion '+models/marts/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:14:26.828347 (Thread-593): 19:14:26  No nodes selected!
2022-01-06 19:14:26.829959 (Thread-593): sending response (<Response 1945 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:14:41.065064 (Thread-594): handling status request
2022-01-06 19:14:41.065457 (Thread-594): 19:14:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45c47c0>]}
2022-01-06 19:14:41.066296 (Thread-594): sending response (<Response 16508 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:14:41.080038 (Thread-595): handling list request
2022-01-06 19:14:41.080282 (Thread-595): 19:14:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45c4880>]}
2022-01-06 19:14:41.110071 (Thread-595): 19:14:41  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45ca820>]}
2022-01-06 19:14:41.110395 (Thread-595): 19:14:41  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:14:41.111163 (Thread-595): 19:14:41  The selection criterion '+models/marts/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:14:41.111333 (Thread-595): 19:14:41  No nodes selected!
2022-01-06 19:14:41.112690 (Thread-595): sending response (<Response 1945 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:15:12.985838 (Thread-596): handling status request
2022-01-06 19:15:12.986196 (Thread-596): 19:15:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45bd460>]}
2022-01-06 19:15:12.987039 (Thread-596): sending response (<Response 16508 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:15:12.993274 (Thread-597): handling list request
2022-01-06 19:15:12.993506 (Thread-597): 19:15:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45bd5b0>]}
2022-01-06 19:15:13.021009 (Thread-597): 19:15:13  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45ca130>]}
2022-01-06 19:15:13.021304 (Thread-597): 19:15:13  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:15:13.022016 (Thread-597): 19:15:13  The selection criterion '+models/marts/core/fct_orders.sql+' does not match any nodes
2022-01-06 19:15:13.022171 (Thread-597): 19:15:13  No nodes selected!
2022-01-06 19:15:13.023356 (Thread-597): sending response (<Response 1945 bytes [200 OK]>) to 10.0.7.144
2022-01-06 19:15:40.504272 (Thread-598): handling status request
2022-01-06 19:15:40.504663 (Thread-598): 19:15:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45e4fd0>]}
2022-01-06 19:15:40.505602 (Thread-598): sending response (<Response 16530 bytes [200 OK]>) to 10.0.39.207
2022-01-06 19:15:41.021430 (Thread-599): handling run_sql request
2022-01-06 19:15:41.021824 (Thread-599): 19:15:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45e47f0>]}
2022-01-06 19:15:43.136055 (Thread-599): sending response (<Response 138 bytes [200 OK]>) to 10.0.36.155
2022-01-06 19:15:43.162007 (MainThread): 19:15:43  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1834f9d9-550c-4be0-a38c-9b15fd23d7b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5da32d6af0>]}
2022-01-06 19:15:43.162524 (MainThread): 19:15:43  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:15:43.163097 (Thread-1): 19:15:43  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:15:43.163241 (Thread-1): 19:15:43  Began compiling node rpc.jaffel_shop.request
2022-01-06 19:15:43.163348 (Thread-1): 19:15:43  Compiling rpc.jaffel_shop.request
2022-01-06 19:15:43.164493 (Thread-1): 19:15:43  finished collecting timing info
2022-01-06 19:15:43.164617 (Thread-1): 19:15:43  Began executing node rpc.jaffel_shop.request
2022-01-06 19:15:43.164713 (Thread-1): 19:15:43  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:15:43.164792 (Thread-1): 19:15:43  On rpc.jaffel_shop.request: with fct_orders as (

    select
        id as payment_id,
        order_id,
        customer_id
        amount

    from stripe.payments

)
select * from stripe.payments
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 19:15:43.164869 (Thread-1): 19:15:43  Opening a new connection, currently in state init
2022-01-06 19:15:43.164948 (Thread-1): 19:15:43  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:15:43.185056 (Thread-1): 19:15:43  Postgres adapter: Postgres error: relation "stripe.payments" does not exist

2022-01-06 19:15:43.185234 (Thread-1): 19:15:43  finished collecting timing info
2022-01-06 19:15:43.185371 (Thread-1): 19:15:43  On rpc.jaffel_shop.request: Close
2022-01-06 19:15:43.185556 (Thread-1): Got an exception: Database Error
  relation "stripe.payments" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "stripe.payments" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "stripe.payments" does not exist
2022-01-06 19:15:43.186661 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "stripe.payments" does not exist', 'raw_sql': 'with fct_orders as (\n\n    select\n        id as payment_id,\n        order_id,\n        customer_id\n        amount\n\n    from stripe.payments\n\n)\nselect * from stripe.payments\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with fct_orders as (\n\n    select\n        id as payment_id,\n        order_id,\n        customer_id\n        amount\n\n    from stripe.payments\n\n)\nselect * from stripe.payments\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "stripe.payments" does not exist', 'raw_sql': 'with fct_orders as (\n\n    select\n        id as payment_id,\n        order_id,\n        customer_id\n        amount\n\n    from stripe.payments\n\n)\nselect * from stripe.payments\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with fct_orders as (\n\n    select\n        id as payment_id,\n        order_id,\n        customer_id\n        amount\n\n    from stripe.payments\n\n)\nselect * from stripe.payments\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 19:15:43.467451 (Thread-600): handling poll request
2022-01-06 19:15:43.467894 (Thread-600): 19:15:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45d5040>]}
2022-01-06 19:15:43.468686 (Thread-600): sending response (<Response 10003 bytes [200 OK]>) to 10.0.13.109
2022-01-06 19:15:55.619366 (Thread-601): handling status request
2022-01-06 19:15:55.619711 (Thread-601): 19:15:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45d5850>]}
2022-01-06 19:15:55.620716 (Thread-601): sending response (<Response 16530 bytes [200 OK]>) to 10.0.44.31
2022-01-06 19:15:55.973292 (Thread-602): handling run_sql request
2022-01-06 19:15:55.973656 (Thread-602): 19:15:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45d5e50>]}
2022-01-06 19:15:58.010810 (Thread-602): sending response (<Response 138 bytes [200 OK]>) to 10.0.28.223
2022-01-06 19:15:58.034216 (MainThread): 19:15:58  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ea4e27c4-d269-4dea-99b8-d29b9905aee9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9284f94a90>]}
2022-01-06 19:15:58.034761 (MainThread): 19:15:58  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:15:58.035358 (Thread-1): 19:15:58  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:15:58.035518 (Thread-1): 19:15:58  Began compiling node rpc.jaffel_shop.request
2022-01-06 19:15:58.035650 (Thread-1): 19:15:58  Compiling rpc.jaffel_shop.request
2022-01-06 19:15:58.036831 (Thread-1): 19:15:58  finished collecting timing info
2022-01-06 19:15:58.036956 (Thread-1): 19:15:58  Began executing node rpc.jaffel_shop.request
2022-01-06 19:15:58.037055 (Thread-1): 19:15:58  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:15:58.037134 (Thread-1): 19:15:58  On rpc.jaffel_shop.request: with fct_orders as (

    select
        id as payment_id,
        order_id,
        customer_id
        amount

    from stripe.payments

)
select * from payments
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 19:15:58.037243 (Thread-1): 19:15:58  Opening a new connection, currently in state init
2022-01-06 19:15:58.037340 (Thread-1): 19:15:58  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:15:58.059297 (Thread-1): 19:15:58  Postgres adapter: Postgres error: relation "stripe.payments" does not exist

2022-01-06 19:15:58.059454 (Thread-1): 19:15:58  finished collecting timing info
2022-01-06 19:15:58.059567 (Thread-1): 19:15:58  On rpc.jaffel_shop.request: Close
2022-01-06 19:15:58.059859 (Thread-1): Got an exception: Database Error
  relation "stripe.payments" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "stripe.payments" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "stripe.payments" does not exist
2022-01-06 19:15:58.061074 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "stripe.payments" does not exist', 'raw_sql': 'with fct_orders as (\n\n    select\n        id as payment_id,\n        order_id,\n        customer_id\n        amount\n\n    from stripe.payments\n\n)\nselect * from payments\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with fct_orders as (\n\n    select\n        id as payment_id,\n        order_id,\n        customer_id\n        amount\n\n    from stripe.payments\n\n)\nselect * from payments\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "stripe.payments" does not exist', 'raw_sql': 'with fct_orders as (\n\n    select\n        id as payment_id,\n        order_id,\n        customer_id\n        amount\n\n    from stripe.payments\n\n)\nselect * from payments\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with fct_orders as (\n\n    select\n        id as payment_id,\n        order_id,\n        customer_id\n        amount\n\n    from stripe.payments\n\n)\nselect * from payments\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 19:15:58.429729 (Thread-603): handling poll request
2022-01-06 19:15:58.430163 (Thread-603): 19:15:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4638580>]}
2022-01-06 19:15:58.430987 (Thread-603): sending response (<Response 9954 bytes [200 OK]>) to 10.0.28.223
2022-01-06 19:16:02.442965 (Thread-604): handling status request
2022-01-06 19:16:02.443316 (Thread-604): 19:16:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4638c10>]}
2022-01-06 19:16:02.497013 (Thread-604): sending response (<Response 16530 bytes [200 OK]>) to 10.0.39.67
2022-01-06 19:16:02.831673 (Thread-605): handling run_sql request
2022-01-06 19:16:02.832042 (Thread-605): 19:16:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4638070>]}
2022-01-06 19:16:04.886731 (Thread-605): sending response (<Response 138 bytes [200 OK]>) to 10.0.36.155
2022-01-06 19:16:04.910591 (MainThread): 19:16:04  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '06875e89-e904-485b-b466-88174c424f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdafc9c89d0>]}
2022-01-06 19:16:04.911190 (MainThread): 19:16:04  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:16:04.911787 (Thread-1): 19:16:04  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:16:04.911914 (Thread-1): 19:16:04  Began compiling node rpc.jaffel_shop.request
2022-01-06 19:16:04.912006 (Thread-1): 19:16:04  Compiling rpc.jaffel_shop.request
2022-01-06 19:16:04.913107 (Thread-1): 19:16:04  finished collecting timing info
2022-01-06 19:16:04.913261 (Thread-1): 19:16:04  Began executing node rpc.jaffel_shop.request
2022-01-06 19:16:04.913367 (Thread-1): 19:16:04  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:16:04.913447 (Thread-1): 19:16:04  On rpc.jaffel_shop.request: with fct_orders as (

    select
        id as payment_id,
        order_id,
        customer_id
        amount

    from stripe.payments

)
select * from fct_orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 19:16:04.913523 (Thread-1): 19:16:04  Opening a new connection, currently in state init
2022-01-06 19:16:04.913604 (Thread-1): 19:16:04  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:16:04.933824 (Thread-1): 19:16:04  Postgres adapter: Postgres error: relation "stripe.payments" does not exist

2022-01-06 19:16:04.933989 (Thread-1): 19:16:04  finished collecting timing info
2022-01-06 19:16:04.934116 (Thread-1): 19:16:04  On rpc.jaffel_shop.request: Close
2022-01-06 19:16:04.934296 (Thread-1): Got an exception: Database Error
  relation "stripe.payments" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "stripe.payments" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "stripe.payments" does not exist
2022-01-06 19:16:04.935381 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "stripe.payments" does not exist', 'raw_sql': 'with fct_orders as (\n\n    select\n        id as payment_id,\n        order_id,\n        customer_id\n        amount\n\n    from stripe.payments\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with fct_orders as (\n\n    select\n        id as payment_id,\n        order_id,\n        customer_id\n        amount\n\n    from stripe.payments\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "stripe.payments" does not exist', 'raw_sql': 'with fct_orders as (\n\n    select\n        id as payment_id,\n        order_id,\n        customer_id\n        amount\n\n    from stripe.payments\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with fct_orders as (\n\n    select\n        id as payment_id,\n        order_id,\n        customer_id\n        amount\n\n    from stripe.payments\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 19:16:05.247175 (Thread-606): handling poll request
2022-01-06 19:16:05.247642 (Thread-606): 19:16:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4572190>]}
2022-01-06 19:16:05.248436 (Thread-606): sending response (<Response 9968 bytes [200 OK]>) to 10.0.44.31
2022-01-06 19:16:15.301873 (Thread-607): handling status request
2022-01-06 19:16:15.302223 (Thread-607): 19:16:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4572e20>]}
2022-01-06 19:16:15.303222 (Thread-607): sending response (<Response 16530 bytes [200 OK]>) to 10.0.14.28
2022-01-06 19:16:15.719105 (Thread-608): handling run_sql request
2022-01-06 19:16:15.719445 (Thread-608): 19:16:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee44de280>]}
2022-01-06 19:16:17.766306 (Thread-608): sending response (<Response 138 bytes [200 OK]>) to 10.0.17.11
2022-01-06 19:16:17.789516 (MainThread): 19:16:17  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4867070f-70e2-4e0b-8be4-eb445f2d8250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a4a67aa60>]}
2022-01-06 19:16:17.790062 (MainThread): 19:16:17  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:16:17.790630 (Thread-1): 19:16:17  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:16:17.790763 (Thread-1): 19:16:17  Began compiling node rpc.jaffel_shop.request
2022-01-06 19:16:17.790858 (Thread-1): 19:16:17  Compiling rpc.jaffel_shop.request
2022-01-06 19:16:17.792006 (Thread-1): 19:16:17  finished collecting timing info
2022-01-06 19:16:17.792129 (Thread-1): 19:16:17  Began executing node rpc.jaffel_shop.request
2022-01-06 19:16:17.792231 (Thread-1): 19:16:17  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:16:17.792308 (Thread-1): 19:16:17  On rpc.jaffel_shop.request: with fct_orders as (

    select
        id as payment_id,
        order_id,
        customer_id
        amount

    from stripe.payment

)
select * from fct_orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 19:16:17.792385 (Thread-1): 19:16:17  Opening a new connection, currently in state init
2022-01-06 19:16:17.792464 (Thread-1): 19:16:17  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:16:17.813846 (Thread-1): 19:16:17  Postgres adapter: Postgres error: column "order_id" does not exist in payment

2022-01-06 19:16:17.814002 (Thread-1): 19:16:17  finished collecting timing info
2022-01-06 19:16:17.814119 (Thread-1): 19:16:17  On rpc.jaffel_shop.request: Close
2022-01-06 19:16:17.814380 (Thread-1): Got an exception: Database Error
  column "order_id" does not exist in payment
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "order_id" does not exist in payment


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  column "order_id" does not exist in payment
2022-01-06 19:16:17.815344 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "order_id" does not exist in payment', 'raw_sql': 'with fct_orders as (\n\n    select\n        id as payment_id,\n        order_id,\n        customer_id\n        amount\n\n    from stripe.payment\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with fct_orders as (\n\n    select\n        id as payment_id,\n        order_id,\n        customer_id\n        amount\n\n    from stripe.payment\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "order_id" does not exist in payment', 'raw_sql': 'with fct_orders as (\n\n    select\n        id as payment_id,\n        order_id,\n        customer_id\n        amount\n\n    from stripe.payment\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with fct_orders as (\n\n    select\n        id as payment_id,\n        order_id,\n        customer_id\n        amount\n\n    from stripe.payment\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 19:16:18.105053 (Thread-609): handling poll request
2022-01-06 19:16:18.105524 (Thread-609): 19:16:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee44de130>]}
2022-01-06 19:16:18.106352 (Thread-609): sending response (<Response 9976 bytes [200 OK]>) to 10.0.1.28
2022-01-06 19:51:47.092768 (Thread-610): handling status request
2022-01-06 19:51:47.094828 (Thread-610): 19:51:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee44ea7c0>]}
2022-01-06 19:51:47.095865 (Thread-610): sending response (<Response 16530 bytes [200 OK]>) to 10.0.6.251
2022-01-06 19:51:47.447256 (Thread-611): handling run_sql request
2022-01-06 19:51:47.447598 (Thread-611): 19:51:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee44eaa90>]}
2022-01-06 19:51:49.539013 (Thread-611): sending response (<Response 138 bytes [200 OK]>) to 10.0.1.28
2022-01-06 19:51:49.566113 (MainThread): 19:51:49  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0f50b597-b913-40fe-ba82-66eba9dd9e06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4402e3a970>]}
2022-01-06 19:51:49.566668 (MainThread): 19:51:49  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:51:49.567266 (Thread-1): 19:51:49  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:51:49.567403 (Thread-1): 19:51:49  Began compiling node rpc.jaffel_shop.request
2022-01-06 19:51:49.567507 (Thread-1): 19:51:49  Compiling rpc.jaffel_shop.request
2022-01-06 19:51:49.568742 (Thread-1): 19:51:49  finished collecting timing info
2022-01-06 19:51:49.568869 (Thread-1): 19:51:49  Began executing node rpc.jaffel_shop.request
2022-01-06 19:51:49.568975 (Thread-1): 19:51:49  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:51:49.569068 (Thread-1): 19:51:49  On rpc.jaffel_shop.request: with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 19:51:49.569148 (Thread-1): 19:51:49  Opening a new connection, currently in state init
2022-01-06 19:51:49.569270 (Thread-1): 19:51:49  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:51:49.590505 (Thread-1): 19:51:49  SQL status: SELECT in 0.02 seconds
2022-01-06 19:51:49.593297 (Thread-1): 19:51:49  finished collecting timing info
2022-01-06 19:51:49.593444 (Thread-1): 19:51:49  On rpc.jaffel_shop.request: Close
2022-01-06 19:51:50.069692 (Thread-612): handling poll request
2022-01-06 19:51:50.070108 (Thread-612): 19:51:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee44eddc0>]}
2022-01-06 19:51:50.072026 (Thread-612): sending response (<Response 11840 bytes [200 OK]>) to 10.0.17.11
2022-01-06 19:52:41.787070 (Thread-613): handling status request
2022-01-06 19:52:41.787430 (Thread-613): 19:52:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee44eafa0>]}
2022-01-06 19:52:41.788423 (Thread-613): sending response (<Response 16530 bytes [200 OK]>) to 10.0.23.128
2022-01-06 19:52:42.168786 (Thread-614): handling run_sql request
2022-01-06 19:52:42.169158 (Thread-614): 19:52:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee46a5e20>]}
2022-01-06 19:52:44.265406 (Thread-614): sending response (<Response 138 bytes [200 OK]>) to 10.0.28.223
2022-01-06 19:52:44.289979 (MainThread): 19:52:44  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '53b7abd4-1111-43bc-94d9-a7ebb9139d95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f254eca60>]}
2022-01-06 19:52:44.290544 (MainThread): 19:52:44  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:52:44.291159 (Thread-1): 19:52:44  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:52:44.291297 (Thread-1): 19:52:44  Began compiling node rpc.jaffel_shop.request
2022-01-06 19:52:44.291390 (Thread-1): 19:52:44  Compiling rpc.jaffel_shop.request
2022-01-06 19:52:44.292666 (Thread-1): 19:52:44  finished collecting timing info
2022-01-06 19:52:44.292805 (Thread-1): 19:52:44  Began executing node rpc.jaffel_shop.request
2022-01-06 19:52:44.292910 (Thread-1): 19:52:44  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:52:44.292994 (Thread-1): 19:52:44  On rpc.jaffel_shop.request: with fct_orders as (

    select
        id as payment_id,
        orderid as order_id,
        amount

    from stripe.payment

)
select * from fct_orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 19:52:44.293071 (Thread-1): 19:52:44  Opening a new connection, currently in state init
2022-01-06 19:52:44.293152 (Thread-1): 19:52:44  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:52:44.496474 (Thread-1): 19:52:44  SQL status: SELECT in 0.2 seconds
2022-01-06 19:52:44.499336 (Thread-1): 19:52:44  finished collecting timing info
2022-01-06 19:52:44.499509 (Thread-1): 19:52:44  On rpc.jaffel_shop.request: Close
2022-01-06 19:52:44.616604 (Thread-615): handling poll request
2022-01-06 19:52:44.617032 (Thread-615): 19:52:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4496160>]}
2022-01-06 19:52:44.617952 (Thread-615): sending response (<Response 5155 bytes [200 OK]>) to 10.0.31.2
2022-01-06 19:52:46.090223 (Thread-616): handling poll request
2022-01-06 19:52:46.090585 (Thread-616): 19:52:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4496430>]}
2022-01-06 19:52:46.091760 (Thread-616): sending response (<Response 5578 bytes [200 OK]>) to 10.0.39.67
2022-01-06 19:52:54.079423 (Thread-617): 19:52:54  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 19:52:54.079862 (Thread-617): 19:52:54  Partial parsing: updated file: jaffel_shop://models/marts/core/fct_orders.sql
2022-01-06 19:52:54.086334 (Thread-617): 19:52:54  1699: static parser successfully parsed marts/core/fct_orders.sql
2022-01-06 19:52:54.129678 (Thread-617): 19:52:54  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee43ecc40>]}
2022-01-06 19:52:54.684837 (Thread-618): handling status request
2022-01-06 19:52:54.685297 (Thread-618): 19:52:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45d3130>]}
2022-01-06 19:52:54.685882 (Thread-618): sending response (<Response 1569 bytes [200 OK]>) to 10.0.44.76
2022-01-06 19:52:54.712046 (Thread-619): handling status request
2022-01-06 19:52:54.712438 (Thread-619): 19:52:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4478790>]}
2022-01-06 19:52:54.712909 (Thread-619): sending response (<Response 1569 bytes [200 OK]>) to 10.0.28.223
2022-01-06 19:53:54.761014 (Thread-620): 19:53:54  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 19:53:54.761466 (Thread-620): 19:53:54  Partial parsing: updated file: jaffel_shop://models/staging/stripe/stg_payments.sql
2022-01-06 19:53:54.765506 (Thread-620): 19:53:54  1699: static parser successfully parsed staging/stripe/stg_payments.sql
2022-01-06 19:53:54.809126 (Thread-620): 19:53:54  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee436d760>]}
2022-01-06 19:53:55.336364 (Thread-621): handling status request
2022-01-06 19:53:55.336721 (Thread-621): 19:53:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4572610>]}
2022-01-06 19:53:55.337188 (Thread-621): sending response (<Response 1581 bytes [200 OK]>) to 10.0.36.155
2022-01-06 19:53:55.410930 (Thread-622): handling status request
2022-01-06 19:53:55.411280 (Thread-622): 19:53:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee44663d0>]}
2022-01-06 19:53:55.411735 (Thread-622): sending response (<Response 1581 bytes [200 OK]>) to 10.0.23.128
2022-01-06 19:56:43.142585 (Thread-623): handling status request
2022-01-06 19:56:43.144273 (Thread-623): 19:56:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee442ce80>]}
2022-01-06 19:56:43.144744 (Thread-623): sending response (<Response 1581 bytes [200 OK]>) to 10.0.17.11
2022-01-06 19:56:43.503015 (Thread-624): handling run_sql request
2022-01-06 19:56:43.503379 (Thread-624): 19:56:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee442cbe0>]}
2022-01-06 19:56:45.864202 (Thread-624): sending response (<Response 138 bytes [200 OK]>) to 10.0.39.207
2022-01-06 19:56:45.890574 (MainThread): 19:56:45  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '11e93eca-e83c-4f6f-8549-7b43f489403b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25c8c0db80>]}
2022-01-06 19:56:45.891140 (MainThread): 19:56:45  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:56:45.891742 (Thread-1): 19:56:45  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:56:45.891866 (Thread-1): 19:56:45  Began compiling node rpc.jaffel_shop.request
2022-01-06 19:56:45.891953 (Thread-1): 19:56:45  Compiling rpc.jaffel_shop.request
2022-01-06 19:56:45.893111 (Thread-1): 19:56:45  finished collecting timing info
2022-01-06 19:56:45.893285 (Thread-1): 19:56:45  Began executing node rpc.jaffel_shop.request
2022-01-06 19:56:45.893397 (Thread-1): 19:56:45  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:56:45.893478 (Thread-1): 19:56:45  On rpc.jaffel_shop.request: with fct_orders as (

    select
        id as order_id,
        user_id as customer_id,

    from stripe.payment
    Where status = completed

)
select * from fct_orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 19:56:45.893560 (Thread-1): 19:56:45  Opening a new connection, currently in state init
2022-01-06 19:56:45.893646 (Thread-1): 19:56:45  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:56:45.913682 (Thread-1): 19:56:45  Postgres adapter: Postgres error: syntax error at or near "from"
LINE 7:     from stripe.payment
            ^

2022-01-06 19:56:45.913847 (Thread-1): 19:56:45  finished collecting timing info
2022-01-06 19:56:45.913965 (Thread-1): 19:56:45  On rpc.jaffel_shop.request: Close
2022-01-06 19:56:45.914175 (Thread-1): Got an exception: Database Error
  syntax error at or near "from"
  LINE 7:     from stripe.payment
              ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "from"
LINE 7:     from stripe.payment
            ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "from"
  LINE 7:     from stripe.payment
              ^
2022-01-06 19:56:45.915371 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "from"\n  LINE 7:     from stripe.payment\n              ^', 'raw_sql': 'with fct_orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n\n    from stripe.payment\n    Where status = completed\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with fct_orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n\n    from stripe.payment\n    Where status = completed\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "from"\n  LINE 7:     from stripe.payment\n              ^', 'raw_sql': 'with fct_orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n\n    from stripe.payment\n    Where status = completed\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with fct_orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n\n    from stripe.payment\n    Where status = completed\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 19:56:46.321167 (Thread-625): handling poll request
2022-01-06 19:56:46.321624 (Thread-625): 19:56:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee43c6d00>]}
2022-01-06 19:56:46.322433 (Thread-625): sending response (<Response 10272 bytes [200 OK]>) to 10.0.36.155
2022-01-06 19:56:56.358071 (Thread-626): handling status request
2022-01-06 19:56:56.358426 (Thread-626): 19:56:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee43c61f0>]}
2022-01-06 19:56:56.358942 (Thread-626): sending response (<Response 1581 bytes [200 OK]>) to 10.0.44.31
2022-01-06 19:56:56.761097 (Thread-627): handling run_sql request
2022-01-06 19:56:56.761490 (Thread-627): 19:56:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4478b80>]}
2022-01-06 19:56:58.830616 (Thread-627): sending response (<Response 138 bytes [200 OK]>) to 10.0.17.11
2022-01-06 19:56:58.856423 (MainThread): 19:56:58  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '318beed7-4aa5-4e35-9d2b-36a1ca458588', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5248feaac0>]}
2022-01-06 19:56:58.857092 (MainThread): 19:56:58  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:56:58.857747 (Thread-1): 19:56:58  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:56:58.857870 (Thread-1): 19:56:58  Began compiling node rpc.jaffel_shop.request
2022-01-06 19:56:58.857959 (Thread-1): 19:56:58  Compiling rpc.jaffel_shop.request
2022-01-06 19:56:58.859096 (Thread-1): 19:56:58  finished collecting timing info
2022-01-06 19:56:58.859221 (Thread-1): 19:56:58  Began executing node rpc.jaffel_shop.request
2022-01-06 19:56:58.859323 (Thread-1): 19:56:58  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:56:58.859419 (Thread-1): 19:56:58  On rpc.jaffel_shop.request: with fct_orders as (

    select
        id as order_id,
        user_id as customer_id,

    from orders
    Where status = completed

)
select * from fct_orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 19:56:58.859499 (Thread-1): 19:56:58  Opening a new connection, currently in state init
2022-01-06 19:56:58.859581 (Thread-1): 19:56:58  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:56:58.886171 (Thread-1): 19:56:58  Postgres adapter: Postgres error: syntax error at or near "from"
LINE 7:     from orders
            ^

2022-01-06 19:56:58.886329 (Thread-1): 19:56:58  finished collecting timing info
2022-01-06 19:56:58.886445 (Thread-1): 19:56:58  On rpc.jaffel_shop.request: Close
2022-01-06 19:56:58.886639 (Thread-1): Got an exception: Database Error
  syntax error at or near "from"
  LINE 7:     from orders
              ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "from"
LINE 7:     from orders
            ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "from"
  LINE 7:     from orders
              ^
2022-01-06 19:56:58.887744 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "from"\n  LINE 7:     from orders\n              ^', 'raw_sql': 'with fct_orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n\n    from orders\n    Where status = completed\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with fct_orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n\n    from orders\n    Where status = completed\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "from"\n  LINE 7:     from orders\n              ^', 'raw_sql': 'with fct_orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n\n    from orders\n    Where status = completed\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with fct_orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n\n    from orders\n    Where status = completed\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 19:56:59.279629 (Thread-628): handling poll request
2022-01-06 19:56:59.280123 (Thread-628): 19:56:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee44062e0>]}
2022-01-06 19:56:59.281040 (Thread-628): sending response (<Response 10160 bytes [200 OK]>) to 10.0.39.207
2022-01-06 19:57:22.860090 (Thread-629): handling status request
2022-01-06 19:57:22.861980 (Thread-629): 19:57:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4478550>]}
2022-01-06 19:57:22.862490 (Thread-629): sending response (<Response 1581 bytes [200 OK]>) to 10.0.10.3
2022-01-06 19:57:23.198414 (Thread-630): handling run_sql request
2022-01-06 19:57:23.198779 (Thread-630): 19:57:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45725b0>]}
2022-01-06 19:57:25.267140 (Thread-630): sending response (<Response 138 bytes [200 OK]>) to 10.0.23.128
2022-01-06 19:57:25.290775 (MainThread): 19:57:25  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '09725907-4c3f-4708-b3a6-39e66e46f13c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5475b0aa60>]}
2022-01-06 19:57:25.291289 (MainThread): 19:57:25  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:57:25.291838 (Thread-1): 19:57:25  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:57:25.291972 (Thread-1): 19:57:25  Began compiling node rpc.jaffel_shop.request
2022-01-06 19:57:25.292063 (Thread-1): 19:57:25  Compiling rpc.jaffel_shop.request
2022-01-06 19:57:25.293171 (Thread-1): 19:57:25  finished collecting timing info
2022-01-06 19:57:25.293348 (Thread-1): 19:57:25  Began executing node rpc.jaffel_shop.request
2022-01-06 19:57:25.293474 (Thread-1): 19:57:25  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:57:25.293556 (Thread-1): 19:57:25  On rpc.jaffel_shop.request: with fct_orders as (

    select
        id as order_id,
        user_id as customer_id

    from orders
    Where status = completed

)
select * from fct_orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 19:57:25.293635 (Thread-1): 19:57:25  Opening a new connection, currently in state init
2022-01-06 19:57:25.293721 (Thread-1): 19:57:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:57:25.314722 (Thread-1): 19:57:25  Postgres adapter: Postgres error: relation "orders" does not exist

2022-01-06 19:57:25.314878 (Thread-1): 19:57:25  finished collecting timing info
2022-01-06 19:57:25.314993 (Thread-1): 19:57:25  On rpc.jaffel_shop.request: Close
2022-01-06 19:57:25.315251 (Thread-1): Got an exception: Database Error
  relation "orders" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "orders" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "orders" does not exist
2022-01-06 19:57:25.316203 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "orders" does not exist', 'raw_sql': 'with fct_orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id\n\n    from orders\n    Where status = completed\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with fct_orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id\n\n    from orders\n    Where status = completed\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "orders" does not exist', 'raw_sql': 'with fct_orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id\n\n    from orders\n    Where status = completed\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with fct_orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id\n\n    from orders\n    Where status = completed\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 19:57:25.686917 (Thread-631): handling poll request
2022-01-06 19:57:25.687502 (Thread-631): 19:57:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4350310>]}
2022-01-06 19:57:25.688611 (Thread-631): sending response (<Response 9866 bytes [200 OK]>) to 10.0.14.28
2022-01-06 19:57:41.762486 (Thread-632): handling status request
2022-01-06 19:57:41.762857 (Thread-632): 19:57:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee434f610>]}
2022-01-06 19:57:41.763415 (Thread-632): sending response (<Response 1581 bytes [200 OK]>) to 10.0.17.11
2022-01-06 19:57:42.196319 (Thread-633): handling run_sql request
2022-01-06 19:57:42.196719 (Thread-633): 19:57:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee434f7f0>]}
2022-01-06 19:57:44.337935 (Thread-633): sending response (<Response 138 bytes [200 OK]>) to 10.0.1.28
2022-01-06 19:57:44.362228 (MainThread): 19:57:44  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '61c9ad4f-45bf-48c9-bf32-b5404a94012e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0af9bb79d0>]}
2022-01-06 19:57:44.362775 (MainThread): 19:57:44  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:57:44.363344 (Thread-1): 19:57:44  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:57:44.363469 (Thread-1): 19:57:44  Began compiling node rpc.jaffel_shop.request
2022-01-06 19:57:44.363566 (Thread-1): 19:57:44  Compiling rpc.jaffel_shop.request
2022-01-06 19:57:44.364715 (Thread-1): 19:57:44  finished collecting timing info
2022-01-06 19:57:44.364840 (Thread-1): 19:57:44  Began executing node rpc.jaffel_shop.request
2022-01-06 19:57:44.364996 (Thread-1): 19:57:44  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:57:44.365108 (Thread-1): 19:57:44  On rpc.jaffel_shop.request: with fct_orders as (

    select
        id as order_id,
        user_id as customer_id

    from jaffle_shop.orders
    Where status = completed

)
select * from fct_orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 19:57:44.365187 (Thread-1): 19:57:44  Opening a new connection, currently in state init
2022-01-06 19:57:44.365299 (Thread-1): 19:57:44  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:57:44.385733 (Thread-1): 19:57:44  Postgres adapter: Postgres error: column "completed" does not exist in orders

2022-01-06 19:57:44.385893 (Thread-1): 19:57:44  finished collecting timing info
2022-01-06 19:57:44.386016 (Thread-1): 19:57:44  On rpc.jaffel_shop.request: Close
2022-01-06 19:57:44.386200 (Thread-1): Got an exception: Database Error
  column "completed" does not exist in orders
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "completed" does not exist in orders


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  column "completed" does not exist in orders
2022-01-06 19:57:44.387278 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "completed" does not exist in orders', 'raw_sql': 'with fct_orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id\n\n    from jaffle_shop.orders\n    Where status = completed\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with fct_orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id\n\n    from jaffle_shop.orders\n    Where status = completed\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "completed" does not exist in orders', 'raw_sql': 'with fct_orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id\n\n    from jaffle_shop.orders\n    Where status = completed\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with fct_orders as (\n\n    select\n        id as order_id,\n        user_id as customer_id\n\n    from jaffle_shop.orders\n    Where status = completed\n\n)\nselect * from fct_orders\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 19:57:44.762877 (Thread-634): handling poll request
2022-01-06 19:57:44.763311 (Thread-634): 19:57:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee434bfd0>]}
2022-01-06 19:57:44.786291 (Thread-634): sending response (<Response 10028 bytes [200 OK]>) to 10.0.28.223
2022-01-06 19:58:01.753993 (Thread-635): handling status request
2022-01-06 19:58:01.754403 (Thread-635): 19:58:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee434b190>]}
2022-01-06 19:58:01.754949 (Thread-635): sending response (<Response 1581 bytes [200 OK]>) to 10.0.39.207
2022-01-06 19:58:02.168172 (Thread-636): handling run_sql request
2022-01-06 19:58:02.168556 (Thread-636): 19:58:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee434b550>]}
2022-01-06 19:58:04.459746 (Thread-636): sending response (<Response 138 bytes [200 OK]>) to 10.0.39.67
2022-01-06 19:58:04.488080 (MainThread): 19:58:04  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '61d9b765-2801-429e-bde1-b438df2350b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43c4492ac0>]}
2022-01-06 19:58:04.488679 (MainThread): 19:58:04  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 19:58:04.489309 (Thread-1): 19:58:04  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:58:04.489437 (Thread-1): 19:58:04  Began compiling node rpc.jaffel_shop.request
2022-01-06 19:58:04.489543 (Thread-1): 19:58:04  Compiling rpc.jaffel_shop.request
2022-01-06 19:58:04.490763 (Thread-1): 19:58:04  finished collecting timing info
2022-01-06 19:58:04.490899 (Thread-1): 19:58:04  Began executing node rpc.jaffel_shop.request
2022-01-06 19:58:04.491067 (Thread-1): 19:58:04  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 19:58:04.491180 (Thread-1): 19:58:04  On rpc.jaffel_shop.request: with fct_orders as (

    select
        id as order_id,
        user_id as customer_id

    from jaffle_shop.orders
    Where status = 'completed'

)
select * from fct_orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 19:58:04.491263 (Thread-1): 19:58:04  Opening a new connection, currently in state init
2022-01-06 19:58:04.491355 (Thread-1): 19:58:04  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 19:58:04.904282 (Thread-637): handling poll request
2022-01-06 19:58:04.904721 (Thread-637): 19:58:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4406dc0>]}
2022-01-06 19:58:04.905740 (Thread-637): sending response (<Response 4202 bytes [200 OK]>) to 10.0.1.28
2022-01-06 19:58:06.246720 (Thread-638): handling poll request
2022-01-06 19:58:06.247081 (Thread-638): 19:58:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee43f3cd0>]}
2022-01-06 19:58:06.247569 (Thread-638): sending response (<Response 394 bytes [200 OK]>) to 10.0.36.155
2022-01-06 19:58:07.665644 (Thread-639): handling poll request
2022-01-06 19:58:07.666018 (Thread-639): 19:58:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee43f3670>]}
2022-01-06 19:58:07.666496 (Thread-639): sending response (<Response 394 bytes [200 OK]>) to 10.0.36.155
2022-01-06 19:58:09.002141 (Thread-640): handling poll request
2022-01-06 19:58:09.002502 (Thread-640): 19:58:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee43f3490>]}
2022-01-06 19:58:09.002978 (Thread-640): sending response (<Response 394 bytes [200 OK]>) to 10.0.6.251
2022-01-06 19:58:10.200027 (Thread-1): 19:58:10  SQL status: SELECT in 5.71 seconds
2022-01-06 19:58:10.201859 (Thread-1): 19:58:10  finished collecting timing info
2022-01-06 19:58:10.202032 (Thread-1): 19:58:10  On rpc.jaffel_shop.request: Close
2022-01-06 19:58:10.393243 (Thread-641): handling poll request
2022-01-06 19:58:10.393638 (Thread-641): 19:58:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee436db50>]}
2022-01-06 19:58:10.394654 (Thread-641): sending response (<Response 4950 bytes [200 OK]>) to 10.0.24.171
2022-01-06 19:58:36.038581 (Thread-642): 19:58:36  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 19:58:36.038992 (Thread-642): 19:58:36  Partial parsing: updated file: jaffel_shop://models/marts/core/fct_orders.sql
2022-01-06 19:58:36.043878 (Thread-642): 19:58:36  1699: static parser successfully parsed marts/core/fct_orders.sql
2022-01-06 19:58:36.085021 (Thread-642): 19:58:36  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee429d580>]}
2022-01-06 19:58:36.572570 (Thread-643): handling status request
2022-01-06 19:58:36.572934 (Thread-643): 19:58:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee42fc3d0>]}
2022-01-06 19:58:36.573463 (Thread-643): sending response (<Response 1569 bytes [200 OK]>) to 10.0.10.3
2022-01-06 19:58:36.631744 (Thread-644): handling status request
2022-01-06 19:58:36.632072 (Thread-644): 19:58:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee42fc160>]}
2022-01-06 19:58:36.632517 (Thread-644): sending response (<Response 1569 bytes [200 OK]>) to 10.0.31.30
2022-01-06 20:13:44.356995 (Thread-645): handling status request
2022-01-06 20:13:44.357420 (Thread-645): 20:13:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4436b50>]}
2022-01-06 20:13:44.357928 (Thread-645): sending response (<Response 1569 bytes [200 OK]>) to 10.0.14.28
2022-01-06 20:13:44.383202 (Thread-646): handling ps request
2022-01-06 20:13:44.383452 (Thread-646): 20:13:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4436670>]}
2022-01-06 20:13:44.388277 (Thread-646): sending response (<Response 55802 bytes [200 OK]>) to 10.0.14.28
2022-01-06 20:13:44.399088 (Thread-647): handling status request
2022-01-06 20:13:44.399323 (Thread-647): 20:13:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee42f5df0>]}
2022-01-06 20:13:44.399695 (Thread-647): sending response (<Response 1569 bytes [200 OK]>) to 10.0.31.2
2022-01-06 20:13:44.578993 (Thread-648): handling status request
2022-01-06 20:13:44.579379 (Thread-648): 20:13:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee436d790>]}
2022-01-06 20:13:44.579832 (Thread-648): sending response (<Response 1569 bytes [200 OK]>) to 10.0.39.207
2022-01-06 20:13:45.350906 (Thread-649): handling poll request
2022-01-06 20:13:45.351260 (Thread-649): 20:13:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4366790>]}
2022-01-06 20:13:45.353898 (Thread-649): sending response (<Response 86014 bytes [200 OK]>) to 10.0.17.11
2022-01-06 20:13:46.131941 (Thread-650): handling status request
2022-01-06 20:13:46.132312 (Thread-650): 20:13:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee436c700>]}
2022-01-06 20:13:46.132798 (Thread-650): sending response (<Response 1547 bytes [200 OK]>) to 10.0.7.144
2022-01-06 20:13:46.135634 (Thread-651): handling status request
2022-01-06 20:13:46.135920 (Thread-651): 20:13:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee436c9d0>]}
2022-01-06 20:13:46.136443 (Thread-651): sending response (<Response 1547 bytes [200 OK]>) to 10.0.7.144
2022-01-06 20:13:46.138646 (Thread-652): handling status request
2022-01-06 20:13:46.138884 (Thread-652): 20:13:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4436550>]}
2022-01-06 20:13:46.139220 (Thread-652): sending response (<Response 1547 bytes [200 OK]>) to 10.0.7.144
2022-01-06 20:13:46.140084 (Thread-653): handling list request
2022-01-06 20:13:46.140427 (Thread-653): 20:13:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff780aff70>]}
2022-01-06 20:13:46.142208 (Thread-655): handling list request
2022-01-06 20:13:46.188026 (Thread-655): sending response (<Response 214 bytes [200 OK]>) to 10.0.7.144
2022-01-06 20:13:46.183185 (Thread-655): 20:13:46  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:13:46.189553 (Thread-656): sending response (<Response 5699 bytes [200 OK]>) to 10.0.7.144
2022-01-06 20:13:46.276768 (Thread-658): handling status request
2022-01-06 20:13:46.277151 (Thread-658): 20:13:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee42a0af0>]}
2022-01-06 20:13:46.277636 (Thread-658): sending response (<Response 1547 bytes [200 OK]>) to 10.0.7.144
2022-01-06 20:13:46.282739 (Thread-659): handling list request
2022-01-06 20:13:46.282979 (Thread-659): 20:13:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee429dd00>]}
2022-01-06 20:13:46.310540 (Thread-659): 20:13:46  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee42fc550>]}
2022-01-06 20:13:46.333796 (Thread-659): 20:13:46  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:13:46.335850 (Thread-659): sending response (<Response 1712 bytes [200 OK]>) to 10.0.7.144
2022-01-06 20:13:46.669882 (Thread-660): handling status request
2022-01-06 20:13:46.670243 (Thread-660): 20:13:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee434b040>]}
2022-01-06 20:13:46.670725 (Thread-660): sending response (<Response 1569 bytes [200 OK]>) to 10.0.31.2
2022-01-06 20:13:46.792992 (Thread-661): handling status request
2022-01-06 20:13:46.793352 (Thread-661): 20:13:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4297070>]}
2022-01-06 20:13:46.793809 (Thread-661): sending response (<Response 1569 bytes [200 OK]>) to 10.0.5.108
2022-01-06 20:13:47.340459 (Thread-662): handling status request
2022-01-06 20:13:47.340835 (Thread-662): 20:13:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee42a0af0>]}
2022-01-06 20:13:47.341366 (Thread-662): sending response (<Response 1547 bytes [200 OK]>) to 10.0.7.144
2022-01-06 20:13:47.346822 (Thread-663): handling list request
2022-01-06 20:13:47.347068 (Thread-663): 20:13:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee42a0eb0>]}
2022-01-06 20:13:47.379779 (Thread-663): 20:13:47  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee42b37c0>]}
2022-01-06 20:13:47.380089 (Thread-663): 20:13:47  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:13:47.382774 (Thread-663): sending response (<Response 2911 bytes [200 OK]>) to 10.0.7.144
2022-01-06 20:16:18.355149 (Thread-664): handling status request
2022-01-06 20:16:18.356724 (Thread-664): 20:16:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee42aafa0>]}
2022-01-06 20:16:18.357257 (Thread-664): sending response (<Response 1547 bytes [200 OK]>) to 10.0.7.144
2022-01-06 20:16:18.387288 (Thread-665): handling list request
2022-01-06 20:16:18.387607 (Thread-665): 20:16:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee42f5eb0>]}
2022-01-06 20:16:18.421686 (Thread-665): 20:16:18  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee42b3550>]}
2022-01-06 20:16:18.422005 (Thread-665): 20:16:18  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:16:18.430766 (Thread-665): sending response (<Response 2911 bytes [200 OK]>) to 10.0.7.144
2022-01-06 20:20:06.237304 (Thread-666): handling status request
2022-01-06 20:20:06.239106 (Thread-666): 20:20:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4249dc0>]}
2022-01-06 20:20:06.239575 (Thread-666): sending response (<Response 1547 bytes [200 OK]>) to 10.0.7.144
2022-01-06 20:20:06.246679 (Thread-667): handling list request
2022-01-06 20:20:06.246913 (Thread-667): 20:20:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee424e100>]}
2022-01-06 20:20:06.282106 (Thread-667): 20:20:06  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4297910>]}
2022-01-06 20:20:06.282379 (Thread-667): 20:20:06  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:20:06.293440 (Thread-667): sending response (<Response 1712 bytes [200 OK]>) to 10.0.7.144
2022-01-06 20:20:09.724426 (Thread-668): handling status request
2022-01-06 20:20:09.724788 (Thread-668): 20:20:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4297be0>]}
2022-01-06 20:20:09.725282 (Thread-668): sending response (<Response 1569 bytes [200 OK]>) to 10.0.31.2
2022-01-06 20:20:10.077156 (Thread-669): handling run_sql request
2022-01-06 20:20:10.077525 (Thread-669): 20:20:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee424eca0>]}
2022-01-06 20:20:12.154593 (Thread-669): sending response (<Response 138 bytes [200 OK]>) to 10.0.44.76
2022-01-06 20:20:12.179093 (MainThread): 20:20:12  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '05aca187-200a-49d9-819c-4a77c0dbe2bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8bee5ca90>]}
2022-01-06 20:20:12.179615 (MainThread): 20:20:12  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:20:12.180191 (Thread-1): 20:20:12  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:20:12.180321 (Thread-1): 20:20:12  Began compiling node rpc.jaffel_shop.request
2022-01-06 20:20:12.180422 (Thread-1): 20:20:12  Compiling rpc.jaffel_shop.request
2022-01-06 20:20:12.181582 (Thread-1): 20:20:12  finished collecting timing info
2022-01-06 20:20:12.181705 (Thread-1): 20:20:12  Began executing node rpc.jaffel_shop.request
2022-01-06 20:20:12.181804 (Thread-1): 20:20:12  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:20:12.181901 (Thread-1): 20:20:12  On rpc.jaffel_shop.request: with payment as (

    select
        id as payment_id,
        orderid as order_id,
        amount

    from stripe.payment

)
select * from payment
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 20:20:12.181976 (Thread-1): 20:20:12  Opening a new connection, currently in state init
2022-01-06 20:20:12.182055 (Thread-1): 20:20:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:20:12.219037 (Thread-1): 20:20:12  SQL status: SELECT in 0.04 seconds
2022-01-06 20:20:12.223257 (Thread-1): 20:20:12  finished collecting timing info
2022-01-06 20:20:12.223396 (Thread-1): 20:20:12  On rpc.jaffel_shop.request: Close
2022-01-06 20:20:12.631519 (Thread-670): handling poll request
2022-01-06 20:20:12.631956 (Thread-670): 20:20:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee426c7c0>]}
2022-01-06 20:20:12.633548 (Thread-670): sending response (<Response 10316 bytes [200 OK]>) to 10.0.44.76
2022-01-06 20:21:29.300514 (Thread-671): handling status request
2022-01-06 20:21:29.302505 (Thread-671): 20:21:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee426c970>]}
2022-01-06 20:21:29.303031 (Thread-671): sending response (<Response 1569 bytes [200 OK]>) to 10.0.39.67
2022-01-06 20:21:29.773931 (Thread-672): handling run_sql request
2022-01-06 20:21:29.774326 (Thread-672): 20:21:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee424d0a0>]}
2022-01-06 20:21:31.867206 (Thread-672): sending response (<Response 138 bytes [200 OK]>) to 10.0.44.31
2022-01-06 20:21:31.895349 (MainThread): 20:21:31  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ef3f8c99-d15b-4b7b-863d-33c4363a3952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff320c534f0>]}
2022-01-06 20:21:31.895876 (MainThread): 20:21:31  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:21:31.896443 (Thread-1): 20:21:31  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:21:31.896572 (Thread-1): 20:21:31  Began compiling node rpc.jaffel_shop.request
2022-01-06 20:21:31.896661 (Thread-1): 20:21:31  Compiling rpc.jaffel_shop.request
2022-01-06 20:21:31.899411 (Thread-1): 20:21:31  finished collecting timing info
2022-01-06 20:21:31.899535 (Thread-1): 20:21:31  Began executing node rpc.jaffel_shop.request
2022-01-06 20:21:31.899630 (Thread-1): 20:21:31  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:21:31.899733 (Thread-1): 20:21:31  On rpc.jaffel_shop.request: 

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

amount as 
    select * from "dev"."dbt_nobodozie"."stg_payments"


customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
    from customers

    left join customer_orders using (customer_id)
    left join 
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 20:21:31.899827 (Thread-1): 20:21:31  Opening a new connection, currently in state init
2022-01-06 20:21:31.899916 (Thread-1): 20:21:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:21:31.921547 (Thread-1): 20:21:31  Postgres adapter: Postgres error: syntax error at or near "select"
LINE 15:     select * from "dev"."dbt_nobodozie"."stg_payments"
             ^

2022-01-06 20:21:31.921784 (Thread-1): 20:21:31  finished collecting timing info
2022-01-06 20:21:31.921972 (Thread-1): 20:21:31  On rpc.jaffel_shop.request: Close
2022-01-06 20:21:31.922247 (Thread-1): Got an exception: Database Error
  syntax error at or near "select"
  LINE 15:     select * from "dev"."dbt_nobodozie"."stg_payments"
               ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "select"
LINE 15:     select * from "dev"."dbt_nobodozie"."stg_payments"
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "select"
  LINE 15:     select * from "dev"."dbt_nobodozie"."stg_payments"
               ^
2022-01-06 20:21:31.923673 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "select"\n  LINE 15:     select * from "dev"."dbt_nobodozie"."stg_payments"\n               ^', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\namount as \n    select * from {{ ref(\'stg_payments\')}}\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\namount as \n    select * from "dev"."dbt_nobodozie"."stg_payments"\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "select"\n  LINE 15:     select * from "dev"."dbt_nobodozie"."stg_payments"\n               ^', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\namount as \n    select * from {{ ref(\'stg_payments\')}}\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\namount as \n    select * from "dev"."dbt_nobodozie"."stg_payments"\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 20:21:32.344383 (Thread-673): handling poll request
2022-01-06 20:21:32.344836 (Thread-673): 20:21:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4275310>]}
2022-01-06 20:21:32.345731 (Thread-673): sending response (<Response 15850 bytes [200 OK]>) to 10.0.31.30
2022-01-06 20:22:04.065624 (Thread-674): handling status request
2022-01-06 20:22:04.065982 (Thread-674): 20:22:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4275820>]}
2022-01-06 20:22:04.066489 (Thread-674): sending response (<Response 1569 bytes [200 OK]>) to 10.0.14.28
2022-01-06 20:22:04.492789 (Thread-675): handling run_sql request
2022-01-06 20:22:04.493123 (Thread-675): 20:22:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4275b20>]}
2022-01-06 20:22:06.594080 (Thread-675): sending response (<Response 138 bytes [200 OK]>) to 10.0.31.2
2022-01-06 20:22:06.620308 (MainThread): 20:22:06  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dc3f4be4-3512-49d3-9a9f-09b33f159402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8520554610>]}
2022-01-06 20:22:06.620879 (MainThread): 20:22:06  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:22:06.621574 (Thread-1): 20:22:06  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:22:06.621736 (Thread-1): 20:22:06  Began compiling node rpc.jaffel_shop.request
2022-01-06 20:22:06.621872 (Thread-1): 20:22:06  Compiling rpc.jaffel_shop.request
2022-01-06 20:22:06.625675 (Thread-1): 20:22:06  finished collecting timing info
2022-01-06 20:22:06.625845 (Thread-1): 20:22:06  Began executing node rpc.jaffel_shop.request
2022-01-06 20:22:06.625981 (Thread-1): 20:22:06  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:22:06.626093 (Thread-1): 20:22:06  On rpc.jaffel_shop.request: 

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

amount as (
    select * from "dev"."dbt_nobodozie"."stg_payments"

),

customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
    from customers

    left join customer_orders using (customer_id)
    left join 
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 20:22:06.626194 (Thread-1): 20:22:06  Opening a new connection, currently in state init
2022-01-06 20:22:06.626301 (Thread-1): 20:22:06  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:22:06.648244 (Thread-1): 20:22:06  Postgres adapter: Postgres error: syntax error at or near ")"
LINE 48: )
         ^

2022-01-06 20:22:06.648518 (Thread-1): 20:22:06  finished collecting timing info
2022-01-06 20:22:06.648708 (Thread-1): 20:22:06  On rpc.jaffel_shop.request: Close
2022-01-06 20:22:06.649044 (Thread-1): Got an exception: Database Error
  syntax error at or near ")"
  LINE 48: )
           ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near ")"
LINE 48: )
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near ")"
  LINE 48: )
           ^
2022-01-06 20:22:06.650615 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near ")"\n  LINE 48: )\n           ^', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\namount as (\n    select * from {{ ref(\'stg_payments\')}}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\namount as (\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near ")"\n  LINE 48: )\n           ^', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\namount as (\n    select * from {{ ref(\'stg_payments\')}}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\namount as (\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 20:22:06.992267 (Thread-676): handling poll request
2022-01-06 20:22:06.992705 (Thread-676): 20:22:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee427ad60>]}
2022-01-06 20:22:06.993603 (Thread-676): sending response (<Response 15413 bytes [200 OK]>) to 10.0.14.28
2022-01-06 20:24:14.061138 (Thread-677): handling status request
2022-01-06 20:24:14.062965 (Thread-677): 20:24:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee41e3700>]}
2022-01-06 20:24:14.063520 (Thread-677): sending response (<Response 1569 bytes [200 OK]>) to 10.0.39.67
2022-01-06 20:24:14.628288 (Thread-678): handling run_sql request
2022-01-06 20:24:14.628645 (Thread-678): 20:24:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee41e3970>]}
2022-01-06 20:24:16.677787 (Thread-678): sending response (<Response 138 bytes [200 OK]>) to 10.0.5.108
2022-01-06 20:24:16.705704 (MainThread): 20:24:16  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '74595d19-1fe1-45ec-9dff-92789f3bc4b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eaf601bb0>]}
2022-01-06 20:24:16.706229 (MainThread): 20:24:16  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:24:16.706796 (Thread-1): 20:24:16  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:24:16.706930 (Thread-1): 20:24:16  Began compiling node rpc.jaffel_shop.request
2022-01-06 20:24:16.707029 (Thread-1): 20:24:16  Compiling rpc.jaffel_shop.request
2022-01-06 20:24:16.709772 (Thread-1): 20:24:16  finished collecting timing info
2022-01-06 20:24:16.709901 (Thread-1): 20:24:16  Began executing node rpc.jaffel_shop.request
2022-01-06 20:24:16.709999 (Thread-1): 20:24:16  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:24:16.710076 (Thread-1): 20:24:16  On rpc.jaffel_shop.request: 

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

amounts as (
    select * from "dev"."dbt_nobodozie"."stg_payments"

),

customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
    from customers

    left join customer_orders using (customer_id)
    left join 
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 20:24:16.710153 (Thread-1): 20:24:16  Opening a new connection, currently in state init
2022-01-06 20:24:16.710230 (Thread-1): 20:24:16  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:24:16.730680 (Thread-1): 20:24:16  Postgres adapter: Postgres error: syntax error at or near ")"
LINE 48: )
         ^

2022-01-06 20:24:16.730874 (Thread-1): 20:24:16  finished collecting timing info
2022-01-06 20:24:16.730999 (Thread-1): 20:24:16  On rpc.jaffel_shop.request: Close
2022-01-06 20:24:16.731188 (Thread-1): Got an exception: Database Error
  syntax error at or near ")"
  LINE 48: )
           ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near ")"
LINE 48: )
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near ")"
  LINE 48: )
           ^
2022-01-06 20:24:16.732441 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near ")"\n  LINE 48: )\n           ^', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\namounts as (\n    select * from {{ ref(\'stg_payments\')}}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\namounts as (\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near ")"\n  LINE 48: )\n           ^', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\namounts as (\n    select * from {{ ref(\'stg_payments\')}}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\namounts as (\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 20:24:17.141874 (Thread-679): handling poll request
2022-01-06 20:24:17.142360 (Thread-679): 20:24:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee41ec400>]}
2022-01-06 20:24:17.143170 (Thread-679): sending response (<Response 15420 bytes [200 OK]>) to 10.0.1.28
2022-01-06 20:24:25.042066 (Thread-680): handling status request
2022-01-06 20:24:25.042422 (Thread-680): 20:24:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee41ec910>]}
2022-01-06 20:24:25.042943 (Thread-680): sending response (<Response 1569 bytes [200 OK]>) to 10.0.5.108
2022-01-06 20:24:25.503525 (Thread-681): handling run_sql request
2022-01-06 20:24:25.503860 (Thread-681): 20:24:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee41ecc10>]}
2022-01-06 20:24:27.548744 (Thread-681): sending response (<Response 138 bytes [200 OK]>) to 10.0.36.155
2022-01-06 20:24:27.573771 (MainThread): 20:24:27  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1d405e1e-14d0-4c00-8288-af7c6bc9a6f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed20207520>]}
2022-01-06 20:24:27.574285 (MainThread): 20:24:27  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:24:27.574833 (Thread-1): 20:24:27  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:24:27.574963 (Thread-1): 20:24:27  Began compiling node rpc.jaffel_shop.request
2022-01-06 20:24:27.575053 (Thread-1): 20:24:27  Compiling rpc.jaffel_shop.request
2022-01-06 20:24:27.577623 (Thread-1): 20:24:27  finished collecting timing info
2022-01-06 20:24:27.577749 (Thread-1): 20:24:27  Began executing node rpc.jaffel_shop.request
2022-01-06 20:24:27.577844 (Thread-1): 20:24:27  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:24:27.577920 (Thread-1): 20:24:27  On rpc.jaffel_shop.request: 

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),



customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
    from customers

    left join customer_orders using (customer_id)
    left join 
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 20:24:27.578019 (Thread-1): 20:24:27  Opening a new connection, currently in state init
2022-01-06 20:24:27.578098 (Thread-1): 20:24:27  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:24:27.598780 (Thread-1): 20:24:27  Postgres adapter: Postgres error: syntax error at or near ")"
LINE 45: )
         ^

2022-01-06 20:24:27.598936 (Thread-1): 20:24:27  finished collecting timing info
2022-01-06 20:24:27.599052 (Thread-1): 20:24:27  On rpc.jaffel_shop.request: Close
2022-01-06 20:24:27.599313 (Thread-1): Got an exception: Database Error
  syntax error at or near ")"
  LINE 45: )
           ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near ")"
LINE 45: )
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near ")"
  LINE 45: )
           ^
2022-01-06 20:24:27.600273 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near ")"\n  LINE 45: )\n           ^', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near ")"\n  LINE 45: )\n           ^', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 20:24:27.937109 (Thread-682): handling poll request
2022-01-06 20:24:27.937592 (Thread-682): 20:24:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee41f4e50>]}
2022-01-06 20:24:27.938402 (Thread-682): sending response (<Response 14894 bytes [200 OK]>) to 10.0.24.171
2022-01-06 20:24:37.605789 (Thread-683): handling status request
2022-01-06 20:24:37.606171 (Thread-683): 20:24:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee42763a0>]}
2022-01-06 20:24:37.606715 (Thread-683): sending response (<Response 1569 bytes [200 OK]>) to 10.0.13.109
2022-01-06 20:24:37.939114 (Thread-684): handling run_sql request
2022-01-06 20:24:37.939462 (Thread-684): 20:24:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee42766a0>]}
2022-01-06 20:24:40.003902 (Thread-684): sending response (<Response 138 bytes [200 OK]>) to 10.0.31.30
2022-01-06 20:24:40.029090 (MainThread): 20:24:40  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ebda628a-1683-4eed-88af-3c9e6b0e972f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfb15012e0>]}
2022-01-06 20:24:40.029639 (MainThread): 20:24:40  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:24:40.030189 (Thread-1): 20:24:40  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:24:40.030316 (Thread-1): 20:24:40  Began compiling node rpc.jaffel_shop.request
2022-01-06 20:24:40.030404 (Thread-1): 20:24:40  Compiling rpc.jaffel_shop.request
2022-01-06 20:24:40.032890 (Thread-1): 20:24:40  finished collecting timing info
2022-01-06 20:24:40.033014 (Thread-1): 20:24:40  Began executing node rpc.jaffel_shop.request
2022-01-06 20:24:40.033107 (Thread-1): 20:24:40  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:24:40.033180 (Thread-1): 20:24:40  On rpc.jaffel_shop.request: 

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),



customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 20:24:40.033292 (Thread-1): 20:24:40  Opening a new connection, currently in state init
2022-01-06 20:24:40.033374 (Thread-1): 20:24:40  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:24:40.100033 (Thread-1): 20:24:40  SQL status: SELECT in 0.07 seconds
2022-01-06 20:24:40.103510 (Thread-1): 20:24:40  finished collecting timing info
2022-01-06 20:24:40.103647 (Thread-1): 20:24:40  On rpc.jaffel_shop.request: Close
2022-01-06 20:24:40.347678 (Thread-685): handling poll request
2022-01-06 20:24:40.348120 (Thread-685): 20:24:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee43876a0>]}
2022-01-06 20:24:40.349803 (Thread-685): sending response (<Response 16335 bytes [200 OK]>) to 10.0.23.128
2022-01-06 20:24:52.653640 (Thread-686): handling status request
2022-01-06 20:24:52.653989 (Thread-686): 20:24:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4387a30>]}
2022-01-06 20:24:52.679684 (Thread-686): sending response (<Response 1569 bytes [200 OK]>) to 10.0.14.28
2022-01-06 20:24:53.112836 (Thread-687): handling run_sql request
2022-01-06 20:24:53.113193 (Thread-687): 20:24:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee43876d0>]}
2022-01-06 20:24:55.164110 (Thread-687): sending response (<Response 138 bytes [200 OK]>) to 10.0.44.31
2022-01-06 20:24:55.189194 (MainThread): 20:24:55  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '247f5bd0-c481-42d2-afb0-542fd180de2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbae6c96ee0>]}
2022-01-06 20:24:55.189723 (MainThread): 20:24:55  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:24:55.190267 (Thread-1): 20:24:55  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:24:55.190394 (Thread-1): 20:24:55  Began compiling node rpc.jaffel_shop.request
2022-01-06 20:24:55.190482 (Thread-1): 20:24:55  Compiling rpc.jaffel_shop.request
2022-01-06 20:24:55.193154 (Thread-1): 20:24:55  finished collecting timing info
2022-01-06 20:24:55.193314 (Thread-1): 20:24:55  Began executing node rpc.jaffel_shop.request
2022-01-06 20:24:55.193414 (Thread-1): 20:24:55  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:24:55.193490 (Thread-1): 20:24:55  On rpc.jaffel_shop.request: 

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

amounts as (
    select * from "dev"."dbt_nobodozie"."stg_payments"

),

customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 20:24:55.193567 (Thread-1): 20:24:55  Opening a new connection, currently in state init
2022-01-06 20:24:55.193644 (Thread-1): 20:24:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:24:55.214980 (Thread-1): 20:24:55  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_payments" does not exist

2022-01-06 20:24:55.215132 (Thread-1): 20:24:55  finished collecting timing info
2022-01-06 20:24:55.215246 (Thread-1): 20:24:55  On rpc.jaffel_shop.request: Close
2022-01-06 20:24:55.215478 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_payments" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_payments" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_payments" does not exist
2022-01-06 20:24:55.216400 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_payments" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\namounts as (\n    select * from {{ ref(\'stg_payments\')}}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\namounts as (\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_payments" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\namounts as (\n    select * from {{ ref(\'stg_payments\')}}\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\namounts as (\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 20:24:55.534670 (Thread-688): handling poll request
2022-01-06 20:24:55.535093 (Thread-688): 20:24:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4276790>]}
2022-01-06 20:24:55.535920 (Thread-688): sending response (<Response 15308 bytes [200 OK]>) to 10.0.5.108
2022-01-06 20:50:35.869138 (Thread-689): handling status request
2022-01-06 20:50:35.871110 (Thread-689): 20:50:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee421a3d0>]}
2022-01-06 20:50:35.871642 (Thread-689): sending response (<Response 1569 bytes [200 OK]>) to 10.0.4.101
2022-01-06 20:50:36.283562 (Thread-690): handling run_sql request
2022-01-06 20:50:36.283908 (Thread-690): 20:50:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee421a6d0>]}
2022-01-06 20:50:38.331204 (Thread-690): sending response (<Response 138 bytes [200 OK]>) to 10.0.3.189
2022-01-06 20:50:38.359018 (MainThread): 20:50:38  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0b089277-10b5-4552-b08e-9473393ff713', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcb8935d30>]}
2022-01-06 20:50:38.359533 (MainThread): 20:50:38  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:50:38.360086 (Thread-1): 20:50:38  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:50:38.360217 (Thread-1): 20:50:38  Began compiling node rpc.jaffel_shop.request
2022-01-06 20:50:38.360306 (Thread-1): 20:50:38  Compiling rpc.jaffel_shop.request
2022-01-06 20:50:38.363079 (Thread-1): 20:50:38  finished collecting timing info
2022-01-06 20:50:38.363205 (Thread-1): 20:50:38  Began executing node rpc.jaffel_shop.request
2022-01-06 20:50:38.363300 (Thread-1): 20:50:38  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:50:38.363375 (Thread-1): 20:50:38  On rpc.jaffel_shop.request: 

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),

lifetime_value as (
    select 
        orders.customer_id as customer_id
        orders.order_id as order_id
        sum(payment.amount) total_value
    from orders 
    
    left join payments using (order_id)
    group by 1
),


customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
        lifetime_value.order_id
        lifetime_value.total_value
    from customers

    left join customer_orders using (customer_id)
    left join lifetime_value using (customer_id)
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 20:50:38.363451 (Thread-1): 20:50:38  Opening a new connection, currently in state init
2022-01-06 20:50:38.363529 (Thread-1): 20:50:38  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:50:38.384420 (Thread-1): 20:50:38  Postgres adapter: Postgres error: syntax error at or near "orders"
LINE 22:         orders.order_id as order_id
                 ^

2022-01-06 20:50:38.384573 (Thread-1): 20:50:38  finished collecting timing info
2022-01-06 20:50:38.384687 (Thread-1): 20:50:38  On rpc.jaffel_shop.request: Close
2022-01-06 20:50:38.384954 (Thread-1): Got an exception: Database Error
  syntax error at or near "orders"
  LINE 22:         orders.order_id as order_id
                   ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "orders"
LINE 22:         orders.order_id as order_id
                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "orders"
  LINE 22:         orders.order_id as order_id
                   ^
2022-01-06 20:50:38.385916 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "orders"\n  LINE 22:         orders.order_id as order_id\n                   ^', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\npayment as (\n\n    select * from {{ ref(\'stg_payments\')}}\n),\n\nlifetime_value as (\n    select \n        orders.customer_id as customer_id\n        orders.order_id as order_id\n        sum(payment.amount) total_value\n    from orders \n    \n    left join payments using (order_id)\n    group by 1\n),\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n        lifetime_value.order_id\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\nlifetime_value as (\n    select \n        orders.customer_id as customer_id\n        orders.order_id as order_id\n        sum(payment.amount) total_value\n    from orders \n    \n    left join payments using (order_id)\n    group by 1\n),\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n        lifetime_value.order_id\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "orders"\n  LINE 22:         orders.order_id as order_id\n                   ^', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\npayment as (\n\n    select * from {{ ref(\'stg_payments\')}}\n),\n\nlifetime_value as (\n    select \n        orders.customer_id as customer_id\n        orders.order_id as order_id\n        sum(payment.amount) total_value\n    from orders \n    \n    left join payments using (order_id)\n    group by 1\n),\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n        lifetime_value.order_id\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\nlifetime_value as (\n    select \n        orders.customer_id as customer_id\n        orders.order_id as order_id\n        sum(payment.amount) total_value\n    from orders \n    \n    left join payments using (order_id)\n    group by 1\n),\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n        lifetime_value.order_id\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 20:50:38.749940 (Thread-691): handling poll request
2022-01-06 20:50:38.750407 (Thread-691): 20:50:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4280070>]}
2022-01-06 20:50:38.751272 (Thread-691): sending response (<Response 18234 bytes [200 OK]>) to 10.0.31.5
2022-01-06 20:54:18.542433 (Thread-692): handling status request
2022-01-06 20:54:18.544300 (Thread-692): 20:54:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee421afd0>]}
2022-01-06 20:54:18.544843 (Thread-692): sending response (<Response 1569 bytes [200 OK]>) to 10.0.35.15
2022-01-06 20:54:18.912006 (Thread-693): handling run_sql request
2022-01-06 20:54:18.912308 (Thread-693): 20:54:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee419a880>]}
2022-01-06 20:54:21.015474 (Thread-693): sending response (<Response 138 bytes [200 OK]>) to 10.0.35.37
2022-01-06 20:54:21.043374 (MainThread): 20:54:21  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '39aa67d6-86eb-4fb5-a6eb-5bc8a503fdc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4c748e610>]}
2022-01-06 20:54:21.043894 (MainThread): 20:54:21  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:54:21.044482 (Thread-1): 20:54:21  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:54:21.044616 (Thread-1): 20:54:21  Began compiling node rpc.jaffel_shop.request
2022-01-06 20:54:21.044762 (Thread-1): 20:54:21  Compiling rpc.jaffel_shop.request
2022-01-06 20:54:21.047879 (Thread-1): 20:54:21  finished collecting timing info
2022-01-06 20:54:21.048041 (Thread-1): 20:54:21  Began executing node rpc.jaffel_shop.request
2022-01-06 20:54:21.048141 (Thread-1): 20:54:21  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:54:21.048234 (Thread-1): 20:54:21  On rpc.jaffel_shop.request: 

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),

lifetime_value as (

    select 
        orders.customer_id as customer_id,
        orders.order_id as order_id,
        sum(payment.amount) total_value

    from orders 
    
    left join payments using (order_id)
    group by 1
),


customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,
        lifetime_value.order_id,
        lifetime_value.total_value
    from customers

    left join customer_orders using (customer_id)
    left join lifetime_value using (customer_id)
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 20:54:21.048329 (Thread-1): 20:54:21  Opening a new connection, currently in state init
2022-01-06 20:54:21.048423 (Thread-1): 20:54:21  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:54:21.069780 (Thread-1): 20:54:21  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_payments" does not exist

2022-01-06 20:54:21.069951 (Thread-1): 20:54:21  finished collecting timing info
2022-01-06 20:54:21.070077 (Thread-1): 20:54:21  On rpc.jaffel_shop.request: Close
2022-01-06 20:54:21.070430 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_payments" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_payments" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_payments" does not exist
2022-01-06 20:54:21.071465 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_payments" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\npayment as (\n\n    select * from {{ ref(\'stg_payments\')}}\n),\n\nlifetime_value as (\n\n    select \n        orders.customer_id as customer_id,\n        orders.order_id as order_id,\n        sum(payment.amount) total_value\n\n    from orders \n    \n    left join payments using (order_id)\n    group by 1\n),\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        lifetime_value.order_id,\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\nlifetime_value as (\n\n    select \n        orders.customer_id as customer_id,\n        orders.order_id as order_id,\n        sum(payment.amount) total_value\n\n    from orders \n    \n    left join payments using (order_id)\n    group by 1\n),\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        lifetime_value.order_id,\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_payments" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\npayment as (\n\n    select * from {{ ref(\'stg_payments\')}}\n),\n\nlifetime_value as (\n\n    select \n        orders.customer_id as customer_id,\n        orders.order_id as order_id,\n        sum(payment.amount) total_value\n\n    from orders \n    \n    left join payments using (order_id)\n    group by 1\n),\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        lifetime_value.order_id,\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\nlifetime_value as (\n\n    select \n        orders.customer_id as customer_id,\n        orders.order_id as order_id,\n        sum(payment.amount) total_value\n\n    from orders \n    \n    left join payments using (order_id)\n    group by 1\n),\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        lifetime_value.order_id,\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 20:54:22.548389 (Thread-694): handling poll request
2022-01-06 20:54:22.548813 (Thread-694): 20:54:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee41a09d0>]}
2022-01-06 20:54:22.549686 (Thread-694): sending response (<Response 17955 bytes [200 OK]>) to 10.0.35.37
2022-01-06 20:54:32.154842 (Thread-695): 20:54:32  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 20:54:32.155059 (Thread-695): 20:54:32  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 20:54:32.160044 (Thread-695): 20:54:32  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee40daf40>]}
2022-01-06 20:54:32.641881 (Thread-696): handling status request
2022-01-06 20:54:32.642240 (Thread-696): 20:54:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4153940>]}
2022-01-06 20:54:32.642751 (Thread-696): sending response (<Response 1244 bytes [200 OK]>) to 10.0.4.101
2022-01-06 20:54:32.683020 (Thread-697): handling status request
2022-01-06 20:54:32.683293 (Thread-697): 20:54:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4153640>]}
2022-01-06 20:54:32.683706 (Thread-697): sending response (<Response 1244 bytes [200 OK]>) to 10.0.3.189
2022-01-06 20:54:35.431836 (Thread-698): handling status request
2022-01-06 20:54:35.432224 (Thread-698): 20:54:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee429d640>]}
2022-01-06 20:54:35.432708 (Thread-698): sending response (<Response 1244 bytes [200 OK]>) to 10.0.21.1
2022-01-06 20:54:35.610447 (Thread-699): handling status request
2022-01-06 20:54:35.610729 (Thread-699): 20:54:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4297790>]}
2022-01-06 20:54:35.611158 (Thread-699): sending response (<Response 1244 bytes [200 OK]>) to 10.0.21.1
2022-01-06 20:54:35.760134 (Thread-700): handling cli_args request
2022-01-06 20:54:35.760482 (Thread-700): 20:54:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee41533d0>]}
2022-01-06 20:54:37.794319 (Thread-700): sending response (<Response 138 bytes [200 OK]>) to 10.0.35.15
2022-01-06 20:54:37.887796 (MainThread): 20:54:37  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 20:54:37.888179 (MainThread): 20:54:37  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 20:54:37.893724 (MainThread): 20:54:37  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7fce47bd-1ff5-4f53-b79f-6a9d8acb5c37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f977b244f70>]}
2022-01-06 20:54:37.921454 (MainThread): 20:54:37  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7fce47bd-1ff5-4f53-b79f-6a9d8acb5c37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f977bab2700>]}
2022-01-06 20:54:37.921701 (MainThread): 20:54:37  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:54:37.922719 (MainThread): 20:54:37  
2022-01-06 20:54:37.922980 (MainThread): 20:54:37  Acquiring new redshift connection "master"
2022-01-06 20:54:37.923873 (ThreadPoolExecutor-0_0): 20:54:37  Acquiring new redshift connection "list_dev"
2022-01-06 20:54:37.933592 (ThreadPoolExecutor-0_0): 20:54:37  Using redshift connection "list_dev"
2022-01-06 20:54:37.933693 (ThreadPoolExecutor-0_0): 20:54:37  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 20:54:37.933778 (ThreadPoolExecutor-0_0): 20:54:37  Opening a new connection, currently in state init
2022-01-06 20:54:37.934020 (ThreadPoolExecutor-0_0): 20:54:37  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:54:37.956751 (ThreadPoolExecutor-0_0): 20:54:37  SQL status: SELECT in 0.02 seconds
2022-01-06 20:54:37.957812 (ThreadPoolExecutor-0_0): 20:54:37  On list_dev: Close
2022-01-06 20:54:37.958935 (ThreadPoolExecutor-1_0): 20:54:37  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 20:54:37.964909 (ThreadPoolExecutor-1_0): 20:54:37  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 20:54:37.965008 (ThreadPoolExecutor-1_0): 20:54:37  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 20:54:37.965087 (ThreadPoolExecutor-1_0): 20:54:37  Opening a new connection, currently in state closed
2022-01-06 20:54:37.965165 (ThreadPoolExecutor-1_0): 20:54:37  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:54:37.988385 (ThreadPoolExecutor-1_0): 20:54:37  SQL status: BEGIN in 0.02 seconds
2022-01-06 20:54:37.988495 (ThreadPoolExecutor-1_0): 20:54:37  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 20:54:37.988572 (ThreadPoolExecutor-1_0): 20:54:37  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 20:54:37.999706 (ThreadPoolExecutor-1_0): 20:54:37  SQL status: SELECT in 0.01 seconds
2022-01-06 20:54:38.000695 (ThreadPoolExecutor-1_0): 20:54:38  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 20:54:38.002497 (ThreadPoolExecutor-1_0): 20:54:38  On list_dev_dbt_nobodozie: Close
2022-01-06 20:54:38.006485 (MainThread): 20:54:38  Using redshift connection "master"
2022-01-06 20:54:38.006597 (MainThread): 20:54:38  On master: BEGIN
2022-01-06 20:54:38.006677 (MainThread): 20:54:38  Opening a new connection, currently in state init
2022-01-06 20:54:38.006755 (MainThread): 20:54:38  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:54:38.028589 (MainThread): 20:54:38  SQL status: BEGIN in 0.02 seconds
2022-01-06 20:54:38.028702 (MainThread): 20:54:38  Using redshift connection "master"
2022-01-06 20:54:38.028780 (MainThread): 20:54:38  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 20:54:38.056885 (MainThread): 20:54:38  SQL status: SELECT in 0.03 seconds
2022-01-06 20:54:38.057925 (MainThread): 20:54:38  On master: ROLLBACK
2022-01-06 20:54:38.059730 (MainThread): 20:54:38  Using redshift connection "master"
2022-01-06 20:54:38.059829 (MainThread): 20:54:38  On master: BEGIN
2022-01-06 20:54:38.063289 (MainThread): 20:54:38  SQL status: BEGIN in 0.0 seconds
2022-01-06 20:54:38.063393 (MainThread): 20:54:38  On master: COMMIT
2022-01-06 20:54:38.063466 (MainThread): 20:54:38  Using redshift connection "master"
2022-01-06 20:54:38.063534 (MainThread): 20:54:38  On master: COMMIT
2022-01-06 20:54:38.065513 (MainThread): 20:54:38  SQL status: COMMIT in 0.0 seconds
2022-01-06 20:54:38.065614 (MainThread): 20:54:38  On master: Close
2022-01-06 20:54:38.065958 (MainThread): 20:54:38  Concurrency: 4 threads (target='default')
2022-01-06 20:54:38.066065 (MainThread): 20:54:38  
2022-01-06 20:54:38.068182 (Thread-1): 20:54:38  Began running node model.jaffel_shop.fct_orders
2022-01-06 20:54:38.068420 (Thread-1): 20:54:38  1 of 5 START view model dbt_nobodozie.fct_orders................................ [RUN]
2022-01-06 20:54:38.068641 (Thread-1): 20:54:38  Acquiring new redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 20:54:38.068732 (Thread-1): 20:54:38  Began compiling node model.jaffel_shop.fct_orders
2022-01-06 20:54:38.068819 (Thread-1): 20:54:38  Compiling model.jaffel_shop.fct_orders
2022-01-06 20:54:38.069952 (Thread-1): 20:54:38  Writing injected SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 20:54:38.070179 (Thread-2): 20:54:38  Began running node model.jaffel_shop.stg_customers
2022-01-06 20:54:38.070412 (Thread-2): 20:54:38  2 of 5 START view model dbt_nobodozie.stg_customers............................. [RUN]
2022-01-06 20:54:38.070663 (Thread-2): 20:54:38  Acquiring new redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 20:54:38.070749 (Thread-2): 20:54:38  Began compiling node model.jaffel_shop.stg_customers
2022-01-06 20:54:38.070830 (Thread-2): 20:54:38  Compiling model.jaffel_shop.stg_customers
2022-01-06 20:54:38.071820 (Thread-2): 20:54:38  Writing injected SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 20:54:38.072115 (Thread-3): 20:54:38  Began running node model.jaffel_shop.stg_orders
2022-01-06 20:54:38.072341 (Thread-3): 20:54:38  3 of 5 START view model dbt_nobodozie.stg_orders................................ [RUN]
2022-01-06 20:54:38.072713 (Thread-3): 20:54:38  Acquiring new redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 20:54:38.072804 (Thread-3): 20:54:38  Began compiling node model.jaffel_shop.stg_orders
2022-01-06 20:54:38.072885 (Thread-3): 20:54:38  Compiling model.jaffel_shop.stg_orders
2022-01-06 20:54:38.073921 (Thread-3): 20:54:38  Writing injected SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 20:54:38.074181 (Thread-4): 20:54:38  Began running node model.jaffel_shop.stg_payments
2022-01-06 20:54:38.074414 (Thread-4): 20:54:38  4 of 5 START view model dbt_nobodozie.stg_payments.............................. [RUN]
2022-01-06 20:54:38.074667 (Thread-4): 20:54:38  Acquiring new redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 20:54:38.074752 (Thread-4): 20:54:38  Began compiling node model.jaffel_shop.stg_payments
2022-01-06 20:54:38.074835 (Thread-4): 20:54:38  Compiling model.jaffel_shop.stg_payments
2022-01-06 20:54:38.075904 (Thread-4): 20:54:38  Writing injected SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 20:54:38.109293 (Thread-1): 20:54:38  finished collecting timing info
2022-01-06 20:54:38.109432 (Thread-1): 20:54:38  Began executing node model.jaffel_shop.fct_orders
2022-01-06 20:54:38.126058 (Thread-4): 20:54:38  finished collecting timing info
2022-01-06 20:54:38.126201 (Thread-4): 20:54:38  Began executing node model.jaffel_shop.stg_payments
2022-01-06 20:54:38.133274 (Thread-4): 20:54:38  Writing runtime SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 20:54:38.134306 (Thread-1): 20:54:38  Writing runtime SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 20:54:38.139408 (Thread-3): 20:54:38  finished collecting timing info
2022-01-06 20:54:38.139550 (Thread-3): 20:54:38  Began executing node model.jaffel_shop.stg_orders
2022-01-06 20:54:38.141458 (Thread-3): 20:54:38  Writing runtime SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 20:54:38.141698 (Thread-2): 20:54:38  finished collecting timing info
2022-01-06 20:54:38.141827 (Thread-2): 20:54:38  Began executing node model.jaffel_shop.stg_customers
2022-01-06 20:54:38.143652 (Thread-2): 20:54:38  Writing runtime SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 20:54:38.178840 (Thread-4): 20:54:38  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 20:54:38.178952 (Thread-4): 20:54:38  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 20:54:38.179035 (Thread-4): 20:54:38  Opening a new connection, currently in state init
2022-01-06 20:54:38.179114 (Thread-4): 20:54:38  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:54:38.183691 (Thread-1): 20:54:38  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 20:54:38.183803 (Thread-1): 20:54:38  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 20:54:38.183885 (Thread-1): 20:54:38  Opening a new connection, currently in state closed
2022-01-06 20:54:38.183962 (Thread-1): 20:54:38  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:54:38.184205 (Thread-3): 20:54:38  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 20:54:38.184307 (Thread-3): 20:54:38  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 20:54:38.184386 (Thread-3): 20:54:38  Opening a new connection, currently in state init
2022-01-06 20:54:38.184462 (Thread-3): 20:54:38  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:54:38.190175 (Thread-701): handling poll request
2022-01-06 20:54:38.190539 (Thread-701): 20:54:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee40deb20>]}
2022-01-06 20:54:38.192077 (Thread-701): sending response (<Response 34736 bytes [200 OK]>) to 10.0.27.154
2022-01-06 20:54:38.190290 (Thread-2): 20:54:38  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 20:54:38.190399 (Thread-2): 20:54:38  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 20:54:38.190496 (Thread-2): 20:54:38  Opening a new connection, currently in state init
2022-01-06 20:54:38.190573 (Thread-2): 20:54:38  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:54:38.214363 (Thread-1): 20:54:38  SQL status: BEGIN in 0.03 seconds
2022-01-06 20:54:38.214473 (Thread-1): 20:54:38  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 20:54:38.214550 (Thread-1): 20:54:38  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */


  create view "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" as (
    with fct_orders as (

    select
        id as order_id,
        user_id as customer_id

    from jaffle_shop.orders
    Where status = 'completed'

)
select * from fct_orders
  ) ;

2022-01-06 20:54:38.224067 (Thread-1): 20:54:38  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 20:54:38.229123 (Thread-1): 20:54:38  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 20:54:38.229419 (Thread-3): 20:54:38  SQL status: BEGIN in 0.04 seconds
2022-01-06 20:54:38.229529 (Thread-3): 20:54:38  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 20:54:38.229606 (Thread-3): 20:54:38  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */


  create view "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" as (
    with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
  ) ;

2022-01-06 20:54:38.229763 (Thread-4): 20:54:38  SQL status: BEGIN in 0.05 seconds
2022-01-06 20:54:38.229874 (Thread-4): 20:54:38  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 20:54:38.229950 (Thread-4): 20:54:38  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */


  create view "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" as (
    with payment as (

    select
        id as payment_id,
        orderid as order_id,
        amount

    from stripe.payment

)
select * from payment
  ) ;

2022-01-06 20:54:38.230322 (Thread-1): 20:54:38  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
alter table "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" rename to "fct_orders"
2022-01-06 20:54:38.230511 (Thread-2): 20:54:38  SQL status: BEGIN in 0.04 seconds
2022-01-06 20:54:38.230619 (Thread-2): 20:54:38  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 20:54:38.230695 (Thread-2): 20:54:38  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */


  create view "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
  ) ;

2022-01-06 20:54:38.234724 (Thread-1): 20:54:38  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 20:54:38.241464 (Thread-1): 20:54:38  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 20:54:38.241565 (Thread-1): 20:54:38  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 20:54:38.241640 (Thread-1): 20:54:38  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 20:54:38.241792 (Thread-2): 20:54:38  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 20:54:38.243513 (Thread-2): 20:54:38  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 20:54:38.243610 (Thread-2): 20:54:38  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers" rename to "stg_customers__dbt_backup"
2022-01-06 20:54:38.243874 (Thread-4): 20:54:38  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 20:54:38.246382 (Thread-4): 20:54:38  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 20:54:38.246480 (Thread-4): 20:54:38  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" rename to "stg_payments"
2022-01-06 20:54:38.246636 (Thread-3): 20:54:38  SQL status: CREATE VIEW in 0.02 seconds
2022-01-06 20:54:38.248449 (Thread-3): 20:54:38  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 20:54:38.248547 (Thread-3): 20:54:38  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders" rename to "stg_orders__dbt_backup"
2022-01-06 20:54:38.249838 (Thread-2): 20:54:38  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 20:54:38.251594 (Thread-2): 20:54:38  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 20:54:38.251692 (Thread-2): 20:54:38  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" rename to "stg_customers"
2022-01-06 20:54:38.251901 (Thread-3): 20:54:38  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 20:54:38.253674 (Thread-3): 20:54:38  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 20:54:38.253772 (Thread-3): 20:54:38  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" rename to "stg_orders"
2022-01-06 20:54:38.253920 (Thread-4): 20:54:38  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 20:54:38.254839 (Thread-4): 20:54:38  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 20:54:38.254936 (Thread-4): 20:54:38  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 20:54:38.255010 (Thread-4): 20:54:38  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 20:54:38.255209 (Thread-2): 20:54:38  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 20:54:38.256120 (Thread-2): 20:54:38  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 20:54:38.256216 (Thread-2): 20:54:38  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 20:54:38.256289 (Thread-2): 20:54:38  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 20:54:38.258388 (Thread-3): 20:54:38  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 20:54:38.259315 (Thread-3): 20:54:38  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 20:54:38.259411 (Thread-3): 20:54:38  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 20:54:38.259484 (Thread-3): 20:54:38  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 20:54:38.300649 (Thread-1): 20:54:38  SQL status: COMMIT in 0.06 seconds
2022-01-06 20:54:38.300856 (Thread-1): 20:54:38  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 20:54:38.300937 (Thread-1): 20:54:38  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 20:54:38.301291 (Thread-4): 20:54:38  SQL status: COMMIT in 0.05 seconds
2022-01-06 20:54:38.303290 (Thread-2): 20:54:38  SQL status: COMMIT in 0.05 seconds
2022-01-06 20:54:38.303628 (Thread-3): 20:54:38  SQL status: COMMIT in 0.04 seconds
2022-01-06 20:54:38.304043 (Thread-1): 20:54:38  SQL status: BEGIN in 0.0 seconds
2022-01-06 20:54:38.307932 (Thread-1): 20:54:38  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 20:54:38.308028 (Thread-1): 20:54:38  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
drop view if exists "dev"."dbt_nobodozie"."fct_orders__dbt_backup" cascade
2022-01-06 20:54:38.309908 (Thread-1): 20:54:38  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 20:54:38.310581 (Thread-1): 20:54:38  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 20:54:38.310675 (Thread-1): 20:54:38  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 20:54:38.310749 (Thread-1): 20:54:38  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 20:54:38.335707 (Thread-1): 20:54:38  SQL status: COMMIT in 0.02 seconds
2022-01-06 20:54:38.335818 (Thread-1): 20:54:38  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 20:54:38.335892 (Thread-1): 20:54:38  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 20:54:38.337933 (Thread-1): 20:54:38  SQL status: BEGIN in 0.0 seconds
2022-01-06 20:54:38.338316 (Thread-1): 20:54:38  finished collecting timing info
2022-01-06 20:54:38.338437 (Thread-1): 20:54:38  On model.jaffel_shop.fct_orders: ROLLBACK
2022-01-06 20:54:38.338634 (Thread-4): 20:54:38  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 20:54:38.338740 (Thread-4): 20:54:38  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 20:54:38.341077 (Thread-1): 20:54:38  On model.jaffel_shop.fct_orders: Close
2022-01-06 20:54:38.341259 (Thread-4): 20:54:38  SQL status: BEGIN in 0.0 seconds
2022-01-06 20:54:38.342485 (Thread-4): 20:54:38  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 20:54:38.342582 (Thread-4): 20:54:38  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
drop view if exists "dev"."dbt_nobodozie"."stg_payments__dbt_backup" cascade
2022-01-06 20:54:38.342963 (Thread-1): 20:54:38  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fce47bd-1ff5-4f53-b79f-6a9d8acb5c37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f977a9d9e80>]}
2022-01-06 20:54:38.343257 (Thread-1): 20:54:38  1 of 5 OK created view model dbt_nobodozie.fct_orders........................... [CREATE VIEW in 0.27s]
2022-01-06 20:54:38.343366 (Thread-1): 20:54:38  Finished running node model.jaffel_shop.fct_orders
2022-01-06 20:54:38.345429 (Thread-4): 20:54:38  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 20:54:38.346051 (Thread-4): 20:54:38  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 20:54:38.346146 (Thread-4): 20:54:38  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 20:54:38.346222 (Thread-4): 20:54:38  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 20:54:38.374338 (Thread-4): 20:54:38  SQL status: COMMIT in 0.03 seconds
2022-01-06 20:54:38.374451 (Thread-4): 20:54:38  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 20:54:38.374525 (Thread-4): 20:54:38  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 20:54:38.376583 (Thread-4): 20:54:38  SQL status: BEGIN in 0.0 seconds
2022-01-06 20:54:38.376961 (Thread-4): 20:54:38  finished collecting timing info
2022-01-06 20:54:38.377079 (Thread-4): 20:54:38  On model.jaffel_shop.stg_payments: ROLLBACK
2022-01-06 20:54:38.377313 (Thread-2): 20:54:38  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 20:54:38.377425 (Thread-2): 20:54:38  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 20:54:38.379782 (Thread-4): 20:54:38  On model.jaffel_shop.stg_payments: Close
2022-01-06 20:54:38.379944 (Thread-2): 20:54:38  SQL status: BEGIN in 0.0 seconds
2022-01-06 20:54:38.381271 (Thread-2): 20:54:38  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 20:54:38.381377 (Thread-2): 20:54:38  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
drop view if exists "dev"."dbt_nobodozie"."stg_customers__dbt_backup" cascade
2022-01-06 20:54:38.381757 (Thread-4): 20:54:38  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fce47bd-1ff5-4f53-b79f-6a9d8acb5c37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9778170610>]}
2022-01-06 20:54:38.382045 (Thread-4): 20:54:38  4 of 5 OK created view model dbt_nobodozie.stg_payments......................... [CREATE VIEW in 0.31s]
2022-01-06 20:54:38.382150 (Thread-4): 20:54:38  Finished running node model.jaffel_shop.stg_payments
2022-01-06 20:54:38.388236 (Thread-2): 20:54:38  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 20:54:38.388863 (Thread-2): 20:54:38  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 20:54:38.388958 (Thread-2): 20:54:38  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 20:54:38.389032 (Thread-2): 20:54:38  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 20:54:38.419867 (Thread-2): 20:54:38  SQL status: COMMIT in 0.03 seconds
2022-01-06 20:54:38.419980 (Thread-2): 20:54:38  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 20:54:38.420054 (Thread-2): 20:54:38  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 20:54:38.422269 (Thread-2): 20:54:38  SQL status: BEGIN in 0.0 seconds
2022-01-06 20:54:38.422635 (Thread-2): 20:54:38  finished collecting timing info
2022-01-06 20:54:38.422751 (Thread-2): 20:54:38  On model.jaffel_shop.stg_customers: ROLLBACK
2022-01-06 20:54:38.422965 (Thread-3): 20:54:38  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 20:54:38.423074 (Thread-3): 20:54:38  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 20:54:38.425401 (Thread-3): 20:54:38  SQL status: BEGIN in 0.0 seconds
2022-01-06 20:54:38.426530 (Thread-3): 20:54:38  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 20:54:38.426631 (Thread-3): 20:54:38  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
drop view if exists "dev"."dbt_nobodozie"."stg_orders__dbt_backup" cascade
2022-01-06 20:54:38.426802 (Thread-2): 20:54:38  On model.jaffel_shop.stg_customers: Close
2022-01-06 20:54:38.427239 (Thread-2): 20:54:38  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fce47bd-1ff5-4f53-b79f-6a9d8acb5c37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f977812fa00>]}
2022-01-06 20:54:38.427523 (Thread-2): 20:54:38  2 of 5 OK created view model dbt_nobodozie.stg_customers........................ [CREATE VIEW in 0.36s]
2022-01-06 20:54:38.427629 (Thread-2): 20:54:38  Finished running node model.jaffel_shop.stg_customers
2022-01-06 20:54:38.431787 (Thread-3): 20:54:38  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 20:54:38.432410 (Thread-3): 20:54:38  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 20:54:38.432505 (Thread-3): 20:54:38  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 20:54:38.432579 (Thread-3): 20:54:38  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 20:54:38.463171 (Thread-3): 20:54:38  SQL status: COMMIT in 0.03 seconds
2022-01-06 20:54:38.463289 (Thread-3): 20:54:38  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 20:54:38.463364 (Thread-3): 20:54:38  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 20:54:38.465325 (Thread-3): 20:54:38  SQL status: BEGIN in 0.0 seconds
2022-01-06 20:54:38.465690 (Thread-3): 20:54:38  finished collecting timing info
2022-01-06 20:54:38.465807 (Thread-3): 20:54:38  On model.jaffel_shop.stg_orders: ROLLBACK
2022-01-06 20:54:38.467621 (Thread-3): 20:54:38  On model.jaffel_shop.stg_orders: Close
2022-01-06 20:54:38.467999 (Thread-3): 20:54:38  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fce47bd-1ff5-4f53-b79f-6a9d8acb5c37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f977819ce20>]}
2022-01-06 20:54:38.468267 (Thread-3): 20:54:38  3 of 5 OK created view model dbt_nobodozie.stg_orders........................... [CREATE VIEW in 0.40s]
2022-01-06 20:54:38.468369 (Thread-3): 20:54:38  Finished running node model.jaffel_shop.stg_orders
2022-01-06 20:54:38.469097 (Thread-1): 20:54:38  Began running node model.jaffel_shop.dim_customers
2022-01-06 20:54:38.469342 (Thread-1): 20:54:38  5 of 5 START view model dbt_nobodozie.dim_customers............................. [RUN]
2022-01-06 20:54:38.469560 (Thread-1): 20:54:38  Acquiring new redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 20:54:38.469649 (Thread-1): 20:54:38  Began compiling node model.jaffel_shop.dim_customers
2022-01-06 20:54:38.469730 (Thread-1): 20:54:38  Compiling model.jaffel_shop.dim_customers
2022-01-06 20:54:38.471966 (Thread-1): 20:54:38  Writing injected SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 20:54:38.483871 (Thread-1): 20:54:38  finished collecting timing info
2022-01-06 20:54:38.484001 (Thread-1): 20:54:38  Began executing node model.jaffel_shop.dim_customers
2022-01-06 20:54:38.485814 (Thread-1): 20:54:38  Writing runtime SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 20:54:38.496472 (Thread-1): 20:54:38  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 20:54:38.496579 (Thread-1): 20:54:38  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 20:54:38.496660 (Thread-1): 20:54:38  Opening a new connection, currently in state closed
2022-01-06 20:54:38.496737 (Thread-1): 20:54:38  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:54:38.513976 (Thread-1): 20:54:38  SQL status: BEGIN in 0.02 seconds
2022-01-06 20:54:38.514089 (Thread-1): 20:54:38  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 20:54:38.514165 (Thread-1): 20:54:38  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */


  create view "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" as (
    with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"


),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  ) ;

2022-01-06 20:54:38.521499 (Thread-1): 20:54:38  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 20:54:38.523226 (Thread-1): 20:54:38  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 20:54:38.523328 (Thread-1): 20:54:38  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 20:54:38.525573 (Thread-1): 20:54:38  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 20:54:38.526482 (Thread-1): 20:54:38  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 20:54:38.526577 (Thread-1): 20:54:38  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 20:54:38.526650 (Thread-1): 20:54:38  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 20:54:38.556601 (Thread-1): 20:54:38  SQL status: COMMIT in 0.03 seconds
2022-01-06 20:54:38.556805 (Thread-1): 20:54:38  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 20:54:38.556886 (Thread-1): 20:54:38  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 20:54:38.559036 (Thread-1): 20:54:38  SQL status: BEGIN in 0.0 seconds
2022-01-06 20:54:38.560238 (Thread-1): 20:54:38  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 20:54:38.560334 (Thread-1): 20:54:38  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
drop view if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 20:54:38.562218 (Thread-1): 20:54:38  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 20:54:38.562832 (Thread-1): 20:54:38  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 20:54:38.562927 (Thread-1): 20:54:38  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 20:54:38.563001 (Thread-1): 20:54:38  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 20:54:38.588204 (Thread-1): 20:54:38  SQL status: COMMIT in 0.03 seconds
2022-01-06 20:54:38.588315 (Thread-1): 20:54:38  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 20:54:38.588387 (Thread-1): 20:54:38  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 20:54:38.590386 (Thread-1): 20:54:38  SQL status: BEGIN in 0.0 seconds
2022-01-06 20:54:38.590736 (Thread-1): 20:54:38  finished collecting timing info
2022-01-06 20:54:38.590853 (Thread-1): 20:54:38  On model.jaffel_shop.dim_customers: ROLLBACK
2022-01-06 20:54:38.592579 (Thread-1): 20:54:38  On model.jaffel_shop.dim_customers: Close
2022-01-06 20:54:38.592963 (Thread-1): 20:54:38  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fce47bd-1ff5-4f53-b79f-6a9d8acb5c37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9778127ac0>]}
2022-01-06 20:54:38.593272 (Thread-1): 20:54:38  5 of 5 OK created view model dbt_nobodozie.dim_customers........................ [CREATE VIEW in 0.12s]
2022-01-06 20:54:38.593398 (Thread-1): 20:54:38  Finished running node model.jaffel_shop.dim_customers
2022-01-06 20:54:38.594645 (MainThread): 20:54:38  Acquiring new redshift connection "master"
2022-01-06 20:54:38.594781 (MainThread): 20:54:38  Using redshift connection "master"
2022-01-06 20:54:38.594859 (MainThread): 20:54:38  On master: BEGIN
2022-01-06 20:54:38.594935 (MainThread): 20:54:38  Opening a new connection, currently in state closed
2022-01-06 20:54:38.595010 (MainThread): 20:54:38  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:54:38.619510 (MainThread): 20:54:38  SQL status: BEGIN in 0.02 seconds
2022-01-06 20:54:38.619625 (MainThread): 20:54:38  On master: COMMIT
2022-01-06 20:54:38.619700 (MainThread): 20:54:38  Using redshift connection "master"
2022-01-06 20:54:38.619770 (MainThread): 20:54:38  On master: COMMIT
2022-01-06 20:54:38.621411 (MainThread): 20:54:38  SQL status: COMMIT in 0.0 seconds
2022-01-06 20:54:38.621516 (MainThread): 20:54:38  On master: Close
2022-01-06 20:54:38.621891 (MainThread): 20:54:38  
2022-01-06 20:54:38.622003 (MainThread): 20:54:38  Finished running 5 view models in 0.70s.
2022-01-06 20:54:38.622085 (MainThread): 20:54:38  Connection 'master' was properly closed.
2022-01-06 20:54:38.622152 (MainThread): 20:54:38  Connection 'model.jaffel_shop.dim_customers' was properly closed.
2022-01-06 20:54:38.622213 (MainThread): 20:54:38  Connection 'model.jaffel_shop.stg_customers' was properly closed.
2022-01-06 20:54:38.622273 (MainThread): 20:54:38  Connection 'model.jaffel_shop.stg_orders' was properly closed.
2022-01-06 20:54:38.622332 (MainThread): 20:54:38  Connection 'model.jaffel_shop.stg_payments' was properly closed.
2022-01-06 20:54:38.699737 (MainThread): 20:54:38  
2022-01-06 20:54:38.699882 (MainThread): 20:54:38  Completed successfully
2022-01-06 20:54:38.699980 (MainThread): 20:54:38  
2022-01-06 20:54:38.700066 (MainThread): 20:54:38  Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2022-01-06 20:54:39.599763 (Thread-702): handling poll request
2022-01-06 20:54:39.600181 (Thread-702): 20:54:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4088a00>]}
2022-01-06 20:54:39.603147 (Thread-702): sending response (<Response 86645 bytes [200 OK]>) to 10.0.27.154
2022-01-06 20:54:40.328130 (Thread-703): handling status request
2022-01-06 20:54:40.328525 (Thread-703): 20:54:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4098250>]}
2022-01-06 20:54:40.329032 (Thread-703): sending response (<Response 1244 bytes [200 OK]>) to 10.0.14.253
2022-01-06 20:54:40.357148 (Thread-704): handling status request
2022-01-06 20:54:40.358085 (Thread-704): 20:54:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4098640>]}
2022-01-06 20:54:40.358557 (Thread-704): sending response (<Response 1244 bytes [200 OK]>) to 10.0.38.43
2022-01-06 20:54:49.149490 (Thread-705): 20:54:49  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 20:54:49.149875 (Thread-705): 20:54:49  Partial parsing: updated file: jaffel_shop://models/marts/core/dim_customers.sql
2022-01-06 20:54:49.154894 (Thread-705): 20:54:49  1699: static parser successfully parsed marts/core/dim_customers.sql
2022-01-06 20:54:49.221440 (Thread-705): 20:54:49  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec47f6be0>]}
2022-01-06 20:54:49.867006 (Thread-706): handling status request
2022-01-06 20:54:49.867407 (Thread-706): 20:54:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec47cadc0>]}
2022-01-06 20:54:49.867887 (Thread-706): sending response (<Response 1575 bytes [200 OK]>) to 10.0.3.189
2022-01-06 20:54:50.082082 (Thread-707): handling status request
2022-01-06 20:54:50.082378 (Thread-707): 20:54:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec47ca9d0>]}
2022-01-06 20:54:50.082808 (Thread-707): sending response (<Response 1575 bytes [200 OK]>) to 10.0.35.37
2022-01-06 20:54:50.791237 (Thread-708): handling status request
2022-01-06 20:54:50.791616 (Thread-708): 20:54:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec47caa60>]}
2022-01-06 20:54:50.792147 (Thread-708): sending response (<Response 1575 bytes [200 OK]>) to 10.0.4.101
2022-01-06 20:54:51.186011 (Thread-709): handling run_sql request
2022-01-06 20:54:51.186346 (Thread-709): 20:54:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec47ca700>]}
2022-01-06 20:54:53.209330 (Thread-709): sending response (<Response 138 bytes [200 OK]>) to 10.0.38.43
2022-01-06 20:54:53.234434 (MainThread): 20:54:53  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'db24aec3-03c9-4650-980d-21c5b142ed19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f195e6b44f0>]}
2022-01-06 20:54:53.234931 (MainThread): 20:54:53  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:54:53.235479 (Thread-1): 20:54:53  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:54:53.235607 (Thread-1): 20:54:53  Began compiling node rpc.jaffel_shop.request
2022-01-06 20:54:53.235695 (Thread-1): 20:54:53  Compiling rpc.jaffel_shop.request
2022-01-06 20:54:53.238467 (Thread-1): 20:54:53  finished collecting timing info
2022-01-06 20:54:53.238593 (Thread-1): 20:54:53  Began executing node rpc.jaffel_shop.request
2022-01-06 20:54:53.238689 (Thread-1): 20:54:53  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:54:53.238764 (Thread-1): 20:54:53  On rpc.jaffel_shop.request: 

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),

lifetime_value as (

    select 
        orders.customer_id as customer_id,
        orders.order_id as order_id,
        sum(payment.amount) total_value

    from orders 
    
    left join payments using (order_id)
    group by 1
),


customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,
        lifetime_value.order_id,
        lifetime_value.total_value
    from customers

    left join customer_orders using (customer_id)
    left join lifetime_value using (customer_id)
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 20:54:53.238840 (Thread-1): 20:54:53  Opening a new connection, currently in state init
2022-01-06 20:54:53.238917 (Thread-1): 20:54:53  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:54:53.264086 (Thread-1): 20:54:53  Postgres adapter: Postgres error: relation "payments" does not exist

2022-01-06 20:54:53.264242 (Thread-1): 20:54:53  finished collecting timing info
2022-01-06 20:54:53.264358 (Thread-1): 20:54:53  On rpc.jaffel_shop.request: Close
2022-01-06 20:54:53.264628 (Thread-1): Got an exception: Database Error
  relation "payments" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "payments" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "payments" does not exist
2022-01-06 20:54:53.265601 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "payments" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\npayment as (\n\n    select * from {{ ref(\'stg_payments\')}}\n),\n\nlifetime_value as (\n\n    select \n        orders.customer_id as customer_id,\n        orders.order_id as order_id,\n        sum(payment.amount) total_value\n\n    from orders \n    \n    left join payments using (order_id)\n    group by 1\n),\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        lifetime_value.order_id,\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\nlifetime_value as (\n\n    select \n        orders.customer_id as customer_id,\n        orders.order_id as order_id,\n        sum(payment.amount) total_value\n\n    from orders \n    \n    left join payments using (order_id)\n    group by 1\n),\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        lifetime_value.order_id,\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "payments" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\npayment as (\n\n    select * from {{ ref(\'stg_payments\')}}\n),\n\nlifetime_value as (\n\n    select \n        orders.customer_id as customer_id,\n        orders.order_id as order_id,\n        sum(payment.amount) total_value\n\n    from orders \n    \n    left join payments using (order_id)\n    group by 1\n),\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        lifetime_value.order_id,\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\nlifetime_value as (\n\n    select \n        orders.customer_id as customer_id,\n        orders.order_id as order_id,\n        sum(payment.amount) total_value\n\n    from orders \n    \n    left join payments using (order_id)\n    group by 1\n),\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        lifetime_value.order_id,\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 20:54:53.620057 (Thread-710): handling poll request
2022-01-06 20:54:53.620507 (Thread-710): 20:54:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee40ab160>]}
2022-01-06 20:54:53.621416 (Thread-710): sending response (<Response 17829 bytes [200 OK]>) to 10.0.3.189
2022-01-06 20:55:28.464858 (Thread-711): 20:55:28  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 20:55:28.465273 (Thread-711): 20:55:28  Partial parsing: updated file: jaffel_shop://models/marts/core/dim_customers.sql
2022-01-06 20:55:28.469578 (Thread-711): 20:55:28  1699: static parser successfully parsed marts/core/dim_customers.sql
2022-01-06 20:55:28.517755 (Thread-711): 20:55:28  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4722eb0>]}
2022-01-06 20:55:29.013203 (Thread-712): handling status request
2022-01-06 20:55:29.013605 (Thread-712): 20:55:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec47d0130>]}
2022-01-06 20:55:29.014128 (Thread-712): sending response (<Response 1575 bytes [200 OK]>) to 10.0.35.15
2022-01-06 20:55:29.046664 (Thread-713): handling status request
2022-01-06 20:55:29.046910 (Thread-713): 20:55:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec47f4dc0>]}
2022-01-06 20:55:29.047290 (Thread-713): sending response (<Response 1575 bytes [200 OK]>) to 10.0.47.136
2022-01-06 20:55:29.977619 (Thread-714): handling status request
2022-01-06 20:55:29.977981 (Thread-714): 20:55:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec47f0eb0>]}
2022-01-06 20:55:29.978453 (Thread-714): sending response (<Response 1575 bytes [200 OK]>) to 10.0.35.37
2022-01-06 20:55:30.324422 (Thread-715): handling run_sql request
2022-01-06 20:55:30.324671 (Thread-715): 20:55:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec47f0910>]}
2022-01-06 20:55:32.356991 (Thread-715): sending response (<Response 138 bytes [200 OK]>) to 10.0.8.128
2022-01-06 20:55:32.382300 (MainThread): 20:55:32  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '35da4b19-adc1-4351-83fc-26ecf8ee8f54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56d14baee0>]}
2022-01-06 20:55:32.382794 (MainThread): 20:55:32  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:55:32.383339 (Thread-1): 20:55:32  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:55:32.383458 (Thread-1): 20:55:32  Began compiling node rpc.jaffel_shop.request
2022-01-06 20:55:32.383543 (Thread-1): 20:55:32  Compiling rpc.jaffel_shop.request
2022-01-06 20:55:32.386278 (Thread-1): 20:55:32  finished collecting timing info
2022-01-06 20:55:32.386398 (Thread-1): 20:55:32  Began executing node rpc.jaffel_shop.request
2022-01-06 20:55:32.386491 (Thread-1): 20:55:32  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:55:32.386564 (Thread-1): 20:55:32  On rpc.jaffel_shop.request: 

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),

lifetime_value as (

    select 
        orders.customer_id as customer_id,
        orders.order_id as order_id,
        sum(payment.amount) total_value

    from orders 
    
    left join payment using (order_id)
    group by 1
),


customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,
        lifetime_value.order_id,
        lifetime_value.total_value
    from customers

    left join customer_orders using (customer_id)
    left join lifetime_value using (customer_id)
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 20:55:32.386637 (Thread-1): 20:55:32  Opening a new connection, currently in state init
2022-01-06 20:55:32.386710 (Thread-1): 20:55:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:55:32.408447 (Thread-1): 20:55:32  Postgres adapter: Postgres error: column "orders.order_id" must appear in the GROUP BY clause or be used in an aggregate function

2022-01-06 20:55:32.408594 (Thread-1): 20:55:32  finished collecting timing info
2022-01-06 20:55:32.408704 (Thread-1): 20:55:32  On rpc.jaffel_shop.request: Close
2022-01-06 20:55:32.408925 (Thread-1): Got an exception: Database Error
  column "orders.order_id" must appear in the GROUP BY clause or be used in an aggregate function
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.GroupingError: column "orders.order_id" must appear in the GROUP BY clause or be used in an aggregate function


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  column "orders.order_id" must appear in the GROUP BY clause or be used in an aggregate function
2022-01-06 20:55:32.409887 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "orders.order_id" must appear in the GROUP BY clause or be used in an aggregate function', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\npayment as (\n\n    select * from {{ ref(\'stg_payments\')}}\n),\n\nlifetime_value as (\n\n    select \n        orders.customer_id as customer_id,\n        orders.order_id as order_id,\n        sum(payment.amount) total_value\n\n    from orders \n    \n    left join payment using (order_id)\n    group by 1\n),\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        lifetime_value.order_id,\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\nlifetime_value as (\n\n    select \n        orders.customer_id as customer_id,\n        orders.order_id as order_id,\n        sum(payment.amount) total_value\n\n    from orders \n    \n    left join payment using (order_id)\n    group by 1\n),\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        lifetime_value.order_id,\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "orders.order_id" must appear in the GROUP BY clause or be used in an aggregate function', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n\n    select * from {{ ref(\'stg_customers\')}}\n),\n\norders as (\n\n    select * from {{ ref(\'stg_orders\')}}\n\n),\n\npayment as (\n\n    select * from {{ ref(\'stg_payments\')}}\n),\n\nlifetime_value as (\n\n    select \n        orders.customer_id as customer_id,\n        orders.order_id as order_id,\n        sum(payment.amount) total_value\n\n    from orders \n    \n    left join payment using (order_id)\n    group by 1\n),\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        lifetime_value.order_id,\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\nlifetime_value as (\n\n    select \n        orders.customer_id as customer_id,\n        orders.order_id as order_id,\n        sum(payment.amount) total_value\n\n    from orders \n    \n    left join payment using (order_id)\n    group by 1\n),\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        lifetime_value.order_id,\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 20:55:32.765900 (Thread-716): handling poll request
2022-01-06 20:55:32.766346 (Thread-716): 20:55:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec471f730>]}
2022-01-06 20:55:32.790457 (Thread-716): sending response (<Response 18248 bytes [200 OK]>) to 10.0.44.8
2022-01-06 20:56:15.740201 (Thread-717): handling status request
2022-01-06 20:56:15.740587 (Thread-717): 20:56:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec471fac0>]}
2022-01-06 20:56:15.741115 (Thread-717): sending response (<Response 1575 bytes [200 OK]>) to 10.0.44.8
2022-01-06 20:56:16.116819 (Thread-718): handling run_sql request
2022-01-06 20:56:16.117179 (Thread-718): 20:56:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec47e32b0>]}
2022-01-06 20:56:18.149592 (Thread-718): sending response (<Response 138 bytes [200 OK]>) to 10.0.4.104
2022-01-06 20:56:18.174870 (MainThread): 20:56:18  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '14513129-29fa-4c59-b6f2-20342a058e48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37ac473f10>]}
2022-01-06 20:56:18.175377 (MainThread): 20:56:18  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 20:56:18.175926 (Thread-1): 20:56:18  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:56:18.176053 (Thread-1): 20:56:18  Began compiling node rpc.jaffel_shop.request
2022-01-06 20:56:18.176138 (Thread-1): 20:56:18  Compiling rpc.jaffel_shop.request
2022-01-06 20:56:18.178898 (Thread-1): 20:56:18  finished collecting timing info
2022-01-06 20:56:18.179023 (Thread-1): 20:56:18  Began executing node rpc.jaffel_shop.request
2022-01-06 20:56:18.179116 (Thread-1): 20:56:18  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 20:56:18.179190 (Thread-1): 20:56:18  On rpc.jaffel_shop.request: 

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),

lifetime_value as (

    select 
        orders.customer_id as customer_id,
        orders.order_id as order_id,
        sum(payment.amount) total_value

    from orders 
    
    left join payment using (order_id)
    group by 1,2
),


customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,
        lifetime_value.order_id,
        lifetime_value.total_value
    from customers

    left join customer_orders using (customer_id)
    left join lifetime_value using (customer_id)
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 20:56:18.179267 (Thread-1): 20:56:18  Opening a new connection, currently in state init
2022-01-06 20:56:18.179342 (Thread-1): 20:56:18  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 20:56:18.508472 (Thread-719): handling poll request
2022-01-06 20:56:18.508863 (Thread-719): 20:56:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4719700>]}
2022-01-06 20:56:18.509799 (Thread-719): sending response (<Response 5296 bytes [200 OK]>) to 10.0.47.136
2022-01-06 20:56:19.931020 (Thread-720): handling poll request
2022-01-06 20:56:19.931396 (Thread-720): 20:56:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4153b50>]}
2022-01-06 20:56:19.931902 (Thread-720): sending response (<Response 397 bytes [200 OK]>) to 10.0.19.7
2022-01-06 20:56:21.261258 (Thread-721): handling poll request
2022-01-06 20:56:21.261633 (Thread-721): 20:56:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4722dc0>]}
2022-01-06 20:56:21.262119 (Thread-721): sending response (<Response 397 bytes [200 OK]>) to 10.0.21.1
2022-01-06 20:56:22.582267 (Thread-722): handling poll request
2022-01-06 20:56:22.582643 (Thread-722): 20:56:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec47e3580>]}
2022-01-06 20:56:22.583133 (Thread-722): sending response (<Response 397 bytes [200 OK]>) to 10.0.3.189
2022-01-06 20:56:23.406231 (Thread-1): 20:56:23  SQL status: SELECT in 5.23 seconds
2022-01-06 20:56:23.411101 (Thread-1): 20:56:23  finished collecting timing info
2022-01-06 20:56:23.411271 (Thread-1): 20:56:23  On rpc.jaffel_shop.request: Close
2022-01-06 20:56:23.925520 (Thread-723): handling poll request
2022-01-06 20:56:23.925892 (Thread-723): 20:56:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4719400>]}
2022-01-06 20:56:23.927607 (Thread-723): sending response (<Response 17616 bytes [200 OK]>) to 10.0.11.87
2022-01-06 20:56:47.687493 (Thread-724): 20:56:47  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 20:56:47.687879 (Thread-724): 20:56:47  Partial parsing: updated file: jaffel_shop://models/marts/core/dim_customers.sql
2022-01-06 20:56:47.692228 (Thread-724): 20:56:47  1699: static parser successfully parsed marts/core/dim_customers.sql
2022-01-06 20:56:47.733195 (Thread-724): 20:56:47  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4655670>]}
2022-01-06 20:56:48.222008 (Thread-725): handling status request
2022-01-06 20:56:48.222412 (Thread-725): 20:56:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4730430>]}
2022-01-06 20:56:48.222931 (Thread-725): sending response (<Response 1575 bytes [200 OK]>) to 10.0.8.128
2022-01-06 20:56:48.238587 (Thread-726): handling status request
2022-01-06 20:56:48.238867 (Thread-726): 20:56:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec46ae9d0>]}
2022-01-06 20:56:48.239318 (Thread-726): sending response (<Response 1575 bytes [200 OK]>) to 10.0.3.189
2022-01-06 21:11:28.593485 (Thread-727): handling status request
2022-01-06 21:11:28.593846 (Thread-727): 21:11:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec46aeaf0>]}
2022-01-06 21:11:28.594305 (Thread-727): sending response (<Response 1575 bytes [200 OK]>) to 10.0.14.253
2022-01-06 21:11:28.617913 (Thread-728): handling ps request
2022-01-06 21:11:28.618556 (Thread-729): handling status request
2022-01-06 21:11:28.618879 (Thread-728): 21:11:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec46ae6d0>]}
2022-01-06 21:11:28.619156 (Thread-729): 21:11:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4690340>]}
2022-01-06 21:11:28.624712 (Thread-728): sending response (<Response 64584 bytes [200 OK]>) to 10.0.2.195
2022-01-06 21:11:28.625186 (Thread-729): sending response (<Response 1575 bytes [200 OK]>) to 10.0.3.189
2022-01-06 21:11:28.643535 (Thread-730): handling status request
2022-01-06 21:11:28.643774 (Thread-730): 21:11:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4703ca0>]}
2022-01-06 21:11:28.644128 (Thread-730): sending response (<Response 1575 bytes [200 OK]>) to 10.0.8.128
2022-01-06 21:11:30.096637 (Thread-731): handling poll request
2022-01-06 21:11:30.097008 (Thread-731): 21:11:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4703940>]}
2022-01-06 21:11:30.100592 (Thread-731): sending response (<Response 121097 bytes [200 OK]>) to 10.0.21.1
2022-01-06 21:11:30.718233 (Thread-732): handling status request
2022-01-06 21:11:30.718598 (Thread-732): 21:11:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4703580>]}
2022-01-06 21:11:30.719070 (Thread-732): sending response (<Response 1575 bytes [200 OK]>) to 10.0.19.7
2022-01-06 21:11:30.848537 (Thread-733): handling status request
2022-01-06 21:11:30.848874 (Thread-733): 21:11:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec46905b0>]}
2022-01-06 21:11:30.849377 (Thread-733): sending response (<Response 1575 bytes [200 OK]>) to 10.0.38.43
2022-01-06 21:11:41.868956 (Thread-734): 21:11:41  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 21:11:41.869368 (Thread-734): 21:11:41  Partial parsing: updated file: jaffel_shop://models/marts/core/fct_orders.sql
2022-01-06 21:11:41.873424 (Thread-734): 21:11:41  1699: static parser successfully parsed marts/core/fct_orders.sql
2022-01-06 21:11:41.917329 (Thread-734): 21:11:41  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec45dedc0>]}
2022-01-06 21:11:42.400308 (Thread-735): handling status request
2022-01-06 21:11:42.400675 (Thread-735): 21:11:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec46ae040>]}
2022-01-06 21:11:42.401158 (Thread-735): sending response (<Response 1569 bytes [200 OK]>) to 10.0.4.104
2022-01-06 21:11:42.539191 (Thread-736): handling status request
2022-01-06 21:11:42.539560 (Thread-736): 21:11:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4738250>]}
2022-01-06 21:11:42.540054 (Thread-736): sending response (<Response 1569 bytes [200 OK]>) to 10.0.44.8
2022-01-06 21:12:16.408023 (Thread-737): handling ps request
2022-01-06 21:12:16.408392 (Thread-737): 21:12:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec47388b0>]}
2022-01-06 21:12:16.412276 (Thread-737): sending response (<Response 64586 bytes [200 OK]>) to 10.0.45.208
2022-01-06 21:12:16.414041 (Thread-738): handling status request
2022-01-06 21:12:16.414330 (Thread-738): 21:12:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee42802b0>]}
2022-01-06 21:12:16.414748 (Thread-738): sending response (<Response 1569 bytes [200 OK]>) to 10.0.19.7
2022-01-06 21:12:16.430537 (Thread-739): handling status request
2022-01-06 21:12:16.430778 (Thread-739): 21:12:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec45b6f70>]}
2022-01-06 21:12:16.431145 (Thread-739): sending response (<Response 1569 bytes [200 OK]>) to 10.0.3.189
2022-01-06 21:12:16.514111 (Thread-740): handling status request
2022-01-06 21:12:16.514390 (Thread-740): 21:12:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec45b6bb0>]}
2022-01-06 21:12:16.514801 (Thread-740): sending response (<Response 1569 bytes [200 OK]>) to 10.0.3.189
2022-01-06 21:12:17.604067 (Thread-741): handling poll request
2022-01-06 21:12:17.604434 (Thread-741): 21:12:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec45b6a90>]}
2022-01-06 21:12:17.607953 (Thread-741): sending response (<Response 121097 bytes [200 OK]>) to 10.0.4.101
2022-01-06 21:12:18.303543 (Thread-742): handling status request
2022-01-06 21:12:18.303923 (Thread-742): 21:12:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4690e20>]}
2022-01-06 21:12:18.304420 (Thread-742): sending response (<Response 1569 bytes [200 OK]>) to 10.0.4.101
2022-01-06 21:12:18.376423 (Thread-743): handling status request
2022-01-06 21:12:18.376697 (Thread-743): 21:12:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec46ae3a0>]}
2022-01-06 21:12:18.377115 (Thread-743): sending response (<Response 1569 bytes [200 OK]>) to 10.0.44.8
2022-01-06 21:12:22.729204 (Thread-744): 21:12:22  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 21:12:22.729591 (Thread-744): 21:12:22  Partial parsing: updated file: jaffel_shop://models/marts/core/fct_orders.sql
2022-01-06 21:12:22.733415 (Thread-744): 21:12:22  1699: static parser successfully parsed marts/core/fct_orders.sql
2022-01-06 21:12:22.781126 (Thread-744): 21:12:22  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec45e05e0>]}
2022-01-06 21:12:23.257023 (Thread-745): handling status request
2022-01-06 21:12:23.257439 (Thread-745): 21:12:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec47d28b0>]}
2022-01-06 21:12:23.257928 (Thread-745): sending response (<Response 1569 bytes [200 OK]>) to 10.0.11.87
2022-01-06 21:12:23.302739 (Thread-746): handling status request
2022-01-06 21:12:23.302988 (Thread-746): 21:12:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee43878b0>]}
2022-01-06 21:12:23.324767 (Thread-746): sending response (<Response 1569 bytes [200 OK]>) to 10.0.44.8
2022-01-06 21:12:51.749720 (Thread-747): handling status request
2022-01-06 21:12:51.750195 (Thread-747): 21:12:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec47f43d0>]}
2022-01-06 21:12:51.750714 (Thread-747): sending response (<Response 1569 bytes [200 OK]>) to 10.0.3.189
2022-01-06 21:12:52.087517 (Thread-748): handling run_sql request
2022-01-06 21:12:52.087895 (Thread-748): 21:12:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4738460>]}
2022-01-06 21:12:54.145298 (Thread-748): sending response (<Response 138 bytes [200 OK]>) to 10.0.44.8
2022-01-06 21:12:54.170666 (MainThread): 21:12:54  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6f588354-6354-43e5-b6da-f4d661e2851d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2b553158b0>]}
2022-01-06 21:12:54.171190 (MainThread): 21:12:54  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 21:12:54.171745 (Thread-1): 21:12:54  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:12:54.171875 (Thread-1): 21:12:54  Began compiling node rpc.jaffel_shop.request
2022-01-06 21:12:54.171977 (Thread-1): 21:12:54  Compiling rpc.jaffel_shop.request
2022-01-06 21:12:54.174269 (Thread-1): 21:12:54  finished collecting timing info
2022-01-06 21:12:54.174398 (Thread-1): 21:12:54  Began executing node rpc.jaffel_shop.request
2022-01-06 21:12:54.174495 (Thread-1): 21:12:54  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:12:54.174568 (Thread-1): 21:12:54  On rpc.jaffel_shop.request: orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),

order_payments as (
    select
    order_id,
    sum(case when status =' success' then amount end ) as amount
    from payment
    group by 1
),

 


final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as number_of_orders,

    from orders

    left join order_payments using (order_id)
   
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 21:12:54.174644 (Thread-1): 21:12:54  Opening a new connection, currently in state init
2022-01-06 21:12:54.174722 (Thread-1): 21:12:54  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:12:54.194744 (Thread-1): 21:12:54  Postgres adapter: Postgres error: syntax error at or near "orders"
LINE 1: orders as (
        ^

2022-01-06 21:12:54.194903 (Thread-1): 21:12:54  finished collecting timing info
2022-01-06 21:12:54.195019 (Thread-1): 21:12:54  On rpc.jaffel_shop.request: Close
2022-01-06 21:12:54.195189 (Thread-1): Got an exception: Database Error
  syntax error at or near "orders"
  LINE 1: orders as (
          ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "orders"
LINE 1: orders as (
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "orders"
  LINE 1: orders as (
          ^
2022-01-06 21:12:54.196275 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "orders"\n  LINE 1: orders as (\n          ^', 'raw_sql': "orders as (\n\n    select * from {{ ref('stg_orders')}}\n\n),\n\npayment as (\n\n    select * from {{ ref('stg_payments')}}\n),\n\norder_payments as (\n    select\n    order_id,\n    sum(case when status =' success' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as number_of_orders,\n\n    from orders\n\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'orders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\norder_payments as (\n    select\n    order_id,\n    sum(case when status =\' success\' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as number_of_orders,\n\n    from orders\n\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "orders"\n  LINE 1: orders as (\n          ^', 'raw_sql': "orders as (\n\n    select * from {{ ref('stg_orders')}}\n\n),\n\npayment as (\n\n    select * from {{ ref('stg_payments')}}\n),\n\norder_payments as (\n    select\n    order_id,\n    sum(case when status =' success' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as number_of_orders,\n\n    from orders\n\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'orders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\norder_payments as (\n    select\n    order_id,\n    sum(case when status =\' success\' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as number_of_orders,\n\n    from orders\n\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 21:12:54.629941 (Thread-749): handling poll request
2022-01-06 21:12:54.630407 (Thread-749): 21:12:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4655940>]}
2022-01-06 21:12:54.631297 (Thread-749): sending response (<Response 13199 bytes [200 OK]>) to 10.0.31.115
2022-01-06 21:13:30.844580 (Thread-750): handling status request
2022-01-06 21:13:30.844955 (Thread-750): 21:13:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec45ae0d0>]}
2022-01-06 21:13:30.845535 (Thread-750): sending response (<Response 1569 bytes [200 OK]>) to 10.0.21.1
2022-01-06 21:13:31.281283 (Thread-751): handling run_sql request
2022-01-06 21:13:31.281667 (Thread-751): 21:13:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec45ae100>]}
2022-01-06 21:13:33.358201 (Thread-751): sending response (<Response 138 bytes [200 OK]>) to 10.0.44.8
2022-01-06 21:13:33.385390 (MainThread): 21:13:33  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '73664f46-a5db-40b6-8684-ad16cd3b8dc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ba8f716d0>]}
2022-01-06 21:13:33.385926 (MainThread): 21:13:33  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 21:13:33.386495 (Thread-1): 21:13:33  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:13:33.386633 (Thread-1): 21:13:33  Began compiling node rpc.jaffel_shop.request
2022-01-06 21:13:33.386725 (Thread-1): 21:13:33  Compiling rpc.jaffel_shop.request
2022-01-06 21:13:33.388984 (Thread-1): 21:13:33  finished collecting timing info
2022-01-06 21:13:33.389112 (Thread-1): 21:13:33  Began executing node rpc.jaffel_shop.request
2022-01-06 21:13:33.389209 (Thread-1): 21:13:33  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:13:33.389326 (Thread-1): 21:13:33  On rpc.jaffel_shop.request: with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),

order_payments as (
    select
    order_id,
    sum(case when status =' success' then amount end ) as amount
    from payment
    group by 1
),

 


final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as number_of_orders,

    from orders

    left join order_payments using (order_id)
   
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 21:13:33.389405 (Thread-1): 21:13:33  Opening a new connection, currently in state init
2022-01-06 21:13:33.389492 (Thread-1): 21:13:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:13:33.409969 (Thread-1): 21:13:33  Postgres adapter: Postgres error: syntax error at or near "from"
LINE 31:     from orders
             ^

2022-01-06 21:13:33.410163 (Thread-1): 21:13:33  finished collecting timing info
2022-01-06 21:13:33.410300 (Thread-1): 21:13:33  On rpc.jaffel_shop.request: Close
2022-01-06 21:13:33.410572 (Thread-1): Got an exception: Database Error
  syntax error at or near "from"
  LINE 31:     from orders
               ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "from"
LINE 31:     from orders
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "from"
  LINE 31:     from orders
               ^
2022-01-06 21:13:33.411558 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "from"\n  LINE 31:     from orders\n               ^', 'raw_sql': "with orders as (\n\n    select * from {{ ref('stg_orders')}}\n\n),\n\npayment as (\n\n    select * from {{ ref('stg_payments')}}\n),\n\norder_payments as (\n    select\n    order_id,\n    sum(case when status =' success' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as number_of_orders,\n\n    from orders\n\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with orders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\norder_payments as (\n    select\n    order_id,\n    sum(case when status =\' success\' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as number_of_orders,\n\n    from orders\n\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "from"\n  LINE 31:     from orders\n               ^', 'raw_sql': "with orders as (\n\n    select * from {{ ref('stg_orders')}}\n\n),\n\npayment as (\n\n    select * from {{ ref('stg_payments')}}\n),\n\norder_payments as (\n    select\n    order_id,\n    sum(case when status =' success' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as number_of_orders,\n\n    from orders\n\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with orders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\norder_payments as (\n    select\n    order_id,\n    sum(case when status =\' success\' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as number_of_orders,\n\n    from orders\n\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 21:13:33.690629 (Thread-752): handling poll request
2022-01-06 21:13:33.691193 (Thread-752): 21:13:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec45b25e0>]}
2022-01-06 21:13:33.692348 (Thread-752): sending response (<Response 13290 bytes [200 OK]>) to 10.0.14.253
2022-01-06 21:14:12.876032 (Thread-753): handling status request
2022-01-06 21:14:12.876404 (Thread-753): 21:14:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec45b2100>]}
2022-01-06 21:14:12.876943 (Thread-753): sending response (<Response 1569 bytes [200 OK]>) to 10.0.3.189
2022-01-06 21:14:13.239449 (Thread-754): handling run_sql request
2022-01-06 21:14:13.239828 (Thread-754): 21:14:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec45ae370>]}
2022-01-06 21:14:15.288108 (Thread-754): sending response (<Response 138 bytes [200 OK]>) to 10.0.47.136
2022-01-06 21:14:15.312560 (MainThread): 21:14:15  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6e7b3dcc-c076-4ce2-996e-690b14f76f7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8fa2ae9a0>]}
2022-01-06 21:14:15.313076 (MainThread): 21:14:15  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 21:14:15.313642 (Thread-1): 21:14:15  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:14:15.313767 (Thread-1): 21:14:15  Began compiling node rpc.jaffel_shop.request
2022-01-06 21:14:15.313852 (Thread-1): 21:14:15  Compiling rpc.jaffel_shop.request
2022-01-06 21:14:15.316055 (Thread-1): 21:14:15  finished collecting timing info
2022-01-06 21:14:15.316179 (Thread-1): 21:14:15  Began executing node rpc.jaffel_shop.request
2022-01-06 21:14:15.316270 (Thread-1): 21:14:15  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:14:15.316342 (Thread-1): 21:14:15  On rpc.jaffel_shop.request: with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),

order_payments as (
    select
    order_id,
    sum(case when status =' success' then amount end ) as amount
    from payment
    group by 1
),

 


final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 21:14:15.316416 (Thread-1): 21:14:15  Opening a new connection, currently in state init
2022-01-06 21:14:15.316488 (Thread-1): 21:14:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:14:15.337098 (Thread-1): 21:14:15  Postgres adapter: Postgres error: column "status" does not exist in payment

2022-01-06 21:14:15.337269 (Thread-1): 21:14:15  finished collecting timing info
2022-01-06 21:14:15.337383 (Thread-1): 21:14:15  On rpc.jaffel_shop.request: Close
2022-01-06 21:14:15.337607 (Thread-1): Got an exception: Database Error
  column "status" does not exist in payment
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "status" does not exist in payment


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  column "status" does not exist in payment
2022-01-06 21:14:15.338535 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "status" does not exist in payment', 'raw_sql': "with orders as (\n\n    select * from {{ ref('stg_orders')}}\n\n),\n\npayment as (\n\n    select * from {{ ref('stg_payments')}}\n),\n\norder_payments as (\n    select\n    order_id,\n    sum(case when status =' success' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with orders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\norder_payments as (\n    select\n    order_id,\n    sum(case when status =\' success\' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "status" does not exist in payment', 'raw_sql': "with orders as (\n\n    select * from {{ ref('stg_orders')}}\n\n),\n\npayment as (\n\n    select * from {{ ref('stg_payments')}}\n),\n\norder_payments as (\n    select\n    order_id,\n    sum(case when status =' success' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with orders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\norder_payments as (\n    select\n    order_id,\n    sum(case when status =\' success\' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 21:14:15.672404 (Thread-755): handling poll request
2022-01-06 21:14:15.672839 (Thread-755): 21:14:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec45d62e0>]}
2022-01-06 21:14:15.673742 (Thread-755): sending response (<Response 12958 bytes [200 OK]>) to 10.0.31.5
2022-01-06 21:14:41.507345 (Thread-756): 21:14:41  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 21:14:41.507745 (Thread-756): 21:14:41  Partial parsing: updated file: jaffel_shop://models/marts/core/fct_orders.sql
2022-01-06 21:14:41.513004 (Thread-756): 21:14:41  1699: static parser successfully parsed marts/core/fct_orders.sql
2022-01-06 21:14:41.555971 (Thread-756): 21:14:41  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec44c0f70>]}
2022-01-06 21:14:42.064075 (Thread-757): handling status request
2022-01-06 21:14:42.064458 (Thread-757): 21:14:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec44b3cd0>]}
2022-01-06 21:14:42.064973 (Thread-757): sending response (<Response 1569 bytes [200 OK]>) to 10.0.45.208
2022-01-06 21:14:42.157175 (Thread-758): handling status request
2022-01-06 21:14:42.157489 (Thread-758): 21:14:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec44b3af0>]}
2022-01-06 21:14:42.157894 (Thread-758): sending response (<Response 1569 bytes [200 OK]>) to 10.0.27.154
2022-01-06 21:15:31.265003 (Thread-759): handling status request
2022-01-06 21:15:31.265396 (Thread-759): 21:15:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec44b3130>]}
2022-01-06 21:15:31.265873 (Thread-759): sending response (<Response 1569 bytes [200 OK]>) to 10.0.35.15
2022-01-06 21:15:31.669426 (Thread-760): handling run_sql request
2022-01-06 21:15:31.669797 (Thread-760): 21:15:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec45d8610>]}
2022-01-06 21:15:33.729347 (Thread-760): sending response (<Response 138 bytes [200 OK]>) to 10.0.27.154
2022-01-06 21:15:33.754856 (MainThread): 21:15:33  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4d92463f-9b2d-4611-8d9c-b946b1e31892', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00e17c59d0>]}
2022-01-06 21:15:33.755397 (MainThread): 21:15:33  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 21:15:33.755964 (Thread-1): 21:15:33  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:15:33.756091 (Thread-1): 21:15:33  Began compiling node rpc.jaffel_shop.request
2022-01-06 21:15:33.756179 (Thread-1): 21:15:33  Compiling rpc.jaffel_shop.request
2022-01-06 21:15:33.758431 (Thread-1): 21:15:33  finished collecting timing info
2022-01-06 21:15:33.758555 (Thread-1): 21:15:33  Began executing node rpc.jaffel_shop.request
2022-01-06 21:15:33.758651 (Thread-1): 21:15:33  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:15:33.758727 (Thread-1): 21:15:33  On rpc.jaffel_shop.request: with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),


order_payments as (
    select
        order_id,
        sum(case when status =' success' then amount end ) as amount
    from payment
    group by 1
),

 


final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 21:15:33.758802 (Thread-1): 21:15:33  Opening a new connection, currently in state init
2022-01-06 21:15:33.758878 (Thread-1): 21:15:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:15:33.779772 (Thread-1): 21:15:33  Postgres adapter: Postgres error: column "status" does not exist in payment

2022-01-06 21:15:33.779941 (Thread-1): 21:15:33  finished collecting timing info
2022-01-06 21:15:33.780062 (Thread-1): 21:15:33  On rpc.jaffel_shop.request: Close
2022-01-06 21:15:33.780254 (Thread-1): Got an exception: Database Error
  column "status" does not exist in payment
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "status" does not exist in payment


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  column "status" does not exist in payment
2022-01-06 21:15:33.781415 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "status" does not exist in payment', 'raw_sql': "with orders as (\n\n    select * from {{ ref('stg_orders')}}\n\n),\n\npayment as (\n\n    select * from {{ ref('stg_payments')}}\n),\n\n\norder_payments as (\n    select\n        order_id,\n        sum(case when status =' success' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with orders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\n\norder_payments as (\n    select\n        order_id,\n        sum(case when status =\' success\' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "status" does not exist in payment', 'raw_sql': "with orders as (\n\n    select * from {{ ref('stg_orders')}}\n\n),\n\npayment as (\n\n    select * from {{ ref('stg_payments')}}\n),\n\n\norder_payments as (\n    select\n        order_id,\n        sum(case when status =' success' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with orders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\n\norder_payments as (\n    select\n        order_id,\n        sum(case when status =\' success\' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 21:15:34.133990 (Thread-761): handling poll request
2022-01-06 21:15:34.134440 (Thread-761): 21:15:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec45497f0>]}
2022-01-06 21:15:34.135360 (Thread-761): sending response (<Response 13032 bytes [200 OK]>) to 10.0.11.87
2022-01-06 21:15:55.655815 (Thread-762): handling status request
2022-01-06 21:15:55.656201 (Thread-762): 21:15:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec45371f0>]}
2022-01-06 21:15:55.656752 (Thread-762): sending response (<Response 1569 bytes [200 OK]>) to 10.0.4.101
2022-01-06 21:15:56.024490 (Thread-763): handling run_sql request
2022-01-06 21:15:56.024842 (Thread-763): 21:15:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4537730>]}
2022-01-06 21:15:58.072830 (Thread-763): sending response (<Response 138 bytes [200 OK]>) to 10.0.19.7
2022-01-06 21:15:58.099930 (MainThread): 21:15:58  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '535f4362-115c-40ca-8a36-924b32a849cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb6763a4c0>]}
2022-01-06 21:15:58.100459 (MainThread): 21:15:58  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 21:15:58.101008 (Thread-1): 21:15:58  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:15:58.101133 (Thread-1): 21:15:58  Began compiling node rpc.jaffel_shop.request
2022-01-06 21:15:58.101248 (Thread-1): 21:15:58  Compiling rpc.jaffel_shop.request
2022-01-06 21:15:58.103450 (Thread-1): 21:15:58  finished collecting timing info
2022-01-06 21:15:58.103574 (Thread-1): 21:15:58  Began executing node rpc.jaffel_shop.request
2022-01-06 21:15:58.103669 (Thread-1): 21:15:58  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:15:58.103742 (Thread-1): 21:15:58  On rpc.jaffel_shop.request: with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),


order_payments as (
    select
        order_id,
        sum(case when status = 'success' then amount end ) as amount
    from payment
    group by 1
),

 


final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 21:15:58.103817 (Thread-1): 21:15:58  Opening a new connection, currently in state init
2022-01-06 21:15:58.103894 (Thread-1): 21:15:58  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:15:58.124649 (Thread-1): 21:15:58  Postgres adapter: Postgres error: column "status" does not exist in payment

2022-01-06 21:15:58.124800 (Thread-1): 21:15:58  finished collecting timing info
2022-01-06 21:15:58.124913 (Thread-1): 21:15:58  On rpc.jaffel_shop.request: Close
2022-01-06 21:15:58.125155 (Thread-1): Got an exception: Database Error
  column "status" does not exist in payment
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "status" does not exist in payment


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  column "status" does not exist in payment
2022-01-06 21:15:58.126099 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "status" does not exist in payment', 'raw_sql': "with orders as (\n\n    select * from {{ ref('stg_orders')}}\n\n),\n\npayment as (\n\n    select * from {{ ref('stg_payments')}}\n),\n\n\norder_payments as (\n    select\n        order_id,\n        sum(case when status = 'success' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with orders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\n\norder_payments as (\n    select\n        order_id,\n        sum(case when status = \'success\' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "status" does not exist in payment', 'raw_sql': "with orders as (\n\n    select * from {{ ref('stg_orders')}}\n\n),\n\npayment as (\n\n    select * from {{ ref('stg_payments')}}\n),\n\n\norder_payments as (\n    select\n        order_id,\n        sum(case when status = 'success' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with orders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\n\norder_payments as (\n    select\n        order_id,\n        sum(case when status = \'success\' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 21:15:58.485331 (Thread-764): handling poll request
2022-01-06 21:15:58.485788 (Thread-764): 21:15:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec44de880>]}
2022-01-06 21:15:58.486649 (Thread-764): sending response (<Response 13032 bytes [200 OK]>) to 10.0.44.8
2022-01-06 21:16:50.915583 (Thread-765): handling status request
2022-01-06 21:16:50.915952 (Thread-765): 21:16:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec45b6070>]}
2022-01-06 21:16:50.916480 (Thread-765): sending response (<Response 1569 bytes [200 OK]>) to 10.0.4.104
2022-01-06 21:16:51.351846 (Thread-766): handling run_sql request
2022-01-06 21:16:51.352194 (Thread-766): 21:16:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4537ca0>]}
2022-01-06 21:16:53.246985 (Thread-767): 21:16:53  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 21:16:53.247487 (Thread-767): 21:16:53  Partial parsing: updated file: jaffel_shop://models/staging/stripe/stg_payments.sql
2022-01-06 21:16:53.252387 (Thread-767): 21:16:53  1699: static parser successfully parsed staging/stripe/stg_payments.sql
2022-01-06 21:16:53.293282 (Thread-767): 21:16:53  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4401fa0>]}
2022-01-06 21:16:53.424404 (Thread-766): sending response (<Response 138 bytes [200 OK]>) to 10.0.19.7
2022-01-06 21:16:53.449360 (MainThread): 21:16:53  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '79f3d1d9-fb82-4542-94c0-ba992e32156c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2faa29bc10>]}
2022-01-06 21:16:53.450075 (MainThread): 21:16:53  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 21:16:53.450690 (Thread-1): 21:16:53  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:16:53.450820 (Thread-1): 21:16:53  Began compiling node rpc.jaffel_shop.request
2022-01-06 21:16:53.450910 (Thread-1): 21:16:53  Compiling rpc.jaffel_shop.request
2022-01-06 21:16:53.452108 (Thread-1): 21:16:53  finished collecting timing info
2022-01-06 21:16:53.452237 (Thread-1): 21:16:53  Began executing node rpc.jaffel_shop.request
2022-01-06 21:16:53.452337 (Thread-1): 21:16:53  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:16:53.452420 (Thread-1): 21:16:53  On rpc.jaffel_shop.request: with payment as (

    select
        id as payment_id,
        orderid as order_id,
        amount,
        status

    from stripe.payment

)
select * from payment
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 21:16:53.452501 (Thread-1): 21:16:53  Opening a new connection, currently in state init
2022-01-06 21:16:53.452588 (Thread-1): 21:16:53  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:16:53.625000 (Thread-1): 21:16:53  SQL status: SELECT in 0.17 seconds
2022-01-06 21:16:53.627852 (Thread-1): 21:16:53  finished collecting timing info
2022-01-06 21:16:53.628024 (Thread-1): 21:16:53  On rpc.jaffel_shop.request: Close
2022-01-06 21:16:53.796673 (Thread-768): handling poll request
2022-01-06 21:16:53.797032 (Thread-768): 21:16:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec43f5610>]}
2022-01-06 21:16:53.798414 (Thread-768): sending response (<Response 11711 bytes [200 OK]>) to 10.0.31.115
2022-01-06 21:16:53.831289 (Thread-769): handling status request
2022-01-06 21:16:53.831553 (Thread-769): 21:16:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec43fe880>]}
2022-01-06 21:16:53.831975 (Thread-769): sending response (<Response 1581 bytes [200 OK]>) to 10.0.35.15
2022-01-06 21:16:53.921315 (Thread-770): handling status request
2022-01-06 21:16:53.921645 (Thread-770): 21:16:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4439610>]}
2022-01-06 21:16:53.922096 (Thread-770): sending response (<Response 1581 bytes [200 OK]>) to 10.0.31.115
2022-01-06 21:17:10.279795 (Thread-771): handling status request
2022-01-06 21:17:10.280171 (Thread-771): 21:17:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4627ca0>]}
2022-01-06 21:17:10.280664 (Thread-771): sending response (<Response 1581 bytes [200 OK]>) to 10.0.19.7
2022-01-06 21:17:10.691949 (Thread-772): handling run_sql request
2022-01-06 21:17:10.692226 (Thread-772): 21:17:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec44395b0>]}
2022-01-06 21:17:12.758355 (Thread-772): sending response (<Response 138 bytes [200 OK]>) to 10.0.35.37
2022-01-06 21:17:12.783289 (MainThread): 21:17:12  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b2c3d037-88e9-41fc-a4ee-4c2e095ef5d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e4e87f760>]}
2022-01-06 21:17:12.783796 (MainThread): 21:17:12  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 21:17:12.784343 (Thread-1): 21:17:12  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:17:12.784471 (Thread-1): 21:17:12  Began compiling node rpc.jaffel_shop.request
2022-01-06 21:17:12.784559 (Thread-1): 21:17:12  Compiling rpc.jaffel_shop.request
2022-01-06 21:17:12.786809 (Thread-1): 21:17:12  finished collecting timing info
2022-01-06 21:17:12.786933 (Thread-1): 21:17:12  Began executing node rpc.jaffel_shop.request
2022-01-06 21:17:12.787028 (Thread-1): 21:17:12  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:17:12.787101 (Thread-1): 21:17:12  On rpc.jaffel_shop.request: with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),


order_payments as (
    select
        order_id,
        sum(case when status = 'success' then amount end ) as amount
    from payment
    group by 1
),

 


final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 21:17:12.787176 (Thread-1): 21:17:12  Opening a new connection, currently in state init
2022-01-06 21:17:12.787251 (Thread-1): 21:17:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:17:12.807805 (Thread-1): 21:17:12  Postgres adapter: Postgres error: column "status" does not exist in payment

2022-01-06 21:17:12.807959 (Thread-1): 21:17:12  finished collecting timing info
2022-01-06 21:17:12.808073 (Thread-1): 21:17:12  On rpc.jaffel_shop.request: Close
2022-01-06 21:17:12.808297 (Thread-1): Got an exception: Database Error
  column "status" does not exist in payment
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "status" does not exist in payment


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  column "status" does not exist in payment
2022-01-06 21:17:12.809275 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "status" does not exist in payment', 'raw_sql': "with orders as (\n\n    select * from {{ ref('stg_orders')}}\n\n),\n\npayment as (\n\n    select * from {{ ref('stg_payments')}}\n),\n\n\norder_payments as (\n    select\n        order_id,\n        sum(case when status = 'success' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with orders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\n\norder_payments as (\n    select\n        order_id,\n        sum(case when status = \'success\' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "status" does not exist in payment', 'raw_sql': "with orders as (\n\n    select * from {{ ref('stg_orders')}}\n\n),\n\npayment as (\n\n    select * from {{ ref('stg_payments')}}\n),\n\n\norder_payments as (\n    select\n        order_id,\n        sum(case when status = 'success' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with orders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\n\norder_payments as (\n    select\n        order_id,\n        sum(case when status = \'success\' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 21:17:13.227977 (Thread-773): handling poll request
2022-01-06 21:17:13.228422 (Thread-773): 21:17:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec44174c0>]}
2022-01-06 21:17:13.229300 (Thread-773): sending response (<Response 13032 bytes [200 OK]>) to 10.0.38.43
2022-01-06 21:17:19.818444 (Thread-774): 21:17:19  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 21:17:19.818663 (Thread-774): 21:17:19  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 21:17:19.824000 (Thread-774): 21:17:19  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec436bdc0>]}
2022-01-06 21:17:20.749618 (Thread-775): handling status request
2022-01-06 21:17:20.749993 (Thread-775): 21:17:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec43832b0>]}
2022-01-06 21:17:20.750519 (Thread-775): sending response (<Response 1244 bytes [200 OK]>) to 10.0.11.87
2022-01-06 21:17:21.248038 (Thread-776): handling status request
2022-01-06 21:17:21.248492 (Thread-776): 21:17:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec43834c0>]}
2022-01-06 21:17:21.272341 (Thread-776): sending response (<Response 1244 bytes [200 OK]>) to 10.0.4.104
2022-01-06 21:17:36.223335 (Thread-777): 21:17:36  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 21:17:36.223730 (Thread-777): 21:17:36  Partial parsing: updated file: jaffel_shop://models/marts/core/fct_orders.sql
2022-01-06 21:17:36.228261 (Thread-777): 21:17:36  1699: static parser successfully parsed marts/core/fct_orders.sql
2022-01-06 21:17:36.288922 (Thread-777): 21:17:36  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec42d5dc0>]}
2022-01-06 21:17:36.862588 (Thread-778): handling status request
2022-01-06 21:17:36.862963 (Thread-778): 21:17:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec44ce9a0>]}
2022-01-06 21:17:36.863449 (Thread-778): sending response (<Response 1569 bytes [200 OK]>) to 10.0.3.189
2022-01-06 21:17:36.967690 (Thread-779): handling status request
2022-01-06 21:17:36.968020 (Thread-779): 21:17:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec44cedf0>]}
2022-01-06 21:17:36.968469 (Thread-779): sending response (<Response 1569 bytes [200 OK]>) to 10.0.47.136
2022-01-06 21:17:38.048149 (Thread-780): handling status request
2022-01-06 21:17:38.048526 (Thread-780): 21:17:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec43f93d0>]}
2022-01-06 21:17:38.049004 (Thread-780): sending response (<Response 1569 bytes [200 OK]>) to 10.0.8.128
2022-01-06 21:17:38.394541 (Thread-781): handling run_sql request
2022-01-06 21:17:38.394912 (Thread-781): 21:17:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec43f9490>]}
2022-01-06 21:17:40.474941 (Thread-781): sending response (<Response 138 bytes [200 OK]>) to 10.0.45.208
2022-01-06 21:17:40.500146 (MainThread): 21:17:40  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3365f7f7-cad7-446b-87e8-ca6b03daf5ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb1b02df7c0>]}
2022-01-06 21:17:40.500734 (MainThread): 21:17:40  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 21:17:40.501340 (Thread-1): 21:17:40  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:17:40.501471 (Thread-1): 21:17:40  Began compiling node rpc.jaffel_shop.request
2022-01-06 21:17:40.501562 (Thread-1): 21:17:40  Compiling rpc.jaffel_shop.request
2022-01-06 21:17:40.503830 (Thread-1): 21:17:40  finished collecting timing info
2022-01-06 21:17:40.503962 (Thread-1): 21:17:40  Began executing node rpc.jaffel_shop.request
2022-01-06 21:17:40.504063 (Thread-1): 21:17:40  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:17:40.504137 (Thread-1): 21:17:40  On rpc.jaffel_shop.request: with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),


order_payments as (
    select
        order_id,
        sum(case when status = 'success' then amount end ) as amount
    from payment
    group by 1
),

 


final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 21:17:40.504215 (Thread-1): 21:17:40  Opening a new connection, currently in state init
2022-01-06 21:17:40.504294 (Thread-1): 21:17:40  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:17:40.525154 (Thread-1): 21:17:40  Postgres adapter: Postgres error: column "status" does not exist in payment

2022-01-06 21:17:40.525349 (Thread-1): 21:17:40  finished collecting timing info
2022-01-06 21:17:40.525474 (Thread-1): 21:17:40  On rpc.jaffel_shop.request: Close
2022-01-06 21:17:40.525723 (Thread-1): Got an exception: Database Error
  column "status" does not exist in payment
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "status" does not exist in payment


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  column "status" does not exist in payment
2022-01-06 21:17:40.526727 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "status" does not exist in payment', 'raw_sql': "with orders as (\n\n    select * from {{ ref('stg_orders')}}\n\n),\n\npayment as (\n\n    select * from {{ ref('stg_payments')}}\n),\n\n\norder_payments as (\n    select\n        order_id,\n        sum(case when status = 'success' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with orders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\n\norder_payments as (\n    select\n        order_id,\n        sum(case when status = \'success\' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "status" does not exist in payment', 'raw_sql': "with orders as (\n\n    select * from {{ ref('stg_orders')}}\n\n),\n\npayment as (\n\n    select * from {{ ref('stg_payments')}}\n),\n\n\norder_payments as (\n    select\n        order_id,\n        sum(case when status = 'success' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with orders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n\n),\n\npayment as (\n\n    select * from "dev"."dbt_nobodozie"."stg_payments"\n),\n\n\norder_payments as (\n    select\n        order_id,\n        sum(case when status = \'success\' then amount end ) as amount\n    from payment\n    group by 1\n),\n\n \n\n\nfinal as (\n\n    select\n        orders.order_id as order_id,\n        orders.customer_id,\n        orders.order_date,\n        coalesce(order_payments.amount, 0) as amount\n\n    from orders\n    left join order_payments using (order_id)\n   \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 21:17:40.928158 (Thread-782): handling poll request
2022-01-06 21:17:40.928604 (Thread-782): 21:17:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec43feb80>]}
2022-01-06 21:17:40.929542 (Thread-782): sending response (<Response 13032 bytes [200 OK]>) to 10.0.27.154
2022-01-06 21:17:49.545790 (Thread-783): 21:17:49  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 21:17:49.545999 (Thread-783): 21:17:49  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 21:17:49.723650 (Thread-783): 21:17:49  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec42b7910>]}
2022-01-06 21:17:50.091288 (Thread-784): handling status request
2022-01-06 21:17:50.091654 (Thread-784): 21:17:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec45c39a0>]}
2022-01-06 21:17:50.092131 (Thread-784): sending response (<Response 1244 bytes [200 OK]>) to 10.0.8.128
2022-01-06 21:17:50.113015 (Thread-785): handling status request
2022-01-06 21:17:50.113294 (Thread-785): 21:17:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec43fa430>]}
2022-01-06 21:17:50.113666 (Thread-785): sending response (<Response 1244 bytes [200 OK]>) to 10.0.4.101
2022-01-06 21:17:52.494244 (Thread-786): handling status request
2022-01-06 21:17:52.494609 (Thread-786): 21:17:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec43fa7f0>]}
2022-01-06 21:17:52.495078 (Thread-786): sending response (<Response 1244 bytes [200 OK]>) to 10.0.4.101
2022-01-06 21:17:52.737885 (Thread-787): handling status request
2022-01-06 21:17:52.738249 (Thread-787): 21:17:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec42b3a60>]}
2022-01-06 21:17:52.738718 (Thread-787): sending response (<Response 1244 bytes [200 OK]>) to 10.0.38.43
2022-01-06 21:17:52.815354 (Thread-788): handling cli_args request
2022-01-06 21:17:52.815627 (Thread-788): 21:17:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec42b72e0>]}
2022-01-06 21:17:54.858958 (Thread-788): sending response (<Response 138 bytes [200 OK]>) to 10.0.4.104
2022-01-06 21:17:54.950409 (MainThread): 21:17:54  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 21:17:54.950801 (MainThread): 21:17:54  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 21:17:54.956350 (MainThread): 21:17:54  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ff6401e9-284a-4c57-af9d-cc31a6774ce2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc446d3ff70>]}
2022-01-06 21:17:54.984635 (MainThread): 21:17:54  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ff6401e9-284a-4c57-af9d-cc31a6774ce2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4475af700>]}
2022-01-06 21:17:54.984879 (MainThread): 21:17:54  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 21:17:54.985880 (MainThread): 21:17:54  
2022-01-06 21:17:54.986165 (MainThread): 21:17:54  Acquiring new redshift connection "master"
2022-01-06 21:17:54.987116 (ThreadPoolExecutor-0_0): 21:17:54  Acquiring new redshift connection "list_dev"
2022-01-06 21:17:54.996885 (ThreadPoolExecutor-0_0): 21:17:54  Using redshift connection "list_dev"
2022-01-06 21:17:54.996991 (ThreadPoolExecutor-0_0): 21:17:54  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 21:17:54.997260 (ThreadPoolExecutor-0_0): 21:17:54  Opening a new connection, currently in state init
2022-01-06 21:17:54.997354 (ThreadPoolExecutor-0_0): 21:17:54  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:17:55.018021 (ThreadPoolExecutor-0_0): 21:17:55  SQL status: SELECT in 0.02 seconds
2022-01-06 21:17:55.019123 (ThreadPoolExecutor-0_0): 21:17:55  On list_dev: Close
2022-01-06 21:17:55.020389 (ThreadPoolExecutor-1_0): 21:17:55  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 21:17:55.026672 (ThreadPoolExecutor-1_0): 21:17:55  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 21:17:55.026774 (ThreadPoolExecutor-1_0): 21:17:55  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 21:17:55.026855 (ThreadPoolExecutor-1_0): 21:17:55  Opening a new connection, currently in state closed
2022-01-06 21:17:55.026934 (ThreadPoolExecutor-1_0): 21:17:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:17:55.048185 (ThreadPoolExecutor-1_0): 21:17:55  SQL status: BEGIN in 0.02 seconds
2022-01-06 21:17:55.048339 (ThreadPoolExecutor-1_0): 21:17:55  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 21:17:55.048418 (ThreadPoolExecutor-1_0): 21:17:55  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 21:17:55.059622 (ThreadPoolExecutor-1_0): 21:17:55  SQL status: SELECT in 0.01 seconds
2022-01-06 21:17:55.061075 (ThreadPoolExecutor-1_0): 21:17:55  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 21:17:55.062961 (ThreadPoolExecutor-1_0): 21:17:55  On list_dev_dbt_nobodozie: Close
2022-01-06 21:17:55.067841 (MainThread): 21:17:55  Using redshift connection "master"
2022-01-06 21:17:55.067964 (MainThread): 21:17:55  On master: BEGIN
2022-01-06 21:17:55.068051 (MainThread): 21:17:55  Opening a new connection, currently in state init
2022-01-06 21:17:55.068132 (MainThread): 21:17:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:17:55.089781 (MainThread): 21:17:55  SQL status: BEGIN in 0.02 seconds
2022-01-06 21:17:55.089900 (MainThread): 21:17:55  Using redshift connection "master"
2022-01-06 21:17:55.089979 (MainThread): 21:17:55  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 21:17:55.118734 (MainThread): 21:17:55  SQL status: SELECT in 0.03 seconds
2022-01-06 21:17:55.119973 (MainThread): 21:17:55  On master: ROLLBACK
2022-01-06 21:17:55.121846 (MainThread): 21:17:55  Using redshift connection "master"
2022-01-06 21:17:55.121967 (MainThread): 21:17:55  On master: BEGIN
2022-01-06 21:17:55.125376 (MainThread): 21:17:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:17:55.125494 (MainThread): 21:17:55  On master: COMMIT
2022-01-06 21:17:55.125568 (MainThread): 21:17:55  Using redshift connection "master"
2022-01-06 21:17:55.125638 (MainThread): 21:17:55  On master: COMMIT
2022-01-06 21:17:55.127351 (MainThread): 21:17:55  SQL status: COMMIT in 0.0 seconds
2022-01-06 21:17:55.127485 (MainThread): 21:17:55  On master: Close
2022-01-06 21:17:55.127944 (MainThread): 21:17:55  Concurrency: 4 threads (target='default')
2022-01-06 21:17:55.128065 (MainThread): 21:17:55  
2022-01-06 21:17:55.130645 (Thread-1): 21:17:55  Began running node model.jaffel_shop.stg_customers
2022-01-06 21:17:55.130928 (Thread-1): 21:17:55  1 of 5 START view model dbt_nobodozie.stg_customers............................. [RUN]
2022-01-06 21:17:55.131193 (Thread-1): 21:17:55  Acquiring new redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:17:55.131289 (Thread-1): 21:17:55  Began compiling node model.jaffel_shop.stg_customers
2022-01-06 21:17:55.131381 (Thread-1): 21:17:55  Compiling model.jaffel_shop.stg_customers
2022-01-06 21:17:55.132663 (Thread-1): 21:17:55  Writing injected SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 21:17:55.132892 (Thread-2): 21:17:55  Began running node model.jaffel_shop.stg_orders
2022-01-06 21:17:55.133127 (Thread-2): 21:17:55  2 of 5 START view model dbt_nobodozie.stg_orders................................ [RUN]
2022-01-06 21:17:55.133426 (Thread-2): 21:17:55  Acquiring new redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:17:55.133516 (Thread-2): 21:17:55  Began compiling node model.jaffel_shop.stg_orders
2022-01-06 21:17:55.133595 (Thread-2): 21:17:55  Compiling model.jaffel_shop.stg_orders
2022-01-06 21:17:55.134727 (Thread-2): 21:17:55  Writing injected SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 21:17:55.135052 (Thread-3): 21:17:55  Began running node model.jaffel_shop.stg_payments
2022-01-06 21:17:55.135282 (Thread-3): 21:17:55  3 of 5 START view model dbt_nobodozie.stg_payments.............................. [RUN]
2022-01-06 21:17:55.135544 (Thread-3): 21:17:55  Acquiring new redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:17:55.135630 (Thread-3): 21:17:55  Began compiling node model.jaffel_shop.stg_payments
2022-01-06 21:17:55.135708 (Thread-3): 21:17:55  Compiling model.jaffel_shop.stg_payments
2022-01-06 21:17:55.136721 (Thread-3): 21:17:55  Writing injected SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 21:17:55.150299 (Thread-1): 21:17:55  finished collecting timing info
2022-01-06 21:17:55.150454 (Thread-1): 21:17:55  Began executing node model.jaffel_shop.stg_customers
2022-01-06 21:17:55.155566 (Thread-3): 21:17:55  finished collecting timing info
2022-01-06 21:17:55.155693 (Thread-3): 21:17:55  Began executing node model.jaffel_shop.stg_payments
2022-01-06 21:17:55.160646 (Thread-2): 21:17:55  finished collecting timing info
2022-01-06 21:17:55.160783 (Thread-2): 21:17:55  Began executing node model.jaffel_shop.stg_orders
2022-01-06 21:17:55.199152 (Thread-3): 21:17:55  Writing runtime SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 21:17:55.200127 (Thread-2): 21:17:55  Writing runtime SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 21:17:55.201295 (Thread-1): 21:17:55  Writing runtime SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 21:17:55.214680 (Thread-789): handling poll request
2022-01-06 21:17:55.215052 (Thread-789): 21:17:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec43a0100>]}
2022-01-06 21:17:55.216651 (Thread-789): sending response (<Response 27119 bytes [200 OK]>) to 10.0.21.1
2022-01-06 21:17:55.219420 (Thread-3): 21:17:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:17:55.219529 (Thread-3): 21:17:55  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 21:17:55.219616 (Thread-3): 21:17:55  Opening a new connection, currently in state init
2022-01-06 21:17:55.219697 (Thread-3): 21:17:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:17:55.219948 (Thread-2): 21:17:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:17:55.220046 (Thread-2): 21:17:55  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 21:17:55.220124 (Thread-2): 21:17:55  Opening a new connection, currently in state init
2022-01-06 21:17:55.220212 (Thread-2): 21:17:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:17:55.225308 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:17:55.225417 (Thread-1): 21:17:55  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 21:17:55.225498 (Thread-1): 21:17:55  Opening a new connection, currently in state closed
2022-01-06 21:17:55.225573 (Thread-1): 21:17:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:17:55.251995 (Thread-3): 21:17:55  SQL status: BEGIN in 0.03 seconds
2022-01-06 21:17:55.252107 (Thread-3): 21:17:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:17:55.252181 (Thread-3): 21:17:55  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */


  create view "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" as (
    with payment as (

    select
        id as payment_id,
        orderid as order_id,
        amount,
        status

    from stripe.payment

)
select * from payment
  ) ;

2022-01-06 21:17:55.253932 (Thread-2): 21:17:55  SQL status: BEGIN in 0.03 seconds
2022-01-06 21:17:55.254049 (Thread-2): 21:17:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:17:55.254126 (Thread-2): 21:17:55  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */


  create view "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" as (
    with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
  ) ;

2022-01-06 21:17:55.257931 (Thread-1): 21:17:55  SQL status: BEGIN in 0.03 seconds
2022-01-06 21:17:55.258045 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:17:55.258121 (Thread-1): 21:17:55  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */


  create view "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
  ) ;

2022-01-06 21:17:55.259675 (Thread-3): 21:17:55  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 21:17:55.264983 (Thread-1): 21:17:55  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 21:17:55.266886 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:17:55.266983 (Thread-1): 21:17:55  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers" rename to "stg_customers__dbt_backup"
2022-01-06 21:17:55.267392 (Thread-3): 21:17:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:17:55.267496 (Thread-3): 21:17:55  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments" rename to "stg_payments__dbt_backup"
2022-01-06 21:17:55.267648 (Thread-2): 21:17:55  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 21:17:55.270434 (Thread-2): 21:17:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:17:55.270535 (Thread-2): 21:17:55  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders" rename to "stg_orders__dbt_backup"
2022-01-06 21:17:55.270694 (Thread-1): 21:17:55  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:17:55.272385 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:17:55.272484 (Thread-1): 21:17:55  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" rename to "stg_customers"
2022-01-06 21:17:55.272668 (Thread-3): 21:17:55  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 21:17:55.274495 (Thread-3): 21:17:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:17:55.274593 (Thread-3): 21:17:55  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" rename to "stg_payments"
2022-01-06 21:17:55.274817 (Thread-2): 21:17:55  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:17:55.276635 (Thread-2): 21:17:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:17:55.276751 (Thread-2): 21:17:55  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" rename to "stg_orders"
2022-01-06 21:17:55.276942 (Thread-1): 21:17:55  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:17:55.282112 (Thread-3): 21:17:55  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 21:17:55.288920 (Thread-1): 21:17:55  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 21:17:55.289019 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:17:55.289092 (Thread-1): 21:17:55  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 21:17:55.289281 (Thread-2): 21:17:55  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 21:17:55.290238 (Thread-2): 21:17:55  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 21:17:55.290336 (Thread-2): 21:17:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:17:55.290409 (Thread-2): 21:17:55  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 21:17:55.290623 (Thread-3): 21:17:55  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 21:17:55.290729 (Thread-3): 21:17:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:17:55.290802 (Thread-3): 21:17:55  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 21:17:55.346956 (Thread-1): 21:17:55  SQL status: COMMIT in 0.06 seconds
2022-01-06 21:17:55.347179 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:17:55.347263 (Thread-1): 21:17:55  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 21:17:55.347485 (Thread-2): 21:17:55  SQL status: COMMIT in 0.06 seconds
2022-01-06 21:17:55.347893 (Thread-3): 21:17:55  SQL status: COMMIT in 0.06 seconds
2022-01-06 21:17:55.349397 (Thread-1): 21:17:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:17:55.353403 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:17:55.353501 (Thread-1): 21:17:55  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
drop view if exists "dev"."dbt_nobodozie"."stg_customers__dbt_backup" cascade
2022-01-06 21:17:55.358662 (Thread-1): 21:17:55  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 21:17:55.359270 (Thread-1): 21:17:55  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 21:17:55.359363 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:17:55.359435 (Thread-1): 21:17:55  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 21:17:55.386292 (Thread-1): 21:17:55  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:17:55.386408 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:17:55.386482 (Thread-1): 21:17:55  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 21:17:55.388648 (Thread-1): 21:17:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:17:55.389045 (Thread-1): 21:17:55  finished collecting timing info
2022-01-06 21:17:55.389174 (Thread-1): 21:17:55  On model.jaffel_shop.stg_customers: ROLLBACK
2022-01-06 21:17:55.389415 (Thread-2): 21:17:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:17:55.389535 (Thread-2): 21:17:55  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 21:17:55.391938 (Thread-2): 21:17:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:17:55.393069 (Thread-2): 21:17:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:17:55.393165 (Thread-2): 21:17:55  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
drop view if exists "dev"."dbt_nobodozie"."stg_orders__dbt_backup" cascade
2022-01-06 21:17:55.393339 (Thread-1): 21:17:55  On model.jaffel_shop.stg_customers: Close
2022-01-06 21:17:55.393854 (Thread-1): 21:17:55  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff6401e9-284a-4c57-af9d-cc31a6774ce2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc446cf62e0>]}
2022-01-06 21:17:55.394249 (Thread-1): 21:17:55  1 of 5 OK created view model dbt_nobodozie.stg_customers........................ [CREATE VIEW in 0.26s]
2022-01-06 21:17:55.394374 (Thread-1): 21:17:55  Finished running node model.jaffel_shop.stg_customers
2022-01-06 21:17:55.398948 (Thread-2): 21:17:55  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 21:17:55.399630 (Thread-2): 21:17:55  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 21:17:55.399724 (Thread-2): 21:17:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:17:55.399795 (Thread-2): 21:17:55  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 21:17:55.429729 (Thread-2): 21:17:55  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:17:55.429840 (Thread-2): 21:17:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:17:55.429911 (Thread-2): 21:17:55  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 21:17:55.431924 (Thread-2): 21:17:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:17:55.432340 (Thread-2): 21:17:55  finished collecting timing info
2022-01-06 21:17:55.432468 (Thread-2): 21:17:55  On model.jaffel_shop.stg_orders: ROLLBACK
2022-01-06 21:17:55.432673 (Thread-3): 21:17:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:17:55.432784 (Thread-3): 21:17:55  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 21:17:55.435233 (Thread-2): 21:17:55  On model.jaffel_shop.stg_orders: Close
2022-01-06 21:17:55.435392 (Thread-3): 21:17:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:17:55.436712 (Thread-3): 21:17:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:17:55.436808 (Thread-3): 21:17:55  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
drop view if exists "dev"."dbt_nobodozie"."stg_payments__dbt_backup" cascade
2022-01-06 21:17:55.437195 (Thread-2): 21:17:55  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff6401e9-284a-4c57-af9d-cc31a6774ce2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4464d6580>]}
2022-01-06 21:17:55.437524 (Thread-2): 21:17:55  2 of 5 OK created view model dbt_nobodozie.stg_orders........................... [CREATE VIEW in 0.30s]
2022-01-06 21:17:55.437631 (Thread-2): 21:17:55  Finished running node model.jaffel_shop.stg_orders
2022-01-06 21:17:55.441891 (Thread-3): 21:17:55  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 21:17:55.442524 (Thread-3): 21:17:55  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 21:17:55.442618 (Thread-3): 21:17:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:17:55.442692 (Thread-3): 21:17:55  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 21:17:55.472463 (Thread-3): 21:17:55  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:17:55.472576 (Thread-3): 21:17:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:17:55.472648 (Thread-3): 21:17:55  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 21:17:55.474694 (Thread-3): 21:17:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:17:55.475085 (Thread-3): 21:17:55  finished collecting timing info
2022-01-06 21:17:55.475207 (Thread-3): 21:17:55  On model.jaffel_shop.stg_payments: ROLLBACK
2022-01-06 21:17:55.476958 (Thread-3): 21:17:55  On model.jaffel_shop.stg_payments: Close
2022-01-06 21:17:55.477411 (Thread-3): 21:17:55  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff6401e9-284a-4c57-af9d-cc31a6774ce2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4464e1bb0>]}
2022-01-06 21:17:55.477709 (Thread-3): 21:17:55  3 of 5 OK created view model dbt_nobodozie.stg_payments......................... [CREATE VIEW in 0.34s]
2022-01-06 21:17:55.477816 (Thread-3): 21:17:55  Finished running node model.jaffel_shop.stg_payments
2022-01-06 21:17:55.478602 (Thread-4): 21:17:55  Began running node model.jaffel_shop.dim_customers
2022-01-06 21:17:55.478824 (Thread-4): 21:17:55  4 of 5 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 21:17:55.479071 (Thread-4): 21:17:55  Acquiring new redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:17:55.479161 (Thread-4): 21:17:55  Began compiling node model.jaffel_shop.dim_customers
2022-01-06 21:17:55.479246 (Thread-4): 21:17:55  Compiling model.jaffel_shop.dim_customers
2022-01-06 21:17:55.482080 (Thread-4): 21:17:55  Writing injected SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 21:17:55.482364 (Thread-1): 21:17:55  Began running node model.jaffel_shop.fct_orders
2022-01-06 21:17:55.482584 (Thread-1): 21:17:55  5 of 5 START view model dbt_nobodozie.fct_orders................................ [RUN]
2022-01-06 21:17:55.482808 (Thread-1): 21:17:55  Acquiring new redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:17:55.482895 (Thread-1): 21:17:55  Began compiling node model.jaffel_shop.fct_orders
2022-01-06 21:17:55.482975 (Thread-1): 21:17:55  Compiling model.jaffel_shop.fct_orders
2022-01-06 21:17:55.485094 (Thread-1): 21:17:55  Writing injected SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 21:17:55.500966 (Thread-4): 21:17:55  finished collecting timing info
2022-01-06 21:17:55.501098 (Thread-4): 21:17:55  Began executing node model.jaffel_shop.dim_customers
2022-01-06 21:17:55.506056 (Thread-1): 21:17:55  finished collecting timing info
2022-01-06 21:17:55.506183 (Thread-1): 21:17:55  Began executing node model.jaffel_shop.fct_orders
2022-01-06 21:17:55.507997 (Thread-1): 21:17:55  Writing runtime SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 21:17:55.529039 (Thread-4): 21:17:55  Writing runtime SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 21:17:55.536419 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:17:55.536529 (Thread-1): 21:17:55  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 21:17:55.536613 (Thread-1): 21:17:55  Opening a new connection, currently in state closed
2022-01-06 21:17:55.536694 (Thread-1): 21:17:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:17:55.545339 (Thread-4): 21:17:55  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:17:55.545447 (Thread-4): 21:17:55  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 21:17:55.545525 (Thread-4): 21:17:55  Opening a new connection, currently in state init
2022-01-06 21:17:55.545601 (Thread-4): 21:17:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:17:55.559079 (Thread-1): 21:17:55  SQL status: BEGIN in 0.02 seconds
2022-01-06 21:17:55.559193 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:17:55.559272 (Thread-1): 21:17:55  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */


  create view "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" as (
    with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),


order_payments as (
    select
        order_id,
        sum(case when status = 'success' then amount end ) as amount
    from payment
    group by 1
),

 


final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
  ) ;

2022-01-06 21:17:55.566641 (Thread-1): 21:17:55  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 21:17:55.568402 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:17:55.568497 (Thread-1): 21:17:55  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
alter table "dev"."dbt_nobodozie"."fct_orders" rename to "fct_orders__dbt_backup"
2022-01-06 21:17:55.570752 (Thread-1): 21:17:55  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:17:55.572550 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:17:55.572644 (Thread-1): 21:17:55  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
alter table "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" rename to "fct_orders"
2022-01-06 21:17:55.574820 (Thread-1): 21:17:55  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:17:55.575739 (Thread-1): 21:17:55  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 21:17:55.575834 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:17:55.575905 (Thread-1): 21:17:55  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 21:17:55.606008 (Thread-1): 21:17:55  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:17:55.606227 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:17:55.606311 (Thread-1): 21:17:55  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 21:17:55.608421 (Thread-1): 21:17:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:17:55.610771 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:17:55.610866 (Thread-1): 21:17:55  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
drop view if exists "dev"."dbt_nobodozie"."fct_orders__dbt_backup" cascade
2022-01-06 21:17:55.614574 (Thread-1): 21:17:55  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 21:17:55.615176 (Thread-1): 21:17:55  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 21:17:55.615268 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:17:55.615342 (Thread-1): 21:17:55  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 21:17:55.641773 (Thread-1): 21:17:55  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:17:55.641889 (Thread-1): 21:17:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:17:55.641963 (Thread-1): 21:17:55  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 21:17:55.643971 (Thread-1): 21:17:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:17:55.644330 (Thread-1): 21:17:55  finished collecting timing info
2022-01-06 21:17:55.644473 (Thread-1): 21:17:55  On model.jaffel_shop.fct_orders: ROLLBACK
2022-01-06 21:17:55.646178 (Thread-1): 21:17:55  On model.jaffel_shop.fct_orders: Close
2022-01-06 21:17:55.646612 (Thread-1): 21:17:55  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff6401e9-284a-4c57-af9d-cc31a6774ce2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4443cd4c0>]}
2022-01-06 21:17:55.646938 (Thread-1): 21:17:55  5 of 5 OK created view model dbt_nobodozie.fct_orders........................... [CREATE VIEW in 0.16s]
2022-01-06 21:17:55.647050 (Thread-1): 21:17:55  Finished running node model.jaffel_shop.fct_orders
2022-01-06 21:17:55.921613 (Thread-4): 21:17:55  SQL status: BEGIN in 0.38 seconds
2022-01-06 21:17:55.921857 (Thread-4): 21:17:55  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:17:55.921964 (Thread-4): 21:17:55  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),

lifetime_value as (

    select 
        orders.customer_id as customer_id,
        orders.order_id as order_id,
        sum(payment.amount) total_value

    from orders 
    
    left join payment using (order_id)
    group by 1,2
),


customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,
        lifetime_value.order_id,
        lifetime_value.total_value
    from customers

    left join customer_orders using (customer_id)
    left join lifetime_value using (customer_id)
)

select * from final
  );
2022-01-06 21:17:56.977816 (Thread-790): handling poll request
2022-01-06 21:17:56.978166 (Thread-790): 21:17:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec44d87c0>]}
2022-01-06 21:17:56.980647 (Thread-790): sending response (<Response 67596 bytes [200 OK]>) to 10.0.38.43
2022-01-06 21:17:58.335908 (Thread-791): handling poll request
2022-01-06 21:17:58.336284 (Thread-791): 21:17:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec44d8760>]}
2022-01-06 21:17:58.336776 (Thread-791): sending response (<Response 286 bytes [200 OK]>) to 10.0.45.208
2022-01-06 21:17:59.684770 (Thread-792): handling poll request
2022-01-06 21:17:59.685116 (Thread-792): 21:17:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4401ee0>]}
2022-01-06 21:17:59.685630 (Thread-792): sending response (<Response 286 bytes [200 OK]>) to 10.0.31.115
2022-01-06 21:18:01.058945 (Thread-793): handling poll request
2022-01-06 21:18:01.059299 (Thread-793): 21:18:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4401b50>]}
2022-01-06 21:18:01.059776 (Thread-793): sending response (<Response 286 bytes [200 OK]>) to 10.0.38.43
2022-01-06 21:18:02.186247 (Thread-794): 21:18:02  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 21:18:02.186481 (Thread-794): 21:18:02  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 21:18:02.191995 (Thread-794): 21:18:02  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec471fa30>]}
2022-01-06 21:18:02.486375 (Thread-795): handling poll request
2022-01-06 21:18:02.486735 (Thread-795): 21:18:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec465a8e0>]}
2022-01-06 21:18:02.487237 (Thread-795): sending response (<Response 286 bytes [200 OK]>) to 10.0.4.104
2022-01-06 21:18:02.762117 (Thread-796): handling status request
2022-01-06 21:18:02.762485 (Thread-796): 21:18:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec465a670>]}
2022-01-06 21:18:02.762990 (Thread-796): sending response (<Response 1244 bytes [200 OK]>) to 10.0.21.1
2022-01-06 21:18:02.904032 (Thread-797): handling status request
2022-01-06 21:18:02.904412 (Thread-797): 21:18:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec42b7d60>]}
2022-01-06 21:18:02.904879 (Thread-797): sending response (<Response 1244 bytes [200 OK]>) to 10.0.35.15
2022-01-06 21:18:03.840421 (Thread-798): handling poll request
2022-01-06 21:18:03.840796 (Thread-798): 21:18:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4371040>]}
2022-01-06 21:18:03.841316 (Thread-798): sending response (<Response 287 bytes [200 OK]>) to 10.0.4.104
2022-01-06 21:18:04.909784 (Thread-799): handling status request
2022-01-06 21:18:04.910160 (Thread-799): 21:18:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4371700>]}
2022-01-06 21:18:04.910670 (Thread-799): sending response (<Response 1244 bytes [200 OK]>) to 10.0.4.104
2022-01-06 21:18:05.218676 (Thread-800): handling poll request
2022-01-06 21:18:05.218949 (Thread-800): 21:18:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4371b80>]}
2022-01-06 21:18:05.219394 (Thread-800): sending response (<Response 287 bytes [200 OK]>) to 10.0.35.15
2022-01-06 21:18:05.311036 (Thread-801): handling run_sql request
2022-01-06 21:18:05.311289 (Thread-801): 21:18:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4371730>]}
2022-01-06 21:18:06.537626 (Thread-802): handling poll request
2022-01-06 21:18:06.538379 (Thread-802): 21:18:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec42c1d00>]}
2022-01-06 21:18:06.539283 (Thread-802): sending response (<Response 286 bytes [200 OK]>) to 10.0.4.101
2022-01-06 21:18:07.350471 (Thread-801): sending response (<Response 138 bytes [200 OK]>) to 10.0.19.7
2022-01-06 21:18:07.375240 (MainThread): 21:18:07  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '10c2358f-4d0d-43c2-a0ea-56fca283b347', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78519a70d0>]}
2022-01-06 21:18:07.375765 (MainThread): 21:18:07  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 21:18:07.376318 (Thread-1): 21:18:07  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:18:07.376449 (Thread-1): 21:18:07  Began compiling node rpc.jaffel_shop.request
2022-01-06 21:18:07.376537 (Thread-1): 21:18:07  Compiling rpc.jaffel_shop.request
2022-01-06 21:18:07.378781 (Thread-1): 21:18:07  finished collecting timing info
2022-01-06 21:18:07.378908 (Thread-1): 21:18:07  Began executing node rpc.jaffel_shop.request
2022-01-06 21:18:07.379005 (Thread-1): 21:18:07  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:18:07.379081 (Thread-1): 21:18:07  On rpc.jaffel_shop.request: with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),


order_payments as (
    select
        order_id,
        sum(case when status = 'success' then amount end ) as amount
    from payment
    group by 1
),

 


final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 21:18:07.379157 (Thread-1): 21:18:07  Opening a new connection, currently in state init
2022-01-06 21:18:07.379236 (Thread-1): 21:18:07  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:18:07.438956 (Thread-4): 21:18:07  SQL status: SELECT in 11.52 seconds
2022-01-06 21:18:07.441362 (Thread-4): 21:18:07  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:18:07.441481 (Thread-4): 21:18:07  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 21:18:07.444889 (Thread-4): 21:18:07  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:18:07.449678 (Thread-4): 21:18:07  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 21:18:07.449780 (Thread-4): 21:18:07  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:18:07.449855 (Thread-4): 21:18:07  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 21:18:07.484948 (Thread-4): 21:18:07  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:18:07.485160 (Thread-4): 21:18:07  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:18:07.485280 (Thread-4): 21:18:07  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 21:18:07.488226 (Thread-4): 21:18:07  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:18:07.489574 (Thread-4): 21:18:07  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:18:07.489670 (Thread-4): 21:18:07  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 21:18:07.491951 (Thread-4): 21:18:07  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 21:18:07.492579 (Thread-4): 21:18:07  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 21:18:07.492671 (Thread-4): 21:18:07  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:18:07.492744 (Thread-4): 21:18:07  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 21:18:07.496401 (Thread-4): 21:18:07  SQL status: COMMIT in 0.0 seconds
2022-01-06 21:18:07.496508 (Thread-4): 21:18:07  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:18:07.496579 (Thread-4): 21:18:07  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 21:18:07.498479 (Thread-4): 21:18:07  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:18:07.498879 (Thread-4): 21:18:07  finished collecting timing info
2022-01-06 21:18:07.499030 (Thread-4): 21:18:07  On model.jaffel_shop.dim_customers: ROLLBACK
2022-01-06 21:18:07.500768 (Thread-4): 21:18:07  On model.jaffel_shop.dim_customers: Close
2022-01-06 21:18:07.501262 (Thread-4): 21:18:07  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff6401e9-284a-4c57-af9d-cc31a6774ce2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4444206d0>]}
2022-01-06 21:18:07.501593 (Thread-4): 21:18:07  4 of 5 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 12.02s]
2022-01-06 21:18:07.501707 (Thread-4): 21:18:07  Finished running node model.jaffel_shop.dim_customers
2022-01-06 21:18:07.503033 (MainThread): 21:18:07  Acquiring new redshift connection "master"
2022-01-06 21:18:07.503177 (MainThread): 21:18:07  Using redshift connection "master"
2022-01-06 21:18:07.503252 (MainThread): 21:18:07  On master: BEGIN
2022-01-06 21:18:07.503329 (MainThread): 21:18:07  Opening a new connection, currently in state closed
2022-01-06 21:18:07.503406 (MainThread): 21:18:07  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:18:07.530161 (MainThread): 21:18:07  SQL status: BEGIN in 0.03 seconds
2022-01-06 21:18:07.530305 (MainThread): 21:18:07  On master: COMMIT
2022-01-06 21:18:07.530384 (MainThread): 21:18:07  Using redshift connection "master"
2022-01-06 21:18:07.530453 (MainThread): 21:18:07  On master: COMMIT
2022-01-06 21:18:07.535872 (MainThread): 21:18:07  SQL status: COMMIT in 0.01 seconds
2022-01-06 21:18:07.535989 (MainThread): 21:18:07  On master: Close
2022-01-06 21:18:07.536406 (MainThread): 21:18:07  
2022-01-06 21:18:07.536518 (MainThread): 21:18:07  Finished running 4 view models, 1 table model in 12.55s.
2022-01-06 21:18:07.536600 (MainThread): 21:18:07  Connection 'master' was properly closed.
2022-01-06 21:18:07.536665 (MainThread): 21:18:07  Connection 'model.jaffel_shop.fct_orders' was properly closed.
2022-01-06 21:18:07.536727 (MainThread): 21:18:07  Connection 'model.jaffel_shop.stg_orders' was properly closed.
2022-01-06 21:18:07.536787 (MainThread): 21:18:07  Connection 'model.jaffel_shop.stg_payments' was properly closed.
2022-01-06 21:18:07.536847 (MainThread): 21:18:07  Connection 'model.jaffel_shop.dim_customers' was properly closed.
2022-01-06 21:18:07.612911 (MainThread): 21:18:07  
2022-01-06 21:18:07.613128 (MainThread): 21:18:07  Completed successfully
2022-01-06 21:18:07.613256 (MainThread): 21:18:07  
2022-01-06 21:18:07.613348 (MainThread): 21:18:07  Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2022-01-06 21:18:07.714959 (Thread-803): handling poll request
2022-01-06 21:18:07.715965 (Thread-803): 21:18:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec42c12e0>]}
2022-01-06 21:18:07.716570 (Thread-803): sending response (<Response 4630 bytes [200 OK]>) to 10.0.3.189
2022-01-06 21:18:07.718530 (Thread-1): 21:18:07  SQL status: SELECT in 0.34 seconds
2022-01-06 21:18:07.721388 (Thread-1): 21:18:07  finished collecting timing info
2022-01-06 21:18:07.721552 (Thread-1): 21:18:07  On rpc.jaffel_shop.request: Close
2022-01-06 21:18:07.868723 (Thread-804): handling poll request
2022-01-06 21:18:07.869106 (Thread-804): 21:18:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec42d5310>]}
2022-01-06 21:18:07.870988 (Thread-804): sending response (<Response 32477 bytes [200 OK]>) to 10.0.31.115
2022-01-06 21:18:08.506854 (Thread-805): handling status request
2022-01-06 21:18:08.507210 (Thread-805): 21:18:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec47e3880>]}
2022-01-06 21:18:08.507698 (Thread-805): sending response (<Response 1244 bytes [200 OK]>) to 10.0.35.15
2022-01-06 21:18:08.780846 (Thread-806): handling status request
2022-01-06 21:18:08.781195 (Thread-806): 21:18:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec46bc5b0>]}
2022-01-06 21:18:08.804358 (Thread-806): sending response (<Response 1244 bytes [200 OK]>) to 10.0.44.8
2022-01-06 21:18:09.168101 (Thread-807): handling poll request
2022-01-06 21:18:09.168469 (Thread-807): 21:18:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec46f9e20>]}
2022-01-06 21:18:09.169788 (Thread-807): sending response (<Response 9304 bytes [200 OK]>) to 10.0.45.208
2022-01-06 21:26:31.044314 (Thread-808): 21:26:31  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 21:26:31.046268 (Thread-808): 21:26:31  Partial parsing: updated file: jaffel_shop://models/marts/core/fct_orders.sql
2022-01-06 21:26:31.051602 (Thread-808): 21:26:31  1699: static parser successfully parsed marts/core/fct_orders.sql
2022-01-06 21:26:31.101244 (Thread-808): 21:26:31  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4709160>]}
2022-01-06 21:26:31.545646 (Thread-809): handling status request
2022-01-06 21:26:31.546021 (Thread-809): 21:26:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee44b3700>]}
2022-01-06 21:26:31.546512 (Thread-809): sending response (<Response 1569 bytes [200 OK]>) to 10.0.19.7
2022-01-06 21:26:31.611894 (Thread-810): handling status request
2022-01-06 21:26:31.612233 (Thread-810): 21:26:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee44b3b20>]}
2022-01-06 21:26:31.612665 (Thread-810): sending response (<Response 1569 bytes [200 OK]>) to 10.0.11.87
2022-01-06 21:29:15.571887 (Thread-811): 21:29:15  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 21:29:15.573498 (Thread-811): 21:29:15  Partial parsing: updated file: jaffel_shop://models/staging/stripe/stg_payments.sql
2022-01-06 21:29:15.577084 (Thread-811): 21:29:15  1699: static parser successfully parsed staging/stripe/stg_payments.sql
2022-01-06 21:29:15.649284 (Thread-811): 21:29:15  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec46c9940>]}
2022-01-06 21:29:16.179838 (Thread-812): handling status request
2022-01-06 21:29:16.180243 (Thread-812): 21:29:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45035b0>]}
2022-01-06 21:29:16.180763 (Thread-812): sending response (<Response 1581 bytes [200 OK]>) to 10.0.45.208
2022-01-06 21:29:16.181831 (Thread-813): handling status request
2022-01-06 21:29:16.182157 (Thread-813): 21:29:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee434a940>]}
2022-01-06 21:29:16.190016 (Thread-813): sending response (<Response 1581 bytes [200 OK]>) to 10.0.44.8
2022-01-06 21:29:17.254569 (Thread-814): handling status request
2022-01-06 21:29:17.254939 (Thread-814): 21:29:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee458b700>]}
2022-01-06 21:29:17.255419 (Thread-814): sending response (<Response 1581 bytes [200 OK]>) to 10.0.4.104
2022-01-06 21:29:17.560586 (Thread-815): handling run_sql request
2022-01-06 21:29:17.560894 (Thread-815): 21:29:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee458b0a0>]}
2022-01-06 21:29:19.606953 (Thread-815): sending response (<Response 138 bytes [200 OK]>) to 10.0.4.101
2022-01-06 21:29:19.630277 (MainThread): 21:29:19  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '35a2c878-5576-457d-ad92-a45f7d8b4b22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e75fcab50>]}
2022-01-06 21:29:19.630773 (MainThread): 21:29:19  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 21:29:19.631311 (Thread-1): 21:29:19  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:29:19.631441 (Thread-1): 21:29:19  Began compiling node rpc.jaffel_shop.request
2022-01-06 21:29:19.631527 (Thread-1): 21:29:19  Compiling rpc.jaffel_shop.request
2022-01-06 21:29:19.632659 (Thread-1): 21:29:19  finished collecting timing info
2022-01-06 21:29:19.632781 (Thread-1): 21:29:19  Began executing node rpc.jaffel_shop.request
2022-01-06 21:29:19.632881 (Thread-1): 21:29:19  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:29:19.632965 (Thread-1): 21:29:19  On rpc.jaffel_shop.request: with payment as (

    select
        id as payment_id,
        orderid as order_id,
        paymentmethos as payment_method,

        -- amount is stored in cents, convert it to dollars
        amount/100 as amount,
        status

    from stripe.payment

)
select * from payment
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 21:29:19.633041 (Thread-1): 21:29:19  Opening a new connection, currently in state init
2022-01-06 21:29:19.633123 (Thread-1): 21:29:19  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:29:19.653490 (Thread-1): 21:29:19  Postgres adapter: Postgres error: column "paymentmethos" does not exist in payment

2022-01-06 21:29:19.653643 (Thread-1): 21:29:19  finished collecting timing info
2022-01-06 21:29:19.653756 (Thread-1): 21:29:19  On rpc.jaffel_shop.request: Close
2022-01-06 21:29:19.653973 (Thread-1): Got an exception: Database Error
  column "paymentmethos" does not exist in payment
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "paymentmethos" does not exist in payment


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  column "paymentmethos" does not exist in payment
2022-01-06 21:29:19.654909 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "paymentmethos" does not exist in payment', 'raw_sql': 'with payment as (\n\n    select\n        id as payment_id,\n        orderid as order_id,\n        paymentmethos as payment_method,\n\n        -- amount is stored in cents, convert it to dollars\n        amount/100 as amount,\n        status\n\n    from stripe.payment\n\n)\nselect * from payment\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with payment as (\n\n    select\n        id as payment_id,\n        orderid as order_id,\n        paymentmethos as payment_method,\n\n        -- amount is stored in cents, convert it to dollars\n        amount/100 as amount,\n        status\n\n    from stripe.payment\n\n)\nselect * from payment\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  column "paymentmethos" does not exist in payment', 'raw_sql': 'with payment as (\n\n    select\n        id as payment_id,\n        orderid as order_id,\n        paymentmethos as payment_method,\n\n        -- amount is stored in cents, convert it to dollars\n        amount/100 as amount,\n        status\n\n    from stripe.payment\n\n)\nselect * from payment\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with payment as (\n\n    select\n        id as payment_id,\n        orderid as order_id,\n        paymentmethos as payment_method,\n\n        -- amount is stored in cents, convert it to dollars\n        amount/100 as amount,\n        status\n\n    from stripe.payment\n\n)\nselect * from payment\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 21:29:19.994068 (Thread-816): handling poll request
2022-01-06 21:29:19.994522 (Thread-816): 21:29:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee44abc10>]}
2022-01-06 21:29:19.995411 (Thread-816): sending response (<Response 10869 bytes [200 OK]>) to 10.0.31.5
2022-01-06 21:30:26.459470 (Thread-817): handling status request
2022-01-06 21:30:26.459863 (Thread-817): 21:30:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee44abc40>]}
2022-01-06 21:30:26.460431 (Thread-817): sending response (<Response 1581 bytes [200 OK]>) to 10.0.45.208
2022-01-06 21:30:26.802576 (Thread-818): handling run_sql request
2022-01-06 21:30:26.802862 (Thread-818): 21:30:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee44ab940>]}
2022-01-06 21:30:27.757561 (Thread-819): 21:30:27  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 21:30:27.758043 (Thread-819): 21:30:27  Partial parsing: updated file: jaffel_shop://models/staging/stripe/stg_payments.sql
2022-01-06 21:30:27.762242 (Thread-819): 21:30:27  1699: static parser successfully parsed staging/stripe/stg_payments.sql
2022-01-06 21:30:27.805362 (Thread-819): 21:30:27  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4233940>]}
2022-01-06 21:30:28.407602 (Thread-820): handling status request
2022-01-06 21:30:28.407996 (Thread-820): 21:30:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4221e20>]}
2022-01-06 21:30:28.408608 (Thread-820): sending response (<Response 1581 bytes [200 OK]>) to 10.0.31.5
2022-01-06 21:30:28.437946 (Thread-821): handling status request
2022-01-06 21:30:28.438212 (Thread-821): 21:30:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4221cd0>]}
2022-01-06 21:30:28.438609 (Thread-821): sending response (<Response 1581 bytes [200 OK]>) to 10.0.11.87
2022-01-06 21:30:28.856415 (Thread-818): sending response (<Response 138 bytes [200 OK]>) to 10.0.31.115
2022-01-06 21:30:28.880578 (MainThread): 21:30:28  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4fa229b1-8cab-4912-9995-f103976429c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc83fdcbb50>]}
2022-01-06 21:30:28.881094 (MainThread): 21:30:28  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 21:30:28.881692 (Thread-1): 21:30:28  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:30:28.881821 (Thread-1): 21:30:28  Began compiling node rpc.jaffel_shop.request
2022-01-06 21:30:28.881912 (Thread-1): 21:30:28  Compiling rpc.jaffel_shop.request
2022-01-06 21:30:28.883023 (Thread-1): 21:30:28  finished collecting timing info
2022-01-06 21:30:28.883146 (Thread-1): 21:30:28  Began executing node rpc.jaffel_shop.request
2022-01-06 21:30:28.883246 (Thread-1): 21:30:28  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 21:30:28.883328 (Thread-1): 21:30:28  On rpc.jaffel_shop.request: with payment as (

    select
        id as payment_id,
        orderid as order_id,
        paymentmethod as payment_method,

        -- amount is stored in cents, convert it to dollars
        amount/100 as amount,
        status

    from stripe.payment

)
select * from payment
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 21:30:28.883405 (Thread-1): 21:30:28  Opening a new connection, currently in state init
2022-01-06 21:30:28.883487 (Thread-1): 21:30:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:30:29.192729 (Thread-822): handling poll request
2022-01-06 21:30:29.193055 (Thread-822): 21:30:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4221910>]}
2022-01-06 21:30:29.193746 (Thread-822): sending response (<Response 4318 bytes [200 OK]>) to 10.0.4.104
2022-01-06 21:30:30.550669 (Thread-823): handling poll request
2022-01-06 21:30:30.551040 (Thread-823): 21:30:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec46c98b0>]}
2022-01-06 21:30:30.551528 (Thread-823): sending response (<Response 400 bytes [200 OK]>) to 10.0.44.8
2022-01-06 21:30:31.938787 (Thread-824): handling poll request
2022-01-06 21:30:31.939176 (Thread-824): 21:30:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec46d81f0>]}
2022-01-06 21:30:31.939665 (Thread-824): sending response (<Response 400 bytes [200 OK]>) to 10.0.14.253
2022-01-06 21:30:32.983610 (Thread-1): 21:30:32  SQL status: SELECT in 4.1 seconds
2022-01-06 21:30:32.986678 (Thread-1): 21:30:32  finished collecting timing info
2022-01-06 21:30:32.986856 (Thread-1): 21:30:32  On rpc.jaffel_shop.request: Close
2022-01-06 21:30:33.298762 (Thread-825): handling poll request
2022-01-06 21:30:33.299150 (Thread-825): 21:30:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee442b790>]}
2022-01-06 21:30:33.300355 (Thread-825): sending response (<Response 9944 bytes [200 OK]>) to 10.0.8.128
2022-01-06 21:30:44.876702 (Thread-826): handling status request
2022-01-06 21:30:44.877072 (Thread-826): 21:30:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee442b520>]}
2022-01-06 21:30:44.877583 (Thread-826): sending response (<Response 1581 bytes [200 OK]>) to 10.0.31.5
2022-01-06 21:30:44.947236 (Thread-827): handling status request
2022-01-06 21:30:44.947480 (Thread-827): 21:30:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee442b130>]}
2022-01-06 21:30:44.947834 (Thread-827): sending response (<Response 1581 bytes [200 OK]>) to 10.0.47.136
2022-01-06 21:30:45.453761 (Thread-828): handling cli_args request
2022-01-06 21:30:45.454032 (Thread-828): 21:30:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec46f9700>]}
2022-01-06 21:30:47.506644 (Thread-828): sending response (<Response 138 bytes [200 OK]>) to 10.0.19.7
2022-01-06 21:30:47.603038 (MainThread): 21:30:47  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 21:30:47.603415 (MainThread): 21:30:47  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 21:30:47.608746 (MainThread): 21:30:47  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c93801f1-341b-4689-a0e2-30d2587cb26c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccbbd92130>]}
2022-01-06 21:30:47.638651 (MainThread): 21:30:47  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c93801f1-341b-4689-a0e2-30d2587cb26c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccbbe2c8b0>]}
2022-01-06 21:30:47.638877 (MainThread): 21:30:47  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 21:30:47.639785 (MainThread): 21:30:47  
2022-01-06 21:30:47.640047 (MainThread): 21:30:47  Acquiring new redshift connection "master"
2022-01-06 21:30:47.640955 (ThreadPoolExecutor-0_0): 21:30:47  Acquiring new redshift connection "list_dev"
2022-01-06 21:30:47.650582 (ThreadPoolExecutor-0_0): 21:30:47  Using redshift connection "list_dev"
2022-01-06 21:30:47.650684 (ThreadPoolExecutor-0_0): 21:30:47  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 21:30:47.650767 (ThreadPoolExecutor-0_0): 21:30:47  Opening a new connection, currently in state init
2022-01-06 21:30:47.650847 (ThreadPoolExecutor-0_0): 21:30:47  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:30:47.673040 (ThreadPoolExecutor-0_0): 21:30:47  SQL status: SELECT in 0.02 seconds
2022-01-06 21:30:47.674044 (ThreadPoolExecutor-0_0): 21:30:47  On list_dev: Close
2022-01-06 21:30:47.675157 (ThreadPoolExecutor-1_0): 21:30:47  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 21:30:47.681180 (ThreadPoolExecutor-1_0): 21:30:47  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 21:30:47.681317 (ThreadPoolExecutor-1_0): 21:30:47  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 21:30:47.681396 (ThreadPoolExecutor-1_0): 21:30:47  Opening a new connection, currently in state closed
2022-01-06 21:30:47.681470 (ThreadPoolExecutor-1_0): 21:30:47  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:30:47.704415 (ThreadPoolExecutor-1_0): 21:30:47  SQL status: BEGIN in 0.02 seconds
2022-01-06 21:30:47.704522 (ThreadPoolExecutor-1_0): 21:30:47  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 21:30:47.704597 (ThreadPoolExecutor-1_0): 21:30:47  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 21:30:47.715951 (ThreadPoolExecutor-1_0): 21:30:47  SQL status: SELECT in 0.01 seconds
2022-01-06 21:30:47.716985 (ThreadPoolExecutor-1_0): 21:30:47  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 21:30:47.718934 (ThreadPoolExecutor-1_0): 21:30:47  On list_dev_dbt_nobodozie: Close
2022-01-06 21:30:47.722967 (MainThread): 21:30:47  Using redshift connection "master"
2022-01-06 21:30:47.723080 (MainThread): 21:30:47  On master: BEGIN
2022-01-06 21:30:47.723160 (MainThread): 21:30:47  Opening a new connection, currently in state init
2022-01-06 21:30:47.723235 (MainThread): 21:30:47  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:30:47.746911 (MainThread): 21:30:47  SQL status: BEGIN in 0.02 seconds
2022-01-06 21:30:47.747023 (MainThread): 21:30:47  Using redshift connection "master"
2022-01-06 21:30:47.747099 (MainThread): 21:30:47  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 21:30:47.776043 (MainThread): 21:30:47  SQL status: SELECT in 0.03 seconds
2022-01-06 21:30:47.777109 (MainThread): 21:30:47  On master: ROLLBACK
2022-01-06 21:30:47.779063 (MainThread): 21:30:47  Using redshift connection "master"
2022-01-06 21:30:47.779174 (MainThread): 21:30:47  On master: BEGIN
2022-01-06 21:30:47.782750 (MainThread): 21:30:47  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:30:47.782857 (MainThread): 21:30:47  On master: COMMIT
2022-01-06 21:30:47.782930 (MainThread): 21:30:47  Using redshift connection "master"
2022-01-06 21:30:47.782998 (MainThread): 21:30:47  On master: COMMIT
2022-01-06 21:30:47.785993 (MainThread): 21:30:47  SQL status: COMMIT in 0.0 seconds
2022-01-06 21:30:47.786097 (MainThread): 21:30:47  On master: Close
2022-01-06 21:30:47.786455 (MainThread): 21:30:47  Concurrency: 4 threads (target='default')
2022-01-06 21:30:47.786568 (MainThread): 21:30:47  
2022-01-06 21:30:47.788722 (Thread-1): 21:30:47  Began running node model.jaffel_shop.stg_customers
2022-01-06 21:30:47.788960 (Thread-1): 21:30:47  1 of 5 START view model dbt_nobodozie.stg_customers............................. [RUN]
2022-01-06 21:30:47.789196 (Thread-1): 21:30:47  Acquiring new redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:30:47.789319 (Thread-1): 21:30:47  Began compiling node model.jaffel_shop.stg_customers
2022-01-06 21:30:47.789408 (Thread-1): 21:30:47  Compiling model.jaffel_shop.stg_customers
2022-01-06 21:30:47.790539 (Thread-1): 21:30:47  Writing injected SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 21:30:47.790767 (Thread-2): 21:30:47  Began running node model.jaffel_shop.stg_orders
2022-01-06 21:30:47.791002 (Thread-2): 21:30:47  2 of 5 START view model dbt_nobodozie.stg_orders................................ [RUN]
2022-01-06 21:30:47.791250 (Thread-2): 21:30:47  Acquiring new redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:30:47.791336 (Thread-2): 21:30:47  Began compiling node model.jaffel_shop.stg_orders
2022-01-06 21:30:47.791415 (Thread-2): 21:30:47  Compiling model.jaffel_shop.stg_orders
2022-01-06 21:30:47.792487 (Thread-2): 21:30:47  Writing injected SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 21:30:47.792808 (Thread-3): 21:30:47  Began running node model.jaffel_shop.stg_payments
2022-01-06 21:30:47.793021 (Thread-3): 21:30:47  3 of 5 START view model dbt_nobodozie.stg_payments.............................. [RUN]
2022-01-06 21:30:47.793298 (Thread-3): 21:30:47  Acquiring new redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:30:47.793387 (Thread-3): 21:30:47  Began compiling node model.jaffel_shop.stg_payments
2022-01-06 21:30:47.793470 (Thread-3): 21:30:47  Compiling model.jaffel_shop.stg_payments
2022-01-06 21:30:47.794448 (Thread-3): 21:30:47  Writing injected SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 21:30:47.808349 (Thread-1): 21:30:47  finished collecting timing info
2022-01-06 21:30:47.808491 (Thread-1): 21:30:47  Began executing node model.jaffel_shop.stg_customers
2022-01-06 21:30:47.813686 (Thread-2): 21:30:47  finished collecting timing info
2022-01-06 21:30:47.813815 (Thread-2): 21:30:47  Began executing node model.jaffel_shop.stg_orders
2022-01-06 21:30:47.825121 (Thread-3): 21:30:47  finished collecting timing info
2022-01-06 21:30:47.825279 (Thread-3): 21:30:47  Began executing node model.jaffel_shop.stg_payments
2022-01-06 21:30:47.852067 (Thread-1): 21:30:47  Writing runtime SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 21:30:47.853070 (Thread-2): 21:30:47  Writing runtime SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 21:30:47.854293 (Thread-3): 21:30:47  Writing runtime SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 21:30:47.868449 (Thread-1): 21:30:47  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:30:47.868564 (Thread-1): 21:30:47  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 21:30:47.868648 (Thread-1): 21:30:47  Opening a new connection, currently in state closed
2022-01-06 21:30:47.868728 (Thread-1): 21:30:47  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:30:47.869390 (Thread-2): 21:30:47  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:30:47.869502 (Thread-2): 21:30:47  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 21:30:47.869614 (Thread-2): 21:30:47  Opening a new connection, currently in state init
2022-01-06 21:30:47.869699 (Thread-2): 21:30:47  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:30:47.869985 (Thread-3): 21:30:47  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:30:47.870101 (Thread-3): 21:30:47  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 21:30:47.870182 (Thread-3): 21:30:47  Opening a new connection, currently in state init
2022-01-06 21:30:47.870257 (Thread-3): 21:30:47  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:30:47.886132 (Thread-829): handling poll request
2022-01-06 21:30:47.886489 (Thread-829): 21:30:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee442ba90>]}
2022-01-06 21:30:47.888046 (Thread-829): sending response (<Response 31237 bytes [200 OK]>) to 10.0.27.154
2022-01-06 21:30:47.896849 (Thread-1): 21:30:47  SQL status: BEGIN in 0.03 seconds
2022-01-06 21:30:47.896963 (Thread-1): 21:30:47  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:30:47.897041 (Thread-1): 21:30:47  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */


  create view "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
  ) ;

2022-01-06 21:30:47.901190 (Thread-2): 21:30:47  SQL status: BEGIN in 0.03 seconds
2022-01-06 21:30:47.901337 (Thread-2): 21:30:47  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:30:47.901414 (Thread-2): 21:30:47  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */


  create view "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" as (
    with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
  ) ;

2022-01-06 21:30:47.907197 (Thread-1): 21:30:47  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 21:30:47.912502 (Thread-2): 21:30:47  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 21:30:47.914447 (Thread-2): 21:30:47  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:30:47.914542 (Thread-2): 21:30:47  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders" rename to "stg_orders__dbt_backup"
2022-01-06 21:30:47.914814 (Thread-1): 21:30:47  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:30:47.914917 (Thread-1): 21:30:47  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers" rename to "stg_customers__dbt_backup"
2022-01-06 21:30:47.915075 (Thread-3): 21:30:47  SQL status: BEGIN in 0.04 seconds
2022-01-06 21:30:47.915183 (Thread-3): 21:30:47  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:30:47.915259 (Thread-3): 21:30:47  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */


  create view "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" as (
    with payment as (

    select
        id as payment_id,
        orderid as order_id,
        paymentmethod as payment_method,

        -- amount is stored in cents, convert it to dollars
        amount/100 as amount,
        status

    from stripe.payment

)
select * from payment
  ) ;

2022-01-06 21:30:47.917584 (Thread-2): 21:30:47  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:30:47.919339 (Thread-2): 21:30:47  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:30:47.919434 (Thread-2): 21:30:47  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" rename to "stg_orders"
2022-01-06 21:30:47.919623 (Thread-1): 21:30:47  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:30:47.922152 (Thread-1): 21:30:47  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:30:47.922248 (Thread-1): 21:30:47  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" rename to "stg_customers"
2022-01-06 21:30:47.922554 (Thread-2): 21:30:47  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:30:47.927867 (Thread-3): 21:30:47  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 21:30:47.929766 (Thread-3): 21:30:47  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:30:47.929861 (Thread-3): 21:30:47  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments" rename to "stg_payments__dbt_backup"
2022-01-06 21:30:47.931266 (Thread-2): 21:30:47  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 21:30:47.931372 (Thread-2): 21:30:47  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:30:47.931446 (Thread-2): 21:30:47  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 21:30:47.931645 (Thread-1): 21:30:47  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 21:30:47.932585 (Thread-1): 21:30:47  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 21:30:47.932682 (Thread-1): 21:30:47  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:30:47.932755 (Thread-1): 21:30:47  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 21:30:47.932940 (Thread-3): 21:30:47  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:30:47.934731 (Thread-3): 21:30:47  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:30:47.934827 (Thread-3): 21:30:47  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" rename to "stg_payments"
2022-01-06 21:30:47.937643 (Thread-3): 21:30:47  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:30:47.938551 (Thread-3): 21:30:47  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 21:30:47.938645 (Thread-3): 21:30:47  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:30:47.938716 (Thread-3): 21:30:47  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 21:30:47.989250 (Thread-2): 21:30:47  SQL status: COMMIT in 0.06 seconds
2022-01-06 21:30:47.989462 (Thread-2): 21:30:47  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:30:47.989556 (Thread-2): 21:30:47  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 21:30:47.989882 (Thread-1): 21:30:47  SQL status: COMMIT in 0.06 seconds
2022-01-06 21:30:47.990395 (Thread-3): 21:30:47  SQL status: COMMIT in 0.05 seconds
2022-01-06 21:30:47.991643 (Thread-2): 21:30:47  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:30:47.995612 (Thread-2): 21:30:47  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:30:47.995709 (Thread-2): 21:30:47  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
drop view if exists "dev"."dbt_nobodozie"."stg_orders__dbt_backup" cascade
2022-01-06 21:30:48.000859 (Thread-2): 21:30:48  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 21:30:48.001489 (Thread-2): 21:30:48  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 21:30:48.001584 (Thread-2): 21:30:48  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:30:48.001657 (Thread-2): 21:30:48  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 21:30:48.029276 (Thread-2): 21:30:48  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:30:48.029388 (Thread-2): 21:30:48  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:30:48.029462 (Thread-2): 21:30:48  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 21:30:48.031759 (Thread-2): 21:30:48  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:30:48.032150 (Thread-2): 21:30:48  finished collecting timing info
2022-01-06 21:30:48.032273 (Thread-2): 21:30:48  On model.jaffel_shop.stg_orders: ROLLBACK
2022-01-06 21:30:48.032465 (Thread-1): 21:30:48  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:30:48.032564 (Thread-1): 21:30:48  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 21:30:48.035015 (Thread-2): 21:30:48  On model.jaffel_shop.stg_orders: Close
2022-01-06 21:30:48.035213 (Thread-1): 21:30:48  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:30:48.036447 (Thread-1): 21:30:48  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:30:48.036541 (Thread-1): 21:30:48  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
drop view if exists "dev"."dbt_nobodozie"."stg_customers__dbt_backup" cascade
2022-01-06 21:30:48.036943 (Thread-2): 21:30:48  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c93801f1-341b-4689-a0e2-30d2587cb26c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccb84c4ac0>]}
2022-01-06 21:30:48.037307 (Thread-2): 21:30:48  2 of 5 OK created view model dbt_nobodozie.stg_orders........................... [CREATE VIEW in 0.25s]
2022-01-06 21:30:48.037427 (Thread-2): 21:30:48  Finished running node model.jaffel_shop.stg_orders
2022-01-06 21:30:48.042863 (Thread-1): 21:30:48  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 21:30:48.043552 (Thread-1): 21:30:48  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 21:30:48.043647 (Thread-1): 21:30:48  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:30:48.043726 (Thread-1): 21:30:48  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 21:30:48.073335 (Thread-1): 21:30:48  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:30:48.073448 (Thread-1): 21:30:48  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:30:48.073522 (Thread-1): 21:30:48  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 21:30:48.075630 (Thread-1): 21:30:48  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:30:48.076011 (Thread-1): 21:30:48  finished collecting timing info
2022-01-06 21:30:48.076131 (Thread-1): 21:30:48  On model.jaffel_shop.stg_customers: ROLLBACK
2022-01-06 21:30:48.076323 (Thread-3): 21:30:48  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:30:48.076427 (Thread-3): 21:30:48  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 21:30:48.078782 (Thread-1): 21:30:48  On model.jaffel_shop.stg_customers: Close
2022-01-06 21:30:48.078994 (Thread-3): 21:30:48  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:30:48.080122 (Thread-3): 21:30:48  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:30:48.080219 (Thread-3): 21:30:48  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
drop view if exists "dev"."dbt_nobodozie"."stg_payments__dbt_backup" cascade
2022-01-06 21:30:48.080604 (Thread-1): 21:30:48  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c93801f1-341b-4689-a0e2-30d2587cb26c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccbb546340>]}
2022-01-06 21:30:48.080899 (Thread-1): 21:30:48  1 of 5 OK created view model dbt_nobodozie.stg_customers........................ [CREATE VIEW in 0.29s]
2022-01-06 21:30:48.081005 (Thread-1): 21:30:48  Finished running node model.jaffel_shop.stg_customers
2022-01-06 21:30:48.085396 (Thread-3): 21:30:48  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 21:30:48.086148 (Thread-3): 21:30:48  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 21:30:48.086247 (Thread-3): 21:30:48  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:30:48.086322 (Thread-3): 21:30:48  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 21:30:48.115792 (Thread-3): 21:30:48  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:30:48.115905 (Thread-3): 21:30:48  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:30:48.115977 (Thread-3): 21:30:48  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 21:30:48.118026 (Thread-3): 21:30:48  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:30:48.118399 (Thread-3): 21:30:48  finished collecting timing info
2022-01-06 21:30:48.118519 (Thread-3): 21:30:48  On model.jaffel_shop.stg_payments: ROLLBACK
2022-01-06 21:30:48.120307 (Thread-3): 21:30:48  On model.jaffel_shop.stg_payments: Close
2022-01-06 21:30:48.120713 (Thread-3): 21:30:48  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c93801f1-341b-4689-a0e2-30d2587cb26c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccb84e1220>]}
2022-01-06 21:30:48.121003 (Thread-3): 21:30:48  3 of 5 OK created view model dbt_nobodozie.stg_payments......................... [CREATE VIEW in 0.33s]
2022-01-06 21:30:48.121173 (Thread-3): 21:30:48  Finished running node model.jaffel_shop.stg_payments
2022-01-06 21:30:48.122017 (Thread-4): 21:30:48  Began running node model.jaffel_shop.dim_customers
2022-01-06 21:30:48.122252 (Thread-4): 21:30:48  4 of 5 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 21:30:48.122504 (Thread-4): 21:30:48  Acquiring new redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:30:48.122591 (Thread-4): 21:30:48  Began compiling node model.jaffel_shop.dim_customers
2022-01-06 21:30:48.122676 (Thread-4): 21:30:48  Compiling model.jaffel_shop.dim_customers
2022-01-06 21:30:48.125368 (Thread-4): 21:30:48  Writing injected SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 21:30:48.125571 (Thread-2): 21:30:48  Began running node model.jaffel_shop.fct_orders
2022-01-06 21:30:48.125787 (Thread-2): 21:30:48  5 of 5 START view model dbt_nobodozie.fct_orders................................ [RUN]
2022-01-06 21:30:48.126185 (Thread-2): 21:30:48  Acquiring new redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:30:48.126281 (Thread-2): 21:30:48  Began compiling node model.jaffel_shop.fct_orders
2022-01-06 21:30:48.126361 (Thread-2): 21:30:48  Compiling model.jaffel_shop.fct_orders
2022-01-06 21:30:48.128300 (Thread-2): 21:30:48  Writing injected SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 21:30:48.143454 (Thread-4): 21:30:48  finished collecting timing info
2022-01-06 21:30:48.143588 (Thread-4): 21:30:48  Began executing node model.jaffel_shop.dim_customers
2022-01-06 21:30:48.148561 (Thread-2): 21:30:48  finished collecting timing info
2022-01-06 21:30:48.148686 (Thread-2): 21:30:48  Began executing node model.jaffel_shop.fct_orders
2022-01-06 21:30:48.150628 (Thread-2): 21:30:48  Writing runtime SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 21:30:48.171595 (Thread-4): 21:30:48  Writing runtime SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 21:30:48.177965 (Thread-2): 21:30:48  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:30:48.178078 (Thread-2): 21:30:48  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 21:30:48.178161 (Thread-2): 21:30:48  Opening a new connection, currently in state closed
2022-01-06 21:30:48.178240 (Thread-2): 21:30:48  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:30:48.186177 (Thread-4): 21:30:48  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:30:48.186287 (Thread-4): 21:30:48  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 21:30:48.186365 (Thread-4): 21:30:48  Opening a new connection, currently in state init
2022-01-06 21:30:48.186439 (Thread-4): 21:30:48  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:30:48.361634 (Thread-4): 21:30:48  SQL status: BEGIN in 0.18 seconds
2022-01-06 21:30:48.361799 (Thread-4): 21:30:48  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:30:48.361883 (Thread-4): 21:30:48  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),

lifetime_value as (

    select 
        orders.customer_id as customer_id,
        orders.order_id as order_id,
        sum(payment.amount) total_value

    from orders 
    
    left join payment using (order_id)
    group by 1,2
),


customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,
        lifetime_value.order_id,
        lifetime_value.total_value
    from customers

    left join customer_orders using (customer_id)
    left join lifetime_value using (customer_id)
)

select * from final
  );
2022-01-06 21:30:48.374649 (Thread-2): 21:30:48  SQL status: BEGIN in 0.2 seconds
2022-01-06 21:30:48.374780 (Thread-2): 21:30:48  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:30:48.374861 (Thread-2): 21:30:48  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */


  create view "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" as (
    with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),


order_payments as (
    select
        order_id,
        sum(case when status = 'success' then amount end ) as amount
    from payment
    group by 1
),



final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
  ) ;

2022-01-06 21:30:48.385714 (Thread-2): 21:30:48  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 21:30:48.387761 (Thread-2): 21:30:48  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:30:48.387861 (Thread-2): 21:30:48  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
alter table "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" rename to "fct_orders"
2022-01-06 21:30:48.391036 (Thread-2): 21:30:48  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:30:48.392216 (Thread-2): 21:30:48  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 21:30:48.392312 (Thread-2): 21:30:48  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:30:48.392385 (Thread-2): 21:30:48  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 21:30:48.432391 (Thread-2): 21:30:48  SQL status: COMMIT in 0.04 seconds
2022-01-06 21:30:48.432613 (Thread-2): 21:30:48  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:30:48.432693 (Thread-2): 21:30:48  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 21:30:48.435766 (Thread-2): 21:30:48  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:30:48.436951 (Thread-2): 21:30:48  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:30:48.437045 (Thread-2): 21:30:48  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
drop view if exists "dev"."dbt_nobodozie"."fct_orders__dbt_backup" cascade
2022-01-06 21:30:48.439811 (Thread-2): 21:30:48  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 21:30:48.441665 (Thread-2): 21:30:48  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 21:30:48.441761 (Thread-2): 21:30:48  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:30:48.441834 (Thread-2): 21:30:48  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 21:30:48.478166 (Thread-2): 21:30:48  SQL status: COMMIT in 0.04 seconds
2022-01-06 21:30:48.478284 (Thread-2): 21:30:48  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:30:48.478359 (Thread-2): 21:30:48  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 21:30:48.480431 (Thread-2): 21:30:48  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:30:48.480845 (Thread-2): 21:30:48  finished collecting timing info
2022-01-06 21:30:48.480973 (Thread-2): 21:30:48  On model.jaffel_shop.fct_orders: ROLLBACK
2022-01-06 21:30:48.482743 (Thread-2): 21:30:48  On model.jaffel_shop.fct_orders: Close
2022-01-06 21:30:48.483185 (Thread-2): 21:30:48  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c93801f1-341b-4689-a0e2-30d2587cb26c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccb846d250>]}
2022-01-06 21:30:48.483511 (Thread-2): 21:30:48  5 of 5 OK created view model dbt_nobodozie.fct_orders........................... [CREATE VIEW in 0.36s]
2022-01-06 21:30:48.483620 (Thread-2): 21:30:48  Finished running node model.jaffel_shop.fct_orders
2022-01-06 21:30:48.760168 (Thread-4): 21:30:48  SQL status: SELECT in 0.4 seconds
2022-01-06 21:30:48.762115 (Thread-4): 21:30:48  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:30:48.762215 (Thread-4): 21:30:48  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 21:30:48.764869 (Thread-4): 21:30:48  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:30:48.766717 (Thread-4): 21:30:48  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:30:48.766812 (Thread-4): 21:30:48  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 21:30:48.769149 (Thread-4): 21:30:48  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:30:48.773822 (Thread-4): 21:30:48  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 21:30:48.773920 (Thread-4): 21:30:48  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:30:48.773993 (Thread-4): 21:30:48  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 21:30:48.808204 (Thread-4): 21:30:48  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:30:48.808417 (Thread-4): 21:30:48  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:30:48.808499 (Thread-4): 21:30:48  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 21:30:48.810667 (Thread-4): 21:30:48  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:30:48.811888 (Thread-4): 21:30:48  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:30:48.811982 (Thread-4): 21:30:48  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 21:30:48.815550 (Thread-4): 21:30:48  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 21:30:48.816156 (Thread-4): 21:30:48  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 21:30:48.816250 (Thread-4): 21:30:48  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:30:48.816323 (Thread-4): 21:30:48  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 21:30:48.845371 (Thread-4): 21:30:48  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:30:48.845484 (Thread-4): 21:30:48  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:30:48.845557 (Thread-4): 21:30:48  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 21:30:48.847701 (Thread-4): 21:30:48  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:30:48.848083 (Thread-4): 21:30:48  finished collecting timing info
2022-01-06 21:30:48.848207 (Thread-4): 21:30:48  On model.jaffel_shop.dim_customers: ROLLBACK
2022-01-06 21:30:48.849937 (Thread-4): 21:30:48  On model.jaffel_shop.dim_customers: Close
2022-01-06 21:30:48.850390 (Thread-4): 21:30:48  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c93801f1-341b-4689-a0e2-30d2587cb26c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccb84a8ac0>]}
2022-01-06 21:30:48.850709 (Thread-4): 21:30:48  4 of 5 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.73s]
2022-01-06 21:30:48.850816 (Thread-4): 21:30:48  Finished running node model.jaffel_shop.dim_customers
2022-01-06 21:30:48.852191 (MainThread): 21:30:48  Acquiring new redshift connection "master"
2022-01-06 21:30:48.852326 (MainThread): 21:30:48  Using redshift connection "master"
2022-01-06 21:30:48.852402 (MainThread): 21:30:48  On master: BEGIN
2022-01-06 21:30:48.852480 (MainThread): 21:30:48  Opening a new connection, currently in state closed
2022-01-06 21:30:48.852558 (MainThread): 21:30:48  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:30:48.877758 (MainThread): 21:30:48  SQL status: BEGIN in 0.03 seconds
2022-01-06 21:30:48.877876 (MainThread): 21:30:48  On master: COMMIT
2022-01-06 21:30:48.877951 (MainThread): 21:30:48  Using redshift connection "master"
2022-01-06 21:30:48.878021 (MainThread): 21:30:48  On master: COMMIT
2022-01-06 21:30:48.879758 (MainThread): 21:30:48  SQL status: COMMIT in 0.0 seconds
2022-01-06 21:30:48.879861 (MainThread): 21:30:48  On master: Close
2022-01-06 21:30:48.880273 (MainThread): 21:30:48  
2022-01-06 21:30:48.880382 (MainThread): 21:30:48  Finished running 4 view models, 1 table model in 1.24s.
2022-01-06 21:30:48.880466 (MainThread): 21:30:48  Connection 'master' was properly closed.
2022-01-06 21:30:48.880532 (MainThread): 21:30:48  Connection 'model.jaffel_shop.stg_customers' was properly closed.
2022-01-06 21:30:48.880593 (MainThread): 21:30:48  Connection 'model.jaffel_shop.fct_orders' was properly closed.
2022-01-06 21:30:48.880653 (MainThread): 21:30:48  Connection 'model.jaffel_shop.stg_payments' was properly closed.
2022-01-06 21:30:48.880712 (MainThread): 21:30:48  Connection 'model.jaffel_shop.dim_customers' was properly closed.
2022-01-06 21:30:48.950614 (MainThread): 21:30:48  
2022-01-06 21:30:48.950761 (MainThread): 21:30:48  Completed successfully
2022-01-06 21:30:48.950858 (MainThread): 21:30:48  
2022-01-06 21:30:48.950943 (MainThread): 21:30:48  Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2022-01-06 21:30:49.306592 (Thread-830): handling poll request
2022-01-06 21:30:49.306969 (Thread-830): 21:30:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec41a3a90>]}
2022-01-06 21:30:49.309929 (Thread-830): sending response (<Response 96034 bytes [200 OK]>) to 10.0.21.1
2022-01-06 21:30:50.039257 (Thread-831): handling status request
2022-01-06 21:30:50.039640 (Thread-831): 21:30:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec41a3c40>]}
2022-01-06 21:30:50.040190 (Thread-831): sending response (<Response 1581 bytes [200 OK]>) to 10.0.31.5
2022-01-06 21:30:50.114298 (Thread-832): handling status request
2022-01-06 21:30:50.114618 (Thread-832): 21:30:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec41a3fd0>]}
2022-01-06 21:30:50.115065 (Thread-832): sending response (<Response 1581 bytes [200 OK]>) to 10.0.47.136
2022-01-06 21:30:59.350446 (Thread-833): handling poll request
2022-01-06 21:30:59.350816 (Thread-833): 21:30:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec41be2b0>]}
2022-01-06 21:30:59.356356 (Thread-833): sending response (<Response 103048 bytes [200 OK]>) to 10.0.47.136
2022-01-06 21:31:00.006017 (Thread-834): handling status request
2022-01-06 21:31:00.006412 (Thread-834): 21:31:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec419bb50>]}
2022-01-06 21:31:00.006899 (Thread-834): sending response (<Response 1581 bytes [200 OK]>) to 10.0.44.8
2022-01-06 21:31:00.049773 (Thread-835): handling status request
2022-01-06 21:31:00.050026 (Thread-835): 21:31:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee45ca670>]}
2022-01-06 21:31:00.050417 (Thread-835): sending response (<Response 1581 bytes [200 OK]>) to 10.0.21.1
2022-01-06 21:31:28.794318 (Thread-836): handling status request
2022-01-06 21:31:28.794743 (Thread-836): 21:31:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee40981c0>]}
2022-01-06 21:31:28.819603 (Thread-836): sending response (<Response 1581 bytes [200 OK]>) to 10.0.44.8
2022-01-06 21:31:29.032127 (Thread-837): handling status request
2022-01-06 21:31:29.032476 (Thread-837): 21:31:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4221dc0>]}
2022-01-06 21:31:29.032942 (Thread-837): sending response (<Response 1581 bytes [200 OK]>) to 10.0.35.15
2022-01-06 21:31:29.185951 (Thread-838): handling cli_args request
2022-01-06 21:31:29.186227 (Thread-838): 21:31:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec41c86d0>]}
2022-01-06 21:31:31.230381 (Thread-838): sending response (<Response 138 bytes [200 OK]>) to 10.0.38.43
2022-01-06 21:31:31.325980 (MainThread): 21:31:31  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 21:31:31.326366 (MainThread): 21:31:31  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 21:31:31.331915 (MainThread): 21:31:31  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b60b715e-dab9-4ac0-8c91-eac781968cb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08e746d0a0>]}
2022-01-06 21:31:31.362948 (MainThread): 21:31:31  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b60b715e-dab9-4ac0-8c91-eac781968cb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08e7506910>]}
2022-01-06 21:31:31.363202 (MainThread): 21:31:31  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 21:31:31.364177 (MainThread): 21:31:31  
2022-01-06 21:31:31.364472 (MainThread): 21:31:31  Acquiring new redshift connection "master"
2022-01-06 21:31:31.365429 (ThreadPoolExecutor-0_0): 21:31:31  Acquiring new redshift connection "list_dev"
2022-01-06 21:31:31.375171 (ThreadPoolExecutor-0_0): 21:31:31  Using redshift connection "list_dev"
2022-01-06 21:31:31.375272 (ThreadPoolExecutor-0_0): 21:31:31  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 21:31:31.375538 (ThreadPoolExecutor-0_0): 21:31:31  Opening a new connection, currently in state init
2022-01-06 21:31:31.375633 (ThreadPoolExecutor-0_0): 21:31:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:31.396257 (ThreadPoolExecutor-0_0): 21:31:31  SQL status: SELECT in 0.02 seconds
2022-01-06 21:31:31.397343 (ThreadPoolExecutor-0_0): 21:31:31  On list_dev: Close
2022-01-06 21:31:31.398602 (ThreadPoolExecutor-1_0): 21:31:31  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 21:31:31.404782 (ThreadPoolExecutor-1_0): 21:31:31  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 21:31:31.404878 (ThreadPoolExecutor-1_0): 21:31:31  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 21:31:31.404957 (ThreadPoolExecutor-1_0): 21:31:31  Opening a new connection, currently in state closed
2022-01-06 21:31:31.405033 (ThreadPoolExecutor-1_0): 21:31:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:31.427009 (ThreadPoolExecutor-1_0): 21:31:31  SQL status: BEGIN in 0.02 seconds
2022-01-06 21:31:31.427176 (ThreadPoolExecutor-1_0): 21:31:31  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 21:31:31.427309 (ThreadPoolExecutor-1_0): 21:31:31  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 21:31:31.438482 (ThreadPoolExecutor-1_0): 21:31:31  SQL status: SELECT in 0.01 seconds
2022-01-06 21:31:31.440271 (ThreadPoolExecutor-1_0): 21:31:31  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 21:31:31.442131 (ThreadPoolExecutor-1_0): 21:31:31  On list_dev_dbt_nobodozie: Close
2022-01-06 21:31:31.446541 (MainThread): 21:31:31  Using redshift connection "master"
2022-01-06 21:31:31.446661 (MainThread): 21:31:31  On master: BEGIN
2022-01-06 21:31:31.446750 (MainThread): 21:31:31  Opening a new connection, currently in state init
2022-01-06 21:31:31.446829 (MainThread): 21:31:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:31.470932 (MainThread): 21:31:31  SQL status: BEGIN in 0.02 seconds
2022-01-06 21:31:31.471048 (MainThread): 21:31:31  Using redshift connection "master"
2022-01-06 21:31:31.471135 (MainThread): 21:31:31  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 21:31:31.500036 (MainThread): 21:31:31  SQL status: SELECT in 0.03 seconds
2022-01-06 21:31:31.501154 (MainThread): 21:31:31  On master: ROLLBACK
2022-01-06 21:31:31.503142 (MainThread): 21:31:31  Using redshift connection "master"
2022-01-06 21:31:31.503248 (MainThread): 21:31:31  On master: BEGIN
2022-01-06 21:31:31.506864 (MainThread): 21:31:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:31.506981 (MainThread): 21:31:31  On master: COMMIT
2022-01-06 21:31:31.507055 (MainThread): 21:31:31  Using redshift connection "master"
2022-01-06 21:31:31.507123 (MainThread): 21:31:31  On master: COMMIT
2022-01-06 21:31:31.508853 (MainThread): 21:31:31  SQL status: COMMIT in 0.0 seconds
2022-01-06 21:31:31.508988 (MainThread): 21:31:31  On master: Close
2022-01-06 21:31:31.509468 (MainThread): 21:31:31  Concurrency: 4 threads (target='default')
2022-01-06 21:31:31.509588 (MainThread): 21:31:31  
2022-01-06 21:31:31.512121 (Thread-1): 21:31:31  Began running node model.jaffel_shop.stg_customers
2022-01-06 21:31:31.512379 (Thread-1): 21:31:31  1 of 5 START view model dbt_nobodozie.stg_customers............................. [RUN]
2022-01-06 21:31:31.512628 (Thread-1): 21:31:31  Acquiring new redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:31.512722 (Thread-1): 21:31:31  Began compiling node model.jaffel_shop.stg_customers
2022-01-06 21:31:31.512813 (Thread-1): 21:31:31  Compiling model.jaffel_shop.stg_customers
2022-01-06 21:31:31.514140 (Thread-1): 21:31:31  Writing injected SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 21:31:31.514379 (Thread-2): 21:31:31  Began running node model.jaffel_shop.stg_orders
2022-01-06 21:31:31.514615 (Thread-2): 21:31:31  2 of 5 START view model dbt_nobodozie.stg_orders................................ [RUN]
2022-01-06 21:31:31.514871 (Thread-2): 21:31:31  Acquiring new redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:31.514958 (Thread-2): 21:31:31  Began compiling node model.jaffel_shop.stg_orders
2022-01-06 21:31:31.515036 (Thread-2): 21:31:31  Compiling model.jaffel_shop.stg_orders
2022-01-06 21:31:31.516149 (Thread-2): 21:31:31  Writing injected SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 21:31:31.516505 (Thread-3): 21:31:31  Began running node model.jaffel_shop.stg_payments
2022-01-06 21:31:31.516728 (Thread-3): 21:31:31  3 of 5 START view model dbt_nobodozie.stg_payments.............................. [RUN]
2022-01-06 21:31:31.516987 (Thread-3): 21:31:31  Acquiring new redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:31.517073 (Thread-3): 21:31:31  Began compiling node model.jaffel_shop.stg_payments
2022-01-06 21:31:31.517148 (Thread-3): 21:31:31  Compiling model.jaffel_shop.stg_payments
2022-01-06 21:31:31.518210 (Thread-3): 21:31:31  Writing injected SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 21:31:31.531669 (Thread-1): 21:31:31  finished collecting timing info
2022-01-06 21:31:31.531807 (Thread-1): 21:31:31  Began executing node model.jaffel_shop.stg_customers
2022-01-06 21:31:31.537010 (Thread-3): 21:31:31  finished collecting timing info
2022-01-06 21:31:31.564431 (Thread-839): handling poll request
2022-01-06 21:31:31.564781 (Thread-839): 21:31:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4226ee0>]}
2022-01-06 21:31:31.566193 (Thread-839): sending response (<Response 24924 bytes [200 OK]>) to 10.0.35.15
2022-01-06 21:31:31.537142 (Thread-3): 21:31:31  Began executing node model.jaffel_shop.stg_payments
2022-01-06 21:31:31.548850 (Thread-2): 21:31:31  finished collecting timing info
2022-01-06 21:31:31.548980 (Thread-2): 21:31:31  Began executing node model.jaffel_shop.stg_orders
2022-01-06 21:31:31.580291 (Thread-2): 21:31:31  Writing runtime SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 21:31:31.581694 (Thread-1): 21:31:31  Writing runtime SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 21:31:31.582592 (Thread-3): 21:31:31  Writing runtime SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 21:31:31.597680 (Thread-2): 21:31:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:31.597795 (Thread-2): 21:31:31  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 21:31:31.597883 (Thread-2): 21:31:31  Opening a new connection, currently in state init
2022-01-06 21:31:31.597964 (Thread-2): 21:31:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:31.598222 (Thread-1): 21:31:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:31.598338 (Thread-1): 21:31:31  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 21:31:31.598421 (Thread-1): 21:31:31  Opening a new connection, currently in state closed
2022-01-06 21:31:31.598498 (Thread-1): 21:31:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:31.598743 (Thread-3): 21:31:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:31.598843 (Thread-3): 21:31:31  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 21:31:31.598922 (Thread-3): 21:31:31  Opening a new connection, currently in state init
2022-01-06 21:31:31.598997 (Thread-3): 21:31:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:31.630818 (Thread-3): 21:31:31  SQL status: BEGIN in 0.03 seconds
2022-01-06 21:31:31.630937 (Thread-3): 21:31:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:31.631015 (Thread-3): 21:31:31  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */


  create view "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" as (
    with payment as (

    select
        id as payment_id,
        orderid as order_id,
        paymentmethod as payment_method,

        -- amount is stored in cents, convert it to dollars
        amount/100 as amount,
        status

    from stripe.payment

)
select * from payment
  ) ;

2022-01-06 21:31:31.631576 (Thread-2): 21:31:31  SQL status: BEGIN in 0.03 seconds
2022-01-06 21:31:31.631698 (Thread-2): 21:31:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:31.631775 (Thread-2): 21:31:31  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */


  create view "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" as (
    with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
  ) ;

2022-01-06 21:31:31.631932 (Thread-1): 21:31:31  SQL status: BEGIN in 0.03 seconds
2022-01-06 21:31:31.632043 (Thread-1): 21:31:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:31.632117 (Thread-1): 21:31:31  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */


  create view "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
  ) ;

2022-01-06 21:31:31.638623 (Thread-3): 21:31:31  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 21:31:31.644134 (Thread-1): 21:31:31  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 21:31:31.648149 (Thread-1): 21:31:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:31.648261 (Thread-1): 21:31:31  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers" rename to "stg_customers__dbt_backup"
2022-01-06 21:31:31.648418 (Thread-2): 21:31:31  SQL status: CREATE VIEW in 0.02 seconds
2022-01-06 21:31:31.650278 (Thread-2): 21:31:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:31.650485 (Thread-2): 21:31:31  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders" rename to "stg_orders__dbt_backup"
2022-01-06 21:31:31.650838 (Thread-3): 21:31:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:31.650946 (Thread-3): 21:31:31  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments" rename to "stg_payments__dbt_backup"
2022-01-06 21:31:31.651154 (Thread-1): 21:31:31  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:31:31.653963 (Thread-1): 21:31:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:31.654076 (Thread-1): 21:31:31  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" rename to "stg_customers"
2022-01-06 21:31:31.654289 (Thread-3): 21:31:31  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:31:31.655973 (Thread-3): 21:31:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:31.656071 (Thread-3): 21:31:31  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" rename to "stg_payments"
2022-01-06 21:31:31.656214 (Thread-2): 21:31:31  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 21:31:31.658032 (Thread-2): 21:31:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:31.658127 (Thread-2): 21:31:31  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" rename to "stg_orders"
2022-01-06 21:31:31.658346 (Thread-1): 21:31:31  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:31:31.663493 (Thread-3): 21:31:31  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 21:31:31.668402 (Thread-3): 21:31:31  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 21:31:31.670415 (Thread-1): 21:31:31  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 21:31:31.670521 (Thread-1): 21:31:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:31.670605 (Thread-1): 21:31:31  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 21:31:31.670729 (Thread-3): 21:31:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:31.670825 (Thread-3): 21:31:31  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 21:31:31.671029 (Thread-2): 21:31:31  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 21:31:31.671952 (Thread-2): 21:31:31  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 21:31:31.672047 (Thread-2): 21:31:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:31.672118 (Thread-2): 21:31:31  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 21:31:31.729020 (Thread-1): 21:31:31  SQL status: COMMIT in 0.06 seconds
2022-01-06 21:31:31.729301 (Thread-1): 21:31:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:31.729394 (Thread-1): 21:31:31  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 21:31:31.729742 (Thread-3): 21:31:31  SQL status: COMMIT in 0.06 seconds
2022-01-06 21:31:31.730096 (Thread-2): 21:31:31  SQL status: COMMIT in 0.06 seconds
2022-01-06 21:31:31.731817 (Thread-1): 21:31:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:31.735950 (Thread-1): 21:31:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:31.736047 (Thread-1): 21:31:31  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
drop view if exists "dev"."dbt_nobodozie"."stg_customers__dbt_backup" cascade
2022-01-06 21:31:31.740720 (Thread-1): 21:31:31  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 21:31:31.741403 (Thread-1): 21:31:31  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 21:31:31.741497 (Thread-1): 21:31:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:31.741569 (Thread-1): 21:31:31  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 21:31:31.769004 (Thread-1): 21:31:31  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:31:31.769169 (Thread-1): 21:31:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:31.769315 (Thread-1): 21:31:31  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 21:31:31.771508 (Thread-1): 21:31:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:31.772136 (Thread-1): 21:31:31  finished collecting timing info
2022-01-06 21:31:31.772323 (Thread-1): 21:31:31  On model.jaffel_shop.stg_customers: ROLLBACK
2022-01-06 21:31:31.772544 (Thread-3): 21:31:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:31.772649 (Thread-3): 21:31:31  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 21:31:31.775498 (Thread-1): 21:31:31  On model.jaffel_shop.stg_customers: Close
2022-01-06 21:31:31.775667 (Thread-3): 21:31:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:31.776854 (Thread-3): 21:31:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:31.776949 (Thread-3): 21:31:31  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
drop view if exists "dev"."dbt_nobodozie"."stg_payments__dbt_backup" cascade
2022-01-06 21:31:31.777435 (Thread-1): 21:31:31  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b60b715e-dab9-4ac0-8c91-eac781968cb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08e4395a00>]}
2022-01-06 21:31:31.777765 (Thread-1): 21:31:31  1 of 5 OK created view model dbt_nobodozie.stg_customers........................ [CREATE VIEW in 0.26s]
2022-01-06 21:31:31.777881 (Thread-1): 21:31:31  Finished running node model.jaffel_shop.stg_customers
2022-01-06 21:31:31.785337 (Thread-3): 21:31:31  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 21:31:31.786050 (Thread-3): 21:31:31  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 21:31:31.786144 (Thread-3): 21:31:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:31.786217 (Thread-3): 21:31:31  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 21:31:31.815342 (Thread-3): 21:31:31  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:31:31.815461 (Thread-3): 21:31:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:31.815535 (Thread-3): 21:31:31  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 21:31:31.817526 (Thread-3): 21:31:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:31.817946 (Thread-3): 21:31:31  finished collecting timing info
2022-01-06 21:31:31.818070 (Thread-3): 21:31:31  On model.jaffel_shop.stg_payments: ROLLBACK
2022-01-06 21:31:31.818272 (Thread-2): 21:31:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:31.818379 (Thread-2): 21:31:31  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 21:31:31.821073 (Thread-3): 21:31:31  On model.jaffel_shop.stg_payments: Close
2022-01-06 21:31:31.821266 (Thread-2): 21:31:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:31.822665 (Thread-2): 21:31:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:31.822762 (Thread-2): 21:31:31  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
drop view if exists "dev"."dbt_nobodozie"."stg_orders__dbt_backup" cascade
2022-01-06 21:31:31.823146 (Thread-3): 21:31:31  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b60b715e-dab9-4ac0-8c91-eac781968cb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08e43a2c10>]}
2022-01-06 21:31:31.823443 (Thread-3): 21:31:31  3 of 5 OK created view model dbt_nobodozie.stg_payments......................... [CREATE VIEW in 0.31s]
2022-01-06 21:31:31.823550 (Thread-3): 21:31:31  Finished running node model.jaffel_shop.stg_payments
2022-01-06 21:31:31.829347 (Thread-2): 21:31:31  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 21:31:31.829994 (Thread-2): 21:31:31  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 21:31:31.830101 (Thread-2): 21:31:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:31.830175 (Thread-2): 21:31:31  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 21:31:31.859413 (Thread-2): 21:31:31  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:31:31.859539 (Thread-2): 21:31:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:31.859616 (Thread-2): 21:31:31  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 21:31:31.861665 (Thread-2): 21:31:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:31.862082 (Thread-2): 21:31:31  finished collecting timing info
2022-01-06 21:31:31.862207 (Thread-2): 21:31:31  On model.jaffel_shop.stg_orders: ROLLBACK
2022-01-06 21:31:31.863931 (Thread-2): 21:31:31  On model.jaffel_shop.stg_orders: Close
2022-01-06 21:31:31.864349 (Thread-2): 21:31:31  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b60b715e-dab9-4ac0-8c91-eac781968cb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08e63e2e50>]}
2022-01-06 21:31:31.864644 (Thread-2): 21:31:31  2 of 5 OK created view model dbt_nobodozie.stg_orders........................... [CREATE VIEW in 0.35s]
2022-01-06 21:31:31.864752 (Thread-2): 21:31:31  Finished running node model.jaffel_shop.stg_orders
2022-01-06 21:31:31.865623 (Thread-4): 21:31:31  Began running node model.jaffel_shop.dim_customers
2022-01-06 21:31:31.865872 (Thread-4): 21:31:31  4 of 5 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 21:31:31.866127 (Thread-4): 21:31:31  Acquiring new redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:31.866232 (Thread-4): 21:31:31  Began compiling node model.jaffel_shop.dim_customers
2022-01-06 21:31:31.866335 (Thread-4): 21:31:31  Compiling model.jaffel_shop.dim_customers
2022-01-06 21:31:31.869189 (Thread-4): 21:31:31  Writing injected SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 21:31:31.869413 (Thread-1): 21:31:31  Began running node model.jaffel_shop.fct_orders
2022-01-06 21:31:31.869623 (Thread-1): 21:31:31  5 of 5 START view model dbt_nobodozie.fct_orders................................ [RUN]
2022-01-06 21:31:31.869843 (Thread-1): 21:31:31  Acquiring new redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:31.869933 (Thread-1): 21:31:31  Began compiling node model.jaffel_shop.fct_orders
2022-01-06 21:31:31.870013 (Thread-1): 21:31:31  Compiling model.jaffel_shop.fct_orders
2022-01-06 21:31:31.872183 (Thread-1): 21:31:31  Writing injected SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 21:31:31.887333 (Thread-1): 21:31:31  finished collecting timing info
2022-01-06 21:31:31.887467 (Thread-1): 21:31:31  Began executing node model.jaffel_shop.fct_orders
2022-01-06 21:31:31.889372 (Thread-1): 21:31:31  Writing runtime SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 21:31:31.889597 (Thread-4): 21:31:31  finished collecting timing info
2022-01-06 21:31:31.889731 (Thread-4): 21:31:31  Began executing node model.jaffel_shop.dim_customers
2022-01-06 21:31:31.915648 (Thread-4): 21:31:31  Writing runtime SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 21:31:31.915922 (Thread-1): 21:31:31  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:31.916027 (Thread-1): 21:31:31  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 21:31:31.916109 (Thread-1): 21:31:31  Opening a new connection, currently in state closed
2022-01-06 21:31:31.916188 (Thread-1): 21:31:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:31.930037 (Thread-4): 21:31:31  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:31.930163 (Thread-4): 21:31:31  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 21:31:31.930243 (Thread-4): 21:31:31  Opening a new connection, currently in state init
2022-01-06 21:31:31.930320 (Thread-4): 21:31:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:31.936977 (Thread-1): 21:31:31  SQL status: BEGIN in 0.02 seconds
2022-01-06 21:31:31.937090 (Thread-1): 21:31:31  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:31.937166 (Thread-1): 21:31:31  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */


  create view "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" as (
    with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),


order_payments as (
    select
        order_id,
        sum(case when status = 'success' then amount end ) as amount
    from payment
    group by 1
),



final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
  ) ;

2022-01-06 21:31:31.948816 (Thread-1): 21:31:31  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 21:31:31.950531 (Thread-1): 21:31:31  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:31.950624 (Thread-1): 21:31:31  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
alter table "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" rename to "fct_orders"
2022-01-06 21:31:31.951519 (Thread-4): 21:31:31  SQL status: BEGIN in 0.02 seconds
2022-01-06 21:31:31.951638 (Thread-4): 21:31:31  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:31.951714 (Thread-4): 21:31:31  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),

lifetime_value as (

    select 
        orders.customer_id as customer_id,
        orders.order_id as order_id,
        sum(payment.amount) total_value

    from orders 
    
    left join payment using (order_id)
    group by 1,2
),


customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,
        lifetime_value.order_id,
        lifetime_value.total_value
    from customers

    left join customer_orders using (customer_id)
    left join lifetime_value using (customer_id)
)

select * from final
  );
2022-01-06 21:31:31.952991 (Thread-1): 21:31:31  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:31:31.954092 (Thread-1): 21:31:31  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 21:31:31.954187 (Thread-1): 21:31:31  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:31.954258 (Thread-1): 21:31:31  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 21:31:31.992037 (Thread-1): 21:31:31  SQL status: COMMIT in 0.04 seconds
2022-01-06 21:31:31.992248 (Thread-1): 21:31:31  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:31.992328 (Thread-1): 21:31:31  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 21:31:31.995010 (Thread-1): 21:31:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:31.996142 (Thread-1): 21:31:31  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:31.996239 (Thread-1): 21:31:31  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
drop view if exists "dev"."dbt_nobodozie"."fct_orders__dbt_backup" cascade
2022-01-06 21:31:31.998702 (Thread-1): 21:31:31  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 21:31:31.999517 (Thread-1): 21:31:31  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 21:31:31.999612 (Thread-1): 21:31:31  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:31.999684 (Thread-1): 21:31:31  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 21:31:32.037067 (Thread-1): 21:31:32  SQL status: COMMIT in 0.04 seconds
2022-01-06 21:31:32.037175 (Thread-1): 21:31:32  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:32.037267 (Thread-1): 21:31:32  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 21:31:32.042900 (Thread-1): 21:31:32  SQL status: BEGIN in 0.01 seconds
2022-01-06 21:31:32.043272 (Thread-1): 21:31:32  finished collecting timing info
2022-01-06 21:31:32.043396 (Thread-1): 21:31:32  On model.jaffel_shop.fct_orders: ROLLBACK
2022-01-06 21:31:32.045635 (Thread-1): 21:31:32  On model.jaffel_shop.fct_orders: Close
2022-01-06 21:31:32.046043 (Thread-1): 21:31:32  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b60b715e-dab9-4ac0-8c91-eac781968cb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08e42d3190>]}
2022-01-06 21:31:32.046334 (Thread-1): 21:31:32  5 of 5 OK created view model dbt_nobodozie.fct_orders........................... [CREATE VIEW in 0.18s]
2022-01-06 21:31:32.046442 (Thread-1): 21:31:32  Finished running node model.jaffel_shop.fct_orders
2022-01-06 21:31:32.116011 (Thread-4): 21:31:32  SQL status: SELECT in 0.16 seconds
2022-01-06 21:31:32.117823 (Thread-4): 21:31:32  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:32.117923 (Thread-4): 21:31:32  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 21:31:32.120668 (Thread-4): 21:31:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:31:32.123628 (Thread-4): 21:31:32  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:32.123722 (Thread-4): 21:31:32  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 21:31:32.126364 (Thread-4): 21:31:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:31:32.130742 (Thread-4): 21:31:32  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 21:31:32.130841 (Thread-4): 21:31:32  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:32.130913 (Thread-4): 21:31:32  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 21:31:32.167920 (Thread-4): 21:31:32  SQL status: COMMIT in 0.04 seconds
2022-01-06 21:31:32.168122 (Thread-4): 21:31:32  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:32.168201 (Thread-4): 21:31:32  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 21:31:32.170348 (Thread-4): 21:31:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:32.171550 (Thread-4): 21:31:32  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:32.171643 (Thread-4): 21:31:32  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 21:31:32.175179 (Thread-4): 21:31:32  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 21:31:32.175774 (Thread-4): 21:31:32  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 21:31:32.175865 (Thread-4): 21:31:32  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:32.175937 (Thread-4): 21:31:32  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 21:31:32.205890 (Thread-4): 21:31:32  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:31:32.206000 (Thread-4): 21:31:32  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:32.206071 (Thread-4): 21:31:32  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 21:31:32.208100 (Thread-4): 21:31:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:32.208450 (Thread-4): 21:31:32  finished collecting timing info
2022-01-06 21:31:32.208569 (Thread-4): 21:31:32  On model.jaffel_shop.dim_customers: ROLLBACK
2022-01-06 21:31:32.210292 (Thread-4): 21:31:32  On model.jaffel_shop.dim_customers: Close
2022-01-06 21:31:32.210682 (Thread-4): 21:31:32  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b60b715e-dab9-4ac0-8c91-eac781968cb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08e4342280>]}
2022-01-06 21:31:32.210958 (Thread-4): 21:31:32  4 of 5 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.34s]
2022-01-06 21:31:32.211061 (Thread-4): 21:31:32  Finished running node model.jaffel_shop.dim_customers
2022-01-06 21:31:32.212360 (MainThread): 21:31:32  Acquiring new redshift connection "master"
2022-01-06 21:31:32.212502 (MainThread): 21:31:32  Using redshift connection "master"
2022-01-06 21:31:32.212576 (MainThread): 21:31:32  On master: BEGIN
2022-01-06 21:31:32.212651 (MainThread): 21:31:32  Opening a new connection, currently in state closed
2022-01-06 21:31:32.212725 (MainThread): 21:31:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:32.236778 (MainThread): 21:31:32  SQL status: BEGIN in 0.02 seconds
2022-01-06 21:31:32.236893 (MainThread): 21:31:32  On master: COMMIT
2022-01-06 21:31:32.236967 (MainThread): 21:31:32  Using redshift connection "master"
2022-01-06 21:31:32.237037 (MainThread): 21:31:32  On master: COMMIT
2022-01-06 21:31:32.238833 (MainThread): 21:31:32  SQL status: COMMIT in 0.0 seconds
2022-01-06 21:31:32.238945 (MainThread): 21:31:32  On master: Close
2022-01-06 21:31:32.239371 (MainThread): 21:31:32  
2022-01-06 21:31:32.239485 (MainThread): 21:31:32  Finished running 4 view models, 1 table model in 0.88s.
2022-01-06 21:31:32.239565 (MainThread): 21:31:32  Connection 'master' was properly closed.
2022-01-06 21:31:32.239631 (MainThread): 21:31:32  Connection 'model.jaffel_shop.fct_orders' was properly closed.
2022-01-06 21:31:32.239708 (MainThread): 21:31:32  Connection 'model.jaffel_shop.stg_orders' was properly closed.
2022-01-06 21:31:32.239791 (MainThread): 21:31:32  Connection 'model.jaffel_shop.stg_payments' was properly closed.
2022-01-06 21:31:32.239861 (MainThread): 21:31:32  Connection 'model.jaffel_shop.dim_customers' was properly closed.
2022-01-06 21:31:32.308846 (MainThread): 21:31:32  
2022-01-06 21:31:32.308998 (MainThread): 21:31:32  Completed successfully
2022-01-06 21:31:32.309097 (MainThread): 21:31:32  
2022-01-06 21:31:32.309182 (MainThread): 21:31:32  Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2022-01-06 21:31:33.295835 (Thread-840): handling poll request
2022-01-06 21:31:33.296219 (Thread-840): 21:31:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec415bd30>]}
2022-01-06 21:31:33.299553 (Thread-840): sending response (<Response 102353 bytes [200 OK]>) to 10.0.2.195
2022-01-06 21:31:34.003335 (Thread-841): handling status request
2022-01-06 21:31:34.003710 (Thread-841): 21:31:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec415bee0>]}
2022-01-06 21:31:34.004244 (Thread-841): sending response (<Response 1581 bytes [200 OK]>) to 10.0.8.128
2022-01-06 21:31:34.334693 (Thread-842): handling status request
2022-01-06 21:31:34.335074 (Thread-842): 21:31:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec41802e0>]}
2022-01-06 21:31:34.335555 (Thread-842): sending response (<Response 1581 bytes [200 OK]>) to 10.0.27.154
2022-01-06 21:31:43.591119 (Thread-843): 21:31:43  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 21:31:43.591327 (Thread-843): 21:31:43  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 21:31:43.596271 (Thread-843): 21:31:43  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec40cb190>]}
2022-01-06 21:31:44.202223 (Thread-844): handling status request
2022-01-06 21:31:44.202601 (Thread-844): 21:31:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec411fac0>]}
2022-01-06 21:31:44.203103 (Thread-844): sending response (<Response 1244 bytes [200 OK]>) to 10.0.31.115
2022-01-06 21:31:44.392800 (Thread-845): handling status request
2022-01-06 21:31:44.393098 (Thread-845): 21:31:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec411f760>]}
2022-01-06 21:31:44.393582 (Thread-845): sending response (<Response 1244 bytes [200 OK]>) to 10.0.11.87
2022-01-06 21:31:48.281577 (Thread-846): 21:31:48  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 21:31:48.281775 (Thread-846): 21:31:48  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 21:31:48.286455 (Thread-846): 21:31:48  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc701cb20>]}
2022-01-06 21:31:48.834036 (Thread-847): handling status request
2022-01-06 21:31:48.834404 (Thread-847): 21:31:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec422c130>]}
2022-01-06 21:31:48.834907 (Thread-847): sending response (<Response 1244 bytes [200 OK]>) to 10.0.35.37
2022-01-06 21:31:48.858064 (Thread-848): handling status request
2022-01-06 21:31:48.858331 (Thread-848): 21:31:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec422c6a0>]}
2022-01-06 21:31:48.858706 (Thread-848): sending response (<Response 1244 bytes [200 OK]>) to 10.0.8.128
2022-01-06 21:31:54.353867 (Thread-849): handling status request
2022-01-06 21:31:54.354253 (Thread-849): 21:31:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4233df0>]}
2022-01-06 21:31:54.354733 (Thread-849): sending response (<Response 1244 bytes [200 OK]>) to 10.0.2.195
2022-01-06 21:31:54.694234 (Thread-850): handling cli_args request
2022-01-06 21:31:54.694497 (Thread-850): 21:31:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4233e80>]}
2022-01-06 21:31:54.879108 (Thread-851): handling status request
2022-01-06 21:31:54.879867 (Thread-851): 21:31:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec408d1f0>]}
2022-01-06 21:31:54.880697 (Thread-851): sending response (<Response 1244 bytes [200 OK]>) to 10.0.21.1
2022-01-06 21:31:56.735407 (Thread-850): sending response (<Response 138 bytes [200 OK]>) to 10.0.38.43
2022-01-06 21:31:56.836311 (MainThread): 21:31:56  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 21:31:56.836772 (MainThread): 21:31:56  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 21:31:56.844846 (MainThread): 21:31:56  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cc7570db-ef1a-4591-bf8f-35b3baeab29e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb99b744fd0>]}
2022-01-06 21:31:56.870959 (MainThread): 21:31:56  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cc7570db-ef1a-4591-bf8f-35b3baeab29e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb99bfb4670>]}
2022-01-06 21:31:56.871191 (MainThread): 21:31:56  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 21:31:56.872140 (MainThread): 21:31:56  
2022-01-06 21:31:56.872403 (MainThread): 21:31:56  Acquiring new redshift connection "master"
2022-01-06 21:31:56.873327 (ThreadPoolExecutor-0_0): 21:31:56  Acquiring new redshift connection "list_dev"
2022-01-06 21:31:56.883061 (ThreadPoolExecutor-0_0): 21:31:56  Using redshift connection "list_dev"
2022-01-06 21:31:56.883164 (ThreadPoolExecutor-0_0): 21:31:56  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 21:31:56.883247 (ThreadPoolExecutor-0_0): 21:31:56  Opening a new connection, currently in state init
2022-01-06 21:31:56.883328 (ThreadPoolExecutor-0_0): 21:31:56  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:56.904543 (ThreadPoolExecutor-0_0): 21:31:56  SQL status: SELECT in 0.02 seconds
2022-01-06 21:31:56.905566 (ThreadPoolExecutor-0_0): 21:31:56  On list_dev: Close
2022-01-06 21:31:56.906783 (ThreadPoolExecutor-1_0): 21:31:56  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 21:31:56.912823 (ThreadPoolExecutor-1_0): 21:31:56  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 21:31:56.912923 (ThreadPoolExecutor-1_0): 21:31:56  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 21:31:56.913001 (ThreadPoolExecutor-1_0): 21:31:56  Opening a new connection, currently in state closed
2022-01-06 21:31:56.913077 (ThreadPoolExecutor-1_0): 21:31:56  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:56.935135 (ThreadPoolExecutor-1_0): 21:31:56  SQL status: BEGIN in 0.02 seconds
2022-01-06 21:31:56.935245 (ThreadPoolExecutor-1_0): 21:31:56  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 21:31:56.935319 (ThreadPoolExecutor-1_0): 21:31:56  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 21:31:56.946469 (ThreadPoolExecutor-1_0): 21:31:56  SQL status: SELECT in 0.01 seconds
2022-01-06 21:31:56.947497 (ThreadPoolExecutor-1_0): 21:31:56  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 21:31:56.949302 (ThreadPoolExecutor-1_0): 21:31:56  On list_dev_dbt_nobodozie: Close
2022-01-06 21:31:56.953356 (MainThread): 21:31:56  Using redshift connection "master"
2022-01-06 21:31:56.953466 (MainThread): 21:31:56  On master: BEGIN
2022-01-06 21:31:56.953545 (MainThread): 21:31:56  Opening a new connection, currently in state init
2022-01-06 21:31:56.953620 (MainThread): 21:31:56  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:57.131891 (Thread-852): handling poll request
2022-01-06 21:31:57.132191 (Thread-852): 21:31:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efee4496be0>]}
2022-01-06 21:31:57.133058 (Thread-852): sending response (<Response 9978 bytes [200 OK]>) to 10.0.14.253
2022-01-06 21:31:57.661374 (MainThread): 21:31:57  SQL status: BEGIN in 0.71 seconds
2022-01-06 21:31:57.661509 (MainThread): 21:31:57  Using redshift connection "master"
2022-01-06 21:31:57.661589 (MainThread): 21:31:57  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 21:31:57.690202 (MainThread): 21:31:57  SQL status: SELECT in 0.03 seconds
2022-01-06 21:31:57.691517 (MainThread): 21:31:57  On master: ROLLBACK
2022-01-06 21:31:57.693375 (MainThread): 21:31:57  Using redshift connection "master"
2022-01-06 21:31:57.693483 (MainThread): 21:31:57  On master: BEGIN
2022-01-06 21:31:57.697083 (MainThread): 21:31:57  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:57.697197 (MainThread): 21:31:57  On master: COMMIT
2022-01-06 21:31:57.697296 (MainThread): 21:31:57  Using redshift connection "master"
2022-01-06 21:31:57.697365 (MainThread): 21:31:57  On master: COMMIT
2022-01-06 21:31:57.699126 (MainThread): 21:31:57  SQL status: COMMIT in 0.0 seconds
2022-01-06 21:31:57.699250 (MainThread): 21:31:57  On master: Close
2022-01-06 21:31:57.699661 (MainThread): 21:31:57  Concurrency: 4 threads (target='default')
2022-01-06 21:31:57.699776 (MainThread): 21:31:57  
2022-01-06 21:31:57.702101 (Thread-1): 21:31:57  Began running node model.jaffel_shop.stg_customers
2022-01-06 21:31:57.702358 (Thread-1): 21:31:57  1 of 5 START view model dbt_nobodozie.stg_customers............................. [RUN]
2022-01-06 21:31:57.702606 (Thread-1): 21:31:57  Acquiring new redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:57.702698 (Thread-1): 21:31:57  Began compiling node model.jaffel_shop.stg_customers
2022-01-06 21:31:57.702786 (Thread-1): 21:31:57  Compiling model.jaffel_shop.stg_customers
2022-01-06 21:31:57.703995 (Thread-1): 21:31:57  Writing injected SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 21:31:57.704227 (Thread-2): 21:31:57  Began running node model.jaffel_shop.stg_orders
2022-01-06 21:31:57.704467 (Thread-2): 21:31:57  2 of 5 START view model dbt_nobodozie.stg_orders................................ [RUN]
2022-01-06 21:31:57.704722 (Thread-2): 21:31:57  Acquiring new redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:57.704809 (Thread-2): 21:31:57  Began compiling node model.jaffel_shop.stg_orders
2022-01-06 21:31:57.704889 (Thread-2): 21:31:57  Compiling model.jaffel_shop.stg_orders
2022-01-06 21:31:57.706029 (Thread-2): 21:31:57  Writing injected SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 21:31:57.706332 (Thread-3): 21:31:57  Began running node model.jaffel_shop.stg_payments
2022-01-06 21:31:57.706554 (Thread-3): 21:31:57  3 of 5 START view model dbt_nobodozie.stg_payments.............................. [RUN]
2022-01-06 21:31:57.706808 (Thread-3): 21:31:57  Acquiring new redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:57.706895 (Thread-3): 21:31:57  Began compiling node model.jaffel_shop.stg_payments
2022-01-06 21:31:57.706973 (Thread-3): 21:31:57  Compiling model.jaffel_shop.stg_payments
2022-01-06 21:31:57.707986 (Thread-3): 21:31:57  Writing injected SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 21:31:57.723218 (Thread-2): 21:31:57  finished collecting timing info
2022-01-06 21:31:57.723371 (Thread-2): 21:31:57  Began executing node model.jaffel_shop.stg_orders
2022-01-06 21:31:57.728388 (Thread-3): 21:31:57  finished collecting timing info
2022-01-06 21:31:57.728514 (Thread-3): 21:31:57  Began executing node model.jaffel_shop.stg_payments
2022-01-06 21:31:57.746618 (Thread-1): 21:31:57  finished collecting timing info
2022-01-06 21:31:57.746804 (Thread-1): 21:31:57  Began executing node model.jaffel_shop.stg_customers
2022-01-06 21:31:57.773008 (Thread-2): 21:31:57  Writing runtime SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 21:31:57.774320 (Thread-3): 21:31:57  Writing runtime SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 21:31:57.774435 (Thread-1): 21:31:57  Writing runtime SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 21:31:57.792078 (Thread-2): 21:31:57  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:57.792196 (Thread-2): 21:31:57  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 21:31:57.792282 (Thread-2): 21:31:57  Opening a new connection, currently in state init
2022-01-06 21:31:57.792362 (Thread-2): 21:31:57  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:57.792616 (Thread-3): 21:31:57  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:57.792716 (Thread-3): 21:31:57  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 21:31:57.792796 (Thread-3): 21:31:57  Opening a new connection, currently in state init
2022-01-06 21:31:57.792873 (Thread-3): 21:31:57  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:57.793122 (Thread-1): 21:31:57  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:57.793246 (Thread-1): 21:31:57  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 21:31:57.793327 (Thread-1): 21:31:57  Opening a new connection, currently in state closed
2022-01-06 21:31:57.793404 (Thread-1): 21:31:57  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:57.820291 (Thread-2): 21:31:57  SQL status: BEGIN in 0.03 seconds
2022-01-06 21:31:57.820411 (Thread-2): 21:31:57  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:57.820490 (Thread-2): 21:31:57  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */


  create view "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" as (
    with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
  ) ;

2022-01-06 21:31:57.827361 (Thread-1): 21:31:57  SQL status: BEGIN in 0.03 seconds
2022-01-06 21:31:57.827473 (Thread-1): 21:31:57  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:57.827548 (Thread-1): 21:31:57  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */


  create view "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
  ) ;

2022-01-06 21:31:57.828585 (Thread-3): 21:31:57  SQL status: BEGIN in 0.04 seconds
2022-01-06 21:31:57.828703 (Thread-3): 21:31:57  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:57.828781 (Thread-3): 21:31:57  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */


  create view "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" as (
    with payment as (

    select
        id as payment_id,
        orderid as order_id,
        paymentmethod as payment_method,

        -- amount is stored in cents, convert it to dollars
        amount/100 as amount,
        status

    from stripe.payment

)
select * from payment
  ) ;

2022-01-06 21:31:57.835187 (Thread-1): 21:31:57  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 21:31:57.840728 (Thread-3): 21:31:57  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 21:31:57.844529 (Thread-3): 21:31:57  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:57.844628 (Thread-3): 21:31:57  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments" rename to "stg_payments__dbt_backup"
2022-01-06 21:31:57.844790 (Thread-2): 21:31:57  SQL status: CREATE VIEW in 0.02 seconds
2022-01-06 21:31:57.847383 (Thread-2): 21:31:57  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:57.847489 (Thread-2): 21:31:57  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders" rename to "stg_orders__dbt_backup"
2022-01-06 21:31:57.848027 (Thread-1): 21:31:57  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:57.848175 (Thread-1): 21:31:57  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers" rename to "stg_customers__dbt_backup"
2022-01-06 21:31:57.848354 (Thread-3): 21:31:57  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:31:57.850073 (Thread-3): 21:31:57  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:57.850185 (Thread-3): 21:31:57  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" rename to "stg_payments"
2022-01-06 21:31:57.850398 (Thread-2): 21:31:57  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:31:57.852236 (Thread-2): 21:31:57  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:57.852334 (Thread-2): 21:31:57  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" rename to "stg_orders"
2022-01-06 21:31:57.852606 (Thread-1): 21:31:57  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:31:57.854745 (Thread-1): 21:31:57  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:57.854844 (Thread-1): 21:31:57  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" rename to "stg_customers"
2022-01-06 21:31:57.855071 (Thread-3): 21:31:57  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:31:57.860268 (Thread-1): 21:31:57  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 21:31:57.866605 (Thread-1): 21:31:57  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 21:31:57.866702 (Thread-1): 21:31:57  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:57.866774 (Thread-1): 21:31:57  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 21:31:57.868548 (Thread-3): 21:31:57  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 21:31:57.868652 (Thread-3): 21:31:57  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:57.868727 (Thread-3): 21:31:57  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 21:31:57.868880 (Thread-2): 21:31:57  SQL status: ALTER TABLE in 0.02 seconds
2022-01-06 21:31:57.869856 (Thread-2): 21:31:57  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 21:31:57.869952 (Thread-2): 21:31:57  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:57.870025 (Thread-2): 21:31:57  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 21:31:57.923967 (Thread-1): 21:31:57  SQL status: COMMIT in 0.06 seconds
2022-01-06 21:31:57.924182 (Thread-1): 21:31:57  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:57.924263 (Thread-1): 21:31:57  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 21:31:57.924598 (Thread-3): 21:31:57  SQL status: COMMIT in 0.06 seconds
2022-01-06 21:31:57.924954 (Thread-2): 21:31:57  SQL status: COMMIT in 0.05 seconds
2022-01-06 21:31:57.926312 (Thread-1): 21:31:57  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:57.930307 (Thread-1): 21:31:57  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:57.930407 (Thread-1): 21:31:57  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
drop view if exists "dev"."dbt_nobodozie"."stg_customers__dbt_backup" cascade
2022-01-06 21:31:57.934264 (Thread-1): 21:31:57  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 21:31:57.934866 (Thread-1): 21:31:57  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 21:31:57.934957 (Thread-1): 21:31:57  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:57.935030 (Thread-1): 21:31:57  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 21:31:57.962468 (Thread-1): 21:31:57  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:31:57.962583 (Thread-1): 21:31:57  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:31:57.962657 (Thread-1): 21:31:57  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 21:31:57.964753 (Thread-1): 21:31:57  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:57.965160 (Thread-1): 21:31:57  finished collecting timing info
2022-01-06 21:31:57.965315 (Thread-1): 21:31:57  On model.jaffel_shop.stg_customers: ROLLBACK
2022-01-06 21:31:57.965522 (Thread-3): 21:31:57  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:57.965629 (Thread-3): 21:31:57  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 21:31:57.967921 (Thread-1): 21:31:57  On model.jaffel_shop.stg_customers: Close
2022-01-06 21:31:57.968070 (Thread-3): 21:31:57  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:57.969234 (Thread-3): 21:31:57  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:57.969332 (Thread-3): 21:31:57  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
drop view if exists "dev"."dbt_nobodozie"."stg_payments__dbt_backup" cascade
2022-01-06 21:31:57.969754 (Thread-1): 21:31:57  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cc7570db-ef1a-4591-bf8f-35b3baeab29e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb99b6fd1f0>]}
2022-01-06 21:31:57.970082 (Thread-1): 21:31:57  1 of 5 OK created view model dbt_nobodozie.stg_customers........................ [CREATE VIEW in 0.27s]
2022-01-06 21:31:57.970199 (Thread-1): 21:31:57  Finished running node model.jaffel_shop.stg_customers
2022-01-06 21:31:57.976915 (Thread-3): 21:31:57  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 21:31:57.977644 (Thread-3): 21:31:57  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 21:31:57.977737 (Thread-3): 21:31:57  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:57.977811 (Thread-3): 21:31:57  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 21:31:58.008988 (Thread-3): 21:31:58  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:31:58.009096 (Thread-3): 21:31:58  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:31:58.009166 (Thread-3): 21:31:58  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 21:31:58.011312 (Thread-3): 21:31:58  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:58.011708 (Thread-3): 21:31:58  finished collecting timing info
2022-01-06 21:31:58.011831 (Thread-3): 21:31:58  On model.jaffel_shop.stg_payments: ROLLBACK
2022-01-06 21:31:58.012022 (Thread-2): 21:31:58  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:58.012129 (Thread-2): 21:31:58  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 21:31:58.014525 (Thread-3): 21:31:58  On model.jaffel_shop.stg_payments: Close
2022-01-06 21:31:58.014684 (Thread-2): 21:31:58  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:58.015994 (Thread-2): 21:31:58  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:58.016091 (Thread-2): 21:31:58  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
drop view if exists "dev"."dbt_nobodozie"."stg_orders__dbt_backup" cascade
2022-01-06 21:31:58.016500 (Thread-3): 21:31:58  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cc7570db-ef1a-4591-bf8f-35b3baeab29e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb99867d880>]}
2022-01-06 21:31:58.016779 (Thread-3): 21:31:58  3 of 5 OK created view model dbt_nobodozie.stg_payments......................... [CREATE VIEW in 0.31s]
2022-01-06 21:31:58.016884 (Thread-3): 21:31:58  Finished running node model.jaffel_shop.stg_payments
2022-01-06 21:31:58.021285 (Thread-2): 21:31:58  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 21:31:58.021913 (Thread-2): 21:31:58  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 21:31:58.022008 (Thread-2): 21:31:58  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:58.022083 (Thread-2): 21:31:58  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 21:31:58.050730 (Thread-2): 21:31:58  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:31:58.050854 (Thread-2): 21:31:58  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:31:58.050932 (Thread-2): 21:31:58  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 21:31:58.053005 (Thread-2): 21:31:58  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:58.053423 (Thread-2): 21:31:58  finished collecting timing info
2022-01-06 21:31:58.053548 (Thread-2): 21:31:58  On model.jaffel_shop.stg_orders: ROLLBACK
2022-01-06 21:31:58.055378 (Thread-2): 21:31:58  On model.jaffel_shop.stg_orders: Close
2022-01-06 21:31:58.055816 (Thread-2): 21:31:58  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cc7570db-ef1a-4591-bf8f-35b3baeab29e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb99aed4af0>]}
2022-01-06 21:31:58.056185 (Thread-2): 21:31:58  2 of 5 OK created view model dbt_nobodozie.stg_orders........................... [CREATE VIEW in 0.35s]
2022-01-06 21:31:58.056295 (Thread-2): 21:31:58  Finished running node model.jaffel_shop.stg_orders
2022-01-06 21:31:58.057046 (Thread-4): 21:31:58  Began running node model.jaffel_shop.dim_customers
2022-01-06 21:31:58.057293 (Thread-4): 21:31:58  4 of 5 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 21:31:58.057555 (Thread-4): 21:31:58  Acquiring new redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:58.057643 (Thread-4): 21:31:58  Began compiling node model.jaffel_shop.dim_customers
2022-01-06 21:31:58.057724 (Thread-4): 21:31:58  Compiling model.jaffel_shop.dim_customers
2022-01-06 21:31:58.060480 (Thread-4): 21:31:58  Writing injected SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 21:31:58.060773 (Thread-1): 21:31:58  Began running node model.jaffel_shop.fct_orders
2022-01-06 21:31:58.060987 (Thread-1): 21:31:58  5 of 5 START view model dbt_nobodozie.fct_orders................................ [RUN]
2022-01-06 21:31:58.061249 (Thread-1): 21:31:58  Acquiring new redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:58.061346 (Thread-1): 21:31:58  Began compiling node model.jaffel_shop.fct_orders
2022-01-06 21:31:58.061427 (Thread-1): 21:31:58  Compiling model.jaffel_shop.fct_orders
2022-01-06 21:31:58.064434 (Thread-1): 21:31:58  Writing injected SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 21:31:58.080916 (Thread-1): 21:31:58  finished collecting timing info
2022-01-06 21:31:58.081109 (Thread-1): 21:31:58  Began executing node model.jaffel_shop.fct_orders
2022-01-06 21:31:58.083933 (Thread-1): 21:31:58  Writing runtime SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 21:31:58.084199 (Thread-4): 21:31:58  finished collecting timing info
2022-01-06 21:31:58.084376 (Thread-4): 21:31:58  Began executing node model.jaffel_shop.dim_customers
2022-01-06 21:31:58.116253 (Thread-4): 21:31:58  Writing runtime SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 21:31:58.116515 (Thread-1): 21:31:58  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:58.116629 (Thread-1): 21:31:58  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 21:31:58.116716 (Thread-1): 21:31:58  Opening a new connection, currently in state closed
2022-01-06 21:31:58.116797 (Thread-1): 21:31:58  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:58.130388 (Thread-4): 21:31:58  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:58.130499 (Thread-4): 21:31:58  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 21:31:58.130579 (Thread-4): 21:31:58  Opening a new connection, currently in state init
2022-01-06 21:31:58.130656 (Thread-4): 21:31:58  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:58.137066 (Thread-1): 21:31:58  SQL status: BEGIN in 0.02 seconds
2022-01-06 21:31:58.137180 (Thread-1): 21:31:58  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:58.137289 (Thread-1): 21:31:58  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */


  create view "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" as (
    with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),


order_payments as (
    select
        order_id,
        sum(case when status = 'success' then amount end ) as amount
    from payment
    group by 1
),



final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
  ) ;

2022-01-06 21:31:58.145106 (Thread-1): 21:31:58  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 21:31:58.146933 (Thread-1): 21:31:58  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:58.147161 (Thread-1): 21:31:58  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
alter table "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" rename to "fct_orders"
2022-01-06 21:31:58.149370 (Thread-1): 21:31:58  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:31:58.150374 (Thread-1): 21:31:58  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 21:31:58.150469 (Thread-1): 21:31:58  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:58.150543 (Thread-1): 21:31:58  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 21:31:58.180875 (Thread-1): 21:31:58  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:31:58.181091 (Thread-1): 21:31:58  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:58.181174 (Thread-1): 21:31:58  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 21:31:58.183513 (Thread-1): 21:31:58  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:58.184693 (Thread-1): 21:31:58  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:58.184791 (Thread-1): 21:31:58  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
drop view if exists "dev"."dbt_nobodozie"."fct_orders__dbt_backup" cascade
2022-01-06 21:31:58.186682 (Thread-1): 21:31:58  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 21:31:58.188642 (Thread-1): 21:31:58  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 21:31:58.188736 (Thread-1): 21:31:58  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:58.188810 (Thread-1): 21:31:58  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 21:31:58.216201 (Thread-1): 21:31:58  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:31:58.216316 (Thread-1): 21:31:58  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:31:58.216391 (Thread-1): 21:31:58  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 21:31:58.218352 (Thread-1): 21:31:58  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:58.218730 (Thread-1): 21:31:58  finished collecting timing info
2022-01-06 21:31:58.218851 (Thread-1): 21:31:58  On model.jaffel_shop.fct_orders: ROLLBACK
2022-01-06 21:31:58.220520 (Thread-1): 21:31:58  On model.jaffel_shop.fct_orders: Close
2022-01-06 21:31:58.220954 (Thread-1): 21:31:58  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cc7570db-ef1a-4591-bf8f-35b3baeab29e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9985b7910>]}
2022-01-06 21:31:58.221390 (Thread-1): 21:31:58  5 of 5 OK created view model dbt_nobodozie.fct_orders........................... [CREATE VIEW in 0.16s]
2022-01-06 21:31:58.221515 (Thread-1): 21:31:58  Finished running node model.jaffel_shop.fct_orders
2022-01-06 21:31:58.470915 (Thread-4): 21:31:58  SQL status: BEGIN in 0.34 seconds
2022-01-06 21:31:58.471047 (Thread-4): 21:31:58  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:58.471135 (Thread-4): 21:31:58  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),

lifetime_value as (

    select 
        orders.customer_id as customer_id,
        orders.order_id as order_id,
        sum(payment.amount) total_value

    from orders 
    
    left join payment using (order_id)
    group by 1,2
),


customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,
        lifetime_value.order_id,
        lifetime_value.total_value
    from customers

    left join customer_orders using (customer_id)
    left join lifetime_value using (customer_id)
)

select * from final
  );
2022-01-06 21:31:58.482304 (Thread-853): handling poll request
2022-01-06 21:31:58.482613 (Thread-853): 21:31:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec40d87f0>]}
2022-01-06 21:31:58.484816 (Thread-853): sending response (<Response 83614 bytes [200 OK]>) to 10.0.47.136
2022-01-06 21:31:58.589358 (Thread-4): 21:31:58  SQL status: SELECT in 0.12 seconds
2022-01-06 21:31:58.591174 (Thread-4): 21:31:58  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:58.591271 (Thread-4): 21:31:58  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 21:31:58.593968 (Thread-4): 21:31:58  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:31:58.595775 (Thread-4): 21:31:58  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:58.595872 (Thread-4): 21:31:58  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 21:31:58.598509 (Thread-4): 21:31:58  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 21:31:58.603048 (Thread-4): 21:31:58  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 21:31:58.603146 (Thread-4): 21:31:58  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:58.603220 (Thread-4): 21:31:58  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 21:31:58.642295 (Thread-4): 21:31:58  SQL status: COMMIT in 0.04 seconds
2022-01-06 21:31:58.642521 (Thread-4): 21:31:58  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:58.642606 (Thread-4): 21:31:58  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 21:31:58.644739 (Thread-4): 21:31:58  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:58.646019 (Thread-4): 21:31:58  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:58.646115 (Thread-4): 21:31:58  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 21:31:58.649598 (Thread-4): 21:31:58  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 21:31:58.650224 (Thread-4): 21:31:58  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 21:31:58.650319 (Thread-4): 21:31:58  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:58.650394 (Thread-4): 21:31:58  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 21:31:58.681250 (Thread-4): 21:31:58  SQL status: COMMIT in 0.03 seconds
2022-01-06 21:31:58.681371 (Thread-4): 21:31:58  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:31:58.681448 (Thread-4): 21:31:58  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 21:31:58.683514 (Thread-4): 21:31:58  SQL status: BEGIN in 0.0 seconds
2022-01-06 21:31:58.683892 (Thread-4): 21:31:58  finished collecting timing info
2022-01-06 21:31:58.684015 (Thread-4): 21:31:58  On model.jaffel_shop.dim_customers: ROLLBACK
2022-01-06 21:31:58.685739 (Thread-4): 21:31:58  On model.jaffel_shop.dim_customers: Close
2022-01-06 21:31:58.686189 (Thread-4): 21:31:58  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cc7570db-ef1a-4591-bf8f-35b3baeab29e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb99862dbe0>]}
2022-01-06 21:31:58.686542 (Thread-4): 21:31:58  4 of 5 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.63s]
2022-01-06 21:31:58.686712 (Thread-4): 21:31:58  Finished running node model.jaffel_shop.dim_customers
2022-01-06 21:31:58.688044 (MainThread): 21:31:58  Acquiring new redshift connection "master"
2022-01-06 21:31:58.688184 (MainThread): 21:31:58  Using redshift connection "master"
2022-01-06 21:31:58.688261 (MainThread): 21:31:58  On master: BEGIN
2022-01-06 21:31:58.688338 (MainThread): 21:31:58  Opening a new connection, currently in state closed
2022-01-06 21:31:58.688413 (MainThread): 21:31:58  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:31:58.712978 (MainThread): 21:31:58  SQL status: BEGIN in 0.02 seconds
2022-01-06 21:31:58.713095 (MainThread): 21:31:58  On master: COMMIT
2022-01-06 21:31:58.713170 (MainThread): 21:31:58  Using redshift connection "master"
2022-01-06 21:31:58.713260 (MainThread): 21:31:58  On master: COMMIT
2022-01-06 21:31:58.715045 (MainThread): 21:31:58  SQL status: COMMIT in 0.0 seconds
2022-01-06 21:31:58.715147 (MainThread): 21:31:58  On master: Close
2022-01-06 21:31:58.715556 (MainThread): 21:31:58  
2022-01-06 21:31:58.715665 (MainThread): 21:31:58  Finished running 4 view models, 1 table model in 1.84s.
2022-01-06 21:31:58.715747 (MainThread): 21:31:58  Connection 'master' was properly closed.
2022-01-06 21:31:58.715813 (MainThread): 21:31:58  Connection 'model.jaffel_shop.fct_orders' was properly closed.
2022-01-06 21:31:58.715874 (MainThread): 21:31:58  Connection 'model.jaffel_shop.stg_orders' was properly closed.
2022-01-06 21:31:58.715932 (MainThread): 21:31:58  Connection 'model.jaffel_shop.stg_payments' was properly closed.
2022-01-06 21:31:58.715990 (MainThread): 21:31:58  Connection 'model.jaffel_shop.dim_customers' was properly closed.
2022-01-06 21:31:58.780632 (MainThread): 21:31:58  
2022-01-06 21:31:58.780777 (MainThread): 21:31:58  Completed successfully
2022-01-06 21:31:58.780873 (MainThread): 21:31:58  
2022-01-06 21:31:58.780958 (MainThread): 21:31:58  Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2022-01-06 21:31:59.833492 (Thread-854): handling poll request
2022-01-06 21:31:59.833860 (Thread-854): 21:31:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4136400>]}
2022-01-06 21:31:59.835491 (Thread-854): sending response (<Response 33965 bytes [200 OK]>) to 10.0.47.136
2022-01-06 21:32:00.510343 (Thread-855): handling status request
2022-01-06 21:32:00.510712 (Thread-855): 21:32:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4136400>]}
2022-01-06 21:32:00.511181 (Thread-855): sending response (<Response 1244 bytes [200 OK]>) to 10.0.19.7
2022-01-06 21:32:00.621291 (Thread-856): handling status request
2022-01-06 21:32:00.621663 (Thread-856): 21:32:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4136790>]}
2022-01-06 21:32:00.622137 (Thread-856): sending response (<Response 1244 bytes [200 OK]>) to 10.0.38.43
2022-01-06 21:32:38.673537 (Thread-857): handling status request
2022-01-06 21:32:38.673940 (Thread-857): 21:32:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4136a00>]}
2022-01-06 21:32:38.674406 (Thread-857): sending response (<Response 1244 bytes [200 OK]>) to 10.0.19.7
2022-01-06 21:32:38.918609 (Thread-858): handling status request
2022-01-06 21:32:38.918898 (Thread-858): 21:32:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4136c70>]}
2022-01-06 21:32:38.919334 (Thread-858): sending response (<Response 1244 bytes [200 OK]>) to 10.0.4.104
2022-01-06 21:32:39.009466 (Thread-859): handling docs.generate request
2022-01-06 21:32:39.009734 (Thread-859): 21:32:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4136ee0>]}
2022-01-06 21:32:41.073338 (Thread-859): sending response (<Response 138 bytes [200 OK]>) to 10.0.8.128
2022-01-06 21:32:41.101861 (MainThread): 21:32:41  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a5d090db-00ac-4bde-b19d-aa41b9314f69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33fb6e7880>]}
2022-01-06 21:32:41.102141 (MainThread): 21:32:41  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 21:32:41.103621 (MainThread): 21:32:41  
2022-01-06 21:32:41.103773 (MainThread): 21:32:41  Acquiring new redshift connection "master"
2022-01-06 21:32:41.104520 (ThreadPoolExecutor-0_0): 21:32:41  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 21:32:41.117378 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/catalog.sql
2022-01-06 21:32:41.131076 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/adapters.sql
2022-01-06 21:32:41.160742 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/relations.sql
2022-01-06 21:32:41.161490 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 21:32:41.162448 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/catalog.sql
2022-01-06 21:32:41.164652 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/adapters.sql
2022-01-06 21:32:41.190059 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/relations.sql
2022-01-06 21:32:41.191476 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 21:32:41.194533 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-06 21:32:41.196138 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-06 21:32:41.197825 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-06 21:32:41.200455 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-06 21:32:41.201927 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/generic_test_sql/not_null.sql
2022-01-06 21:32:41.202601 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/generic_test_sql/relationships.sql
2022-01-06 21:32:41.203559 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/generic_test_sql/unique.sql
2022-01-06 21:32:41.204358 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/configs.sql
2022-01-06 21:32:41.206731 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/hooks.sql
2022-01-06 21:32:41.210587 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/snapshots/strategies.sql
2022-01-06 21:32:41.226747 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-06 21:32:41.228445 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-06 21:32:41.239581 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/snapshots/helpers.sql
2022-01-06 21:32:41.250344 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/seeds/seed.sql
2022-01-06 21:32:41.256192 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/seeds/helpers.sql
2022-01-06 21:32:41.272198 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-06 21:32:41.274619 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/models/view/view.sql
2022-01-06 21:32:41.281420 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-06 21:32:41.284069 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/models/view/helpers.sql
2022-01-06 21:32:41.285523 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/models/table/table.sql
2022-01-06 21:32:41.292559 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-06 21:32:41.295510 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/models/incremental/merge.sql
2022-01-06 21:32:41.306536 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-06 21:32:41.321321 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-06 21:32:41.325737 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-06 21:32:41.335525 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-06 21:32:41.337102 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/tests/test.sql
2022-01-06 21:32:41.341523 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/tests/where_subquery.sql
2022-01-06 21:32:41.343393 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/materializations/tests/helpers.sql
2022-01-06 21:32:41.345201 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/etc/statement.sql
2022-01-06 21:32:41.349594 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/etc/datetime.sql
2022-01-06 21:32:41.357788 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/adapters/indexes.sql
2022-01-06 21:32:41.360494 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/adapters/persist_docs.sql
2022-01-06 21:32:41.364841 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/adapters/freshness.sql
2022-01-06 21:32:41.367796 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/adapters/relation.sql
2022-01-06 21:32:41.377082 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/adapters/metadata.sql
2022-01-06 21:32:41.384393 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/adapters/columns.sql
2022-01-06 21:32:41.394851 (Thread-860): handling poll request
2022-01-06 21:32:41.395249 (Thread-860): 21:32:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec40ffeb0>]}
2022-01-06 21:32:41.396447 (Thread-860): sending response (<Response 15637 bytes [200 OK]>) to 10.0.4.101
2022-01-06 21:32:41.394003 (ThreadPoolExecutor-0_0): 21:32:41  Parsing macros/adapters/schema.sql
2022-01-06 21:32:41.406056 (ThreadPoolExecutor-0_0): 21:32:41  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 21:32:41.406175 (ThreadPoolExecutor-0_0): 21:32:41  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 21:32:41.406261 (ThreadPoolExecutor-0_0): 21:32:41  Opening a new connection, currently in state init
2022-01-06 21:32:41.406342 (ThreadPoolExecutor-0_0): 21:32:41  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:32:41.425341 (ThreadPoolExecutor-0_0): 21:32:41  SQL status: BEGIN in 0.02 seconds
2022-01-06 21:32:41.425450 (ThreadPoolExecutor-0_0): 21:32:41  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 21:32:41.425523 (ThreadPoolExecutor-0_0): 21:32:41  On list_dev_dbt_nobodozie: select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 21:32:41.436573 (ThreadPoolExecutor-0_0): 21:32:41  SQL status: SELECT in 0.01 seconds
2022-01-06 21:32:41.437772 (ThreadPoolExecutor-0_0): 21:32:41  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 21:32:41.439545 (ThreadPoolExecutor-0_0): 21:32:41  On list_dev_dbt_nobodozie: Close
2022-01-06 21:32:41.443214 (MainThread): 21:32:41  Using redshift connection "master"
2022-01-06 21:32:41.443324 (MainThread): 21:32:41  On master: BEGIN
2022-01-06 21:32:41.443406 (MainThread): 21:32:41  Opening a new connection, currently in state init
2022-01-06 21:32:41.443481 (MainThread): 21:32:41  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:32:41.466922 (MainThread): 21:32:41  SQL status: BEGIN in 0.02 seconds
2022-01-06 21:32:41.467025 (MainThread): 21:32:41  Using redshift connection "master"
2022-01-06 21:32:41.467098 (MainThread): 21:32:41  On master: with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 21:32:41.495732 (MainThread): 21:32:41  SQL status: SELECT in 0.03 seconds
2022-01-06 21:32:41.496819 (MainThread): 21:32:41  On master: ROLLBACK
2022-01-06 21:32:41.498716 (MainThread): 21:32:41  On master: Close
2022-01-06 21:32:41.498980 (MainThread): 21:32:41  Concurrency: 4 threads (target='default')
2022-01-06 21:32:41.499086 (MainThread): 21:32:41  
2022-01-06 21:32:41.501355 (Thread-1): 21:32:41  Began running node model.jaffel_shop.stg_customers
2022-01-06 21:32:41.501528 (Thread-1): 21:32:41  Acquiring new redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 21:32:41.501615 (Thread-1): 21:32:41  Began compiling node model.jaffel_shop.stg_customers
2022-01-06 21:32:41.501700 (Thread-1): 21:32:41  Compiling model.jaffel_shop.stg_customers
2022-01-06 21:32:41.502921 (Thread-1): 21:32:41  Writing injected SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 21:32:41.503150 (Thread-2): 21:32:41  Began running node model.jaffel_shop.stg_orders
2022-01-06 21:32:41.503326 (Thread-2): 21:32:41  Acquiring new redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 21:32:41.503407 (Thread-2): 21:32:41  Began compiling node model.jaffel_shop.stg_orders
2022-01-06 21:32:41.503485 (Thread-2): 21:32:41  Compiling model.jaffel_shop.stg_orders
2022-01-06 21:32:41.504642 (Thread-2): 21:32:41  Writing injected SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 21:32:41.504975 (Thread-3): 21:32:41  Began running node model.jaffel_shop.stg_payments
2022-01-06 21:32:41.505143 (Thread-3): 21:32:41  Acquiring new redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 21:32:41.505254 (Thread-3): 21:32:41  Began compiling node model.jaffel_shop.stg_payments
2022-01-06 21:32:41.505344 (Thread-3): 21:32:41  Compiling model.jaffel_shop.stg_payments
2022-01-06 21:32:41.506390 (Thread-3): 21:32:41  Writing injected SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 21:32:41.518765 (Thread-1): 21:32:41  finished collecting timing info
2022-01-06 21:32:41.518902 (Thread-1): 21:32:41  Began executing node model.jaffel_shop.stg_customers
2022-01-06 21:32:41.519006 (Thread-1): 21:32:41  finished collecting timing info
2022-01-06 21:32:41.519149 (Thread-1): 21:32:41  Finished running node model.jaffel_shop.stg_customers
2022-01-06 21:32:41.520463 (Thread-2): 21:32:41  finished collecting timing info
2022-01-06 21:32:41.520600 (Thread-2): 21:32:41  Began executing node model.jaffel_shop.stg_orders
2022-01-06 21:32:41.520690 (Thread-2): 21:32:41  finished collecting timing info
2022-01-06 21:32:41.520818 (Thread-2): 21:32:41  Finished running node model.jaffel_shop.stg_orders
2022-01-06 21:32:41.521497 (Thread-3): 21:32:41  finished collecting timing info
2022-01-06 21:32:41.521626 (Thread-3): 21:32:41  Began executing node model.jaffel_shop.stg_payments
2022-01-06 21:32:41.521714 (Thread-3): 21:32:41  finished collecting timing info
2022-01-06 21:32:41.521836 (Thread-3): 21:32:41  Finished running node model.jaffel_shop.stg_payments
2022-01-06 21:32:41.522597 (Thread-4): 21:32:41  Began running node model.jaffel_shop.dim_customers
2022-01-06 21:32:41.522793 (Thread-4): 21:32:41  Acquiring new redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 21:32:41.522877 (Thread-4): 21:32:41  Began compiling node model.jaffel_shop.dim_customers
2022-01-06 21:32:41.522952 (Thread-4): 21:32:41  Compiling model.jaffel_shop.dim_customers
2022-01-06 21:32:41.525778 (Thread-4): 21:32:41  Writing injected SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 21:32:41.525958 (Thread-1): 21:32:41  Began running node model.jaffel_shop.fct_orders
2022-01-06 21:32:41.526098 (Thread-1): 21:32:41  Acquiring new redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 21:32:41.526175 (Thread-1): 21:32:41  Began compiling node model.jaffel_shop.fct_orders
2022-01-06 21:32:41.526247 (Thread-1): 21:32:41  Compiling model.jaffel_shop.fct_orders
2022-01-06 21:32:41.528889 (Thread-1): 21:32:41  Writing injected SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 21:32:41.543397 (Thread-1): 21:32:41  finished collecting timing info
2022-01-06 21:32:41.543524 (Thread-1): 21:32:41  Began executing node model.jaffel_shop.fct_orders
2022-01-06 21:32:41.543613 (Thread-1): 21:32:41  finished collecting timing info
2022-01-06 21:32:41.543739 (Thread-1): 21:32:41  Finished running node model.jaffel_shop.fct_orders
2022-01-06 21:32:41.544496 (Thread-4): 21:32:41  finished collecting timing info
2022-01-06 21:32:41.544640 (Thread-4): 21:32:41  Began executing node model.jaffel_shop.dim_customers
2022-01-06 21:32:41.544730 (Thread-4): 21:32:41  finished collecting timing info
2022-01-06 21:32:41.544855 (Thread-4): 21:32:41  Finished running node model.jaffel_shop.dim_customers
2022-01-06 21:32:41.545896 (MainThread): 21:32:41  Connection 'master' was properly closed.
2022-01-06 21:32:41.546005 (MainThread): 21:32:41  Connection 'model.jaffel_shop.fct_orders' was properly closed.
2022-01-06 21:32:41.546073 (MainThread): 21:32:41  Connection 'model.jaffel_shop.stg_orders' was properly closed.
2022-01-06 21:32:41.546134 (MainThread): 21:32:41  Connection 'model.jaffel_shop.stg_payments' was properly closed.
2022-01-06 21:32:41.546195 (MainThread): 21:32:41  Connection 'model.jaffel_shop.dim_customers' was properly closed.
2022-01-06 21:32:41.611722 (MainThread): 21:32:41  Done.
2022-01-06 21:32:41.690385 (MainThread): 21:32:41  Acquiring new redshift connection "generate_catalog"
2022-01-06 21:32:41.690491 (MainThread): 21:32:41  Building catalog
2022-01-06 21:32:41.691649 (ThreadPoolExecutor-1_0): 21:32:41  Acquiring new redshift connection "dev.information_schema"
2022-01-06 21:32:41.701678 (ThreadPoolExecutor-1_0): 21:32:41  Using redshift connection "dev.information_schema"
2022-01-06 21:32:41.701775 (ThreadPoolExecutor-1_0): 21:32:41  On dev.information_schema: BEGIN
2022-01-06 21:32:41.701852 (ThreadPoolExecutor-1_0): 21:32:41  Opening a new connection, currently in state init
2022-01-06 21:32:41.701929 (ThreadPoolExecutor-1_0): 21:32:41  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 21:32:41.720060 (ThreadPoolExecutor-1_0): 21:32:41  SQL status: BEGIN in 0.02 seconds
2022-01-06 21:32:41.720167 (ThreadPoolExecutor-1_0): 21:32:41  Using redshift connection "dev.information_schema"
2022-01-06 21:32:41.720240 (ThreadPoolExecutor-1_0): 21:32:41  On dev.information_schema: 
    

    with late_binding as (
      select
        'dev'::varchar as table_database,
        table_schema,
        table_name,
        'LATE BINDING VIEW'::varchar as table_type,
        null::text as table_comment,

        column_name,
        column_index,
        column_type,
        null::text as column_comment
      from pg_get_late_binding_view_cols()
        cols(table_schema name, table_name name, column_name name,
             column_type varchar,
             column_index int)
        order by "column_index"
    ),

    early_binding as (
        select
            'dev'::varchar as table_database,
            sch.nspname as table_schema,
            tbl.relname as table_name,
            case tbl.relkind
                when 'v' then 'VIEW'
                else 'BASE TABLE'
            end as table_type,
            tbl_desc.description as table_comment,
            col.attname as column_name,
            col.attnum as column_index,
            pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
            col_desc.description as column_comment

        from pg_catalog.pg_namespace sch
        join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
        join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
        left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
        left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
        where (upper(sch.nspname) = upper('dbt_nobodozie'))
            and tbl.relkind in ('r', 'v', 'f', 'p')
            and col.attnum > 0
            and not col.attisdropped
    ),

    table_owners as (

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            tablename as table_name,
            tableowner as table_owner

        from pg_tables

        union all

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            viewname as table_name,
            viewowner as table_owner

        from pg_views

    ),

    unioned as (

        select *
        from early_binding

        union all

        select *
        from late_binding

    )

    select *,
        table_database || '.' || table_schema || '.' || table_name as table_id

    from unioned
    join table_owners using (table_database, table_schema, table_name)

    where (upper(table_schema) = upper('dbt_nobodozie'))

    order by "column_index"
2022-01-06 21:32:41.777431 (ThreadPoolExecutor-1_0): 21:32:41  SQL status: SELECT in 0.06 seconds
2022-01-06 21:32:41.781206 (ThreadPoolExecutor-1_0): 21:32:41  Using redshift connection "dev.information_schema"
2022-01-06 21:32:41.781331 (ThreadPoolExecutor-1_0): 21:32:41  On dev.information_schema: select has_table_privilege(current_user, 'svv_table_info', 'SELECT') as can_select
2022-01-06 21:32:41.783733 (ThreadPoolExecutor-1_0): 21:32:41  SQL status: SELECT in 0.0 seconds
2022-01-06 21:32:41.787579 (ThreadPoolExecutor-1_0): 21:32:41  Using redshift connection "dev.information_schema"
2022-01-06 21:32:41.787673 (ThreadPoolExecutor-1_0): 21:32:41  On dev.information_schema: select
        "database" || '.' || "schema" || '.' || "table" as table_id,

        'Encoded'::text as "stats:encoded:label",
        encoded as "stats:encoded:value",
        'Indicates whether any column in the table has compression encoding defined.'::text as "stats:encoded:description",
        true as "stats:encoded:include",

        'Dist Style' as "stats:diststyle:label",
        diststyle as "stats:diststyle:value",
        'Distribution style or distribution key column, if key distribution is defined.'::text as "stats:diststyle:description",
        true as "stats:diststyle:include",

        'Sort Key 1' as "stats:sortkey1:label",
        -- handle 0xFF byte in response for interleaved sort styles
        case
            when sortkey1 like 'INTERLEAVED%' then 'INTERLEAVED'::text
            else sortkey1
        end as "stats:sortkey1:value",
        'First column in the sort key.'::text as "stats:sortkey1:description",
        (sortkey1 is not null) as "stats:sortkey1:include",

        'Max Varchar' as "stats:max_varchar:label",
        max_varchar as "stats:max_varchar:value",
        'Size of the largest column that uses a VARCHAR data type.'::text as "stats:max_varchar:description",
        true as "stats:max_varchar:include",

        -- exclude this, as the data is strangely returned with null-byte characters
        'Sort Key 1 Encoding' as "stats:sortkey1_enc:label",
        sortkey1_enc as "stats:sortkey1_enc:value",
        'Compression encoding of the first column in the sort key.' as "stats:sortkey1_enc:description",
        false as "stats:sortkey1_enc:include",

        '# Sort Keys' as "stats:sortkey_num:label",
        sortkey_num as "stats:sortkey_num:value",
        'Number of columns defined as sort keys.' as "stats:sortkey_num:description",
        (sortkey_num > 0) as "stats:sortkey_num:include",

        'Approximate Size' as "stats:size:label",
        size * 1000000 as "stats:size:value",
        'Approximate size of the table, calculated from a count of 1MB blocks'::text as "stats:size:description",
        true as "stats:size:include",

        'Disk Utilization' as "stats:pct_used:label",
        pct_used / 100.0 as "stats:pct_used:value",
        'Percent of available space that is used by the table.'::text as "stats:pct_used:description",
        true as "stats:pct_used:include",

        'Unsorted %' as "stats:unsorted:label",
        unsorted / 100.0 as "stats:unsorted:value",
        'Percent of unsorted rows in the table.'::text as "stats:unsorted:description",
        (unsorted is not null) as "stats:unsorted:include",

        'Stats Off' as "stats:stats_off:label",
        stats_off as "stats:stats_off:value",
        'Number that indicates how stale the table statistics are; 0 is current, 100 is out of date.'::text as "stats:stats_off:description",
        true as "stats:stats_off:include",

        'Approximate Row Count' as "stats:rows:label",
        tbl_rows as "stats:rows:value",
        'Approximate number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed.'::text as "stats:rows:description",
        true as "stats:rows:include",

        'Sort Key Skew' as "stats:skew_sortkey1:label",
        skew_sortkey1 as "stats:skew_sortkey1:value",
        'Ratio of the size of the largest non-sort key column to the size of the first column of the sort key.'::text as "stats:skew_sortkey1:description",
        (skew_sortkey1 is not null) as "stats:skew_sortkey1:include",

        'Skew Rows' as "stats:skew_rows:label",
        skew_rows as "stats:skew_rows:value",
        'Ratio of the number of rows in the slice with the most rows to the number of rows in the slice with the fewest rows.'::text as "stats:skew_rows:description",
        (skew_rows is not null) as "stats:skew_rows:include"

    from svv_table_info
    where (upper(schema) = upper('dbt_nobodozie'))
2022-01-06 21:32:42.519193 (ThreadPoolExecutor-1_0): 21:32:42  SQL status: SELECT in 0.73 seconds
2022-01-06 21:32:42.531220 (ThreadPoolExecutor-1_0): 21:32:42  On dev.information_schema: ROLLBACK
2022-01-06 21:32:42.533328 (ThreadPoolExecutor-1_0): 21:32:42  On dev.information_schema: Close
2022-01-06 21:32:42.622588 (MainThread): 21:32:42  Catalog written to /usr/src/develop/user-52374/environment-57794/repository-46678/target/catalog.json
2022-01-06 21:32:42.826915 (Thread-861): handling poll request
2022-01-06 21:32:42.827300 (Thread-861): 21:32:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc704eca0>]}
2022-01-06 21:32:42.828923 (Thread-861): sending response (<Response 48354 bytes [200 OK]>) to 10.0.8.128
2022-01-06 21:32:43.480937 (Thread-862): handling status request
2022-01-06 21:32:43.481345 (Thread-862): 21:32:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc704ee50>]}
2022-01-06 21:32:43.481861 (Thread-862): sending response (<Response 1244 bytes [200 OK]>) to 10.0.47.136
2022-01-06 21:32:43.549652 (Thread-863): handling status request
2022-01-06 21:32:43.549968 (Thread-863): 21:32:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc702c250>]}
2022-01-06 21:32:43.550453 (Thread-863): sending response (<Response 1244 bytes [200 OK]>) to 10.0.11.87
2022-01-06 21:32:43.555620 (Thread-864): handling status request
2022-01-06 21:32:43.562846 (Thread-864): 21:32:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc702c4c0>]}
2022-01-06 21:32:43.563198 (Thread-864): sending response (<Response 1244 bytes [200 OK]>) to 10.0.45.208
2022-01-06 22:05:30.491425 (Thread-865): handling status request
2022-01-06 22:05:30.491813 (Thread-865): 22:05:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc702cc70>]}
2022-01-06 22:05:30.492293 (Thread-865): sending response (<Response 1244 bytes [200 OK]>) to 10.0.14.166
2022-01-06 22:05:30.593926 (Thread-866): handling status request
2022-01-06 22:05:30.594196 (Thread-866): 22:05:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc702cb80>]}
2022-01-06 22:05:30.618014 (Thread-867): handling ps request
2022-01-06 22:05:30.618741 (Thread-866): sending response (<Response 1244 bytes [200 OK]>) to 10.0.16.23
2022-01-06 22:05:30.619067 (Thread-867): 22:05:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc7032310>]}
2022-01-06 22:05:30.625525 (Thread-867): sending response (<Response 72198 bytes [200 OK]>) to 10.0.32.47
2022-01-06 22:05:30.928116 (Thread-868): handling status request
2022-01-06 22:05:30.928501 (Thread-868): 22:05:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc702e6d0>]}
2022-01-06 22:05:30.928983 (Thread-868): sending response (<Response 1244 bytes [200 OK]>) to 10.0.8.124
2022-01-06 22:05:32.316241 (Thread-869): handling status request
2022-01-06 22:05:32.317079 (Thread-870): handling status request
2022-01-06 22:05:32.317381 (Thread-869): 22:05:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc702e7f0>]}
2022-01-06 22:05:32.317750 (Thread-870): 22:05:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4116790>]}
2022-01-06 22:05:32.318463 (Thread-869): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:05:32.318947 (Thread-871): handling status request
2022-01-06 22:05:32.319580 (Thread-870): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:05:32.320189 (Thread-872): handling status request
2022-01-06 22:05:32.320822 (Thread-871): 22:05:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc702ce80>]}
2022-01-06 22:05:32.321564 (Thread-872): 22:05:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec422c8e0>]}
2022-01-06 22:05:32.322027 (Thread-871): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:05:32.322505 (Thread-872): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:05:32.326918 (Thread-873): handling list request
2022-01-06 22:05:32.327143 (Thread-873): 22:05:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc702c8b0>]}
2022-01-06 22:05:32.328763 (Thread-874): handling list request
2022-01-06 22:05:32.329167 (Thread-874): 22:05:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc704ef70>]}
2022-01-06 22:05:32.330495 (Thread-875): handling list request
2022-01-06 22:05:32.378301 (Thread-875): sending response (<Response 214 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:05:32.437799 (Thread-877): handling poll request
2022-01-06 22:05:32.438070 (Thread-877): 22:05:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc70321c0>]}
2022-01-06 22:05:32.440092 (Thread-877): sending response (<Response 63697 bytes [200 OK]>) to 10.0.8.124
2022-01-06 22:05:32.459638 (Thread-878): handling status request
2022-01-06 22:05:32.459885 (Thread-878): 22:05:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc70321f0>]}
2022-01-06 22:05:32.460238 (Thread-878): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:05:32.465703 (Thread-879): handling list request
2022-01-06 22:05:32.465930 (Thread-879): 22:05:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc702c340>]}
2022-01-06 22:05:32.495064 (Thread-879): 22:05:32  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc703aac0>]}
2022-01-06 22:05:32.495319 (Thread-879): 22:05:32  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:05:32.497382 (Thread-879): sending response (<Response 2992 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:05:33.117510 (Thread-880): handling status request
2022-01-06 22:05:33.117868 (Thread-880): 22:05:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6fd15e0>]}
2022-01-06 22:05:33.118326 (Thread-880): sending response (<Response 1244 bytes [200 OK]>) to 10.0.40.204
2022-01-06 22:05:33.174914 (Thread-881): handling status request
2022-01-06 22:05:33.175208 (Thread-881): 22:05:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6fd1550>]}
2022-01-06 22:05:33.175646 (Thread-881): sending response (<Response 1244 bytes [200 OK]>) to 10.0.32.47
2022-01-06 22:05:33.836388 (Thread-882): handling status request
2022-01-06 22:05:33.836813 (Thread-882): 22:05:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc702efd0>]}
2022-01-06 22:05:33.837315 (Thread-882): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:05:33.842337 (Thread-883): handling list request
2022-01-06 22:05:33.842574 (Thread-883): 22:05:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6fd19d0>]}
2022-01-06 22:05:33.875530 (Thread-883): 22:05:33  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6fc7ac0>]}
2022-01-06 22:05:33.875802 (Thread-883): 22:05:33  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:05:33.878066 (Thread-883): sending response (<Response 3510 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:05:49.039748 (Thread-884): handling status request
2022-01-06 22:05:49.040153 (Thread-884): 22:05:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc704ef70>]}
2022-01-06 22:05:49.040627 (Thread-884): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:05:49.063316 (Thread-885): handling list request
2022-01-06 22:05:49.063574 (Thread-885): 22:05:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6fe7490>]}
2022-01-06 22:05:49.093115 (Thread-885): 22:05:49  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6fe7fa0>]}
2022-01-06 22:05:49.093425 (Thread-885): 22:05:49  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:05:49.095892 (Thread-885): sending response (<Response 3510 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:05:53.959559 (Thread-886): handling status request
2022-01-06 22:05:53.959951 (Thread-886): 22:05:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc702c5b0>]}
2022-01-06 22:05:53.960420 (Thread-886): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:05:53.965614 (Thread-887): handling list request
2022-01-06 22:05:53.965879 (Thread-887): 22:05:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6fc7ca0>]}
2022-01-06 22:05:53.998102 (Thread-887): 22:05:53  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6feddf0>]}
2022-01-06 22:05:53.998376 (Thread-887): 22:05:53  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:05:54.000449 (Thread-887): sending response (<Response 2889 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:05:55.387732 (Thread-888): handling status request
2022-01-06 22:05:55.388103 (Thread-888): 22:05:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6ff1910>]}
2022-01-06 22:05:55.408544 (Thread-888): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:05:55.414177 (Thread-889): handling list request
2022-01-06 22:05:55.414418 (Thread-889): 22:05:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc70004f0>]}
2022-01-06 22:05:55.445091 (Thread-889): 22:05:55  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6ff1d30>]}
2022-01-06 22:05:55.445374 (Thread-889): 22:05:55  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:05:55.447446 (Thread-889): sending response (<Response 2992 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:06:06.303872 (Thread-890): handling status request
2022-01-06 22:06:06.304262 (Thread-890): 22:06:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6ff19a0>]}
2022-01-06 22:06:06.304781 (Thread-890): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:06:06.312958 (Thread-891): handling list request
2022-01-06 22:06:06.313204 (Thread-891): 22:06:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6fe7dc0>]}
2022-01-06 22:06:06.343997 (Thread-891): 22:06:06  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6ff1580>]}
2022-01-06 22:06:06.344273 (Thread-891): 22:06:06  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:06:06.346275 (Thread-891): sending response (<Response 2385 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:06:10.634116 (Thread-892): handling status request
2022-01-06 22:06:10.634522 (Thread-892): 22:06:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec422c2e0>]}
2022-01-06 22:06:10.634995 (Thread-892): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:06:10.640464 (Thread-893): handling list request
2022-01-06 22:06:10.640707 (Thread-893): 22:06:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc701d100>]}
2022-01-06 22:06:10.672706 (Thread-893): 22:06:10  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f77be0>]}
2022-01-06 22:06:10.672982 (Thread-893): 22:06:10  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:06:10.675161 (Thread-893): sending response (<Response 3510 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:06:12.048115 (Thread-894): handling status request
2022-01-06 22:06:12.048825 (Thread-894): 22:06:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc7000730>]}
2022-01-06 22:06:12.049356 (Thread-894): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:06:12.054903 (Thread-895): handling list request
2022-01-06 22:06:12.055160 (Thread-895): 22:06:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6fe7f10>]}
2022-01-06 22:06:12.081660 (Thread-895): 22:06:12  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f84040>]}
2022-01-06 22:06:12.081924 (Thread-895): 22:06:12  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:06:12.085380 (Thread-895): sending response (<Response 2889 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:06:13.402158 (Thread-896): handling status request
2022-01-06 22:06:13.402548 (Thread-896): 22:06:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f84f40>]}
2022-01-06 22:06:13.403029 (Thread-896): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:06:13.408550 (Thread-897): handling list request
2022-01-06 22:06:13.408811 (Thread-897): 22:06:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f92280>]}
2022-01-06 22:06:13.436390 (Thread-897): 22:06:13  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f84d60>]}
2022-01-06 22:06:13.436659 (Thread-897): 22:06:13  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:06:13.438868 (Thread-897): sending response (<Response 2992 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:07:01.006512 (Thread-898): handling status request
2022-01-06 22:07:01.006878 (Thread-898): 22:07:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f844c0>]}
2022-01-06 22:07:01.007341 (Thread-898): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:07:01.015913 (Thread-899): handling list request
2022-01-06 22:07:01.016158 (Thread-899): 22:07:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f9d310>]}
2022-01-06 22:07:01.049292 (Thread-899): 22:07:01  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f9de80>]}
2022-01-06 22:07:01.049587 (Thread-899): 22:07:01  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:07:01.059533 (Thread-899): sending response (<Response 2992 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:08:06.727921 (Thread-900): handling status request
2022-01-06 22:08:06.728293 (Thread-900): 22:08:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6fa61f0>]}
2022-01-06 22:08:06.728765 (Thread-900): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:08:06.742420 (Thread-901): handling list request
2022-01-06 22:08:06.742958 (Thread-901): 22:08:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f9d130>]}
2022-01-06 22:08:06.777012 (Thread-901): 22:08:06  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6fed550>]}
2022-01-06 22:08:06.777311 (Thread-901): 22:08:06  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:08:06.788869 (Thread-901): sending response (<Response 2992 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:08:11.482244 (Thread-902): handling status request
2022-01-06 22:08:11.484268 (Thread-902): 22:08:11  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6faa550>]}
2022-01-06 22:08:11.484758 (Thread-902): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:08:11.490384 (Thread-903): handling list request
2022-01-06 22:08:11.490680 (Thread-903): 22:08:11  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6fa6fa0>]}
2022-01-06 22:08:11.520368 (Thread-903): 22:08:11  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6fa62b0>]}
2022-01-06 22:08:11.520645 (Thread-903): 22:08:11  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:08:11.522864 (Thread-903): sending response (<Response 2992 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:08:17.861879 (Thread-904): handling status request
2022-01-06 22:08:17.862248 (Thread-904): 22:08:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6fb5130>]}
2022-01-06 22:08:17.862712 (Thread-904): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:08:17.870227 (Thread-905): handling list request
2022-01-06 22:08:17.870486 (Thread-905): 22:08:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6fb5760>]}
2022-01-06 22:08:17.900981 (Thread-905): 22:08:17  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f2e310>]}
2022-01-06 22:08:17.901281 (Thread-905): 22:08:17  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:08:17.906374 (Thread-905): sending response (<Response 2385 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:08:20.866873 (Thread-906): handling status request
2022-01-06 22:08:20.867248 (Thread-906): 22:08:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f2e760>]}
2022-01-06 22:08:20.867712 (Thread-906): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:08:20.874818 (Thread-907): handling list request
2022-01-06 22:08:20.875077 (Thread-907): 22:08:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f3b0a0>]}
2022-01-06 22:08:20.907943 (Thread-907): 22:08:20  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f2e130>]}
2022-01-06 22:08:20.908219 (Thread-907): 22:08:20  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:08:20.911768 (Thread-907): sending response (<Response 2989 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:08:29.271947 (Thread-908): handling status request
2022-01-06 22:08:29.272315 (Thread-908): 22:08:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f3b940>]}
2022-01-06 22:08:29.292769 (Thread-908): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:08:29.298756 (Thread-909): handling list request
2022-01-06 22:08:29.299010 (Thread-909): 22:08:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f3bbb0>]}
2022-01-06 22:08:29.330633 (Thread-909): 22:08:29  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f46220>]}
2022-01-06 22:08:29.330923 (Thread-909): 22:08:29  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:08:29.333243 (Thread-909): sending response (<Response 2385 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:08:32.371168 (Thread-910): handling status request
2022-01-06 22:08:32.371568 (Thread-910): 22:08:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f9d0d0>]}
2022-01-06 22:08:32.372030 (Thread-910): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:08:32.377455 (Thread-911): handling list request
2022-01-06 22:08:32.377694 (Thread-911): 22:08:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f2e040>]}
2022-01-06 22:08:32.407799 (Thread-911): 22:08:32  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f51670>]}
2022-01-06 22:08:32.408073 (Thread-911): 22:08:32  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:08:32.410154 (Thread-911): sending response (<Response 2989 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:08:41.617916 (Thread-912): handling status request
2022-01-06 22:08:41.618281 (Thread-912): 22:08:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f53100>]}
2022-01-06 22:08:41.618751 (Thread-912): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:08:41.624092 (Thread-913): handling list request
2022-01-06 22:08:41.624330 (Thread-913): 22:08:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f534c0>]}
2022-01-06 22:08:41.657835 (Thread-913): 22:08:41  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f531c0>]}
2022-01-06 22:08:41.658101 (Thread-913): 22:08:41  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:08:41.660188 (Thread-913): sending response (<Response 2992 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:09:01.904135 (Thread-914): handling status request
2022-01-06 22:09:01.904568 (Thread-914): 22:09:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6fb5850>]}
2022-01-06 22:09:01.905050 (Thread-914): sending response (<Response 1222 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:09:01.911786 (Thread-915): handling list request
2022-01-06 22:09:01.912041 (Thread-915): 22:09:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f51340>]}
2022-01-06 22:09:01.939800 (Thread-915): 22:09:01  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6ed3be0>]}
2022-01-06 22:09:01.940062 (Thread-915): 22:09:01  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:09:01.946845 (Thread-915): sending response (<Response 3510 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:09:28.988651 (Thread-916): 22:09:28  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 22:09:28.989080 (Thread-916): 22:09:28  Partial parsing: updated file: jaffel_shop://models/marts/core/dim_customers.sql
2022-01-06 22:09:28.993350 (Thread-916): 22:09:28  1699: static parser successfully parsed marts/core/dim_customers.sql
2022-01-06 22:09:29.053406 (Thread-916): 22:09:29  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4063ca0>]}
2022-01-06 22:09:29.531064 (Thread-917): handling status request
2022-01-06 22:09:29.531476 (Thread-917): 22:09:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6f84430>]}
2022-01-06 22:09:29.531973 (Thread-917): sending response (<Response 1553 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:09:29.537381 (Thread-918): handling list request
2022-01-06 22:09:29.537625 (Thread-918): 22:09:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6eb38b0>]}
2022-01-06 22:09:29.566557 (Thread-918): 22:09:29  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6e7bfd0>]}
2022-01-06 22:09:29.566825 (Thread-918): 22:09:29  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:09:29.568903 (Thread-918): sending response (<Response 2911 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:09:29.674549 (Thread-919): handling status request
2022-01-06 22:09:29.674840 (Thread-919): 22:09:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6eee280>]}
2022-01-06 22:09:29.675243 (Thread-919): sending response (<Response 1575 bytes [200 OK]>) to 10.0.28.107
2022-01-06 22:09:29.716787 (Thread-920): handling status request
2022-01-06 22:09:29.717049 (Thread-920): 22:09:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6eee520>]}
2022-01-06 22:09:29.717460 (Thread-920): sending response (<Response 1575 bytes [200 OK]>) to 10.0.8.124
2022-01-06 22:09:30.570149 (Thread-921): handling status request
2022-01-06 22:09:30.570518 (Thread-921): 22:09:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4063730>]}
2022-01-06 22:09:30.570989 (Thread-921): sending response (<Response 1553 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:09:30.576719 (Thread-922): handling list request
2022-01-06 22:09:30.576985 (Thread-922): 22:09:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4063ac0>]}
2022-01-06 22:09:30.604161 (Thread-922): 22:09:30  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6eeeeb0>]}
2022-01-06 22:09:30.604431 (Thread-922): 22:09:30  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:09:30.606610 (Thread-922): sending response (<Response 2911 bytes [200 OK]>) to 10.0.7.144
2022-01-06 22:09:30.925743 (Thread-923): handling status request
2022-01-06 22:09:30.926139 (Thread-923): 22:09:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec422c8e0>]}
2022-01-06 22:09:30.926610 (Thread-923): sending response (<Response 1575 bytes [200 OK]>) to 10.0.9.169
2022-01-06 22:09:31.277365 (Thread-924): handling run_sql request
2022-01-06 22:09:31.277705 (Thread-924): 22:09:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4063e20>]}
2022-01-06 22:09:33.308334 (Thread-924): sending response (<Response 138 bytes [200 OK]>) to 10.0.7.0
2022-01-06 22:09:33.333067 (MainThread): 22:09:33  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1af0425e-4c53-462a-8080-98f5eebeeb8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa833f02760>]}
2022-01-06 22:09:33.333600 (MainThread): 22:09:33  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:09:33.334152 (Thread-1): 22:09:33  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:09:33.334282 (Thread-1): 22:09:33  Began compiling node rpc.jaffel_shop.request
2022-01-06 22:09:33.334372 (Thread-1): 22:09:33  Compiling rpc.jaffel_shop.request
2022-01-06 22:09:33.336609 (Thread-1): 22:09:33  finished collecting timing info
2022-01-06 22:09:33.336734 (Thread-1): 22:09:33  Began executing node rpc.jaffel_shop.request
2022-01-06 22:09:33.336830 (Thread-1): 22:09:33  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:09:33.336906 (Thread-1): 22:09:33  On rpc.jaffel_shop.request: with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"
),




customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,
        lifetime_value.order_id,
        lifetime_value.total_value
    from customers

    left join customer_orders using (customer_id)
    left join lifetime_value using (customer_id)
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 22:09:33.336994 (Thread-1): 22:09:33  Opening a new connection, currently in state init
2022-01-06 22:09:33.337072 (Thread-1): 22:09:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:09:33.363964 (Thread-1): 22:09:33  Postgres adapter: Postgres error: relation "lifetime_value" does not exist

2022-01-06 22:09:33.364116 (Thread-1): 22:09:33  finished collecting timing info
2022-01-06 22:09:33.364231 (Thread-1): 22:09:33  On rpc.jaffel_shop.request: Close
2022-01-06 22:09:33.364419 (Thread-1): Got an exception: Database Error
  relation "lifetime_value" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "lifetime_value" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "lifetime_value" does not exist
2022-01-06 22:09:33.365479 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "lifetime_value" does not exist', 'raw_sql': "with customers as (\n\n    select * from {{ ref('stg_customers')}}\n),\n\norders as (\n\n    select * from {{ ref('stg_orders')}}\n),\n\n\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        lifetime_value.order_id,\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\n\n\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        lifetime_value.order_id,\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "lifetime_value" does not exist', 'raw_sql': "with customers as (\n\n    select * from {{ ref('stg_customers')}}\n),\n\norders as (\n\n    select * from {{ ref('stg_orders')}}\n),\n\n\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        lifetime_value.order_id,\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\n\n\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        lifetime_value.order_id,\n        lifetime_value.total_value\n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 22:09:33.711632 (Thread-925): handling poll request
2022-01-06 22:09:33.712073 (Thread-925): 22:09:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4071b50>]}
2022-01-06 22:09:33.712901 (Thread-925): sending response (<Response 15355 bytes [200 OK]>) to 10.0.32.47
2022-01-06 22:09:48.706733 (Thread-926): handling status request
2022-01-06 22:09:48.707099 (Thread-926): 22:09:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec40550a0>]}
2022-01-06 22:09:48.707646 (Thread-926): sending response (<Response 1575 bytes [200 OK]>) to 10.0.8.124
2022-01-06 22:09:49.005194 (Thread-927): handling run_sql request
2022-01-06 22:09:49.005507 (Thread-927): 22:09:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec40553a0>]}
2022-01-06 22:09:51.105558 (Thread-927): sending response (<Response 138 bytes [200 OK]>) to 10.0.13.200
2022-01-06 22:09:51.130238 (MainThread): 22:09:51  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '11217c5c-eebc-49dd-b72c-a2befea461bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90833e4430>]}
2022-01-06 22:09:51.130744 (MainThread): 22:09:51  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:09:51.131299 (Thread-1): 22:09:51  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:09:51.131430 (Thread-1): 22:09:51  Began compiling node rpc.jaffel_shop.request
2022-01-06 22:09:51.131521 (Thread-1): 22:09:51  Compiling rpc.jaffel_shop.request
2022-01-06 22:09:51.133831 (Thread-1): 22:09:51  finished collecting timing info
2022-01-06 22:09:51.133958 (Thread-1): 22:09:51  Began executing node rpc.jaffel_shop.request
2022-01-06 22:09:51.134054 (Thread-1): 22:09:51  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:09:51.134127 (Thread-1): 22:09:51  On rpc.jaffel_shop.request: with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"
),




customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
        
    from customers

    left join customer_orders using (customer_id)
    left join lifetime_value using (customer_id)
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 22:09:51.134204 (Thread-1): 22:09:51  Opening a new connection, currently in state init
2022-01-06 22:09:51.134279 (Thread-1): 22:09:51  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:09:51.156618 (Thread-1): 22:09:51  Postgres adapter: Postgres error: relation "lifetime_value" does not exist

2022-01-06 22:09:51.156768 (Thread-1): 22:09:51  finished collecting timing info
2022-01-06 22:09:51.156880 (Thread-1): 22:09:51  On rpc.jaffel_shop.request: Close
2022-01-06 22:09:51.157152 (Thread-1): Got an exception: Database Error
  relation "lifetime_value" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "lifetime_value" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "lifetime_value" does not exist
2022-01-06 22:09:51.158133 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "lifetime_value" does not exist', 'raw_sql': "with customers as (\n\n    select * from {{ ref('stg_customers')}}\n),\n\norders as (\n\n    select * from {{ ref('stg_orders')}}\n),\n\n\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n        \n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\n\n\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n        \n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "lifetime_value" does not exist', 'raw_sql': "with customers as (\n\n    select * from {{ ref('stg_customers')}}\n),\n\norders as (\n\n    select * from {{ ref('stg_orders')}}\n),\n\n\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n        \n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\n\n\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n        \n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 22:09:51.436656 (Thread-928): handling poll request
2022-01-06 22:09:51.437093 (Thread-928): 22:09:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec40551c0>]}
2022-01-06 22:09:51.437974 (Thread-928): sending response (<Response 14924 bytes [200 OK]>) to 10.0.34.75
2022-01-06 22:09:52.967285 (Thread-929): handling status request
2022-01-06 22:09:52.967657 (Thread-929): 22:09:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec4055fa0>]}
2022-01-06 22:09:52.968205 (Thread-929): sending response (<Response 1575 bytes [200 OK]>) to 10.0.8.124
2022-01-06 22:09:52.990022 (Thread-930): handling ps request
2022-01-06 22:09:52.990289 (Thread-930): 22:09:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efec40502e0>]}
2022-01-06 22:09:52.998494 (Thread-930): sending response (<Response 80116 bytes [200 OK]>) to 10.0.14.166
2022-01-06 22:09:53.055071 (Thread-931): handling status request
2022-01-06 22:09:53.055321 (Thread-931): 22:09:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6e8b0a0>]}
2022-01-06 22:09:53.055706 (Thread-931): sending response (<Response 1575 bytes [200 OK]>) to 10.0.27.183
2022-01-06 22:09:53.065774 (Thread-932): handling status request
2022-01-06 22:09:53.066002 (Thread-932): 22:09:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6e8b700>]}
2022-01-06 22:09:53.089617 (Thread-932): sending response (<Response 1575 bytes [200 OK]>) to 10.0.13.200
2022-01-06 22:09:54.291929 (Thread-933): handling poll request
2022-01-06 22:09:54.292349 (Thread-933): 22:09:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6e8b4c0>]}
2022-01-06 22:09:54.294418 (Thread-933): sending response (<Response 63697 bytes [200 OK]>) to 10.0.27.183
2022-01-06 22:09:54.994364 (Thread-934): handling status request
2022-01-06 22:09:54.994735 (Thread-934): 22:09:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6e86f10>]}
2022-01-06 22:09:54.995204 (Thread-934): sending response (<Response 1575 bytes [200 OK]>) to 10.0.9.169
2022-01-06 22:09:54.999192 (Thread-935): handling status request
2022-01-06 22:09:54.999431 (Thread-935): 22:09:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6e868b0>]}
2022-01-06 22:09:54.999792 (Thread-935): sending response (<Response 1575 bytes [200 OK]>) to 10.0.40.204
2022-01-06 22:09:58.296422 (Thread-936): 22:09:58  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 22:09:58.296811 (Thread-936): 22:09:58  Partial parsing: updated file: jaffel_shop://models/marts/core/dim_customers.sql
2022-01-06 22:09:58.300965 (Thread-936): 22:09:58  1699: static parser successfully parsed marts/core/dim_customers.sql
2022-01-06 22:09:58.347382 (Thread-936): 22:09:58  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6e7eca0>]}
2022-01-06 22:09:58.791903 (Thread-937): handling status request
2022-01-06 22:09:58.792284 (Thread-937): 22:09:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea42eab80>]}
2022-01-06 22:09:58.792803 (Thread-937): sending response (<Response 1575 bytes [200 OK]>) to 10.0.25.198
2022-01-06 22:09:58.888703 (Thread-938): handling status request
2022-01-06 22:09:58.889039 (Thread-938): 22:09:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea42eaa90>]}
2022-01-06 22:09:58.889528 (Thread-938): sending response (<Response 1575 bytes [200 OK]>) to 10.0.39.202
2022-01-06 22:09:59.715280 (Thread-939): handling status request
2022-01-06 22:09:59.715649 (Thread-939): 22:09:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea42ea940>]}
2022-01-06 22:09:59.716121 (Thread-939): sending response (<Response 1575 bytes [200 OK]>) to 10.0.39.202
2022-01-06 22:10:00.040190 (Thread-940): handling run_sql request
2022-01-06 22:10:00.040543 (Thread-940): 22:10:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea42ea610>]}
2022-01-06 22:10:02.094955 (Thread-940): sending response (<Response 138 bytes [200 OK]>) to 10.0.32.47
2022-01-06 22:10:02.119657 (MainThread): 22:10:02  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '806558ef-c41c-48d9-bae5-4a912646938d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7eca10e3a0>]}
2022-01-06 22:10:02.120214 (MainThread): 22:10:02  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:10:02.120827 (Thread-1): 22:10:02  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:10:02.120958 (Thread-1): 22:10:02  Began compiling node rpc.jaffel_shop.request
2022-01-06 22:10:02.121048 (Thread-1): 22:10:02  Compiling rpc.jaffel_shop.request
2022-01-06 22:10:02.123478 (Thread-1): 22:10:02  finished collecting timing info
2022-01-06 22:10:02.123608 (Thread-1): 22:10:02  Began executing node rpc.jaffel_shop.request
2022-01-06 22:10:02.123705 (Thread-1): 22:10:02  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:10:02.123794 (Thread-1): 22:10:02  On rpc.jaffel_shop.request: with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"
),




customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
        
    from customers

    left join customer_orders using (customer_id)
    left join lifetime_value using (customer_id)
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 22:10:02.123870 (Thread-1): 22:10:02  Opening a new connection, currently in state init
2022-01-06 22:10:02.123948 (Thread-1): 22:10:02  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:10:02.147852 (Thread-1): 22:10:02  Postgres adapter: Postgres error: relation "lifetime_value" does not exist

2022-01-06 22:10:02.148036 (Thread-1): 22:10:02  finished collecting timing info
2022-01-06 22:10:02.148165 (Thread-1): 22:10:02  On rpc.jaffel_shop.request: Close
2022-01-06 22:10:02.148404 (Thread-1): Got an exception: Database Error
  relation "lifetime_value" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "lifetime_value" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "lifetime_value" does not exist
2022-01-06 22:10:02.149698 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "lifetime_value" does not exist', 'raw_sql': "with customers as (\n\n    select * from {{ ref('stg_customers')}}\n),\n\norders as (\n\n    select * from {{ ref('stg_orders')}}\n),\n\n\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n        \n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\n\n\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n        \n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "lifetime_value" does not exist', 'raw_sql': "with customers as (\n\n    select * from {{ ref('stg_customers')}}\n),\n\norders as (\n\n    select * from {{ ref('stg_orders')}}\n),\n\n\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n        \n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\n\n\n\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n        \n    from customers\n\n    left join customer_orders using (customer_id)\n    left join lifetime_value using (customer_id)\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 22:10:02.426529 (Thread-941): handling poll request
2022-01-06 22:10:02.426972 (Thread-941): 22:10:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6e885b0>]}
2022-01-06 22:10:02.427817 (Thread-941): sending response (<Response 14924 bytes [200 OK]>) to 10.0.32.47
2022-01-06 22:10:10.382267 (Thread-942): handling status request
2022-01-06 22:10:10.382641 (Thread-942): 22:10:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6e7e9d0>]}
2022-01-06 22:10:10.383177 (Thread-942): sending response (<Response 1575 bytes [200 OK]>) to 10.0.9.169
2022-01-06 22:10:10.716075 (Thread-943): handling run_sql request
2022-01-06 22:10:10.716441 (Thread-943): 22:10:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6e7eaf0>]}
2022-01-06 22:10:12.748565 (Thread-943): sending response (<Response 138 bytes [200 OK]>) to 10.0.40.103
2022-01-06 22:10:12.774122 (MainThread): 22:10:12  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '25406562-e7d5-45a7-8ab3-34c29234ca22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08b5999910>]}
2022-01-06 22:10:12.774648 (MainThread): 22:10:12  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:10:12.775217 (Thread-1): 22:10:12  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:10:12.775347 (Thread-1): 22:10:12  Began compiling node rpc.jaffel_shop.request
2022-01-06 22:10:12.775440 (Thread-1): 22:10:12  Compiling rpc.jaffel_shop.request
2022-01-06 22:10:12.777725 (Thread-1): 22:10:12  finished collecting timing info
2022-01-06 22:10:12.777852 (Thread-1): 22:10:12  Began executing node rpc.jaffel_shop.request
2022-01-06 22:10:12.777950 (Thread-1): 22:10:12  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:10:12.778027 (Thread-1): 22:10:12  On rpc.jaffel_shop.request: with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"
),




customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
        
    from customers

    left join customer_orders using (customer_id)
 
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 22:10:12.778104 (Thread-1): 22:10:12  Opening a new connection, currently in state init
2022-01-06 22:10:12.778180 (Thread-1): 22:10:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:10:12.842790 (Thread-1): 22:10:12  SQL status: SELECT in 0.06 seconds
2022-01-06 22:10:12.845958 (Thread-1): 22:10:12  finished collecting timing info
2022-01-06 22:10:12.846104 (Thread-1): 22:10:12  On rpc.jaffel_shop.request: Close
2022-01-06 22:10:13.095108 (Thread-944): handling poll request
2022-01-06 22:10:13.095596 (Thread-944): 22:10:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea42ef520>]}
2022-01-06 22:10:13.097879 (Thread-944): sending response (<Response 16258 bytes [200 OK]>) to 10.0.29.201
2022-01-06 22:10:25.149186 (Thread-945): handling status request
2022-01-06 22:10:25.149580 (Thread-945): 22:10:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea42eab80>]}
2022-01-06 22:10:25.150107 (Thread-945): sending response (<Response 1575 bytes [200 OK]>) to 10.0.34.75
2022-01-06 22:10:25.269607 (Thread-946): handling status request
2022-01-06 22:10:25.269877 (Thread-946): 22:10:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6e86520>]}
2022-01-06 22:10:25.270245 (Thread-946): sending response (<Response 1575 bytes [200 OK]>) to 10.0.13.200
2022-01-06 22:10:25.629239 (Thread-947): handling cli_args request
2022-01-06 22:10:25.629499 (Thread-947): 22:10:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc6e7ed00>]}
2022-01-06 22:10:27.678636 (Thread-947): sending response (<Response 138 bytes [200 OK]>) to 10.0.29.201
2022-01-06 22:10:27.772645 (MainThread): 22:10:27  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 22:10:27.773065 (MainThread): 22:10:27  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 22:10:27.778530 (MainThread): 22:10:27  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97960341-9f6e-497d-b37b-ceb7c32f26b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f977e55c0d0>]}
2022-01-06 22:10:27.806015 (MainThread): 22:10:27  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '97960341-9f6e-497d-b37b-ceb7c32f26b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f977e5f6940>]}
2022-01-06 22:10:27.806264 (MainThread): 22:10:27  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:10:27.807308 (MainThread): 22:10:27  
2022-01-06 22:10:27.807585 (MainThread): 22:10:27  Acquiring new redshift connection "master"
2022-01-06 22:10:27.808496 (ThreadPoolExecutor-0_0): 22:10:27  Acquiring new redshift connection "list_dev"
2022-01-06 22:10:27.818309 (ThreadPoolExecutor-0_0): 22:10:27  Using redshift connection "list_dev"
2022-01-06 22:10:27.818410 (ThreadPoolExecutor-0_0): 22:10:27  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 22:10:27.818580 (ThreadPoolExecutor-0_0): 22:10:27  Opening a new connection, currently in state init
2022-01-06 22:10:27.818667 (ThreadPoolExecutor-0_0): 22:10:27  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:10:27.839910 (ThreadPoolExecutor-0_0): 22:10:27  SQL status: SELECT in 0.02 seconds
2022-01-06 22:10:27.840929 (ThreadPoolExecutor-0_0): 22:10:27  On list_dev: Close
2022-01-06 22:10:27.842296 (ThreadPoolExecutor-1_0): 22:10:27  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:10:27.848354 (ThreadPoolExecutor-1_0): 22:10:27  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:10:27.848453 (ThreadPoolExecutor-1_0): 22:10:27  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 22:10:27.848532 (ThreadPoolExecutor-1_0): 22:10:27  Opening a new connection, currently in state closed
2022-01-06 22:10:27.848609 (ThreadPoolExecutor-1_0): 22:10:27  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:10:27.870972 (ThreadPoolExecutor-1_0): 22:10:27  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:10:27.871081 (ThreadPoolExecutor-1_0): 22:10:27  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:10:27.871157 (ThreadPoolExecutor-1_0): 22:10:27  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 22:10:27.882632 (ThreadPoolExecutor-1_0): 22:10:27  SQL status: SELECT in 0.01 seconds
2022-01-06 22:10:27.883675 (ThreadPoolExecutor-1_0): 22:10:27  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 22:10:27.886722 (ThreadPoolExecutor-1_0): 22:10:27  On list_dev_dbt_nobodozie: Close
2022-01-06 22:10:27.890924 (MainThread): 22:10:27  Using redshift connection "master"
2022-01-06 22:10:27.891037 (MainThread): 22:10:27  On master: BEGIN
2022-01-06 22:10:27.891118 (MainThread): 22:10:27  Opening a new connection, currently in state init
2022-01-06 22:10:27.891198 (MainThread): 22:10:27  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:10:27.914515 (MainThread): 22:10:27  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:10:27.914625 (MainThread): 22:10:27  Using redshift connection "master"
2022-01-06 22:10:27.914702 (MainThread): 22:10:27  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 22:10:27.944005 (MainThread): 22:10:27  SQL status: SELECT in 0.03 seconds
2022-01-06 22:10:27.945056 (MainThread): 22:10:27  On master: ROLLBACK
2022-01-06 22:10:27.947022 (MainThread): 22:10:27  Using redshift connection "master"
2022-01-06 22:10:27.947118 (MainThread): 22:10:27  On master: BEGIN
2022-01-06 22:10:27.950604 (MainThread): 22:10:27  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:10:27.950707 (MainThread): 22:10:27  On master: COMMIT
2022-01-06 22:10:27.950779 (MainThread): 22:10:27  Using redshift connection "master"
2022-01-06 22:10:27.950846 (MainThread): 22:10:27  On master: COMMIT
2022-01-06 22:10:27.952644 (MainThread): 22:10:27  SQL status: COMMIT in 0.0 seconds
2022-01-06 22:10:27.952746 (MainThread): 22:10:27  On master: Close
2022-01-06 22:10:27.953102 (MainThread): 22:10:27  Concurrency: 4 threads (target='default')
2022-01-06 22:10:27.953234 (MainThread): 22:10:27  
2022-01-06 22:10:27.955409 (Thread-1): 22:10:27  Began running node model.jaffel_shop.stg_customers
2022-01-06 22:10:27.955643 (Thread-1): 22:10:27  1 of 5 START view model dbt_nobodozie.stg_customers............................. [RUN]
2022-01-06 22:10:27.955874 (Thread-1): 22:10:27  Acquiring new redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:10:27.955963 (Thread-1): 22:10:27  Began compiling node model.jaffel_shop.stg_customers
2022-01-06 22:10:27.956052 (Thread-1): 22:10:27  Compiling model.jaffel_shop.stg_customers
2022-01-06 22:10:27.957152 (Thread-1): 22:10:27  Writing injected SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 22:10:27.957396 (Thread-2): 22:10:27  Began running node model.jaffel_shop.stg_orders
2022-01-06 22:10:27.957617 (Thread-2): 22:10:27  2 of 5 START view model dbt_nobodozie.stg_orders................................ [RUN]
2022-01-06 22:10:27.957862 (Thread-2): 22:10:27  Acquiring new redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:10:27.957946 (Thread-2): 22:10:27  Began compiling node model.jaffel_shop.stg_orders
2022-01-06 22:10:27.958030 (Thread-2): 22:10:27  Compiling model.jaffel_shop.stg_orders
2022-01-06 22:10:27.959024 (Thread-2): 22:10:27  Writing injected SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 22:10:27.959341 (Thread-3): 22:10:27  Began running node model.jaffel_shop.stg_payments
2022-01-06 22:10:27.959686 (Thread-3): 22:10:27  3 of 5 START view model dbt_nobodozie.stg_payments.............................. [RUN]
2022-01-06 22:10:27.959952 (Thread-3): 22:10:27  Acquiring new redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:10:27.960039 (Thread-3): 22:10:27  Began compiling node model.jaffel_shop.stg_payments
2022-01-06 22:10:27.960120 (Thread-3): 22:10:27  Compiling model.jaffel_shop.stg_payments
2022-01-06 22:10:27.961101 (Thread-3): 22:10:27  Writing injected SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 22:10:27.974672 (Thread-1): 22:10:27  finished collecting timing info
2022-01-06 22:10:27.974818 (Thread-1): 22:10:27  Began executing node model.jaffel_shop.stg_customers
2022-01-06 22:10:27.979991 (Thread-3): 22:10:27  finished collecting timing info
2022-01-06 22:10:27.980119 (Thread-3): 22:10:27  Began executing node model.jaffel_shop.stg_payments
2022-01-06 22:10:27.985067 (Thread-2): 22:10:27  finished collecting timing info
2022-01-06 22:10:27.985194 (Thread-2): 22:10:27  Began executing node model.jaffel_shop.stg_orders
2022-01-06 22:10:28.022128 (Thread-1): 22:10:28  Writing runtime SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 22:10:28.023329 (Thread-3): 22:10:28  Writing runtime SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 22:10:28.024455 (Thread-2): 22:10:28  Writing runtime SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 22:10:28.037980 (Thread-948): handling poll request
2022-01-06 22:10:28.038333 (Thread-948): 22:10:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea428c940>]}
2022-01-06 22:10:28.039736 (Thread-948): sending response (<Response 27119 bytes [200 OK]>) to 10.0.39.187
2022-01-06 22:10:28.039729 (Thread-2): 22:10:28  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:10:28.039847 (Thread-2): 22:10:28  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 22:10:28.039942 (Thread-2): 22:10:28  Opening a new connection, currently in state init
2022-01-06 22:10:28.040028 (Thread-2): 22:10:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:10:28.040344 (Thread-3): 22:10:28  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:10:28.040443 (Thread-3): 22:10:28  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 22:10:28.040522 (Thread-3): 22:10:28  Opening a new connection, currently in state init
2022-01-06 22:10:28.040598 (Thread-3): 22:10:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:10:28.040835 (Thread-1): 22:10:28  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:10:28.040933 (Thread-1): 22:10:28  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 22:10:28.041026 (Thread-1): 22:10:28  Opening a new connection, currently in state closed
2022-01-06 22:10:28.041102 (Thread-1): 22:10:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:10:28.073299 (Thread-2): 22:10:28  SQL status: BEGIN in 0.03 seconds
2022-01-06 22:10:28.073409 (Thread-2): 22:10:28  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:10:28.073486 (Thread-2): 22:10:28  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */


  create view "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" as (
    with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
  ) ;

2022-01-06 22:10:28.076717 (Thread-3): 22:10:28  SQL status: BEGIN in 0.04 seconds
2022-01-06 22:10:28.076836 (Thread-3): 22:10:28  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:10:28.076912 (Thread-3): 22:10:28  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */


  create view "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" as (
    with payment as (

    select
        id as payment_id,
        orderid as order_id,
        paymentmethod as payment_method,

        -- amount is stored in cents, convert it to dollars
        amount/100 as amount,
        status

    from stripe.payment

)
select * from payment
  ) ;

2022-01-06 22:10:28.077111 (Thread-1): 22:10:28  SQL status: BEGIN in 0.04 seconds
2022-01-06 22:10:28.077238 (Thread-1): 22:10:28  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:10:28.077317 (Thread-1): 22:10:28  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */


  create view "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
  ) ;

2022-01-06 22:10:28.082827 (Thread-2): 22:10:28  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:10:28.087869 (Thread-2): 22:10:28  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:10:28.088075 (Thread-2): 22:10:28  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders" rename to "stg_orders__dbt_backup"
2022-01-06 22:10:28.088225 (Thread-1): 22:10:28  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:10:28.090093 (Thread-1): 22:10:28  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:10:28.090190 (Thread-1): 22:10:28  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers" rename to "stg_customers__dbt_backup"
2022-01-06 22:10:28.090337 (Thread-3): 22:10:28  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:10:28.092686 (Thread-3): 22:10:28  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:10:28.092784 (Thread-3): 22:10:28  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments" rename to "stg_payments__dbt_backup"
2022-01-06 22:10:28.093020 (Thread-2): 22:10:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:10:28.094690 (Thread-2): 22:10:28  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:10:28.094788 (Thread-2): 22:10:28  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" rename to "stg_orders"
2022-01-06 22:10:28.094958 (Thread-1): 22:10:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:10:28.096781 (Thread-1): 22:10:28  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:10:28.096884 (Thread-1): 22:10:28  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" rename to "stg_customers"
2022-01-06 22:10:28.097099 (Thread-3): 22:10:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:10:28.098977 (Thread-3): 22:10:28  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:10:28.099074 (Thread-3): 22:10:28  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" rename to "stg_payments"
2022-01-06 22:10:28.099213 (Thread-2): 22:10:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:10:28.105837 (Thread-2): 22:10:28  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:10:28.105935 (Thread-2): 22:10:28  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:10:28.106008 (Thread-2): 22:10:28  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:10:28.106156 (Thread-3): 22:10:28  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 22:10:28.107055 (Thread-3): 22:10:28  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:10:28.107149 (Thread-3): 22:10:28  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:10:28.107222 (Thread-3): 22:10:28  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:10:28.107372 (Thread-1): 22:10:28  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 22:10:28.108272 (Thread-1): 22:10:28  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:10:28.108366 (Thread-1): 22:10:28  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:10:28.108438 (Thread-1): 22:10:28  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:10:28.162570 (Thread-2): 22:10:28  SQL status: COMMIT in 0.06 seconds
2022-01-06 22:10:28.162786 (Thread-2): 22:10:28  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:10:28.162870 (Thread-2): 22:10:28  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 22:10:28.163234 (Thread-3): 22:10:28  SQL status: COMMIT in 0.06 seconds
2022-01-06 22:10:28.164974 (Thread-1): 22:10:28  SQL status: COMMIT in 0.06 seconds
2022-01-06 22:10:28.165259 (Thread-2): 22:10:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:10:28.169163 (Thread-2): 22:10:28  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:10:28.169283 (Thread-2): 22:10:28  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
drop view if exists "dev"."dbt_nobodozie"."stg_orders__dbt_backup" cascade
2022-01-06 22:10:28.174603 (Thread-2): 22:10:28  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 22:10:28.175208 (Thread-2): 22:10:28  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:10:28.175299 (Thread-2): 22:10:28  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:10:28.175372 (Thread-2): 22:10:28  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:10:28.203236 (Thread-2): 22:10:28  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:10:28.203350 (Thread-2): 22:10:28  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:10:28.203424 (Thread-2): 22:10:28  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 22:10:28.205404 (Thread-2): 22:10:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:10:28.205792 (Thread-2): 22:10:28  finished collecting timing info
2022-01-06 22:10:28.205916 (Thread-2): 22:10:28  On model.jaffel_shop.stg_orders: ROLLBACK
2022-01-06 22:10:28.206132 (Thread-3): 22:10:28  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:10:28.206241 (Thread-3): 22:10:28  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 22:10:28.208607 (Thread-2): 22:10:28  On model.jaffel_shop.stg_orders: Close
2022-01-06 22:10:28.208808 (Thread-3): 22:10:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:10:28.209952 (Thread-3): 22:10:28  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:10:28.210051 (Thread-3): 22:10:28  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
drop view if exists "dev"."dbt_nobodozie"."stg_payments__dbt_backup" cascade
2022-01-06 22:10:28.210455 (Thread-2): 22:10:28  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97960341-9f6e-497d-b37b-ceb7c32f26b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f977d4d2ee0>]}
2022-01-06 22:10:28.210757 (Thread-2): 22:10:28  2 of 5 OK created view model dbt_nobodozie.stg_orders........................... [CREATE VIEW in 0.25s]
2022-01-06 22:10:28.210871 (Thread-2): 22:10:28  Finished running node model.jaffel_shop.stg_orders
2022-01-06 22:10:28.215223 (Thread-3): 22:10:28  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 22:10:28.215890 (Thread-3): 22:10:28  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:10:28.215983 (Thread-3): 22:10:28  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:10:28.216056 (Thread-3): 22:10:28  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:10:28.245386 (Thread-3): 22:10:28  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:10:28.245498 (Thread-3): 22:10:28  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:10:28.245568 (Thread-3): 22:10:28  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 22:10:28.247694 (Thread-3): 22:10:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:10:28.248070 (Thread-3): 22:10:28  finished collecting timing info
2022-01-06 22:10:28.248190 (Thread-3): 22:10:28  On model.jaffel_shop.stg_payments: ROLLBACK
2022-01-06 22:10:28.248389 (Thread-1): 22:10:28  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:10:28.248498 (Thread-1): 22:10:28  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 22:10:28.250971 (Thread-3): 22:10:28  On model.jaffel_shop.stg_payments: Close
2022-01-06 22:10:28.251124 (Thread-1): 22:10:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:10:28.252498 (Thread-1): 22:10:28  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:10:28.252593 (Thread-1): 22:10:28  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
drop view if exists "dev"."dbt_nobodozie"."stg_customers__dbt_backup" cascade
2022-01-06 22:10:28.252967 (Thread-3): 22:10:28  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97960341-9f6e-497d-b37b-ceb7c32f26b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f977c484a30>]}
2022-01-06 22:10:28.253274 (Thread-3): 22:10:28  3 of 5 OK created view model dbt_nobodozie.stg_payments......................... [CREATE VIEW in 0.29s]
2022-01-06 22:10:28.253386 (Thread-3): 22:10:28  Finished running node model.jaffel_shop.stg_payments
2022-01-06 22:10:28.254022 (Thread-4): 22:10:28  Began running node model.jaffel_shop.fct_orders
2022-01-06 22:10:28.254251 (Thread-4): 22:10:28  4 of 5 START view model dbt_nobodozie.fct_orders................................ [RUN]
2022-01-06 22:10:28.254492 (Thread-4): 22:10:28  Acquiring new redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:10:28.254597 (Thread-4): 22:10:28  Began compiling node model.jaffel_shop.fct_orders
2022-01-06 22:10:28.254682 (Thread-4): 22:10:28  Compiling model.jaffel_shop.fct_orders
2022-01-06 22:10:28.256831 (Thread-4): 22:10:28  Writing injected SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 22:10:28.258336 (Thread-1): 22:10:28  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 22:10:28.258969 (Thread-1): 22:10:28  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:10:28.259064 (Thread-1): 22:10:28  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:10:28.259139 (Thread-1): 22:10:28  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:10:28.272396 (Thread-4): 22:10:28  finished collecting timing info
2022-01-06 22:10:28.272534 (Thread-4): 22:10:28  Began executing node model.jaffel_shop.fct_orders
2022-01-06 22:10:28.274373 (Thread-4): 22:10:28  Writing runtime SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 22:10:28.288870 (Thread-4): 22:10:28  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:10:28.288981 (Thread-4): 22:10:28  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 22:10:28.289061 (Thread-4): 22:10:28  Opening a new connection, currently in state init
2022-01-06 22:10:28.289145 (Thread-4): 22:10:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:10:28.289431 (Thread-1): 22:10:28  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:10:28.289528 (Thread-1): 22:10:28  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:10:28.289596 (Thread-1): 22:10:28  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 22:10:28.291812 (Thread-1): 22:10:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:10:28.292159 (Thread-1): 22:10:28  finished collecting timing info
2022-01-06 22:10:28.292276 (Thread-1): 22:10:28  On model.jaffel_shop.stg_customers: ROLLBACK
2022-01-06 22:10:28.297699 (Thread-1): 22:10:28  On model.jaffel_shop.stg_customers: Close
2022-01-06 22:10:28.298074 (Thread-1): 22:10:28  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97960341-9f6e-497d-b37b-ceb7c32f26b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f977dd1c100>]}
2022-01-06 22:10:28.298347 (Thread-1): 22:10:28  1 of 5 OK created view model dbt_nobodozie.stg_customers........................ [CREATE VIEW in 0.34s]
2022-01-06 22:10:28.298452 (Thread-1): 22:10:28  Finished running node model.jaffel_shop.stg_customers
2022-01-06 22:10:28.298913 (Thread-3): 22:10:28  Began running node model.jaffel_shop.dim_customers
2022-01-06 22:10:28.299120 (Thread-3): 22:10:28  5 of 5 START view model dbt_nobodozie.dim_customers............................. [RUN]
2022-01-06 22:10:28.299328 (Thread-3): 22:10:28  Acquiring new redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:10:28.299421 (Thread-3): 22:10:28  Began compiling node model.jaffel_shop.dim_customers
2022-01-06 22:10:28.299501 (Thread-3): 22:10:28  Compiling model.jaffel_shop.dim_customers
2022-01-06 22:10:28.301693 (Thread-3): 22:10:28  Writing injected SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 22:10:28.311953 (Thread-4): 22:10:28  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:10:28.312065 (Thread-4): 22:10:28  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:10:28.312143 (Thread-4): 22:10:28  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */


  create view "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" as (
    with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),


order_payments as (
    select
        order_id,
        sum(case when status = 'success' then amount end ) as amount
    from payment
    group by 1
),



final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
  ) ;

2022-01-06 22:10:28.315910 (Thread-3): 22:10:28  finished collecting timing info
2022-01-06 22:10:28.316045 (Thread-3): 22:10:28  Began executing node model.jaffel_shop.dim_customers
2022-01-06 22:10:28.317851 (Thread-3): 22:10:28  Writing runtime SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 22:10:28.322609 (Thread-4): 22:10:28  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:10:28.324363 (Thread-4): 22:10:28  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:10:28.324461 (Thread-4): 22:10:28  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
alter table "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" rename to "fct_orders"
2022-01-06 22:10:28.326721 (Thread-4): 22:10:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:10:28.327641 (Thread-4): 22:10:28  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:10:28.327736 (Thread-4): 22:10:28  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:10:28.327809 (Thread-4): 22:10:28  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:10:28.331580 (Thread-3): 22:10:28  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:10:28.331690 (Thread-3): 22:10:28  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 22:10:28.331770 (Thread-3): 22:10:28  Opening a new connection, currently in state closed
2022-01-06 22:10:28.331846 (Thread-3): 22:10:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:10:28.355023 (Thread-3): 22:10:28  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:10:28.355133 (Thread-3): 22:10:28  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:10:28.355208 (Thread-3): 22:10:28  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */


  create view "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" as (
    with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"
),




customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
        
    from customers

    left join customer_orders using (customer_id)
    left join lifetime_value using (customer_id)
)

select * from final
  ) ;

2022-01-06 22:10:28.361416 (Thread-3): 22:10:28  Postgres adapter: Postgres error: relation "lifetime_value" does not exist

2022-01-06 22:10:28.361519 (Thread-3): 22:10:28  On model.jaffel_shop.dim_customers: ROLLBACK
2022-01-06 22:10:28.363713 (Thread-3): 22:10:28  finished collecting timing info
2022-01-06 22:10:28.363842 (Thread-3): 22:10:28  On model.jaffel_shop.dim_customers: Close
2022-01-06 22:10:28.364184 (Thread-3): 22:10:28  Database Error in model dim_customers (models/marts/core/dim_customers.sql)
  relation "lifetime_value" does not exist
  compiled SQL at target/run/jaffel_shop/models/marts/core/dim_customers.sql
2022-01-06 22:10:28.364370 (Thread-3): 22:10:28  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97960341-9f6e-497d-b37b-ceb7c32f26b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f977c3e8d60>]}
2022-01-06 22:10:28.364628 (Thread-3): 22:10:28  5 of 5 ERROR creating view model dbt_nobodozie.dim_customers.................... [ERROR in 0.07s]
2022-01-06 22:10:28.364737 (Thread-3): 22:10:28  Finished running node model.jaffel_shop.dim_customers
2022-01-06 22:10:28.370529 (Thread-4): 22:10:28  SQL status: COMMIT in 0.04 seconds
2022-01-06 22:10:28.370752 (Thread-4): 22:10:28  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:10:28.370836 (Thread-4): 22:10:28  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 22:10:28.373635 (Thread-4): 22:10:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:10:28.374884 (Thread-4): 22:10:28  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:10:28.374987 (Thread-4): 22:10:28  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
drop view if exists "dev"."dbt_nobodozie"."fct_orders__dbt_backup" cascade
2022-01-06 22:10:28.377476 (Thread-4): 22:10:28  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 22:10:28.378090 (Thread-4): 22:10:28  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:10:28.378185 (Thread-4): 22:10:28  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:10:28.378259 (Thread-4): 22:10:28  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:10:28.404880 (Thread-4): 22:10:28  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:10:28.404990 (Thread-4): 22:10:28  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:10:28.405060 (Thread-4): 22:10:28  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 22:10:28.407210 (Thread-4): 22:10:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:10:28.407557 (Thread-4): 22:10:28  finished collecting timing info
2022-01-06 22:10:28.407675 (Thread-4): 22:10:28  On model.jaffel_shop.fct_orders: ROLLBACK
2022-01-06 22:10:28.409469 (Thread-4): 22:10:28  On model.jaffel_shop.fct_orders: Close
2022-01-06 22:10:28.409874 (Thread-4): 22:10:28  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97960341-9f6e-497d-b37b-ceb7c32f26b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f977c424ac0>]}
2022-01-06 22:10:28.410144 (Thread-4): 22:10:28  4 of 5 OK created view model dbt_nobodozie.fct_orders........................... [CREATE VIEW in 0.16s]
2022-01-06 22:10:28.410249 (Thread-4): 22:10:28  Finished running node model.jaffel_shop.fct_orders
2022-01-06 22:10:28.411484 (MainThread): 22:10:28  Acquiring new redshift connection "master"
2022-01-06 22:10:28.411623 (MainThread): 22:10:28  Using redshift connection "master"
2022-01-06 22:10:28.411699 (MainThread): 22:10:28  On master: BEGIN
2022-01-06 22:10:28.411774 (MainThread): 22:10:28  Opening a new connection, currently in state closed
2022-01-06 22:10:28.411847 (MainThread): 22:10:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:10:28.436062 (MainThread): 22:10:28  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:10:28.436179 (MainThread): 22:10:28  On master: COMMIT
2022-01-06 22:10:28.436254 (MainThread): 22:10:28  Using redshift connection "master"
2022-01-06 22:10:28.436324 (MainThread): 22:10:28  On master: COMMIT
2022-01-06 22:10:28.438019 (MainThread): 22:10:28  SQL status: COMMIT in 0.0 seconds
2022-01-06 22:10:28.438129 (MainThread): 22:10:28  On master: Close
2022-01-06 22:10:28.438506 (MainThread): 22:10:28  
2022-01-06 22:10:28.438618 (MainThread): 22:10:28  Finished running 5 view models in 0.63s.
2022-01-06 22:10:28.438698 (MainThread): 22:10:28  Connection 'master' was properly closed.
2022-01-06 22:10:28.438765 (MainThread): 22:10:28  Connection 'model.jaffel_shop.stg_customers' was properly closed.
2022-01-06 22:10:28.438828 (MainThread): 22:10:28  Connection 'model.jaffel_shop.stg_orders' was properly closed.
2022-01-06 22:10:28.438888 (MainThread): 22:10:28  Connection 'model.jaffel_shop.dim_customers' was properly closed.
2022-01-06 22:10:28.438947 (MainThread): 22:10:28  Connection 'model.jaffel_shop.fct_orders' was properly closed.
2022-01-06 22:10:28.509751 (MainThread): 22:10:28  
2022-01-06 22:10:28.509901 (MainThread): 22:10:28  Completed with 1 error and 0 warnings:
2022-01-06 22:10:28.509989 (MainThread): 22:10:28  
2022-01-06 22:10:28.510077 (MainThread): 22:10:28  Database Error in model dim_customers (models/marts/core/dim_customers.sql)
2022-01-06 22:10:28.510154 (MainThread): 22:10:28    relation "lifetime_value" does not exist
2022-01-06 22:10:28.510223 (MainThread): 22:10:28    compiled SQL at target/run/jaffel_shop/models/marts/core/dim_customers.sql
2022-01-06 22:10:28.510302 (MainThread): 22:10:28  
2022-01-06 22:10:28.510378 (MainThread): 22:10:28  Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2022-01-06 22:10:29.353258 (Thread-949): handling poll request
2022-01-06 22:10:29.353633 (Thread-949): 22:10:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4253f40>]}
2022-01-06 22:10:29.356500 (Thread-949): sending response (<Response 92712 bytes [200 OK]>) to 10.0.7.0
2022-01-06 22:10:30.624111 (Thread-950): handling status request
2022-01-06 22:10:30.624470 (Thread-950): 22:10:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4259130>]}
2022-01-06 22:10:30.624968 (Thread-950): sending response (<Response 1575 bytes [200 OK]>) to 10.0.15.38
2022-01-06 22:10:30.647876 (Thread-951): handling status request
2022-01-06 22:10:30.648150 (Thread-951): 22:10:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4259520>]}
2022-01-06 22:10:30.648529 (Thread-951): sending response (<Response 1575 bytes [200 OK]>) to 10.0.25.198
2022-01-06 22:10:53.527548 (Thread-952): handling status request
2022-01-06 22:10:53.527920 (Thread-952): 22:10:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4259760>]}
2022-01-06 22:10:53.528400 (Thread-952): sending response (<Response 1575 bytes [200 OK]>) to 10.0.29.201
2022-01-06 22:10:53.959251 (Thread-953): handling run_sql request
2022-01-06 22:10:53.959621 (Thread-953): 22:10:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea42599d0>]}
2022-01-06 22:10:54.772677 (Thread-954): 22:10:54  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 22:10:54.773165 (Thread-954): 22:10:54  Partial parsing: updated file: jaffel_shop://models/marts/core/dim_customers.sql
2022-01-06 22:10:54.777675 (Thread-954): 22:10:54  1699: static parser successfully parsed marts/core/dim_customers.sql
2022-01-06 22:10:54.824312 (Thread-954): 22:10:54  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4199f70>]}
2022-01-06 22:10:55.342437 (Thread-955): handling status request
2022-01-06 22:10:55.342858 (Thread-955): 22:10:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea41f4c40>]}
2022-01-06 22:10:55.343505 (Thread-955): sending response (<Response 1575 bytes [200 OK]>) to 10.0.40.103
2022-01-06 22:10:55.523418 (Thread-956): handling status request
2022-01-06 22:10:55.523751 (Thread-956): 22:10:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea41f4c40>]}
2022-01-06 22:10:55.524190 (Thread-956): sending response (<Response 1575 bytes [200 OK]>) to 10.0.32.47
2022-01-06 22:10:56.042160 (Thread-953): sending response (<Response 138 bytes [200 OK]>) to 10.0.39.187
2022-01-06 22:10:56.067332 (MainThread): 22:10:56  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0f046c1e-2f96-4559-ad90-3fe3c912f024', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd66d7eb9d0>]}
2022-01-06 22:10:56.067842 (MainThread): 22:10:56  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:10:56.068390 (Thread-1): 22:10:56  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:10:56.068518 (Thread-1): 22:10:56  Began compiling node rpc.jaffel_shop.request
2022-01-06 22:10:56.068603 (Thread-1): 22:10:56  Compiling rpc.jaffel_shop.request
2022-01-06 22:10:56.070892 (Thread-1): 22:10:56  finished collecting timing info
2022-01-06 22:10:56.071014 (Thread-1): 22:10:56  Began executing node rpc.jaffel_shop.request
2022-01-06 22:10:56.071106 (Thread-1): 22:10:56  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:10:56.071180 (Thread-1): 22:10:56  On rpc.jaffel_shop.request: with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"
),




customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
        
    from customers

    left join customer_orders using (customer_id)
 
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 22:10:56.071254 (Thread-1): 22:10:56  Opening a new connection, currently in state init
2022-01-06 22:10:56.071329 (Thread-1): 22:10:56  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:10:56.137415 (Thread-1): 22:10:56  SQL status: SELECT in 0.07 seconds
2022-01-06 22:10:56.140506 (Thread-1): 22:10:56  finished collecting timing info
2022-01-06 22:10:56.140639 (Thread-1): 22:10:56  On rpc.jaffel_shop.request: Close
2022-01-06 22:10:56.383934 (Thread-957): handling poll request
2022-01-06 22:10:56.384321 (Thread-957): 22:10:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea41f4400>]}
2022-01-06 22:10:56.385728 (Thread-957): sending response (<Response 16258 bytes [200 OK]>) to 10.0.39.202
2022-01-06 22:10:59.115183 (Thread-958): handling status request
2022-01-06 22:10:59.115571 (Thread-958): 22:10:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea41f4370>]}
2022-01-06 22:10:59.116060 (Thread-958): sending response (<Response 1575 bytes [200 OK]>) to 10.0.16.23
2022-01-06 22:10:59.360197 (Thread-959): handling status request
2022-01-06 22:10:59.360467 (Thread-959): 22:10:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea41fbbb0>]}
2022-01-06 22:10:59.360887 (Thread-959): sending response (<Response 1575 bytes [200 OK]>) to 10.0.14.166
2022-01-06 22:10:59.570956 (Thread-960): handling cli_args request
2022-01-06 22:10:59.571212 (Thread-960): 22:10:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea41d21f0>]}
2022-01-06 22:11:01.622539 (Thread-960): sending response (<Response 138 bytes [200 OK]>) to 10.0.15.38
2022-01-06 22:11:01.723641 (MainThread): 22:11:01  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 22:11:01.724022 (MainThread): 22:11:01  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 22:11:01.729439 (MainThread): 22:11:01  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '947fbfe1-dece-4973-a5fc-ea4432e49bc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb522986160>]}
2022-01-06 22:11:01.761278 (MainThread): 22:11:01  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '947fbfe1-dece-4973-a5fc-ea4432e49bc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb522a20a00>]}
2022-01-06 22:11:01.761519 (MainThread): 22:11:01  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:11:01.762460 (MainThread): 22:11:01  
2022-01-06 22:11:01.762742 (MainThread): 22:11:01  Acquiring new redshift connection "master"
2022-01-06 22:11:01.763682 (ThreadPoolExecutor-0_0): 22:11:01  Acquiring new redshift connection "list_dev"
2022-01-06 22:11:01.773388 (ThreadPoolExecutor-0_0): 22:11:01  Using redshift connection "list_dev"
2022-01-06 22:11:01.773492 (ThreadPoolExecutor-0_0): 22:11:01  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 22:11:01.773573 (ThreadPoolExecutor-0_0): 22:11:01  Opening a new connection, currently in state init
2022-01-06 22:11:01.773834 (ThreadPoolExecutor-0_0): 22:11:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:11:01.809202 (ThreadPoolExecutor-0_0): 22:11:01  SQL status: SELECT in 0.04 seconds
2022-01-06 22:11:01.810803 (ThreadPoolExecutor-0_0): 22:11:01  On list_dev: Close
2022-01-06 22:11:01.811954 (ThreadPoolExecutor-1_0): 22:11:01  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:11:01.818055 (ThreadPoolExecutor-1_0): 22:11:01  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:11:01.818155 (ThreadPoolExecutor-1_0): 22:11:01  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 22:11:01.818234 (ThreadPoolExecutor-1_0): 22:11:01  Opening a new connection, currently in state closed
2022-01-06 22:11:01.818312 (ThreadPoolExecutor-1_0): 22:11:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:11:01.860241 (ThreadPoolExecutor-1_0): 22:11:01  SQL status: BEGIN in 0.04 seconds
2022-01-06 22:11:01.860375 (ThreadPoolExecutor-1_0): 22:11:01  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:11:01.860454 (ThreadPoolExecutor-1_0): 22:11:01  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 22:11:01.877417 (ThreadPoolExecutor-1_0): 22:11:01  SQL status: SELECT in 0.02 seconds
2022-01-06 22:11:01.878569 (ThreadPoolExecutor-1_0): 22:11:01  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 22:11:01.881043 (ThreadPoolExecutor-1_0): 22:11:01  On list_dev_dbt_nobodozie: Close
2022-01-06 22:11:01.885530 (MainThread): 22:11:01  Using redshift connection "master"
2022-01-06 22:11:01.885644 (MainThread): 22:11:01  On master: BEGIN
2022-01-06 22:11:01.885727 (MainThread): 22:11:01  Opening a new connection, currently in state init
2022-01-06 22:11:01.885808 (MainThread): 22:11:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:11:02.044012 (Thread-961): handling poll request
2022-01-06 22:11:02.044439 (Thread-961): 22:11:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4190d90>]}
2022-01-06 22:11:02.045536 (Thread-961): sending response (<Response 9978 bytes [200 OK]>) to 10.0.34.75
2022-01-06 22:11:02.079266 (MainThread): 22:11:02  SQL status: BEGIN in 0.19 seconds
2022-01-06 22:11:02.079430 (MainThread): 22:11:02  Using redshift connection "master"
2022-01-06 22:11:02.079515 (MainThread): 22:11:02  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 22:11:02.129676 (MainThread): 22:11:02  SQL status: SELECT in 0.05 seconds
2022-01-06 22:11:02.131333 (MainThread): 22:11:02  On master: ROLLBACK
2022-01-06 22:11:02.133935 (MainThread): 22:11:02  Using redshift connection "master"
2022-01-06 22:11:02.134056 (MainThread): 22:11:02  On master: BEGIN
2022-01-06 22:11:02.138915 (MainThread): 22:11:02  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:11:02.139031 (MainThread): 22:11:02  On master: COMMIT
2022-01-06 22:11:02.139104 (MainThread): 22:11:02  Using redshift connection "master"
2022-01-06 22:11:02.139173 (MainThread): 22:11:02  On master: COMMIT
2022-01-06 22:11:02.141504 (MainThread): 22:11:02  SQL status: COMMIT in 0.0 seconds
2022-01-06 22:11:02.141620 (MainThread): 22:11:02  On master: Close
2022-01-06 22:11:02.142090 (MainThread): 22:11:02  Concurrency: 4 threads (target='default')
2022-01-06 22:11:02.142208 (MainThread): 22:11:02  
2022-01-06 22:11:02.144616 (Thread-1): 22:11:02  Began running node model.jaffel_shop.stg_customers
2022-01-06 22:11:02.144897 (Thread-1): 22:11:02  1 of 5 START view model dbt_nobodozie.stg_customers............................. [RUN]
2022-01-06 22:11:02.145169 (Thread-1): 22:11:02  Acquiring new redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:11:02.145297 (Thread-1): 22:11:02  Began compiling node model.jaffel_shop.stg_customers
2022-01-06 22:11:02.145391 (Thread-1): 22:11:02  Compiling model.jaffel_shop.stg_customers
2022-01-06 22:11:02.146713 (Thread-1): 22:11:02  Writing injected SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 22:11:02.146950 (Thread-2): 22:11:02  Began running node model.jaffel_shop.stg_orders
2022-01-06 22:11:02.147201 (Thread-2): 22:11:02  2 of 5 START view model dbt_nobodozie.stg_orders................................ [RUN]
2022-01-06 22:11:02.147462 (Thread-2): 22:11:02  Acquiring new redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:11:02.147558 (Thread-2): 22:11:02  Began compiling node model.jaffel_shop.stg_orders
2022-01-06 22:11:02.147640 (Thread-2): 22:11:02  Compiling model.jaffel_shop.stg_orders
2022-01-06 22:11:02.148708 (Thread-2): 22:11:02  Writing injected SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 22:11:02.149020 (Thread-3): 22:11:02  Began running node model.jaffel_shop.stg_payments
2022-01-06 22:11:02.149420 (Thread-3): 22:11:02  3 of 5 START view model dbt_nobodozie.stg_payments.............................. [RUN]
2022-01-06 22:11:02.149685 (Thread-3): 22:11:02  Acquiring new redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:11:02.149782 (Thread-3): 22:11:02  Began compiling node model.jaffel_shop.stg_payments
2022-01-06 22:11:02.149860 (Thread-3): 22:11:02  Compiling model.jaffel_shop.stg_payments
2022-01-06 22:11:02.150903 (Thread-3): 22:11:02  Writing injected SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 22:11:02.166836 (Thread-2): 22:11:02  finished collecting timing info
2022-01-06 22:11:02.167014 (Thread-2): 22:11:02  Began executing node model.jaffel_shop.stg_orders
2022-01-06 22:11:02.171940 (Thread-1): 22:11:02  finished collecting timing info
2022-01-06 22:11:02.172081 (Thread-1): 22:11:02  Began executing node model.jaffel_shop.stg_customers
2022-01-06 22:11:02.188945 (Thread-3): 22:11:02  finished collecting timing info
2022-01-06 22:11:02.189089 (Thread-3): 22:11:02  Began executing node model.jaffel_shop.stg_payments
2022-01-06 22:11:02.217650 (Thread-2): 22:11:02  Writing runtime SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 22:11:02.217913 (Thread-1): 22:11:02  Writing runtime SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 22:11:02.218953 (Thread-3): 22:11:02  Writing runtime SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 22:11:02.234419 (Thread-2): 22:11:02  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:11:02.234540 (Thread-2): 22:11:02  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 22:11:02.234630 (Thread-2): 22:11:02  Opening a new connection, currently in state init
2022-01-06 22:11:02.234714 (Thread-2): 22:11:02  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:11:02.235089 (Thread-1): 22:11:02  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:11:02.235195 (Thread-1): 22:11:02  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 22:11:02.235277 (Thread-1): 22:11:02  Opening a new connection, currently in state closed
2022-01-06 22:11:02.235355 (Thread-1): 22:11:02  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:11:02.235617 (Thread-3): 22:11:02  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:11:02.235721 (Thread-3): 22:11:02  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 22:11:02.235804 (Thread-3): 22:11:02  Opening a new connection, currently in state init
2022-01-06 22:11:02.235881 (Thread-3): 22:11:02  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:11:02.286877 (Thread-3): 22:11:02  SQL status: BEGIN in 0.05 seconds
2022-01-06 22:11:02.287053 (Thread-3): 22:11:02  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:11:02.287139 (Thread-3): 22:11:02  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */


  create view "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" as (
    with payment as (

    select
        id as payment_id,
        orderid as order_id,
        paymentmethod as payment_method,

        -- amount is stored in cents, convert it to dollars
        amount/100 as amount,
        status

    from stripe.payment

)
select * from payment
  ) ;

2022-01-06 22:11:02.289814 (Thread-1): 22:11:02  SQL status: BEGIN in 0.05 seconds
2022-01-06 22:11:02.289955 (Thread-1): 22:11:02  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:11:02.290038 (Thread-1): 22:11:02  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */


  create view "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
  ) ;

2022-01-06 22:11:02.298817 (Thread-3): 22:11:02  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:11:02.304913 (Thread-3): 22:11:02  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:11:02.305026 (Thread-3): 22:11:02  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments" rename to "stg_payments__dbt_backup"
2022-01-06 22:11:02.305203 (Thread-1): 22:11:02  SQL status: CREATE VIEW in 0.02 seconds
2022-01-06 22:11:02.307284 (Thread-1): 22:11:02  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:11:02.307384 (Thread-1): 22:11:02  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers" rename to "stg_customers__dbt_backup"
2022-01-06 22:11:02.308339 (Thread-3): 22:11:02  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:11:02.310269 (Thread-3): 22:11:02  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:11:02.310368 (Thread-3): 22:11:02  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" rename to "stg_payments"
2022-01-06 22:11:02.310580 (Thread-1): 22:11:02  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:11:02.313206 (Thread-1): 22:11:02  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:11:02.313341 (Thread-1): 22:11:02  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" rename to "stg_customers"
2022-01-06 22:11:02.313680 (Thread-3): 22:11:02  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:11:02.320316 (Thread-3): 22:11:02  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:11:02.320420 (Thread-3): 22:11:02  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:11:02.320584 (Thread-3): 22:11:02  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:11:02.320741 (Thread-1): 22:11:02  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 22:11:02.321716 (Thread-1): 22:11:02  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:11:02.321813 (Thread-1): 22:11:02  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:11:02.321886 (Thread-1): 22:11:02  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:11:02.397717 (Thread-3): 22:11:02  SQL status: COMMIT in 0.08 seconds
2022-01-06 22:11:02.398009 (Thread-3): 22:11:02  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:11:02.398100 (Thread-3): 22:11:02  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 22:11:02.398923 (Thread-1): 22:11:02  SQL status: COMMIT in 0.08 seconds
2022-01-06 22:11:02.401103 (Thread-3): 22:11:02  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:11:02.405632 (Thread-3): 22:11:02  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:11:02.405735 (Thread-3): 22:11:02  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
drop view if exists "dev"."dbt_nobodozie"."stg_payments__dbt_backup" cascade
2022-01-06 22:11:02.413604 (Thread-3): 22:11:02  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 22:11:02.414303 (Thread-3): 22:11:02  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:11:02.414398 (Thread-3): 22:11:02  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:11:02.414471 (Thread-3): 22:11:02  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:11:02.453388 (Thread-3): 22:11:02  SQL status: COMMIT in 0.04 seconds
2022-01-06 22:11:02.453544 (Thread-3): 22:11:02  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:11:02.453651 (Thread-3): 22:11:02  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 22:11:02.456742 (Thread-3): 22:11:02  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:11:02.457373 (Thread-3): 22:11:02  finished collecting timing info
2022-01-06 22:11:02.457541 (Thread-3): 22:11:02  On model.jaffel_shop.stg_payments: ROLLBACK
2022-01-06 22:11:02.457922 (Thread-1): 22:11:02  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:11:02.458043 (Thread-1): 22:11:02  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 22:11:02.460841 (Thread-1): 22:11:02  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:11:02.462209 (Thread-1): 22:11:02  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:11:02.462464 (Thread-1): 22:11:02  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
drop view if exists "dev"."dbt_nobodozie"."stg_customers__dbt_backup" cascade
2022-01-06 22:11:02.462780 (Thread-3): 22:11:02  On model.jaffel_shop.stg_payments: Close
2022-01-06 22:11:02.463284 (Thread-3): 22:11:02  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '947fbfe1-dece-4973-a5fc-ea4432e49bc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5200ba5e0>]}
2022-01-06 22:11:02.463623 (Thread-3): 22:11:02  3 of 5 OK created view model dbt_nobodozie.stg_payments......................... [CREATE VIEW in 0.31s]
2022-01-06 22:11:02.463741 (Thread-3): 22:11:02  Finished running node model.jaffel_shop.stg_payments
2022-01-06 22:11:02.472529 (Thread-1): 22:11:02  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 22:11:02.473246 (Thread-1): 22:11:02  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:11:02.473350 (Thread-1): 22:11:02  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:11:02.473427 (Thread-1): 22:11:02  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:11:02.524316 (Thread-1): 22:11:02  SQL status: COMMIT in 0.05 seconds
2022-01-06 22:11:02.524446 (Thread-1): 22:11:02  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:11:02.524524 (Thread-1): 22:11:02  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 22:11:02.527222 (Thread-1): 22:11:02  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:11:02.527681 (Thread-1): 22:11:02  finished collecting timing info
2022-01-06 22:11:02.527809 (Thread-1): 22:11:02  On model.jaffel_shop.stg_customers: ROLLBACK
2022-01-06 22:11:02.530005 (Thread-1): 22:11:02  On model.jaffel_shop.stg_customers: Close
2022-01-06 22:11:02.530461 (Thread-1): 22:11:02  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '947fbfe1-dece-4973-a5fc-ea4432e49bc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb522167ee0>]}
2022-01-06 22:11:02.530783 (Thread-1): 22:11:02  1 of 5 OK created view model dbt_nobodozie.stg_customers........................ [CREATE VIEW in 0.39s]
2022-01-06 22:11:02.530892 (Thread-1): 22:11:02  Finished running node model.jaffel_shop.stg_customers
2022-01-06 22:11:02.737177 (Thread-2): 22:11:02  SQL status: BEGIN in 0.5 seconds
2022-01-06 22:11:02.737397 (Thread-2): 22:11:02  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:11:02.737499 (Thread-2): 22:11:02  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */


  create view "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" as (
    with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
  ) ;

2022-01-06 22:11:02.745721 (Thread-2): 22:11:02  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:11:02.748338 (Thread-2): 22:11:02  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:11:02.748454 (Thread-2): 22:11:02  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders" rename to "stg_orders__dbt_backup"
2022-01-06 22:11:02.751599 (Thread-2): 22:11:02  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:11:02.753645 (Thread-2): 22:11:02  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:11:02.753743 (Thread-2): 22:11:02  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" rename to "stg_orders"
2022-01-06 22:11:02.756696 (Thread-2): 22:11:02  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:11:02.757818 (Thread-2): 22:11:02  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:11:02.757930 (Thread-2): 22:11:02  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:11:02.758034 (Thread-2): 22:11:02  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:11:02.796021 (Thread-2): 22:11:02  SQL status: COMMIT in 0.04 seconds
2022-01-06 22:11:02.796304 (Thread-2): 22:11:02  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:11:02.796393 (Thread-2): 22:11:02  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 22:11:02.799351 (Thread-2): 22:11:02  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:11:02.800830 (Thread-2): 22:11:02  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:11:02.800928 (Thread-2): 22:11:02  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
drop view if exists "dev"."dbt_nobodozie"."stg_orders__dbt_backup" cascade
2022-01-06 22:11:02.805377 (Thread-2): 22:11:02  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 22:11:02.806115 (Thread-2): 22:11:02  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:11:02.806208 (Thread-2): 22:11:02  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:11:02.806281 (Thread-2): 22:11:02  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:11:02.839302 (Thread-2): 22:11:02  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:11:02.839418 (Thread-2): 22:11:02  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:11:02.839492 (Thread-2): 22:11:02  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 22:11:02.842091 (Thread-2): 22:11:02  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:11:02.842537 (Thread-2): 22:11:02  finished collecting timing info
2022-01-06 22:11:02.842668 (Thread-2): 22:11:02  On model.jaffel_shop.stg_orders: ROLLBACK
2022-01-06 22:11:02.844801 (Thread-2): 22:11:02  On model.jaffel_shop.stg_orders: Close
2022-01-06 22:11:02.845301 (Thread-2): 22:11:02  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '947fbfe1-dece-4973-a5fc-ea4432e49bc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5218fbf70>]}
2022-01-06 22:11:02.845632 (Thread-2): 22:11:02  2 of 5 OK created view model dbt_nobodozie.stg_orders........................... [CREATE VIEW in 0.70s]
2022-01-06 22:11:02.845745 (Thread-2): 22:11:02  Finished running node model.jaffel_shop.stg_orders
2022-01-06 22:11:02.846679 (Thread-4): 22:11:02  Began running node model.jaffel_shop.dim_customers
2022-01-06 22:11:02.846936 (Thread-4): 22:11:02  4 of 5 START view model dbt_nobodozie.dim_customers............................. [RUN]
2022-01-06 22:11:02.847193 (Thread-4): 22:11:02  Acquiring new redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:11:02.847282 (Thread-4): 22:11:02  Began compiling node model.jaffel_shop.dim_customers
2022-01-06 22:11:02.847367 (Thread-4): 22:11:02  Compiling model.jaffel_shop.dim_customers
2022-01-06 22:11:02.849979 (Thread-4): 22:11:02  Writing injected SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 22:11:02.850190 (Thread-3): 22:11:02  Began running node model.jaffel_shop.fct_orders
2022-01-06 22:11:02.850407 (Thread-3): 22:11:02  5 of 5 START view model dbt_nobodozie.fct_orders................................ [RUN]
2022-01-06 22:11:02.850637 (Thread-3): 22:11:02  Acquiring new redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:11:02.850727 (Thread-3): 22:11:02  Began compiling node model.jaffel_shop.fct_orders
2022-01-06 22:11:02.850806 (Thread-3): 22:11:02  Compiling model.jaffel_shop.fct_orders
2022-01-06 22:11:02.853050 (Thread-3): 22:11:02  Writing injected SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 22:11:02.869516 (Thread-3): 22:11:02  finished collecting timing info
2022-01-06 22:11:02.869673 (Thread-3): 22:11:02  Began executing node model.jaffel_shop.fct_orders
2022-01-06 22:11:02.871607 (Thread-3): 22:11:02  Writing runtime SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 22:11:02.871882 (Thread-4): 22:11:02  finished collecting timing info
2022-01-06 22:11:02.872016 (Thread-4): 22:11:02  Began executing node model.jaffel_shop.dim_customers
2022-01-06 22:11:02.873977 (Thread-4): 22:11:02  Writing runtime SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 22:11:02.889178 (Thread-4): 22:11:02  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:11:02.889327 (Thread-4): 22:11:02  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 22:11:02.889414 (Thread-4): 22:11:02  Opening a new connection, currently in state init
2022-01-06 22:11:02.889498 (Thread-4): 22:11:02  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:11:02.889792 (Thread-3): 22:11:02  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:11:02.889907 (Thread-3): 22:11:02  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 22:11:02.890021 (Thread-3): 22:11:02  Opening a new connection, currently in state closed
2022-01-06 22:11:02.890107 (Thread-3): 22:11:02  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:11:02.934100 (Thread-4): 22:11:02  SQL status: BEGIN in 0.04 seconds
2022-01-06 22:11:02.934244 (Thread-4): 22:11:02  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:11:02.934326 (Thread-4): 22:11:02  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */


  create view "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" as (
    with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"
),




customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
        
    from customers

    left join customer_orders using (customer_id)
 
)

select * from final
  ) ;

2022-01-06 22:11:02.934500 (Thread-3): 22:11:02  SQL status: BEGIN in 0.04 seconds
2022-01-06 22:11:02.934628 (Thread-3): 22:11:02  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:11:02.934747 (Thread-3): 22:11:02  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */


  create view "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" as (
    with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),


order_payments as (
    select
        order_id,
        sum(case when status = 'success' then amount end ) as amount
    from payment
    group by 1
),



final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
  ) ;

2022-01-06 22:11:02.951176 (Thread-3): 22:11:02  SQL status: CREATE VIEW in 0.02 seconds
2022-01-06 22:11:02.953447 (Thread-3): 22:11:02  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:11:02.953554 (Thread-3): 22:11:02  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
alter table "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" rename to "fct_orders"
2022-01-06 22:11:02.954774 (Thread-4): 22:11:02  SQL status: CREATE VIEW in 0.02 seconds
2022-01-06 22:11:02.956730 (Thread-4): 22:11:02  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:11:02.956831 (Thread-4): 22:11:02  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 22:11:02.957040 (Thread-3): 22:11:02  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:11:02.958198 (Thread-3): 22:11:02  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:11:02.958293 (Thread-3): 22:11:02  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:11:02.958364 (Thread-3): 22:11:02  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:11:02.961431 (Thread-4): 22:11:02  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:11:02.963185 (Thread-4): 22:11:02  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:11:02.963284 (Thread-4): 22:11:02  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 22:11:02.966322 (Thread-4): 22:11:02  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:11:02.967282 (Thread-4): 22:11:02  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 22:11:02.967375 (Thread-4): 22:11:02  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:11:02.967447 (Thread-4): 22:11:02  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 22:11:03.040809 (Thread-3): 22:11:03  SQL status: COMMIT in 0.08 seconds
2022-01-06 22:11:03.041116 (Thread-3): 22:11:03  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:11:03.041209 (Thread-3): 22:11:03  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 22:11:03.042011 (Thread-4): 22:11:03  SQL status: COMMIT in 0.07 seconds
2022-01-06 22:11:03.044405 (Thread-3): 22:11:03  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:11:03.046017 (Thread-3): 22:11:03  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:11:03.046117 (Thread-3): 22:11:03  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
drop view if exists "dev"."dbt_nobodozie"."fct_orders__dbt_backup" cascade
2022-01-06 22:11:03.048674 (Thread-3): 22:11:03  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 22:11:03.049459 (Thread-3): 22:11:03  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:11:03.049558 (Thread-3): 22:11:03  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:11:03.049631 (Thread-3): 22:11:03  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:11:03.085098 (Thread-3): 22:11:03  SQL status: COMMIT in 0.04 seconds
2022-01-06 22:11:03.085254 (Thread-3): 22:11:03  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:11:03.085341 (Thread-3): 22:11:03  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 22:11:03.088122 (Thread-3): 22:11:03  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:11:03.088595 (Thread-3): 22:11:03  finished collecting timing info
2022-01-06 22:11:03.088727 (Thread-3): 22:11:03  On model.jaffel_shop.fct_orders: ROLLBACK
2022-01-06 22:11:03.088941 (Thread-4): 22:11:03  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:11:03.089053 (Thread-4): 22:11:03  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 22:11:03.091226 (Thread-3): 22:11:03  On model.jaffel_shop.fct_orders: Close
2022-01-06 22:11:03.091730 (Thread-3): 22:11:03  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '947fbfe1-dece-4973-a5fc-ea4432e49bc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb520035730>]}
2022-01-06 22:11:03.092081 (Thread-3): 22:11:03  5 of 5 OK created view model dbt_nobodozie.fct_orders........................... [CREATE VIEW in 0.24s]
2022-01-06 22:11:03.092205 (Thread-3): 22:11:03  Finished running node model.jaffel_shop.fct_orders
2022-01-06 22:11:03.092441 (Thread-4): 22:11:03  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:11:03.095155 (Thread-4): 22:11:03  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:11:03.095267 (Thread-4): 22:11:03  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 22:11:03.100714 (Thread-4): 22:11:03  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 22:11:03.101432 (Thread-4): 22:11:03  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 22:11:03.101527 (Thread-4): 22:11:03  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:11:03.101600 (Thread-4): 22:11:03  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 22:11:03.144198 (Thread-4): 22:11:03  SQL status: COMMIT in 0.04 seconds
2022-01-06 22:11:03.144318 (Thread-4): 22:11:03  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:11:03.144394 (Thread-4): 22:11:03  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 22:11:03.147066 (Thread-4): 22:11:03  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:11:03.147467 (Thread-4): 22:11:03  finished collecting timing info
2022-01-06 22:11:03.147590 (Thread-4): 22:11:03  On model.jaffel_shop.dim_customers: ROLLBACK
2022-01-06 22:11:03.149777 (Thread-4): 22:11:03  On model.jaffel_shop.dim_customers: Close
2022-01-06 22:11:03.150196 (Thread-4): 22:11:03  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '947fbfe1-dece-4973-a5fc-ea4432e49bc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb50a7e73d0>]}
2022-01-06 22:11:03.150506 (Thread-4): 22:11:03  4 of 5 OK created view model dbt_nobodozie.dim_customers........................ [CREATE VIEW in 0.30s]
2022-01-06 22:11:03.150633 (Thread-4): 22:11:03  Finished running node model.jaffel_shop.dim_customers
2022-01-06 22:11:03.151945 (MainThread): 22:11:03  Acquiring new redshift connection "master"
2022-01-06 22:11:03.152088 (MainThread): 22:11:03  Using redshift connection "master"
2022-01-06 22:11:03.152164 (MainThread): 22:11:03  On master: BEGIN
2022-01-06 22:11:03.152241 (MainThread): 22:11:03  Opening a new connection, currently in state closed
2022-01-06 22:11:03.152321 (MainThread): 22:11:03  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:11:03.177910 (MainThread): 22:11:03  SQL status: BEGIN in 0.03 seconds
2022-01-06 22:11:03.178029 (MainThread): 22:11:03  On master: COMMIT
2022-01-06 22:11:03.178103 (MainThread): 22:11:03  Using redshift connection "master"
2022-01-06 22:11:03.178173 (MainThread): 22:11:03  On master: COMMIT
2022-01-06 22:11:03.180435 (MainThread): 22:11:03  SQL status: COMMIT in 0.0 seconds
2022-01-06 22:11:03.180549 (MainThread): 22:11:03  On master: Close
2022-01-06 22:11:03.180976 (MainThread): 22:11:03  
2022-01-06 22:11:03.181090 (MainThread): 22:11:03  Finished running 5 view models in 1.42s.
2022-01-06 22:11:03.181171 (MainThread): 22:11:03  Connection 'master' was properly closed.
2022-01-06 22:11:03.181277 (MainThread): 22:11:03  Connection 'model.jaffel_shop.stg_customers' was properly closed.
2022-01-06 22:11:03.181347 (MainThread): 22:11:03  Connection 'model.jaffel_shop.stg_orders' was properly closed.
2022-01-06 22:11:03.181408 (MainThread): 22:11:03  Connection 'model.jaffel_shop.fct_orders' was properly closed.
2022-01-06 22:11:03.181467 (MainThread): 22:11:03  Connection 'model.jaffel_shop.dim_customers' was properly closed.
2022-01-06 22:11:03.231863 (MainThread): 22:11:03  
2022-01-06 22:11:03.232026 (MainThread): 22:11:03  Completed successfully
2022-01-06 22:11:03.232124 (MainThread): 22:11:03  
2022-01-06 22:11:03.232209 (MainThread): 22:11:03  Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2022-01-06 22:11:03.497836 (Thread-962): handling poll request
2022-01-06 22:11:03.498215 (Thread-962): 22:11:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea41701f0>]}
2022-01-06 22:11:03.523948 (Thread-962): sending response (<Response 115784 bytes [200 OK]>) to 10.0.39.202
2022-01-06 22:11:04.250221 (Thread-963): handling status request
2022-01-06 22:11:04.250597 (Thread-963): 22:11:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4170cd0>]}
2022-01-06 22:11:04.251105 (Thread-963): sending response (<Response 1575 bytes [200 OK]>) to 10.0.28.107
2022-01-06 22:11:04.772012 (Thread-964): handling status request
2022-01-06 22:11:04.772391 (Thread-964): 22:11:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4170970>]}
2022-01-06 22:11:04.772891 (Thread-964): sending response (<Response 1575 bytes [200 OK]>) to 10.0.25.198
2022-01-06 22:11:22.741941 (Thread-965): handling status request
2022-01-06 22:11:22.742382 (Thread-965): 22:11:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4170790>]}
2022-01-06 22:11:22.742876 (Thread-965): sending response (<Response 1575 bytes [200 OK]>) to 10.0.15.38
2022-01-06 22:11:23.181867 (Thread-966): handling run_sql request
2022-01-06 22:11:23.182222 (Thread-966): 22:11:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4170c40>]}
2022-01-06 22:11:25.250634 (Thread-966): sending response (<Response 138 bytes [200 OK]>) to 10.0.29.201
2022-01-06 22:11:25.274772 (MainThread): 22:11:25  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '43aa7840-e601-4280-b691-bbe146359285', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53c7a32790>]}
2022-01-06 22:11:25.275278 (MainThread): 22:11:25  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:11:25.275821 (Thread-1): 22:11:25  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:11:25.275950 (Thread-1): 22:11:25  Began compiling node rpc.jaffel_shop.request
2022-01-06 22:11:25.276035 (Thread-1): 22:11:25  Compiling rpc.jaffel_shop.request
2022-01-06 22:11:25.278275 (Thread-1): 22:11:25  finished collecting timing info
2022-01-06 22:11:25.278400 (Thread-1): 22:11:25  Began executing node rpc.jaffel_shop.request
2022-01-06 22:11:25.278495 (Thread-1): 22:11:25  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:11:25.278569 (Thread-1): 22:11:25  On rpc.jaffel_shop.request: with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),


order_payments as (
    select
        order_id,
        sum(case when status = 'success' then amount end ) as amount
    from payment
    group by 1
),



final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 22:11:25.278645 (Thread-1): 22:11:25  Opening a new connection, currently in state init
2022-01-06 22:11:25.278720 (Thread-1): 22:11:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:11:25.635151 (Thread-1): 22:11:25  SQL status: SELECT in 0.36 seconds
2022-01-06 22:11:25.637818 (Thread-1): 22:11:25  finished collecting timing info
2022-01-06 22:11:25.637963 (Thread-1): 22:11:25  On rpc.jaffel_shop.request: Close
2022-01-06 22:11:25.650733 (Thread-967): handling poll request
2022-01-06 22:11:25.651112 (Thread-967): 22:11:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea411d5e0>]}
2022-01-06 22:11:25.651997 (Thread-967): sending response (<Response 5601 bytes [200 OK]>) to 10.0.32.47
2022-01-06 22:11:27.757671 (Thread-968): handling poll request
2022-01-06 22:11:27.758063 (Thread-968): 22:11:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea411d580>]}
2022-01-06 22:11:27.759333 (Thread-968): sending response (<Response 8124 bytes [200 OK]>) to 10.0.9.169
2022-01-06 22:13:16.417989 (Thread-969): handling status request
2022-01-06 22:13:16.420693 (Thread-969): 22:13:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea411d910>]}
2022-01-06 22:13:16.421265 (Thread-969): sending response (<Response 1575 bytes [200 OK]>) to 10.0.25.198
2022-01-06 22:13:16.801388 (Thread-970): handling run_sql request
2022-01-06 22:13:16.801770 (Thread-970): 22:13:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea411dca0>]}
2022-01-06 22:13:18.845566 (Thread-970): sending response (<Response 138 bytes [200 OK]>) to 10.0.34.75
2022-01-06 22:13:18.871903 (MainThread): 22:13:18  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e855d350-4a2a-4520-a21a-7d043634eaec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75c37f9ac0>]}
2022-01-06 22:13:18.872424 (MainThread): 22:13:18  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:13:18.872989 (Thread-1): 22:13:18  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:13:18.873122 (Thread-1): 22:13:18  Began compiling node rpc.jaffel_shop.request
2022-01-06 22:13:18.873210 (Thread-1): 22:13:18  Compiling rpc.jaffel_shop.request
2022-01-06 22:13:18.874388 (Thread-1): 22:13:18  finished collecting timing info
2022-01-06 22:13:18.874523 (Thread-1): 22:13:18  Began executing node rpc.jaffel_shop.request
2022-01-06 22:13:18.874624 (Thread-1): 22:13:18  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:13:18.874706 (Thread-1): 22:13:18  On rpc.jaffel_shop.request: with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 22:13:18.874787 (Thread-1): 22:13:18  Opening a new connection, currently in state init
2022-01-06 22:13:18.874867 (Thread-1): 22:13:18  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:13:18.896837 (Thread-1): 22:13:18  SQL status: SELECT in 0.02 seconds
2022-01-06 22:13:18.899349 (Thread-1): 22:13:18  finished collecting timing info
2022-01-06 22:13:18.899482 (Thread-1): 22:13:18  On rpc.jaffel_shop.request: Close
2022-01-06 22:13:19.231598 (Thread-971): handling poll request
2022-01-06 22:13:19.232026 (Thread-971): 22:13:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea41701c0>]}
2022-01-06 22:13:19.233568 (Thread-971): sending response (<Response 11841 bytes [200 OK]>) to 10.0.14.166
2022-01-06 22:30:26.148360 (Thread-972): 22:30:26  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 22:30:26.149997 (Thread-972): 22:30:26  Partial parsing: updated file: jaffel_shop://models/marts/core/dim_customers.sql
2022-01-06 22:30:26.154136 (Thread-972): 22:30:26  1699: static parser successfully parsed marts/core/dim_customers.sql
2022-01-06 22:30:26.199297 (Thread-972): 22:30:26  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4180a00>]}
2022-01-06 22:30:26.789478 (Thread-973): handling status request
2022-01-06 22:30:26.789849 (Thread-973): 22:30:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4096a60>]}
2022-01-06 22:30:26.790347 (Thread-973): sending response (<Response 1575 bytes [200 OK]>) to 10.0.16.23
2022-01-06 22:30:26.793677 (Thread-974): handling status request
2022-01-06 22:30:26.793964 (Thread-974): 22:30:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea425f550>]}
2022-01-06 22:30:26.794328 (Thread-974): sending response (<Response 1575 bytes [200 OK]>) to 10.0.29.201
2022-01-06 22:30:28.510639 (Thread-975): handling status request
2022-01-06 22:30:28.511021 (Thread-975): 22:30:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4096610>]}
2022-01-06 22:30:28.511506 (Thread-975): sending response (<Response 1575 bytes [200 OK]>) to 10.0.32.47
2022-01-06 22:30:28.926732 (Thread-976): handling cli_args request
2022-01-06 22:30:28.927058 (Thread-976): 22:30:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4096400>]}
2022-01-06 22:30:28.967369 (Thread-977): handling status request
2022-01-06 22:30:28.968022 (Thread-977): 22:30:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea417b250>]}
2022-01-06 22:30:28.968780 (Thread-977): sending response (<Response 1575 bytes [200 OK]>) to 10.0.28.107
2022-01-06 22:30:30.968928 (Thread-976): sending response (<Response 138 bytes [200 OK]>) to 10.0.15.38
2022-01-06 22:30:31.065310 (MainThread): 22:30:31  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 22:30:31.065714 (MainThread): 22:30:31  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 22:30:31.071280 (MainThread): 22:30:31  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b501e00a-f7de-4d08-b2ca-6f3a069c42f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54d7fde0d0>]}
2022-01-06 22:30:31.100249 (MainThread): 22:30:31  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b501e00a-f7de-4d08-b2ca-6f3a069c42f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54d80759d0>]}
2022-01-06 22:30:31.100502 (MainThread): 22:30:31  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:30:31.101518 (MainThread): 22:30:31  
2022-01-06 22:30:31.101812 (MainThread): 22:30:31  Acquiring new redshift connection "master"
2022-01-06 22:30:31.102762 (ThreadPoolExecutor-0_0): 22:30:31  Acquiring new redshift connection "list_dev"
2022-01-06 22:30:31.112570 (ThreadPoolExecutor-0_0): 22:30:31  Using redshift connection "list_dev"
2022-01-06 22:30:31.112676 (ThreadPoolExecutor-0_0): 22:30:31  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 22:30:31.112761 (ThreadPoolExecutor-0_0): 22:30:31  Opening a new connection, currently in state init
2022-01-06 22:30:31.112842 (ThreadPoolExecutor-0_0): 22:30:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:30:31.133630 (ThreadPoolExecutor-0_0): 22:30:31  SQL status: SELECT in 0.02 seconds
2022-01-06 22:30:31.134664 (ThreadPoolExecutor-0_0): 22:30:31  On list_dev: Close
2022-01-06 22:30:31.135851 (ThreadPoolExecutor-1_0): 22:30:31  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:30:31.141967 (ThreadPoolExecutor-1_0): 22:30:31  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:30:31.142066 (ThreadPoolExecutor-1_0): 22:30:31  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 22:30:31.142145 (ThreadPoolExecutor-1_0): 22:30:31  Opening a new connection, currently in state closed
2022-01-06 22:30:31.142222 (ThreadPoolExecutor-1_0): 22:30:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:30:31.164045 (ThreadPoolExecutor-1_0): 22:30:31  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:30:31.164156 (ThreadPoolExecutor-1_0): 22:30:31  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:30:31.164230 (ThreadPoolExecutor-1_0): 22:30:31  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 22:30:31.175315 (ThreadPoolExecutor-1_0): 22:30:31  SQL status: SELECT in 0.01 seconds
2022-01-06 22:30:31.176381 (ThreadPoolExecutor-1_0): 22:30:31  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 22:30:31.178119 (ThreadPoolExecutor-1_0): 22:30:31  On list_dev_dbt_nobodozie: Close
2022-01-06 22:30:31.182328 (MainThread): 22:30:31  Using redshift connection "master"
2022-01-06 22:30:31.182454 (MainThread): 22:30:31  On master: BEGIN
2022-01-06 22:30:31.182537 (MainThread): 22:30:31  Opening a new connection, currently in state init
2022-01-06 22:30:31.182614 (MainThread): 22:30:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:30:31.205506 (MainThread): 22:30:31  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:30:31.205623 (MainThread): 22:30:31  Using redshift connection "master"
2022-01-06 22:30:31.205701 (MainThread): 22:30:31  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 22:30:31.234683 (MainThread): 22:30:31  SQL status: SELECT in 0.03 seconds
2022-01-06 22:30:31.235870 (MainThread): 22:30:31  On master: ROLLBACK
2022-01-06 22:30:31.237739 (MainThread): 22:30:31  Using redshift connection "master"
2022-01-06 22:30:31.237847 (MainThread): 22:30:31  On master: BEGIN
2022-01-06 22:30:31.241280 (MainThread): 22:30:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:30:31.241398 (MainThread): 22:30:31  On master: COMMIT
2022-01-06 22:30:31.241474 (MainThread): 22:30:31  Using redshift connection "master"
2022-01-06 22:30:31.241544 (MainThread): 22:30:31  On master: COMMIT
2022-01-06 22:30:31.243330 (MainThread): 22:30:31  SQL status: COMMIT in 0.0 seconds
2022-01-06 22:30:31.243458 (MainThread): 22:30:31  On master: Close
2022-01-06 22:30:31.243899 (MainThread): 22:30:31  Concurrency: 4 threads (target='default')
2022-01-06 22:30:31.244024 (MainThread): 22:30:31  
2022-01-06 22:30:31.246418 (Thread-1): 22:30:31  Began running node model.jaffel_shop.stg_customers
2022-01-06 22:30:31.246678 (Thread-1): 22:30:31  1 of 5 START view model dbt_nobodozie.stg_customers............................. [RUN]
2022-01-06 22:30:31.246927 (Thread-1): 22:30:31  Acquiring new redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:30:31.247020 (Thread-1): 22:30:31  Began compiling node model.jaffel_shop.stg_customers
2022-01-06 22:30:31.247108 (Thread-1): 22:30:31  Compiling model.jaffel_shop.stg_customers
2022-01-06 22:30:31.248302 (Thread-1): 22:30:31  Writing injected SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 22:30:31.248525 (Thread-2): 22:30:31  Began running node model.jaffel_shop.stg_orders
2022-01-06 22:30:31.248761 (Thread-2): 22:30:31  2 of 5 START view model dbt_nobodozie.stg_orders................................ [RUN]
2022-01-06 22:30:31.249014 (Thread-2): 22:30:31  Acquiring new redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:30:31.249099 (Thread-2): 22:30:31  Began compiling node model.jaffel_shop.stg_orders
2022-01-06 22:30:31.249181 (Thread-2): 22:30:31  Compiling model.jaffel_shop.stg_orders
2022-01-06 22:30:31.250327 (Thread-2): 22:30:31  Writing injected SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 22:30:31.250656 (Thread-3): 22:30:31  Began running node model.jaffel_shop.stg_payments
2022-01-06 22:30:31.251005 (Thread-3): 22:30:31  3 of 5 START view model dbt_nobodozie.stg_payments.............................. [RUN]
2022-01-06 22:30:31.251248 (Thread-3): 22:30:31  Acquiring new redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:30:31.251334 (Thread-3): 22:30:31  Began compiling node model.jaffel_shop.stg_payments
2022-01-06 22:30:31.251412 (Thread-3): 22:30:31  Compiling model.jaffel_shop.stg_payments
2022-01-06 22:30:31.252388 (Thread-3): 22:30:31  Writing injected SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 22:30:31.268438 (Thread-1): 22:30:31  finished collecting timing info
2022-01-06 22:30:31.268586 (Thread-1): 22:30:31  Began executing node model.jaffel_shop.stg_customers
2022-01-06 22:30:31.273533 (Thread-2): 22:30:31  finished collecting timing info
2022-01-06 22:30:31.273661 (Thread-2): 22:30:31  Began executing node model.jaffel_shop.stg_orders
2022-01-06 22:30:31.291270 (Thread-3): 22:30:31  finished collecting timing info
2022-01-06 22:30:31.291399 (Thread-3): 22:30:31  Began executing node model.jaffel_shop.stg_payments
2022-01-06 22:30:31.316155 (Thread-2): 22:30:31  Writing runtime SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 22:30:31.317241 (Thread-3): 22:30:31  Writing runtime SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 22:30:31.318209 (Thread-1): 22:30:31  Writing runtime SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 22:30:31.333447 (Thread-1): 22:30:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:30:31.333558 (Thread-1): 22:30:31  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 22:30:31.333640 (Thread-1): 22:30:31  Opening a new connection, currently in state closed
2022-01-06 22:30:31.333719 (Thread-1): 22:30:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:30:31.334017 (Thread-3): 22:30:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:30:31.334116 (Thread-3): 22:30:31  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 22:30:31.334194 (Thread-3): 22:30:31  Opening a new connection, currently in state init
2022-01-06 22:30:31.334270 (Thread-3): 22:30:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:30:31.334562 (Thread-2): 22:30:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:30:31.334663 (Thread-2): 22:30:31  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 22:30:31.334740 (Thread-2): 22:30:31  Opening a new connection, currently in state init
2022-01-06 22:30:31.334814 (Thread-2): 22:30:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:30:31.363686 (Thread-1): 22:30:31  SQL status: BEGIN in 0.03 seconds
2022-01-06 22:30:31.363800 (Thread-1): 22:30:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:30:31.363877 (Thread-1): 22:30:31  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */


  create view "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
  ) ;

2022-01-06 22:30:31.367064 (Thread-2): 22:30:31  SQL status: BEGIN in 0.03 seconds
2022-01-06 22:30:31.367187 (Thread-2): 22:30:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:30:31.367266 (Thread-2): 22:30:31  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */


  create view "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" as (
    with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
  ) ;

2022-01-06 22:30:31.370649 (Thread-3): 22:30:31  SQL status: BEGIN in 0.04 seconds
2022-01-06 22:30:31.370767 (Thread-3): 22:30:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:30:31.370845 (Thread-3): 22:30:31  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */


  create view "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" as (
    with payment as (

    select
        id as payment_id,
        orderid as order_id,
        paymentmethod as payment_method,

        -- amount is stored in cents, convert it to dollars
        amount/100 as amount,
        status

    from stripe.payment

)
select * from payment
  ) ;

2022-01-06 22:30:31.371656 (Thread-1): 22:30:31  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:30:31.376954 (Thread-1): 22:30:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:30:31.377058 (Thread-1): 22:30:31  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers" rename to "stg_customers__dbt_backup"
2022-01-06 22:30:31.377198 (Thread-2): 22:30:31  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:30:31.379099 (Thread-2): 22:30:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:30:31.379196 (Thread-2): 22:30:31  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders" rename to "stg_orders__dbt_backup"
2022-01-06 22:30:31.379398 (Thread-3): 22:30:31  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:30:31.381191 (Thread-3): 22:30:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:30:31.381329 (Thread-3): 22:30:31  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments" rename to "stg_payments__dbt_backup"
2022-01-06 22:30:31.381724 (Thread-2): 22:30:31  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:30:31.383402 (Thread-2): 22:30:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:30:31.383497 (Thread-2): 22:30:31  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" rename to "stg_orders"
2022-01-06 22:30:31.383650 (Thread-1): 22:30:31  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 22:30:31.386121 (Thread-1): 22:30:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:30:31.386220 (Thread-1): 22:30:31  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" rename to "stg_customers"
2022-01-06 22:30:31.386362 (Thread-3): 22:30:31  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:30:31.388074 (Thread-3): 22:30:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:30:31.388171 (Thread-3): 22:30:31  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" rename to "stg_payments"
2022-01-06 22:30:31.388314 (Thread-2): 22:30:31  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:30:31.393492 (Thread-3): 22:30:31  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 22:30:31.400140 (Thread-2): 22:30:31  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:30:31.400240 (Thread-2): 22:30:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:30:31.400313 (Thread-2): 22:30:31  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:30:31.400450 (Thread-3): 22:30:31  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:30:31.400553 (Thread-3): 22:30:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:30:31.400626 (Thread-3): 22:30:31  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:30:31.400769 (Thread-1): 22:30:31  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 22:30:31.401733 (Thread-1): 22:30:31  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:30:31.401830 (Thread-1): 22:30:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:30:31.401902 (Thread-1): 22:30:31  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:30:31.408627 (Thread-978): handling poll request
2022-01-06 22:30:31.408916 (Thread-978): 22:30:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea40a39d0>]}
2022-01-06 22:30:31.410759 (Thread-978): sending response (<Response 47114 bytes [200 OK]>) to 10.0.7.0
2022-01-06 22:30:31.458399 (Thread-3): 22:30:31  SQL status: COMMIT in 0.06 seconds
2022-01-06 22:30:31.458638 (Thread-3): 22:30:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:30:31.458726 (Thread-3): 22:30:31  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 22:30:31.459310 (Thread-2): 22:30:31  SQL status: COMMIT in 0.06 seconds
2022-01-06 22:30:31.459659 (Thread-1): 22:30:31  SQL status: COMMIT in 0.06 seconds
2022-01-06 22:30:31.460891 (Thread-3): 22:30:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:30:31.464883 (Thread-3): 22:30:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:30:31.464979 (Thread-3): 22:30:31  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
drop view if exists "dev"."dbt_nobodozie"."stg_payments__dbt_backup" cascade
2022-01-06 22:30:31.469845 (Thread-3): 22:30:31  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 22:30:31.470455 (Thread-3): 22:30:31  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:30:31.470548 (Thread-3): 22:30:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:30:31.470620 (Thread-3): 22:30:31  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:30:31.497737 (Thread-3): 22:30:31  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:30:31.497854 (Thread-3): 22:30:31  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:30:31.497931 (Thread-3): 22:30:31  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 22:30:31.499972 (Thread-3): 22:30:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:30:31.500358 (Thread-3): 22:30:31  finished collecting timing info
2022-01-06 22:30:31.500479 (Thread-3): 22:30:31  On model.jaffel_shop.stg_payments: ROLLBACK
2022-01-06 22:30:31.500700 (Thread-2): 22:30:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:30:31.500830 (Thread-2): 22:30:31  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 22:30:31.503215 (Thread-3): 22:30:31  On model.jaffel_shop.stg_payments: Close
2022-01-06 22:30:31.503385 (Thread-2): 22:30:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:30:31.504507 (Thread-2): 22:30:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:30:31.504601 (Thread-2): 22:30:31  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
drop view if exists "dev"."dbt_nobodozie"."stg_orders__dbt_backup" cascade
2022-01-06 22:30:31.504986 (Thread-3): 22:30:31  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b501e00a-f7de-4d08-b2ca-6f3a069c42f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54d471b8b0>]}
2022-01-06 22:30:31.505376 (Thread-3): 22:30:31  3 of 5 OK created view model dbt_nobodozie.stg_payments......................... [CREATE VIEW in 0.25s]
2022-01-06 22:30:31.505492 (Thread-3): 22:30:31  Finished running node model.jaffel_shop.stg_payments
2022-01-06 22:30:31.511937 (Thread-2): 22:30:31  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 22:30:31.512619 (Thread-2): 22:30:31  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:30:31.512712 (Thread-2): 22:30:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:30:31.512784 (Thread-2): 22:30:31  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:30:31.542643 (Thread-2): 22:30:31  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:30:31.542761 (Thread-2): 22:30:31  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:30:31.542835 (Thread-2): 22:30:31  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 22:30:31.544895 (Thread-2): 22:30:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:30:31.545327 (Thread-2): 22:30:31  finished collecting timing info
2022-01-06 22:30:31.545450 (Thread-2): 22:30:31  On model.jaffel_shop.stg_orders: ROLLBACK
2022-01-06 22:30:31.545643 (Thread-1): 22:30:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:30:31.545748 (Thread-1): 22:30:31  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 22:30:31.548200 (Thread-2): 22:30:31  On model.jaffel_shop.stg_orders: Close
2022-01-06 22:30:31.548362 (Thread-1): 22:30:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:30:31.549690 (Thread-1): 22:30:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:30:31.549785 (Thread-1): 22:30:31  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
drop view if exists "dev"."dbt_nobodozie"."stg_customers__dbt_backup" cascade
2022-01-06 22:30:31.550209 (Thread-2): 22:30:31  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b501e00a-f7de-4d08-b2ca-6f3a069c42f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54d6f55e50>]}
2022-01-06 22:30:31.550493 (Thread-2): 22:30:31  2 of 5 OK created view model dbt_nobodozie.stg_orders........................... [CREATE VIEW in 0.30s]
2022-01-06 22:30:31.550597 (Thread-2): 22:30:31  Finished running node model.jaffel_shop.stg_orders
2022-01-06 22:30:31.551221 (Thread-4): 22:30:31  Began running node model.jaffel_shop.fct_orders
2022-01-06 22:30:31.551453 (Thread-4): 22:30:31  4 of 5 START view model dbt_nobodozie.fct_orders................................ [RUN]
2022-01-06 22:30:31.551706 (Thread-4): 22:30:31  Acquiring new redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:30:31.551793 (Thread-4): 22:30:31  Began compiling node model.jaffel_shop.fct_orders
2022-01-06 22:30:31.551875 (Thread-4): 22:30:31  Compiling model.jaffel_shop.fct_orders
2022-01-06 22:30:31.554050 (Thread-4): 22:30:31  Writing injected SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 22:30:31.555036 (Thread-1): 22:30:31  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 22:30:31.555667 (Thread-1): 22:30:31  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:30:31.555762 (Thread-1): 22:30:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:30:31.555835 (Thread-1): 22:30:31  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:30:31.569850 (Thread-4): 22:30:31  finished collecting timing info
2022-01-06 22:30:31.569985 (Thread-4): 22:30:31  Began executing node model.jaffel_shop.fct_orders
2022-01-06 22:30:31.571749 (Thread-4): 22:30:31  Writing runtime SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 22:30:31.585006 (Thread-1): 22:30:31  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:30:31.585121 (Thread-1): 22:30:31  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:30:31.585196 (Thread-1): 22:30:31  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 22:30:31.586324 (Thread-4): 22:30:31  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:30:31.586449 (Thread-4): 22:30:31  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 22:30:31.586533 (Thread-4): 22:30:31  Opening a new connection, currently in state init
2022-01-06 22:30:31.586611 (Thread-4): 22:30:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:30:31.587253 (Thread-1): 22:30:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:30:31.587616 (Thread-1): 22:30:31  finished collecting timing info
2022-01-06 22:30:31.587733 (Thread-1): 22:30:31  On model.jaffel_shop.stg_customers: ROLLBACK
2022-01-06 22:30:31.594265 (Thread-1): 22:30:31  On model.jaffel_shop.stg_customers: Close
2022-01-06 22:30:31.594658 (Thread-1): 22:30:31  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b501e00a-f7de-4d08-b2ca-6f3a069c42f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54d779e160>]}
2022-01-06 22:30:31.594928 (Thread-1): 22:30:31  1 of 5 OK created view model dbt_nobodozie.stg_customers........................ [CREATE VIEW in 0.35s]
2022-01-06 22:30:31.595030 (Thread-1): 22:30:31  Finished running node model.jaffel_shop.stg_customers
2022-01-06 22:30:31.611910 (Thread-4): 22:30:31  SQL status: BEGIN in 0.03 seconds
2022-01-06 22:30:31.612030 (Thread-4): 22:30:31  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:30:31.612108 (Thread-4): 22:30:31  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */


  create view "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" as (
    with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),


order_payments as (
    select
        order_id,
        sum(case when status = 'success' then amount end ) as amount
    from payment
    group by 1
),



final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
  ) ;

2022-01-06 22:30:31.621609 (Thread-4): 22:30:31  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:30:31.623372 (Thread-4): 22:30:31  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:30:31.623469 (Thread-4): 22:30:31  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
alter table "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" rename to "fct_orders"
2022-01-06 22:30:31.625710 (Thread-4): 22:30:31  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:30:31.626620 (Thread-4): 22:30:31  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:30:31.626714 (Thread-4): 22:30:31  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:30:31.626785 (Thread-4): 22:30:31  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:30:31.656748 (Thread-4): 22:30:31  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:30:31.656958 (Thread-4): 22:30:31  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:30:31.657041 (Thread-4): 22:30:31  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 22:30:31.659190 (Thread-4): 22:30:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:30:31.660483 (Thread-4): 22:30:31  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:30:31.660586 (Thread-4): 22:30:31  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
drop view if exists "dev"."dbt_nobodozie"."fct_orders__dbt_backup" cascade
2022-01-06 22:30:31.662461 (Thread-4): 22:30:31  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 22:30:31.663086 (Thread-4): 22:30:31  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:30:31.663180 (Thread-4): 22:30:31  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:30:31.663252 (Thread-4): 22:30:31  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:30:31.688351 (Thread-4): 22:30:31  SQL status: COMMIT in 0.02 seconds
2022-01-06 22:30:31.688465 (Thread-4): 22:30:31  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:30:31.688539 (Thread-4): 22:30:31  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 22:30:31.690659 (Thread-4): 22:30:31  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:30:31.691012 (Thread-4): 22:30:31  finished collecting timing info
2022-01-06 22:30:31.691127 (Thread-4): 22:30:31  On model.jaffel_shop.fct_orders: ROLLBACK
2022-01-06 22:30:31.692861 (Thread-4): 22:30:31  On model.jaffel_shop.fct_orders: Close
2022-01-06 22:30:31.693352 (Thread-4): 22:30:31  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b501e00a-f7de-4d08-b2ca-6f3a069c42f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54d46908e0>]}
2022-01-06 22:30:31.693633 (Thread-4): 22:30:31  4 of 5 OK created view model dbt_nobodozie.fct_orders........................... [CREATE VIEW in 0.14s]
2022-01-06 22:30:31.693745 (Thread-4): 22:30:31  Finished running node model.jaffel_shop.fct_orders
2022-01-06 22:30:31.694445 (Thread-2): 22:30:31  Began running node model.jaffel_shop.dim_customers
2022-01-06 22:30:31.694655 (Thread-2): 22:30:31  5 of 5 START view model dbt_nobodozie.dim_customers............................. [RUN]
2022-01-06 22:30:31.694868 (Thread-2): 22:30:31  Acquiring new redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:30:31.694955 (Thread-2): 22:30:31  Began compiling node model.jaffel_shop.dim_customers
2022-01-06 22:30:31.695034 (Thread-2): 22:30:31  Compiling model.jaffel_shop.dim_customers
2022-01-06 22:30:31.697058 (Thread-2): 22:30:31  Writing injected SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 22:30:31.713202 (Thread-2): 22:30:31  finished collecting timing info
2022-01-06 22:30:31.713358 (Thread-2): 22:30:31  Began executing node model.jaffel_shop.dim_customers
2022-01-06 22:30:31.715143 (Thread-2): 22:30:31  Writing runtime SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 22:30:31.732467 (Thread-2): 22:30:31  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:30:31.732578 (Thread-2): 22:30:31  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 22:30:31.732659 (Thread-2): 22:30:31  Opening a new connection, currently in state closed
2022-01-06 22:30:31.732734 (Thread-2): 22:30:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:30:31.750883 (Thread-2): 22:30:31  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:30:31.750994 (Thread-2): 22:30:31  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:30:31.751071 (Thread-2): 22:30:31  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */


  create view "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" as (
    with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."fct_orders"
),

customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        sum(amount) as lifetime_value
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
        customer_orders.lifetime_value
        
    from customers

    left join customer_orders using (customer_id)
 
)

select * from final
  ) ;

2022-01-06 22:30:31.754118 (Thread-2): 22:30:31  Postgres adapter: Postgres error: syntax error at or near "sum"
LINE 22:         sum(amount) as lifetime_value
                 ^

2022-01-06 22:30:31.754235 (Thread-2): 22:30:31  On model.jaffel_shop.dim_customers: ROLLBACK
2022-01-06 22:30:31.756133 (Thread-2): 22:30:31  finished collecting timing info
2022-01-06 22:30:31.756271 (Thread-2): 22:30:31  On model.jaffel_shop.dim_customers: Close
2022-01-06 22:30:31.756714 (Thread-2): 22:30:31  Database Error in model dim_customers (models/marts/core/dim_customers.sql)
  syntax error at or near "sum"
  LINE 22:         sum(amount) as lifetime_value
                   ^
  compiled SQL at target/run/jaffel_shop/models/marts/core/dim_customers.sql
2022-01-06 22:30:31.756911 (Thread-2): 22:30:31  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b501e00a-f7de-4d08-b2ca-6f3a069c42f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54d464a3d0>]}
2022-01-06 22:30:31.757175 (Thread-2): 22:30:31  5 of 5 ERROR creating view model dbt_nobodozie.dim_customers.................... [ERROR in 0.06s]
2022-01-06 22:30:31.757304 (Thread-2): 22:30:31  Finished running node model.jaffel_shop.dim_customers
2022-01-06 22:30:31.758591 (MainThread): 22:30:31  Acquiring new redshift connection "master"
2022-01-06 22:30:31.758730 (MainThread): 22:30:31  Using redshift connection "master"
2022-01-06 22:30:31.758807 (MainThread): 22:30:31  On master: BEGIN
2022-01-06 22:30:31.758880 (MainThread): 22:30:31  Opening a new connection, currently in state closed
2022-01-06 22:30:31.758951 (MainThread): 22:30:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:30:31.781785 (MainThread): 22:30:31  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:30:31.781908 (MainThread): 22:30:31  On master: COMMIT
2022-01-06 22:30:31.781984 (MainThread): 22:30:31  Using redshift connection "master"
2022-01-06 22:30:31.782054 (MainThread): 22:30:31  On master: COMMIT
2022-01-06 22:30:31.783788 (MainThread): 22:30:31  SQL status: COMMIT in 0.0 seconds
2022-01-06 22:30:31.783909 (MainThread): 22:30:31  On master: Close
2022-01-06 22:30:31.784337 (MainThread): 22:30:31  
2022-01-06 22:30:31.784455 (MainThread): 22:30:31  Finished running 5 view models in 0.68s.
2022-01-06 22:30:31.784538 (MainThread): 22:30:31  Connection 'master' was properly closed.
2022-01-06 22:30:31.784603 (MainThread): 22:30:31  Connection 'model.jaffel_shop.stg_customers' was properly closed.
2022-01-06 22:30:31.784665 (MainThread): 22:30:31  Connection 'model.jaffel_shop.dim_customers' was properly closed.
2022-01-06 22:30:31.784725 (MainThread): 22:30:31  Connection 'model.jaffel_shop.stg_payments' was properly closed.
2022-01-06 22:30:31.784783 (MainThread): 22:30:31  Connection 'model.jaffel_shop.fct_orders' was properly closed.
2022-01-06 22:30:31.835311 (MainThread): 22:30:31  
2022-01-06 22:30:31.835460 (MainThread): 22:30:31  Completed with 1 error and 0 warnings:
2022-01-06 22:30:31.835547 (MainThread): 22:30:31  
2022-01-06 22:30:31.835634 (MainThread): 22:30:31  Database Error in model dim_customers (models/marts/core/dim_customers.sql)
2022-01-06 22:30:31.835708 (MainThread): 22:30:31    syntax error at or near "sum"
2022-01-06 22:30:31.835775 (MainThread): 22:30:31    LINE 22:         sum(amount) as lifetime_value
2022-01-06 22:30:31.835840 (MainThread): 22:30:31                     ^
2022-01-06 22:30:31.835903 (MainThread): 22:30:31    compiled SQL at target/run/jaffel_shop/models/marts/core/dim_customers.sql
2022-01-06 22:30:31.835982 (MainThread): 22:30:31  
2022-01-06 22:30:31.836059 (MainThread): 22:30:31  Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2022-01-06 22:30:32.780867 (Thread-979): handling poll request
2022-01-06 22:30:32.781273 (Thread-979): 22:30:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea405bee0>]}
2022-01-06 22:30:32.783822 (Thread-979): sending response (<Response 73861 bytes [200 OK]>) to 10.0.7.0
2022-01-06 22:30:33.418822 (Thread-980): handling status request
2022-01-06 22:30:33.419195 (Thread-980): 22:30:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4061190>]}
2022-01-06 22:30:33.419692 (Thread-980): sending response (<Response 1575 bytes [200 OK]>) to 10.0.13.200
2022-01-06 22:30:33.451165 (Thread-981): handling status request
2022-01-06 22:30:33.451420 (Thread-981): 22:30:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4061490>]}
2022-01-06 22:30:33.451810 (Thread-981): sending response (<Response 1575 bytes [200 OK]>) to 10.0.25.198
2022-01-06 22:30:55.304002 (Thread-982): handling status request
2022-01-06 22:30:55.304368 (Thread-982): 22:30:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4061700>]}
2022-01-06 22:30:55.304838 (Thread-982): sending response (<Response 1575 bytes [200 OK]>) to 10.0.8.124
2022-01-06 22:30:55.608358 (Thread-983): handling run_sql request
2022-01-06 22:30:55.608713 (Thread-983): 22:30:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4061970>]}
2022-01-06 22:30:57.682197 (Thread-983): sending response (<Response 138 bytes [200 OK]>) to 10.0.13.200
2022-01-06 22:30:57.706955 (MainThread): 22:30:57  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ab11e08e-7bc2-4134-98a3-b57b6e4de371', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a05a929a0>]}
2022-01-06 22:30:57.707496 (MainThread): 22:30:57  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:30:57.708093 (Thread-1): 22:30:57  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:30:57.708268 (Thread-1): 22:30:57  Began compiling node rpc.jaffel_shop.request
2022-01-06 22:30:57.708365 (Thread-1): 22:30:57  Compiling rpc.jaffel_shop.request
2022-01-06 22:30:57.710962 (Thread-1): 22:30:57  finished collecting timing info
2022-01-06 22:30:57.711110 (Thread-1): 22:30:57  Began executing node rpc.jaffel_shop.request
2022-01-06 22:30:57.711225 (Thread-1): 22:30:57  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:30:57.711302 (Thread-1): 22:30:57  On rpc.jaffel_shop.request: with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."fct_orders"
),

customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders
        sum(amount) as lifetime_value
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,
        customer_orders.lifetime_value
        
    from customers

    left join customer_orders using (customer_id)
 
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 22:30:57.711380 (Thread-1): 22:30:57  Opening a new connection, currently in state init
2022-01-06 22:30:57.711459 (Thread-1): 22:30:57  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:30:57.732613 (Thread-1): 22:30:57  Postgres adapter: Postgres error: syntax error at or near "sum"
LINE 18:         sum(amount) as lifetime_value
                 ^

2022-01-06 22:30:57.732809 (Thread-1): 22:30:57  finished collecting timing info
2022-01-06 22:30:57.732937 (Thread-1): 22:30:57  On rpc.jaffel_shop.request: Close
2022-01-06 22:30:57.733135 (Thread-1): Got an exception: Database Error
  syntax error at or near "sum"
  LINE 18:         sum(amount) as lifetime_value
                   ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "sum"
LINE 18:         sum(amount) as lifetime_value
                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "sum"
  LINE 18:         sum(amount) as lifetime_value
                   ^
2022-01-06 22:30:57.734544 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "sum"\n  LINE 18:         sum(amount) as lifetime_value\n                   ^', 'raw_sql': "with customers as (\n\n    select * from {{ ref('stg_customers')}}\n),\n\norders as (\n\n    select * from {{ ref('fct_orders')}}\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        sum(amount) as lifetime_value\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        customer_orders.lifetime_value\n        \n    from customers\n\n    left join customer_orders using (customer_id)\n \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."fct_orders"\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        sum(amount) as lifetime_value\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        customer_orders.lifetime_value\n        \n    from customers\n\n    left join customer_orders using (customer_id)\n \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "sum"\n  LINE 18:         sum(amount) as lifetime_value\n                   ^', 'raw_sql': "with customers as (\n\n    select * from {{ ref('stg_customers')}}\n),\n\norders as (\n\n    select * from {{ ref('fct_orders')}}\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        sum(amount) as lifetime_value\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        customer_orders.lifetime_value\n        \n    from customers\n\n    left join customer_orders using (customer_id)\n \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': 'with customers as (\n\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\n\norders as (\n\n    select * from "dev"."dbt_nobodozie"."fct_orders"\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n        sum(amount) as lifetime_value\n        \n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,\n        customer_orders.lifetime_value\n        \n    from customers\n\n    left join customer_orders using (customer_id)\n \n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 22:30:58.002795 (Thread-984): handling poll request
2022-01-06 22:30:58.003231 (Thread-984): 22:30:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4073bb0>]}
2022-01-06 22:30:58.004125 (Thread-984): sending response (<Response 15529 bytes [200 OK]>) to 10.0.7.0
2022-01-06 22:31:09.963376 (Thread-985): handling status request
2022-01-06 22:31:09.963752 (Thread-985): 22:31:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea406a100>]}
2022-01-06 22:31:09.964289 (Thread-985): sending response (<Response 1575 bytes [200 OK]>) to 10.0.39.187
2022-01-06 22:31:10.378922 (Thread-986): handling run_sql request
2022-01-06 22:31:10.379315 (Thread-986): 22:31:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea406a400>]}
2022-01-06 22:31:11.584820 (Thread-987): 22:31:11  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-06 22:31:11.585326 (Thread-987): 22:31:11  Partial parsing: updated file: jaffel_shop://models/marts/core/dim_customers.sql
2022-01-06 22:31:11.589554 (Thread-987): 22:31:11  1699: static parser successfully parsed marts/core/dim_customers.sql
2022-01-06 22:31:11.630807 (Thread-987): 22:31:11  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe84775850>]}
2022-01-06 22:31:12.080471 (Thread-988): handling status request
2022-01-06 22:31:12.080862 (Thread-988): 22:31:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe847d9af0>]}
2022-01-06 22:31:12.081518 (Thread-988): sending response (<Response 1575 bytes [200 OK]>) to 10.0.7.0
2022-01-06 22:31:12.123929 (Thread-989): handling status request
2022-01-06 22:31:12.124253 (Thread-989): 22:31:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe847d9970>]}
2022-01-06 22:31:12.124719 (Thread-989): sending response (<Response 1575 bytes [200 OK]>) to 10.0.13.200
2022-01-06 22:31:12.419115 (Thread-986): sending response (<Response 138 bytes [200 OK]>) to 10.0.32.47
2022-01-06 22:31:12.444345 (MainThread): 22:31:12  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '51ca68de-1ce0-484d-9b11-c48fbe33d452', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb96bb0700>]}
2022-01-06 22:31:12.444845 (MainThread): 22:31:12  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:31:12.445420 (Thread-1): 22:31:12  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:31:12.445552 (Thread-1): 22:31:12  Began compiling node rpc.jaffel_shop.request
2022-01-06 22:31:12.445641 (Thread-1): 22:31:12  Compiling rpc.jaffel_shop.request
2022-01-06 22:31:12.447941 (Thread-1): 22:31:12  finished collecting timing info
2022-01-06 22:31:12.448065 (Thread-1): 22:31:12  Began executing node rpc.jaffel_shop.request
2022-01-06 22:31:12.448159 (Thread-1): 22:31:12  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:31:12.448235 (Thread-1): 22:31:12  On rpc.jaffel_shop.request: with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."fct_orders"
),

customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders,
        sum(amount) as lifetime_value
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,
        customer_orders.lifetime_value
        
    from customers

    left join customer_orders using (customer_id)
 
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 22:31:12.448311 (Thread-1): 22:31:12  Opening a new connection, currently in state init
2022-01-06 22:31:12.448416 (Thread-1): 22:31:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:31:12.946468 (Thread-1): 22:31:12  SQL status: SELECT in 0.5 seconds
2022-01-06 22:31:12.950233 (Thread-1): 22:31:12  finished collecting timing info
2022-01-06 22:31:12.950414 (Thread-1): 22:31:12  On rpc.jaffel_shop.request: Close
2022-01-06 22:31:13.456652 (Thread-990): handling poll request
2022-01-06 22:31:13.457024 (Thread-990): 22:31:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4077340>]}
2022-01-06 22:31:13.458468 (Thread-990): sending response (<Response 17238 bytes [200 OK]>) to 10.0.27.183
2022-01-06 22:31:18.026100 (Thread-991): handling status request
2022-01-06 22:31:18.026506 (Thread-991): 22:31:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efea4077d30>]}
2022-01-06 22:31:18.027032 (Thread-991): sending response (<Response 1575 bytes [200 OK]>) to 10.0.16.23
2022-01-06 22:31:18.267974 (Thread-992): handling status request
2022-01-06 22:31:18.268215 (Thread-992): 22:31:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe847d5940>]}
2022-01-06 22:31:18.290692 (Thread-992): sending response (<Response 1575 bytes [200 OK]>) to 10.0.40.103
2022-01-06 22:31:18.790583 (Thread-993): handling cli_args request
2022-01-06 22:31:18.790820 (Thread-993): 22:31:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe847d5670>]}
2022-01-06 22:31:20.831110 (Thread-993): sending response (<Response 138 bytes [200 OK]>) to 10.0.28.107
2022-01-06 22:31:20.925129 (MainThread): 22:31:20  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 22:31:20.925551 (MainThread): 22:31:20  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 22:31:20.931028 (MainThread): 22:31:20  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3e398b33-e321-4060-986f-d5b9b97282c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9032a8130>]}
2022-01-06 22:31:20.957609 (MainThread): 22:31:20  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3e398b33-e321-4060-986f-d5b9b97282c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe903342b20>]}
2022-01-06 22:31:20.957839 (MainThread): 22:31:20  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:31:20.958882 (MainThread): 22:31:20  
2022-01-06 22:31:20.959157 (MainThread): 22:31:20  Acquiring new redshift connection "master"
2022-01-06 22:31:20.960090 (ThreadPoolExecutor-0_0): 22:31:20  Acquiring new redshift connection "list_dev"
2022-01-06 22:31:20.969859 (ThreadPoolExecutor-0_0): 22:31:20  Using redshift connection "list_dev"
2022-01-06 22:31:20.969961 (ThreadPoolExecutor-0_0): 22:31:20  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 22:31:20.970198 (ThreadPoolExecutor-0_0): 22:31:20  Opening a new connection, currently in state init
2022-01-06 22:31:20.970289 (ThreadPoolExecutor-0_0): 22:31:20  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:31:20.995887 (ThreadPoolExecutor-0_0): 22:31:20  SQL status: SELECT in 0.03 seconds
2022-01-06 22:31:20.996912 (ThreadPoolExecutor-0_0): 22:31:20  On list_dev: Close
2022-01-06 22:31:20.998076 (ThreadPoolExecutor-1_0): 22:31:20  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:31:21.004102 (ThreadPoolExecutor-1_0): 22:31:21  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:31:21.004203 (ThreadPoolExecutor-1_0): 22:31:21  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 22:31:21.004283 (ThreadPoolExecutor-1_0): 22:31:21  Opening a new connection, currently in state closed
2022-01-06 22:31:21.004362 (ThreadPoolExecutor-1_0): 22:31:21  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:31:21.026433 (ThreadPoolExecutor-1_0): 22:31:21  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:31:21.026543 (ThreadPoolExecutor-1_0): 22:31:21  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:31:21.026619 (ThreadPoolExecutor-1_0): 22:31:21  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 22:31:21.037834 (ThreadPoolExecutor-1_0): 22:31:21  SQL status: SELECT in 0.01 seconds
2022-01-06 22:31:21.038848 (ThreadPoolExecutor-1_0): 22:31:21  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 22:31:21.040629 (ThreadPoolExecutor-1_0): 22:31:21  On list_dev_dbt_nobodozie: Close
2022-01-06 22:31:21.044826 (MainThread): 22:31:21  Using redshift connection "master"
2022-01-06 22:31:21.044938 (MainThread): 22:31:21  On master: BEGIN
2022-01-06 22:31:21.045019 (MainThread): 22:31:21  Opening a new connection, currently in state init
2022-01-06 22:31:21.045097 (MainThread): 22:31:21  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:31:21.068695 (MainThread): 22:31:21  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:31:21.068805 (MainThread): 22:31:21  Using redshift connection "master"
2022-01-06 22:31:21.068882 (MainThread): 22:31:21  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 22:31:21.097800 (MainThread): 22:31:21  SQL status: SELECT in 0.03 seconds
2022-01-06 22:31:21.098847 (MainThread): 22:31:21  On master: ROLLBACK
2022-01-06 22:31:21.100691 (MainThread): 22:31:21  Using redshift connection "master"
2022-01-06 22:31:21.100789 (MainThread): 22:31:21  On master: BEGIN
2022-01-06 22:31:21.104244 (MainThread): 22:31:21  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:31:21.104349 (MainThread): 22:31:21  On master: COMMIT
2022-01-06 22:31:21.104420 (MainThread): 22:31:21  Using redshift connection "master"
2022-01-06 22:31:21.104487 (MainThread): 22:31:21  On master: COMMIT
2022-01-06 22:31:21.106144 (MainThread): 22:31:21  SQL status: COMMIT in 0.0 seconds
2022-01-06 22:31:21.106243 (MainThread): 22:31:21  On master: Close
2022-01-06 22:31:21.106595 (MainThread): 22:31:21  Concurrency: 4 threads (target='default')
2022-01-06 22:31:21.106708 (MainThread): 22:31:21  
2022-01-06 22:31:21.108920 (Thread-1): 22:31:21  Began running node model.jaffel_shop.stg_customers
2022-01-06 22:31:21.109166 (Thread-1): 22:31:21  1 of 5 START view model dbt_nobodozie.stg_customers............................. [RUN]
2022-01-06 22:31:21.109436 (Thread-1): 22:31:21  Acquiring new redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:31:21.109536 (Thread-1): 22:31:21  Began compiling node model.jaffel_shop.stg_customers
2022-01-06 22:31:21.109623 (Thread-1): 22:31:21  Compiling model.jaffel_shop.stg_customers
2022-01-06 22:31:21.110746 (Thread-1): 22:31:21  Writing injected SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 22:31:21.110970 (Thread-2): 22:31:21  Began running node model.jaffel_shop.stg_orders
2022-01-06 22:31:21.111203 (Thread-2): 22:31:21  2 of 5 START view model dbt_nobodozie.stg_orders................................ [RUN]
2022-01-06 22:31:21.111447 (Thread-2): 22:31:21  Acquiring new redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:31:21.111531 (Thread-2): 22:31:21  Began compiling node model.jaffel_shop.stg_orders
2022-01-06 22:31:21.111609 (Thread-2): 22:31:21  Compiling model.jaffel_shop.stg_orders
2022-01-06 22:31:21.112614 (Thread-2): 22:31:21  Writing injected SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 22:31:21.112934 (Thread-3): 22:31:21  Began running node model.jaffel_shop.stg_payments
2022-01-06 22:31:21.113142 (Thread-3): 22:31:21  3 of 5 START view model dbt_nobodozie.stg_payments.............................. [RUN]
2022-01-06 22:31:21.113523 (Thread-3): 22:31:21  Acquiring new redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:31:21.113615 (Thread-3): 22:31:21  Began compiling node model.jaffel_shop.stg_payments
2022-01-06 22:31:21.113692 (Thread-3): 22:31:21  Compiling model.jaffel_shop.stg_payments
2022-01-06 22:31:21.114668 (Thread-3): 22:31:21  Writing injected SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 22:31:21.128416 (Thread-2): 22:31:21  finished collecting timing info
2022-01-06 22:31:21.128554 (Thread-2): 22:31:21  Began executing node model.jaffel_shop.stg_orders
2022-01-06 22:31:21.133557 (Thread-1): 22:31:21  finished collecting timing info
2022-01-06 22:31:21.133692 (Thread-1): 22:31:21  Began executing node model.jaffel_shop.stg_customers
2022-01-06 22:31:21.151409 (Thread-3): 22:31:21  finished collecting timing info
2022-01-06 22:31:21.151539 (Thread-3): 22:31:21  Began executing node model.jaffel_shop.stg_payments
2022-01-06 22:31:21.175925 (Thread-3): 22:31:21  Writing runtime SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 22:31:21.177198 (Thread-1): 22:31:21  Writing runtime SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 22:31:21.178263 (Thread-2): 22:31:21  Writing runtime SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 22:31:21.194485 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:31:21.194604 (Thread-3): 22:31:21  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 22:31:21.194695 (Thread-3): 22:31:21  Opening a new connection, currently in state init
2022-01-06 22:31:21.194786 (Thread-3): 22:31:21  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:31:21.195049 (Thread-2): 22:31:21  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:31:21.195151 (Thread-2): 22:31:21  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 22:31:21.195232 (Thread-2): 22:31:21  Opening a new connection, currently in state init
2022-01-06 22:31:21.195310 (Thread-2): 22:31:21  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:31:21.195664 (Thread-1): 22:31:21  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:31:21.195771 (Thread-1): 22:31:21  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 22:31:21.195854 (Thread-1): 22:31:21  Opening a new connection, currently in state closed
2022-01-06 22:31:21.195930 (Thread-1): 22:31:21  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:31:21.217717 (Thread-994): handling poll request
2022-01-06 22:31:21.218071 (Thread-994): 22:31:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe84708400>]}
2022-01-06 22:31:21.219751 (Thread-994): sending response (<Response 31237 bytes [200 OK]>) to 10.0.39.202
2022-01-06 22:31:21.226495 (Thread-3): 22:31:21  SQL status: BEGIN in 0.03 seconds
2022-01-06 22:31:21.226608 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:31:21.226685 (Thread-3): 22:31:21  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */


  create view "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" as (
    with payment as (

    select
        id as payment_id,
        orderid as order_id,
        paymentmethod as payment_method,

        -- amount is stored in cents, convert it to dollars
        amount/100 as amount,
        status

    from stripe.payment

)
select * from payment
  ) ;

2022-01-06 22:31:21.228522 (Thread-2): 22:31:21  SQL status: BEGIN in 0.03 seconds
2022-01-06 22:31:21.228644 (Thread-2): 22:31:21  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:31:21.228722 (Thread-2): 22:31:21  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */


  create view "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" as (
    with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
  ) ;

2022-01-06 22:31:21.229817 (Thread-1): 22:31:21  SQL status: BEGIN in 0.03 seconds
2022-01-06 22:31:21.229938 (Thread-1): 22:31:21  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:31:21.230015 (Thread-1): 22:31:21  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */


  create view "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
  ) ;

2022-01-06 22:31:21.236401 (Thread-1): 22:31:21  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:31:21.241698 (Thread-3): 22:31:21  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:31:21.245414 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:31:21.245513 (Thread-3): 22:31:21  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments" rename to "stg_payments__dbt_backup"
2022-01-06 22:31:21.245734 (Thread-2): 22:31:21  SQL status: CREATE VIEW in 0.02 seconds
2022-01-06 22:31:21.247650 (Thread-2): 22:31:21  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:31:21.247749 (Thread-2): 22:31:21  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders" rename to "stg_orders__dbt_backup"
2022-01-06 22:31:21.248156 (Thread-1): 22:31:21  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:31:21.248262 (Thread-1): 22:31:21  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers" rename to "stg_customers__dbt_backup"
2022-01-06 22:31:21.248406 (Thread-3): 22:31:21  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:31:21.250979 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:31:21.251077 (Thread-3): 22:31:21  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" rename to "stg_payments"
2022-01-06 22:31:21.251289 (Thread-2): 22:31:21  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:31:21.252954 (Thread-2): 22:31:21  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:31:21.253052 (Thread-2): 22:31:21  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" rename to "stg_orders"
2022-01-06 22:31:21.253203 (Thread-1): 22:31:21  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:31:21.255029 (Thread-1): 22:31:21  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:31:21.255146 (Thread-1): 22:31:21  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" rename to "stg_customers"
2022-01-06 22:31:21.255369 (Thread-3): 22:31:21  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:31:21.260442 (Thread-2): 22:31:21  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 22:31:21.265384 (Thread-2): 22:31:21  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:31:21.265588 (Thread-2): 22:31:21  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:31:21.265665 (Thread-2): 22:31:21  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:31:21.267503 (Thread-3): 22:31:21  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:31:21.267609 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:31:21.267684 (Thread-3): 22:31:21  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:31:21.267829 (Thread-1): 22:31:21  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 22:31:21.268770 (Thread-1): 22:31:21  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:31:21.268872 (Thread-1): 22:31:21  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:31:21.268947 (Thread-1): 22:31:21  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:31:21.322295 (Thread-2): 22:31:21  SQL status: COMMIT in 0.06 seconds
2022-01-06 22:31:21.322511 (Thread-2): 22:31:21  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:31:21.322594 (Thread-2): 22:31:21  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 22:31:21.322977 (Thread-3): 22:31:21  SQL status: COMMIT in 0.06 seconds
2022-01-06 22:31:21.324687 (Thread-1): 22:31:21  SQL status: COMMIT in 0.06 seconds
2022-01-06 22:31:21.324956 (Thread-2): 22:31:21  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:31:21.328913 (Thread-2): 22:31:21  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:31:21.329012 (Thread-2): 22:31:21  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
drop view if exists "dev"."dbt_nobodozie"."stg_orders__dbt_backup" cascade
2022-01-06 22:31:21.333978 (Thread-2): 22:31:21  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 22:31:21.334665 (Thread-2): 22:31:21  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:31:21.334762 (Thread-2): 22:31:21  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:31:21.334836 (Thread-2): 22:31:21  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:31:21.370718 (Thread-2): 22:31:21  SQL status: COMMIT in 0.04 seconds
2022-01-06 22:31:21.370845 (Thread-2): 22:31:21  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:31:21.370922 (Thread-2): 22:31:21  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 22:31:21.373110 (Thread-2): 22:31:21  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:31:21.373571 (Thread-2): 22:31:21  finished collecting timing info
2022-01-06 22:31:21.373705 (Thread-2): 22:31:21  On model.jaffel_shop.stg_orders: ROLLBACK
2022-01-06 22:31:21.373914 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:31:21.374027 (Thread-3): 22:31:21  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 22:31:21.375874 (Thread-2): 22:31:21  On model.jaffel_shop.stg_orders: Close
2022-01-06 22:31:21.376327 (Thread-2): 22:31:21  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e398b33-e321-4060-986f-d5b9b97282c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe902249730>]}
2022-01-06 22:31:21.376654 (Thread-2): 22:31:21  2 of 5 OK created view model dbt_nobodozie.stg_orders........................... [CREATE VIEW in 0.26s]
2022-01-06 22:31:21.376769 (Thread-2): 22:31:21  Finished running node model.jaffel_shop.stg_orders
2022-01-06 22:31:21.377364 (Thread-3): 22:31:21  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:31:21.378553 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:31:21.378651 (Thread-3): 22:31:21  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
drop view if exists "dev"."dbt_nobodozie"."stg_payments__dbt_backup" cascade
2022-01-06 22:31:21.384137 (Thread-3): 22:31:21  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 22:31:21.384837 (Thread-3): 22:31:21  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:31:21.384931 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:31:21.385004 (Thread-3): 22:31:21  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:31:21.415896 (Thread-3): 22:31:21  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:31:21.416018 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:31:21.416094 (Thread-3): 22:31:21  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 22:31:21.418133 (Thread-3): 22:31:21  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:31:21.418558 (Thread-3): 22:31:21  finished collecting timing info
2022-01-06 22:31:21.418681 (Thread-3): 22:31:21  On model.jaffel_shop.stg_payments: ROLLBACK
2022-01-06 22:31:21.418885 (Thread-1): 22:31:21  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:31:21.418997 (Thread-1): 22:31:21  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 22:31:21.421358 (Thread-3): 22:31:21  On model.jaffel_shop.stg_payments: Close
2022-01-06 22:31:21.421530 (Thread-1): 22:31:21  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:31:21.422928 (Thread-1): 22:31:21  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:31:21.423028 (Thread-1): 22:31:21  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
drop view if exists "dev"."dbt_nobodozie"."stg_customers__dbt_backup" cascade
2022-01-06 22:31:21.423419 (Thread-3): 22:31:21  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e398b33-e321-4060-986f-d5b9b97282c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9001f5df0>]}
2022-01-06 22:31:21.423727 (Thread-3): 22:31:21  3 of 5 OK created view model dbt_nobodozie.stg_payments......................... [CREATE VIEW in 0.31s]
2022-01-06 22:31:21.423834 (Thread-3): 22:31:21  Finished running node model.jaffel_shop.stg_payments
2022-01-06 22:31:21.424480 (Thread-4): 22:31:21  Began running node model.jaffel_shop.fct_orders
2022-01-06 22:31:21.424684 (Thread-4): 22:31:21  4 of 5 START view model dbt_nobodozie.fct_orders................................ [RUN]
2022-01-06 22:31:21.424925 (Thread-4): 22:31:21  Acquiring new redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:31:21.425010 (Thread-4): 22:31:21  Began compiling node model.jaffel_shop.fct_orders
2022-01-06 22:31:21.425092 (Thread-4): 22:31:21  Compiling model.jaffel_shop.fct_orders
2022-01-06 22:31:21.427417 (Thread-4): 22:31:21  Writing injected SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 22:31:21.428274 (Thread-1): 22:31:21  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 22:31:21.428945 (Thread-1): 22:31:21  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:31:21.429047 (Thread-1): 22:31:21  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:31:21.429136 (Thread-1): 22:31:21  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:31:21.443343 (Thread-4): 22:31:21  finished collecting timing info
2022-01-06 22:31:21.443479 (Thread-4): 22:31:21  Began executing node model.jaffel_shop.fct_orders
2022-01-06 22:31:21.445345 (Thread-4): 22:31:21  Writing runtime SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 22:31:21.457660 (Thread-1): 22:31:21  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:31:21.457780 (Thread-1): 22:31:21  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:31:21.457855 (Thread-1): 22:31:21  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 22:31:21.459911 (Thread-4): 22:31:21  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:31:21.460023 (Thread-4): 22:31:21  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 22:31:21.460106 (Thread-4): 22:31:21  Opening a new connection, currently in state init
2022-01-06 22:31:21.460187 (Thread-4): 22:31:21  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:31:21.460398 (Thread-1): 22:31:21  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:31:21.460786 (Thread-1): 22:31:21  finished collecting timing info
2022-01-06 22:31:21.460910 (Thread-1): 22:31:21  On model.jaffel_shop.stg_customers: ROLLBACK
2022-01-06 22:31:21.462647 (Thread-1): 22:31:21  On model.jaffel_shop.stg_customers: Close
2022-01-06 22:31:21.463087 (Thread-1): 22:31:21  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e398b33-e321-4060-986f-d5b9b97282c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9001cfa30>]}
2022-01-06 22:31:21.463389 (Thread-1): 22:31:21  1 of 5 OK created view model dbt_nobodozie.stg_customers........................ [CREATE VIEW in 0.35s]
2022-01-06 22:31:21.463506 (Thread-1): 22:31:21  Finished running node model.jaffel_shop.stg_customers
2022-01-06 22:31:21.542895 (Thread-4): 22:31:21  SQL status: BEGIN in 0.08 seconds
2022-01-06 22:31:21.543027 (Thread-4): 22:31:21  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:31:21.543109 (Thread-4): 22:31:21  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */


  create view "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" as (
    with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),


order_payments as (
    select
        order_id,
        sum(case when status = 'success' then amount end ) as amount
    from payment
    group by 1
),



final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
  ) ;

2022-01-06 22:31:21.550840 (Thread-4): 22:31:21  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:31:21.553009 (Thread-4): 22:31:21  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:31:21.553106 (Thread-4): 22:31:21  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
alter table "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" rename to "fct_orders"
2022-01-06 22:31:21.555455 (Thread-4): 22:31:21  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:31:21.556455 (Thread-4): 22:31:21  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:31:21.556577 (Thread-4): 22:31:21  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:31:21.556674 (Thread-4): 22:31:21  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:31:21.586099 (Thread-4): 22:31:21  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:31:21.586332 (Thread-4): 22:31:21  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:31:21.586415 (Thread-4): 22:31:21  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 22:31:21.588523 (Thread-4): 22:31:21  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:31:21.589947 (Thread-4): 22:31:21  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:31:21.590047 (Thread-4): 22:31:21  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
drop view if exists "dev"."dbt_nobodozie"."fct_orders__dbt_backup" cascade
2022-01-06 22:31:21.591955 (Thread-4): 22:31:21  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 22:31:21.592587 (Thread-4): 22:31:21  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:31:21.592681 (Thread-4): 22:31:21  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:31:21.592753 (Thread-4): 22:31:21  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:31:21.621032 (Thread-4): 22:31:21  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:31:21.621150 (Thread-4): 22:31:21  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:31:21.621252 (Thread-4): 22:31:21  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 22:31:21.623980 (Thread-4): 22:31:21  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:31:21.624389 (Thread-4): 22:31:21  finished collecting timing info
2022-01-06 22:31:21.624517 (Thread-4): 22:31:21  On model.jaffel_shop.fct_orders: ROLLBACK
2022-01-06 22:31:21.626308 (Thread-4): 22:31:21  On model.jaffel_shop.fct_orders: Close
2022-01-06 22:31:21.626739 (Thread-4): 22:31:21  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e398b33-e321-4060-986f-d5b9b97282c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe900179b50>]}
2022-01-06 22:31:21.627055 (Thread-4): 22:31:21  4 of 5 OK created view model dbt_nobodozie.fct_orders........................... [CREATE VIEW in 0.20s]
2022-01-06 22:31:21.627245 (Thread-4): 22:31:21  Finished running node model.jaffel_shop.fct_orders
2022-01-06 22:31:21.628045 (Thread-3): 22:31:21  Began running node model.jaffel_shop.dim_customers
2022-01-06 22:31:21.628270 (Thread-3): 22:31:21  5 of 5 START view model dbt_nobodozie.dim_customers............................. [RUN]
2022-01-06 22:31:21.628497 (Thread-3): 22:31:21  Acquiring new redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:31:21.628586 (Thread-3): 22:31:21  Began compiling node model.jaffel_shop.dim_customers
2022-01-06 22:31:21.628668 (Thread-3): 22:31:21  Compiling model.jaffel_shop.dim_customers
2022-01-06 22:31:21.631223 (Thread-3): 22:31:21  Writing injected SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 22:31:21.645462 (Thread-3): 22:31:21  finished collecting timing info
2022-01-06 22:31:21.645594 (Thread-3): 22:31:21  Began executing node model.jaffel_shop.dim_customers
2022-01-06 22:31:21.647475 (Thread-3): 22:31:21  Writing runtime SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 22:31:21.662448 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:31:21.662557 (Thread-3): 22:31:21  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 22:31:21.662640 (Thread-3): 22:31:21  Opening a new connection, currently in state closed
2022-01-06 22:31:21.662720 (Thread-3): 22:31:21  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:31:21.681550 (Thread-3): 22:31:21  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:31:21.681667 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:31:21.681746 (Thread-3): 22:31:21  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */


  create view "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" as (
    with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."fct_orders"
),

customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders,
        sum(amount) as lifetime_value
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,
        customer_orders.lifetime_value
        
    from customers

    left join customer_orders using (customer_id)
 
)

select * from final
  ) ;

2022-01-06 22:31:21.689476 (Thread-3): 22:31:21  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:31:21.691362 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:31:21.691459 (Thread-3): 22:31:21  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 22:31:21.693776 (Thread-3): 22:31:21  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:31:21.694738 (Thread-3): 22:31:21  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 22:31:21.694835 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:31:21.694907 (Thread-3): 22:31:21  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 22:31:21.726238 (Thread-3): 22:31:21  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:31:21.726462 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:31:21.726548 (Thread-3): 22:31:21  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 22:31:21.728618 (Thread-3): 22:31:21  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:31:21.729897 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:31:21.729992 (Thread-3): 22:31:21  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
drop view if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 22:31:21.732037 (Thread-3): 22:31:21  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 22:31:21.732671 (Thread-3): 22:31:21  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 22:31:21.732766 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:31:21.732839 (Thread-3): 22:31:21  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 22:31:21.758663 (Thread-3): 22:31:21  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:31:21.758806 (Thread-3): 22:31:21  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:31:21.758885 (Thread-3): 22:31:21  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 22:31:21.760945 (Thread-3): 22:31:21  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:31:21.761437 (Thread-3): 22:31:21  finished collecting timing info
2022-01-06 22:31:21.761576 (Thread-3): 22:31:21  On model.jaffel_shop.dim_customers: ROLLBACK
2022-01-06 22:31:21.763352 (Thread-3): 22:31:21  On model.jaffel_shop.dim_customers: Close
2022-01-06 22:31:21.763850 (Thread-3): 22:31:21  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e398b33-e321-4060-986f-d5b9b97282c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe900182220>]}
2022-01-06 22:31:21.764356 (Thread-3): 22:31:21  5 of 5 OK created view model dbt_nobodozie.dim_customers........................ [CREATE VIEW in 0.14s]
2022-01-06 22:31:21.764480 (Thread-3): 22:31:21  Finished running node model.jaffel_shop.dim_customers
2022-01-06 22:31:21.765829 (MainThread): 22:31:21  Acquiring new redshift connection "master"
2022-01-06 22:31:21.765977 (MainThread): 22:31:21  Using redshift connection "master"
2022-01-06 22:31:21.766057 (MainThread): 22:31:21  On master: BEGIN
2022-01-06 22:31:21.766136 (MainThread): 22:31:21  Opening a new connection, currently in state closed
2022-01-06 22:31:21.766213 (MainThread): 22:31:21  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:31:21.790400 (MainThread): 22:31:21  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:31:21.790524 (MainThread): 22:31:21  On master: COMMIT
2022-01-06 22:31:21.790601 (MainThread): 22:31:21  Using redshift connection "master"
2022-01-06 22:31:21.790671 (MainThread): 22:31:21  On master: COMMIT
2022-01-06 22:31:21.792454 (MainThread): 22:31:21  SQL status: COMMIT in 0.0 seconds
2022-01-06 22:31:21.792575 (MainThread): 22:31:21  On master: Close
2022-01-06 22:31:21.793024 (MainThread): 22:31:21  
2022-01-06 22:31:21.793146 (MainThread): 22:31:21  Finished running 5 view models in 0.83s.
2022-01-06 22:31:21.793261 (MainThread): 22:31:21  Connection 'master' was properly closed.
2022-01-06 22:31:21.793335 (MainThread): 22:31:21  Connection 'model.jaffel_shop.stg_customers' was properly closed.
2022-01-06 22:31:21.793399 (MainThread): 22:31:21  Connection 'model.jaffel_shop.stg_orders' was properly closed.
2022-01-06 22:31:21.793460 (MainThread): 22:31:21  Connection 'model.jaffel_shop.dim_customers' was properly closed.
2022-01-06 22:31:21.793521 (MainThread): 22:31:21  Connection 'model.jaffel_shop.fct_orders' was properly closed.
2022-01-06 22:31:21.848445 (MainThread): 22:31:21  
2022-01-06 22:31:21.848602 (MainThread): 22:31:21  Completed successfully
2022-01-06 22:31:21.848701 (MainThread): 22:31:21  
2022-01-06 22:31:21.848786 (MainThread): 22:31:21  Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2022-01-06 22:31:22.558554 (Thread-995): handling poll request
2022-01-06 22:31:22.558919 (Thread-995): 22:31:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe846c4940>]}
2022-01-06 22:31:22.561777 (Thread-995): sending response (<Response 93488 bytes [200 OK]>) to 10.0.39.187
2022-01-06 22:31:23.256098 (Thread-996): handling status request
2022-01-06 22:31:23.256456 (Thread-996): 22:31:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe846c4af0>]}
2022-01-06 22:31:23.256970 (Thread-996): sending response (<Response 1575 bytes [200 OK]>) to 10.0.14.166
2022-01-06 22:31:23.263010 (Thread-997): handling status request
2022-01-06 22:31:23.263247 (Thread-997): 22:31:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe846c4ee0>]}
2022-01-06 22:31:23.263593 (Thread-997): sending response (<Response 1575 bytes [200 OK]>) to 10.0.7.0
2022-01-06 22:32:52.463343 (Thread-998): handling status request
2022-01-06 22:32:52.465051 (Thread-998): 22:32:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe846e70d0>]}
2022-01-06 22:32:52.465579 (Thread-998): sending response (<Response 1575 bytes [200 OK]>) to 10.0.25.198
2022-01-06 22:32:52.607074 (Thread-999): handling status request
2022-01-06 22:32:52.607322 (Thread-999): 22:32:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe846e73d0>]}
2022-01-06 22:32:52.607708 (Thread-999): sending response (<Response 1575 bytes [200 OK]>) to 10.0.7.0
2022-01-06 22:32:52.806651 (Thread-1000): handling cli_args request
2022-01-06 22:32:52.807001 (Thread-1000): 22:32:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe846e7640>]}
2022-01-06 22:32:54.853048 (Thread-1000): sending response (<Response 138 bytes [200 OK]>) to 10.0.27.183
2022-01-06 22:32:54.958373 (MainThread): 22:32:54  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 22:32:54.958773 (MainThread): 22:32:54  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 22:32:54.964211 (MainThread): 22:32:54  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fa6bd596-df0f-4b2e-b19c-6640ceb0cb6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd37e324190>]}
2022-01-06 22:32:54.994430 (MainThread): 22:32:54  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fa6bd596-df0f-4b2e-b19c-6640ceb0cb6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd37e3bfa00>]}
2022-01-06 22:32:54.994666 (MainThread): 22:32:54  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:32:54.995675 (MainThread): 22:32:54  
2022-01-06 22:32:54.995948 (MainThread): 22:32:54  Acquiring new redshift connection "master"
2022-01-06 22:32:54.996862 (ThreadPoolExecutor-0_0): 22:32:54  Acquiring new redshift connection "list_dev"
2022-01-06 22:32:55.006580 (ThreadPoolExecutor-0_0): 22:32:55  Using redshift connection "list_dev"
2022-01-06 22:32:55.006686 (ThreadPoolExecutor-0_0): 22:32:55  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 22:32:55.006770 (ThreadPoolExecutor-0_0): 22:32:55  Opening a new connection, currently in state init
2022-01-06 22:32:55.007022 (ThreadPoolExecutor-0_0): 22:32:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:32:55.027305 (ThreadPoolExecutor-0_0): 22:32:55  SQL status: SELECT in 0.02 seconds
2022-01-06 22:32:55.028318 (ThreadPoolExecutor-0_0): 22:32:55  On list_dev: Close
2022-01-06 22:32:55.029585 (ThreadPoolExecutor-1_0): 22:32:55  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:32:55.035642 (ThreadPoolExecutor-1_0): 22:32:55  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:32:55.035743 (ThreadPoolExecutor-1_0): 22:32:55  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 22:32:55.035824 (ThreadPoolExecutor-1_0): 22:32:55  Opening a new connection, currently in state closed
2022-01-06 22:32:55.035901 (ThreadPoolExecutor-1_0): 22:32:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:32:55.057749 (ThreadPoolExecutor-1_0): 22:32:55  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:32:55.057860 (ThreadPoolExecutor-1_0): 22:32:55  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:32:55.057937 (ThreadPoolExecutor-1_0): 22:32:55  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 22:32:55.069148 (ThreadPoolExecutor-1_0): 22:32:55  SQL status: SELECT in 0.01 seconds
2022-01-06 22:32:55.070226 (ThreadPoolExecutor-1_0): 22:32:55  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 22:32:55.072025 (ThreadPoolExecutor-1_0): 22:32:55  On list_dev_dbt_nobodozie: Close
2022-01-06 22:32:55.076084 (MainThread): 22:32:55  Using redshift connection "master"
2022-01-06 22:32:55.076200 (MainThread): 22:32:55  On master: BEGIN
2022-01-06 22:32:55.076281 (MainThread): 22:32:55  Opening a new connection, currently in state init
2022-01-06 22:32:55.076357 (MainThread): 22:32:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:32:55.098988 (MainThread): 22:32:55  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:32:55.099096 (MainThread): 22:32:55  Using redshift connection "master"
2022-01-06 22:32:55.099172 (MainThread): 22:32:55  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 22:32:55.128173 (MainThread): 22:32:55  SQL status: SELECT in 0.03 seconds
2022-01-06 22:32:55.129292 (MainThread): 22:32:55  On master: ROLLBACK
2022-01-06 22:32:55.131232 (MainThread): 22:32:55  Using redshift connection "master"
2022-01-06 22:32:55.131329 (MainThread): 22:32:55  On master: BEGIN
2022-01-06 22:32:55.134794 (MainThread): 22:32:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:32:55.134894 (MainThread): 22:32:55  On master: COMMIT
2022-01-06 22:32:55.134965 (MainThread): 22:32:55  Using redshift connection "master"
2022-01-06 22:32:55.135032 (MainThread): 22:32:55  On master: COMMIT
2022-01-06 22:32:55.136704 (MainThread): 22:32:55  SQL status: COMMIT in 0.0 seconds
2022-01-06 22:32:55.136802 (MainThread): 22:32:55  On master: Close
2022-01-06 22:32:55.137246 (MainThread): 22:32:55  Concurrency: 4 threads (target='default')
2022-01-06 22:32:55.137359 (MainThread): 22:32:55  
2022-01-06 22:32:55.139608 (Thread-1): 22:32:55  Began running node model.jaffel_shop.stg_customers
2022-01-06 22:32:55.139847 (Thread-1): 22:32:55  1 of 5 START view model dbt_nobodozie.stg_customers............................. [RUN]
2022-01-06 22:32:55.140081 (Thread-1): 22:32:55  Acquiring new redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:32:55.140175 (Thread-1): 22:32:55  Began compiling node model.jaffel_shop.stg_customers
2022-01-06 22:32:55.140262 (Thread-1): 22:32:55  Compiling model.jaffel_shop.stg_customers
2022-01-06 22:32:55.141421 (Thread-1): 22:32:55  Writing injected SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 22:32:55.141647 (Thread-2): 22:32:55  Began running node model.jaffel_shop.stg_orders
2022-01-06 22:32:55.141879 (Thread-2): 22:32:55  2 of 5 START view model dbt_nobodozie.stg_orders................................ [RUN]
2022-01-06 22:32:55.142122 (Thread-2): 22:32:55  Acquiring new redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:32:55.142210 (Thread-2): 22:32:55  Began compiling node model.jaffel_shop.stg_orders
2022-01-06 22:32:55.142289 (Thread-2): 22:32:55  Compiling model.jaffel_shop.stg_orders
2022-01-06 22:32:55.143293 (Thread-2): 22:32:55  Writing injected SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 22:32:55.143653 (Thread-3): 22:32:55  Began running node model.jaffel_shop.stg_payments
2022-01-06 22:32:55.144004 (Thread-3): 22:32:55  3 of 5 START view model dbt_nobodozie.stg_payments.............................. [RUN]
2022-01-06 22:32:55.144243 (Thread-3): 22:32:55  Acquiring new redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:32:55.144330 (Thread-3): 22:32:55  Began compiling node model.jaffel_shop.stg_payments
2022-01-06 22:32:55.144407 (Thread-3): 22:32:55  Compiling model.jaffel_shop.stg_payments
2022-01-06 22:32:55.145406 (Thread-3): 22:32:55  Writing injected SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 22:32:55.163012 (Thread-3): 22:32:55  finished collecting timing info
2022-01-06 22:32:55.163157 (Thread-3): 22:32:55  Began executing node model.jaffel_shop.stg_payments
2022-01-06 22:32:55.168409 (Thread-1): 22:32:55  finished collecting timing info
2022-01-06 22:32:55.168538 (Thread-1): 22:32:55  Began executing node model.jaffel_shop.stg_customers
2022-01-06 22:32:55.186069 (Thread-2): 22:32:55  finished collecting timing info
2022-01-06 22:32:55.186204 (Thread-2): 22:32:55  Began executing node model.jaffel_shop.stg_orders
2022-01-06 22:32:55.211237 (Thread-2): 22:32:55  Writing runtime SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 22:32:55.212272 (Thread-3): 22:32:55  Writing runtime SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 22:32:55.213568 (Thread-1): 22:32:55  Writing runtime SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 22:32:55.232576 (Thread-1): 22:32:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:32:55.232727 (Thread-1): 22:32:55  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 22:32:55.232842 (Thread-1): 22:32:55  Opening a new connection, currently in state closed
2022-01-06 22:32:55.232932 (Thread-1): 22:32:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:32:55.233348 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:32:55.233475 (Thread-2): 22:32:55  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 22:32:55.233560 (Thread-2): 22:32:55  Opening a new connection, currently in state init
2022-01-06 22:32:55.233640 (Thread-2): 22:32:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:32:55.233920 (Thread-3): 22:32:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:32:55.234036 (Thread-3): 22:32:55  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 22:32:55.234119 (Thread-3): 22:32:55  Opening a new connection, currently in state init
2022-01-06 22:32:55.234194 (Thread-3): 22:32:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:32:55.260914 (Thread-2): 22:32:55  SQL status: BEGIN in 0.03 seconds
2022-01-06 22:32:55.261056 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:32:55.261136 (Thread-2): 22:32:55  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */


  create view "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" as (
    with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
  ) ;

2022-01-06 22:32:55.262751 (Thread-3): 22:32:55  SQL status: BEGIN in 0.03 seconds
2022-01-06 22:32:55.262881 (Thread-3): 22:32:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:32:55.262962 (Thread-3): 22:32:55  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */


  create view "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" as (
    with payment as (

    select
        id as payment_id,
        orderid as order_id,
        paymentmethod as payment_method,

        -- amount is stored in cents, convert it to dollars
        amount/100 as amount,
        status

    from stripe.payment

)
select * from payment
  ) ;

2022-01-06 22:32:55.269248 (Thread-2): 22:32:55  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:32:55.274549 (Thread-3): 22:32:55  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:32:55.278531 (Thread-3): 22:32:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:32:55.278633 (Thread-3): 22:32:55  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments" rename to "stg_payments__dbt_backup"
2022-01-06 22:32:55.279527 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:32:55.279635 (Thread-2): 22:32:55  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders" rename to "stg_orders__dbt_backup"
2022-01-06 22:32:55.281076 (Thread-3): 22:32:55  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:32:55.282906 (Thread-3): 22:32:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:32:55.283006 (Thread-3): 22:32:55  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
alter table "dev"."dbt_nobodozie"."stg_payments__dbt_tmp" rename to "stg_payments"
2022-01-06 22:32:55.286024 (Thread-1001): handling poll request
2022-01-06 22:32:55.283285 (Thread-2): 22:32:55  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:32:55.286578 (Thread-1001): 22:32:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe847541f0>]}
2022-01-06 22:32:55.288470 (Thread-1001): sending response (<Response 38261 bytes [200 OK]>) to 10.0.7.0
2022-01-06 22:32:55.285922 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:32:55.286020 (Thread-2): 22:32:55  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
alter table "dev"."dbt_nobodozie"."stg_orders__dbt_tmp" rename to "stg_orders"
2022-01-06 22:32:55.286259 (Thread-3): 22:32:55  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:32:55.292993 (Thread-3): 22:32:55  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:32:55.293096 (Thread-3): 22:32:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:32:55.293170 (Thread-3): 22:32:55  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:32:55.293336 (Thread-2): 22:32:55  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 22:32:55.294258 (Thread-2): 22:32:55  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:32:55.294356 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:32:55.294428 (Thread-2): 22:32:55  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:32:55.348121 (Thread-3): 22:32:55  SQL status: COMMIT in 0.05 seconds
2022-01-06 22:32:55.348343 (Thread-3): 22:32:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:32:55.348426 (Thread-3): 22:32:55  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 22:32:55.348650 (Thread-2): 22:32:55  SQL status: COMMIT in 0.05 seconds
2022-01-06 22:32:55.350531 (Thread-3): 22:32:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:32:55.354489 (Thread-3): 22:32:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:32:55.354588 (Thread-3): 22:32:55  On model.jaffel_shop.stg_payments: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_payments"} */
drop view if exists "dev"."dbt_nobodozie"."stg_payments__dbt_backup" cascade
2022-01-06 22:32:55.360874 (Thread-3): 22:32:55  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 22:32:55.361506 (Thread-3): 22:32:55  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:32:55.361601 (Thread-3): 22:32:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:32:55.361676 (Thread-3): 22:32:55  On model.jaffel_shop.stg_payments: COMMIT
2022-01-06 22:32:55.389401 (Thread-3): 22:32:55  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:32:55.389503 (Thread-3): 22:32:55  Using redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:32:55.389573 (Thread-3): 22:32:55  On model.jaffel_shop.stg_payments: BEGIN
2022-01-06 22:32:55.391618 (Thread-3): 22:32:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:32:55.392018 (Thread-3): 22:32:55  finished collecting timing info
2022-01-06 22:32:55.392145 (Thread-3): 22:32:55  On model.jaffel_shop.stg_payments: ROLLBACK
2022-01-06 22:32:55.392343 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:32:55.392452 (Thread-2): 22:32:55  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 22:32:55.394916 (Thread-3): 22:32:55  On model.jaffel_shop.stg_payments: Close
2022-01-06 22:32:55.395068 (Thread-2): 22:32:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:32:55.396192 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:32:55.396290 (Thread-2): 22:32:55  On model.jaffel_shop.stg_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_orders"} */
drop view if exists "dev"."dbt_nobodozie"."stg_orders__dbt_backup" cascade
2022-01-06 22:32:55.396717 (Thread-3): 22:32:55  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fa6bd596-df0f-4b2e-b19c-6640ceb0cb6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd37c255460>]}
2022-01-06 22:32:55.397095 (Thread-3): 22:32:55  3 of 5 OK created view model dbt_nobodozie.stg_payments......................... [CREATE VIEW in 0.25s]
2022-01-06 22:32:55.397239 (Thread-3): 22:32:55  Finished running node model.jaffel_shop.stg_payments
2022-01-06 22:32:55.408650 (Thread-2): 22:32:55  SQL status: DROP VIEW in 0.01 seconds
2022-01-06 22:32:55.409386 (Thread-2): 22:32:55  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:32:55.409498 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:32:55.409576 (Thread-2): 22:32:55  On model.jaffel_shop.stg_orders: COMMIT
2022-01-06 22:32:55.424823 (Thread-1): 22:32:55  SQL status: BEGIN in 0.19 seconds
2022-01-06 22:32:55.424939 (Thread-1): 22:32:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:32:55.425017 (Thread-1): 22:32:55  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */


  create view "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
  ) ;

2022-01-06 22:32:55.432013 (Thread-1): 22:32:55  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:32:55.433936 (Thread-1): 22:32:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:32:55.434034 (Thread-1): 22:32:55  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers" rename to "stg_customers__dbt_backup"
2022-01-06 22:32:55.436963 (Thread-1): 22:32:55  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:32:55.438687 (Thread-1): 22:32:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:32:55.438783 (Thread-1): 22:32:55  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
alter table "dev"."dbt_nobodozie"."stg_customers__dbt_tmp" rename to "stg_customers"
2022-01-06 22:32:55.441870 (Thread-1): 22:32:55  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:32:55.442939 (Thread-1): 22:32:55  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:32:55.443034 (Thread-1): 22:32:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:32:55.443107 (Thread-1): 22:32:55  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:32:55.449322 (Thread-2): 22:32:55  SQL status: COMMIT in 0.04 seconds
2022-01-06 22:32:55.449458 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:32:55.449534 (Thread-2): 22:32:55  On model.jaffel_shop.stg_orders: BEGIN
2022-01-06 22:32:55.452284 (Thread-2): 22:32:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:32:55.452665 (Thread-2): 22:32:55  finished collecting timing info
2022-01-06 22:32:55.452789 (Thread-2): 22:32:55  On model.jaffel_shop.stg_orders: ROLLBACK
2022-01-06 22:32:55.455044 (Thread-2): 22:32:55  On model.jaffel_shop.stg_orders: Close
2022-01-06 22:32:55.455477 (Thread-2): 22:32:55  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fa6bd596-df0f-4b2e-b19c-6640ceb0cb6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd37c26f160>]}
2022-01-06 22:32:55.455786 (Thread-2): 22:32:55  2 of 5 OK created view model dbt_nobodozie.stg_orders........................... [CREATE VIEW in 0.31s]
2022-01-06 22:32:55.455895 (Thread-2): 22:32:55  Finished running node model.jaffel_shop.stg_orders
2022-01-06 22:32:55.456401 (Thread-4): 22:32:55  Began running node model.jaffel_shop.fct_orders
2022-01-06 22:32:55.456602 (Thread-4): 22:32:55  4 of 5 START view model dbt_nobodozie.fct_orders................................ [RUN]
2022-01-06 22:32:55.456852 (Thread-4): 22:32:55  Acquiring new redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:32:55.456940 (Thread-4): 22:32:55  Began compiling node model.jaffel_shop.fct_orders
2022-01-06 22:32:55.457023 (Thread-4): 22:32:55  Compiling model.jaffel_shop.fct_orders
2022-01-06 22:32:55.459326 (Thread-4): 22:32:55  Writing injected SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 22:32:55.476716 (Thread-4): 22:32:55  finished collecting timing info
2022-01-06 22:32:55.476850 (Thread-4): 22:32:55  Began executing node model.jaffel_shop.fct_orders
2022-01-06 22:32:55.478732 (Thread-4): 22:32:55  Writing runtime SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 22:32:55.480620 (Thread-1): 22:32:55  SQL status: COMMIT in 0.04 seconds
2022-01-06 22:32:55.480843 (Thread-1): 22:32:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:32:55.480927 (Thread-1): 22:32:55  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 22:32:55.483124 (Thread-1): 22:32:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:32:55.484379 (Thread-1): 22:32:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:32:55.484479 (Thread-1): 22:32:55  On model.jaffel_shop.stg_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.stg_customers"} */
drop view if exists "dev"."dbt_nobodozie"."stg_customers__dbt_backup" cascade
2022-01-06 22:32:55.488411 (Thread-1): 22:32:55  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 22:32:55.489031 (Thread-1): 22:32:55  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:32:55.489124 (Thread-1): 22:32:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:32:55.489197 (Thread-1): 22:32:55  On model.jaffel_shop.stg_customers: COMMIT
2022-01-06 22:32:55.495415 (Thread-4): 22:32:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:32:55.495529 (Thread-4): 22:32:55  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 22:32:55.495612 (Thread-4): 22:32:55  Opening a new connection, currently in state init
2022-01-06 22:32:55.495692 (Thread-4): 22:32:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:32:55.517322 (Thread-1): 22:32:55  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:32:55.517432 (Thread-1): 22:32:55  Using redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:32:55.517505 (Thread-1): 22:32:55  On model.jaffel_shop.stg_customers: BEGIN
2022-01-06 22:32:55.519631 (Thread-1): 22:32:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:32:55.519996 (Thread-1): 22:32:55  finished collecting timing info
2022-01-06 22:32:55.520117 (Thread-1): 22:32:55  On model.jaffel_shop.stg_customers: ROLLBACK
2022-01-06 22:32:55.521869 (Thread-1): 22:32:55  On model.jaffel_shop.stg_customers: Close
2022-01-06 22:32:55.522268 (Thread-1): 22:32:55  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fa6bd596-df0f-4b2e-b19c-6640ceb0cb6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd37db0de20>]}
2022-01-06 22:32:55.522546 (Thread-1): 22:32:55  1 of 5 OK created view model dbt_nobodozie.stg_customers........................ [CREATE VIEW in 0.38s]
2022-01-06 22:32:55.522652 (Thread-1): 22:32:55  Finished running node model.jaffel_shop.stg_customers
2022-01-06 22:32:55.775064 (Thread-4): 22:32:55  SQL status: BEGIN in 0.28 seconds
2022-01-06 22:32:55.775206 (Thread-4): 22:32:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:32:55.775291 (Thread-4): 22:32:55  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */


  create view "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" as (
    with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),


order_payments as (
    select
        order_id,
        sum(case when status = 'success' then amount end ) as amount
    from payment
    group by 1
),



final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
  ) ;

2022-01-06 22:32:55.783194 (Thread-4): 22:32:55  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:32:55.785199 (Thread-4): 22:32:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:32:55.785352 (Thread-4): 22:32:55  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
alter table "dev"."dbt_nobodozie"."fct_orders__dbt_tmp" rename to "fct_orders"
2022-01-06 22:32:55.787568 (Thread-4): 22:32:55  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:32:55.788596 (Thread-4): 22:32:55  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:32:55.788693 (Thread-4): 22:32:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:32:55.788765 (Thread-4): 22:32:55  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:32:55.818889 (Thread-4): 22:32:55  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:32:55.819330 (Thread-4): 22:32:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:32:55.819443 (Thread-4): 22:32:55  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 22:32:55.821540 (Thread-4): 22:32:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:32:55.822750 (Thread-4): 22:32:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:32:55.822856 (Thread-4): 22:32:55  On model.jaffel_shop.fct_orders: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.fct_orders"} */
drop view if exists "dev"."dbt_nobodozie"."fct_orders__dbt_backup" cascade
2022-01-06 22:32:55.824782 (Thread-4): 22:32:55  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 22:32:55.825455 (Thread-4): 22:32:55  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:32:55.825550 (Thread-4): 22:32:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:32:55.825623 (Thread-4): 22:32:55  On model.jaffel_shop.fct_orders: COMMIT
2022-01-06 22:32:55.850255 (Thread-4): 22:32:55  SQL status: COMMIT in 0.02 seconds
2022-01-06 22:32:55.850382 (Thread-4): 22:32:55  Using redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:32:55.850460 (Thread-4): 22:32:55  On model.jaffel_shop.fct_orders: BEGIN
2022-01-06 22:32:55.852405 (Thread-4): 22:32:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:32:55.852835 (Thread-4): 22:32:55  finished collecting timing info
2022-01-06 22:32:55.852967 (Thread-4): 22:32:55  On model.jaffel_shop.fct_orders: ROLLBACK
2022-01-06 22:32:55.854701 (Thread-4): 22:32:55  On model.jaffel_shop.fct_orders: Close
2022-01-06 22:32:55.855162 (Thread-4): 22:32:55  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fa6bd596-df0f-4b2e-b19c-6640ceb0cb6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd37c1d2ee0>]}
2022-01-06 22:32:55.855528 (Thread-4): 22:32:55  4 of 5 OK created view model dbt_nobodozie.fct_orders........................... [CREATE VIEW in 0.40s]
2022-01-06 22:32:55.855694 (Thread-4): 22:32:55  Finished running node model.jaffel_shop.fct_orders
2022-01-06 22:32:55.856451 (Thread-2): 22:32:55  Began running node model.jaffel_shop.dim_customers
2022-01-06 22:32:55.856663 (Thread-2): 22:32:55  5 of 5 START view model dbt_nobodozie.dim_customers............................. [RUN]
2022-01-06 22:32:55.856895 (Thread-2): 22:32:55  Acquiring new redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:32:55.856989 (Thread-2): 22:32:55  Began compiling node model.jaffel_shop.dim_customers
2022-01-06 22:32:55.857074 (Thread-2): 22:32:55  Compiling model.jaffel_shop.dim_customers
2022-01-06 22:32:55.859639 (Thread-2): 22:32:55  Writing injected SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 22:32:55.873808 (Thread-2): 22:32:55  finished collecting timing info
2022-01-06 22:32:55.873948 (Thread-2): 22:32:55  Began executing node model.jaffel_shop.dim_customers
2022-01-06 22:32:55.875851 (Thread-2): 22:32:55  Writing runtime SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 22:32:55.889552 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:32:55.889665 (Thread-2): 22:32:55  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 22:32:55.889750 (Thread-2): 22:32:55  Opening a new connection, currently in state closed
2022-01-06 22:32:55.889837 (Thread-2): 22:32:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:32:55.907941 (Thread-2): 22:32:55  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:32:55.908058 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:32:55.908137 (Thread-2): 22:32:55  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */


  create view "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" as (
    with customers as (

    select * from "dev"."dbt_nobodozie"."stg_customers"
),

orders as (

    select * from "dev"."dbt_nobodozie"."fct_orders"
),

customer_orders as (

    select
        customer_id,
        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders,
        sum(amount) as lifetime_value
        

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders,
        customer_orders.lifetime_value
        
    from customers

    left join customer_orders using (customer_id)
 
)

select * from final
  ) ;

2022-01-06 22:32:55.915777 (Thread-2): 22:32:55  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 22:32:55.917684 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:32:55.917783 (Thread-2): 22:32:55  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 22:32:55.920211 (Thread-2): 22:32:55  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 22:32:55.921167 (Thread-2): 22:32:55  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 22:32:55.921306 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:32:55.921383 (Thread-2): 22:32:55  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 22:32:55.952265 (Thread-2): 22:32:55  SQL status: COMMIT in 0.03 seconds
2022-01-06 22:32:55.952481 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:32:55.952563 (Thread-2): 22:32:55  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 22:32:55.954754 (Thread-2): 22:32:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:32:55.957051 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:32:55.957149 (Thread-2): 22:32:55  On model.jaffel_shop.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.jaffel_shop.dim_customers"} */
drop view if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 22:32:55.959075 (Thread-2): 22:32:55  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 22:32:55.959776 (Thread-2): 22:32:55  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 22:32:55.959873 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:32:55.959946 (Thread-2): 22:32:55  On model.jaffel_shop.dim_customers: COMMIT
2022-01-06 22:32:55.984571 (Thread-2): 22:32:55  SQL status: COMMIT in 0.02 seconds
2022-01-06 22:32:55.984687 (Thread-2): 22:32:55  Using redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:32:55.984763 (Thread-2): 22:32:55  On model.jaffel_shop.dim_customers: BEGIN
2022-01-06 22:32:55.986796 (Thread-2): 22:32:55  SQL status: BEGIN in 0.0 seconds
2022-01-06 22:32:55.987181 (Thread-2): 22:32:55  finished collecting timing info
2022-01-06 22:32:55.987305 (Thread-2): 22:32:55  On model.jaffel_shop.dim_customers: ROLLBACK
2022-01-06 22:32:55.988979 (Thread-2): 22:32:55  On model.jaffel_shop.dim_customers: Close
2022-01-06 22:32:55.989445 (Thread-2): 22:32:55  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fa6bd596-df0f-4b2e-b19c-6640ceb0cb6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd37c199ac0>]}
2022-01-06 22:32:55.989755 (Thread-2): 22:32:55  5 of 5 OK created view model dbt_nobodozie.dim_customers........................ [CREATE VIEW in 0.13s]
2022-01-06 22:32:55.989867 (Thread-2): 22:32:55  Finished running node model.jaffel_shop.dim_customers
2022-01-06 22:32:55.991133 (MainThread): 22:32:55  Acquiring new redshift connection "master"
2022-01-06 22:32:55.991278 (MainThread): 22:32:55  Using redshift connection "master"
2022-01-06 22:32:55.991355 (MainThread): 22:32:55  On master: BEGIN
2022-01-06 22:32:55.991431 (MainThread): 22:32:55  Opening a new connection, currently in state closed
2022-01-06 22:32:55.991505 (MainThread): 22:32:55  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:32:56.016186 (MainThread): 22:32:56  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:32:56.016302 (MainThread): 22:32:56  On master: COMMIT
2022-01-06 22:32:56.016377 (MainThread): 22:32:56  Using redshift connection "master"
2022-01-06 22:32:56.016447 (MainThread): 22:32:56  On master: COMMIT
2022-01-06 22:32:56.018220 (MainThread): 22:32:56  SQL status: COMMIT in 0.0 seconds
2022-01-06 22:32:56.018330 (MainThread): 22:32:56  On master: Close
2022-01-06 22:32:56.018745 (MainThread): 22:32:56  
2022-01-06 22:32:56.018856 (MainThread): 22:32:56  Finished running 5 view models in 1.02s.
2022-01-06 22:32:56.018937 (MainThread): 22:32:56  Connection 'master' was properly closed.
2022-01-06 22:32:56.019002 (MainThread): 22:32:56  Connection 'model.jaffel_shop.stg_customers' was properly closed.
2022-01-06 22:32:56.019062 (MainThread): 22:32:56  Connection 'model.jaffel_shop.dim_customers' was properly closed.
2022-01-06 22:32:56.019153 (MainThread): 22:32:56  Connection 'model.jaffel_shop.stg_payments' was properly closed.
2022-01-06 22:32:56.019248 (MainThread): 22:32:56  Connection 'model.jaffel_shop.fct_orders' was properly closed.
2022-01-06 22:32:56.071981 (MainThread): 22:32:56  
2022-01-06 22:32:56.072133 (MainThread): 22:32:56  Completed successfully
2022-01-06 22:32:56.072231 (MainThread): 22:32:56  
2022-01-06 22:32:56.072316 (MainThread): 22:32:56  Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2022-01-06 22:32:56.787012 (Thread-1002): handling poll request
2022-01-06 22:32:56.787402 (Thread-1002): 22:32:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe84680730>]}
2022-01-06 22:32:56.790200 (Thread-1002): sending response (<Response 86463 bytes [200 OK]>) to 10.0.28.107
2022-01-06 22:32:57.525705 (Thread-1003): handling status request
2022-01-06 22:32:57.526056 (Thread-1003): 22:32:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe846808e0>]}
2022-01-06 22:32:57.526619 (Thread-1003): sending response (<Response 1575 bytes [200 OK]>) to 10.0.39.187
2022-01-06 22:32:57.589929 (Thread-1004): handling status request
2022-01-06 22:32:57.590328 (Thread-1004): 22:32:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe847acca0>]}
2022-01-06 22:32:57.590774 (Thread-1004): sending response (<Response 1575 bytes [200 OK]>) to 10.0.28.107
2022-01-06 22:33:04.937164 (Thread-1005): handling status request
2022-01-06 22:33:04.937574 (Thread-1005): 22:33:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe84680f10>]}
2022-01-06 22:33:04.938073 (Thread-1005): sending response (<Response 1575 bytes [200 OK]>) to 10.0.15.38
2022-01-06 22:33:05.149988 (Thread-1006): handling status request
2022-01-06 22:33:05.150282 (Thread-1006): 22:33:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe846a4130>]}
2022-01-06 22:33:05.150708 (Thread-1006): sending response (<Response 1575 bytes [200 OK]>) to 10.0.40.204
2022-01-06 22:33:05.262348 (Thread-1007): handling docs.generate request
2022-01-06 22:33:05.262626 (Thread-1007): 22:33:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe846a4430>]}
2022-01-06 22:33:07.306617 (Thread-1007): sending response (<Response 138 bytes [200 OK]>) to 10.0.39.187
2022-01-06 22:33:07.334512 (MainThread): 22:33:07  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4d610386-c01d-493f-b88b-70d062a3158a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f127b1628e0>]}
2022-01-06 22:33:07.334789 (MainThread): 22:33:07  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:33:07.335888 (MainThread): 22:33:07  
2022-01-06 22:33:07.336037 (MainThread): 22:33:07  Acquiring new redshift connection "master"
2022-01-06 22:33:07.336789 (ThreadPoolExecutor-0_0): 22:33:07  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:33:07.348087 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/catalog.sql
2022-01-06 22:33:07.361540 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/adapters.sql
2022-01-06 22:33:07.388419 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/relations.sql
2022-01-06 22:33:07.389092 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 22:33:07.390054 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/catalog.sql
2022-01-06 22:33:07.392225 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/adapters.sql
2022-01-06 22:33:07.413093 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/relations.sql
2022-01-06 22:33:07.414492 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 22:33:07.417373 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-06 22:33:07.418916 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-06 22:33:07.420548 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-06 22:33:07.423137 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-06 22:33:07.424588 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/generic_test_sql/not_null.sql
2022-01-06 22:33:07.425278 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/generic_test_sql/relationships.sql
2022-01-06 22:33:07.426228 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/generic_test_sql/unique.sql
2022-01-06 22:33:07.427021 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/configs.sql
2022-01-06 22:33:07.429342 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/hooks.sql
2022-01-06 22:33:07.433097 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/snapshots/strategies.sql
2022-01-06 22:33:07.448923 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-06 22:33:07.450697 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-06 22:33:07.461987 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/snapshots/helpers.sql
2022-01-06 22:33:07.472497 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/seeds/seed.sql
2022-01-06 22:33:07.478248 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/seeds/helpers.sql
2022-01-06 22:33:07.493555 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-06 22:33:07.495886 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/models/view/view.sql
2022-01-06 22:33:07.502561 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-06 22:33:07.505170 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/models/view/helpers.sql
2022-01-06 22:33:07.506553 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/models/table/table.sql
2022-01-06 22:33:07.513416 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-06 22:33:07.516239 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/models/incremental/merge.sql
2022-01-06 22:33:07.526954 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-06 22:33:07.541742 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-06 22:33:07.546074 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-06 22:33:07.555632 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-06 22:33:07.557200 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/tests/test.sql
2022-01-06 22:33:07.561505 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/tests/where_subquery.sql
2022-01-06 22:33:07.563336 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/materializations/tests/helpers.sql
2022-01-06 22:33:07.565126 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/etc/statement.sql
2022-01-06 22:33:07.569427 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/etc/datetime.sql
2022-01-06 22:33:07.577357 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/adapters/indexes.sql
2022-01-06 22:33:07.580058 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/adapters/persist_docs.sql
2022-01-06 22:33:07.584372 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/adapters/freshness.sql
2022-01-06 22:33:07.587268 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/adapters/relation.sql
2022-01-06 22:33:07.596433 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/adapters/metadata.sql
2022-01-06 22:33:07.603699 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/adapters/columns.sql
2022-01-06 22:33:07.613657 (ThreadPoolExecutor-0_0): 22:33:07  Parsing macros/adapters/schema.sql
2022-01-06 22:33:07.625554 (ThreadPoolExecutor-0_0): 22:33:07  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:33:07.625669 (ThreadPoolExecutor-0_0): 22:33:07  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 22:33:07.625753 (ThreadPoolExecutor-0_0): 22:33:07  Opening a new connection, currently in state init
2022-01-06 22:33:07.625833 (ThreadPoolExecutor-0_0): 22:33:07  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:33:07.647580 (ThreadPoolExecutor-0_0): 22:33:07  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:33:07.647686 (ThreadPoolExecutor-0_0): 22:33:07  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:33:07.647761 (ThreadPoolExecutor-0_0): 22:33:07  On list_dev_dbt_nobodozie: select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 22:33:07.659036 (ThreadPoolExecutor-0_0): 22:33:07  SQL status: SELECT in 0.01 seconds
2022-01-06 22:33:07.660188 (ThreadPoolExecutor-0_0): 22:33:07  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 22:33:07.661952 (ThreadPoolExecutor-0_0): 22:33:07  On list_dev_dbt_nobodozie: Close
2022-01-06 22:33:07.665631 (MainThread): 22:33:07  Using redshift connection "master"
2022-01-06 22:33:07.665738 (MainThread): 22:33:07  On master: BEGIN
2022-01-06 22:33:07.665819 (MainThread): 22:33:07  Opening a new connection, currently in state init
2022-01-06 22:33:07.665895 (MainThread): 22:33:07  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:33:07.688120 (MainThread): 22:33:07  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:33:07.688227 (MainThread): 22:33:07  Using redshift connection "master"
2022-01-06 22:33:07.688301 (MainThread): 22:33:07  On master: with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 22:33:07.731404 (MainThread): 22:33:07  SQL status: SELECT in 0.04 seconds
2022-01-06 22:33:07.732564 (MainThread): 22:33:07  On master: ROLLBACK
2022-01-06 22:33:07.734761 (Thread-1008): handling poll request
2022-01-06 22:33:07.734458 (MainThread): 22:33:07  On master: Close
2022-01-06 22:33:07.735380 (Thread-1008): 22:33:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe8468fb80>]}
2022-01-06 22:33:07.734728 (MainThread): 22:33:07  Concurrency: 4 threads (target='default')
2022-01-06 22:33:07.737128 (Thread-1008): sending response (<Response 24594 bytes [200 OK]>) to 10.0.15.38
2022-01-06 22:33:07.734837 (MainThread): 22:33:07  
2022-01-06 22:33:07.737087 (Thread-1): 22:33:07  Began running node model.jaffel_shop.stg_customers
2022-01-06 22:33:07.737283 (Thread-1): 22:33:07  Acquiring new redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:33:07.737376 (Thread-1): 22:33:07  Began compiling node model.jaffel_shop.stg_customers
2022-01-06 22:33:07.737462 (Thread-1): 22:33:07  Compiling model.jaffel_shop.stg_customers
2022-01-06 22:33:07.738731 (Thread-1): 22:33:07  Writing injected SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 22:33:07.738999 (Thread-2): 22:33:07  Began running node model.jaffel_shop.stg_orders
2022-01-06 22:33:07.739177 (Thread-2): 22:33:07  Acquiring new redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:33:07.739261 (Thread-2): 22:33:07  Began compiling node model.jaffel_shop.stg_orders
2022-01-06 22:33:07.739341 (Thread-2): 22:33:07  Compiling model.jaffel_shop.stg_orders
2022-01-06 22:33:07.740547 (Thread-2): 22:33:07  Writing injected SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 22:33:07.740904 (Thread-3): 22:33:07  Began running node model.jaffel_shop.stg_payments
2022-01-06 22:33:07.741068 (Thread-3): 22:33:07  Acquiring new redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:33:07.741149 (Thread-3): 22:33:07  Began compiling node model.jaffel_shop.stg_payments
2022-01-06 22:33:07.741258 (Thread-3): 22:33:07  Compiling model.jaffel_shop.stg_payments
2022-01-06 22:33:07.742306 (Thread-3): 22:33:07  Writing injected SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 22:33:07.754531 (Thread-1): 22:33:07  finished collecting timing info
2022-01-06 22:33:07.754684 (Thread-1): 22:33:07  Began executing node model.jaffel_shop.stg_customers
2022-01-06 22:33:07.754790 (Thread-1): 22:33:07  finished collecting timing info
2022-01-06 22:33:07.754957 (Thread-1): 22:33:07  Finished running node model.jaffel_shop.stg_customers
2022-01-06 22:33:07.755781 (Thread-2): 22:33:07  finished collecting timing info
2022-01-06 22:33:07.755916 (Thread-2): 22:33:07  Began executing node model.jaffel_shop.stg_orders
2022-01-06 22:33:07.756005 (Thread-2): 22:33:07  finished collecting timing info
2022-01-06 22:33:07.756133 (Thread-2): 22:33:07  Finished running node model.jaffel_shop.stg_orders
2022-01-06 22:33:07.756343 (Thread-3): 22:33:07  finished collecting timing info
2022-01-06 22:33:07.756473 (Thread-3): 22:33:07  Began executing node model.jaffel_shop.stg_payments
2022-01-06 22:33:07.756562 (Thread-3): 22:33:07  finished collecting timing info
2022-01-06 22:33:07.756695 (Thread-3): 22:33:07  Finished running node model.jaffel_shop.stg_payments
2022-01-06 22:33:07.757444 (Thread-4): 22:33:07  Began running node model.jaffel_shop.fct_orders
2022-01-06 22:33:07.757636 (Thread-4): 22:33:07  Acquiring new redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:33:07.757726 (Thread-4): 22:33:07  Began compiling node model.jaffel_shop.fct_orders
2022-01-06 22:33:07.757808 (Thread-4): 22:33:07  Compiling model.jaffel_shop.fct_orders
2022-01-06 22:33:07.760739 (Thread-4): 22:33:07  Writing injected SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 22:33:07.775537 (Thread-4): 22:33:07  finished collecting timing info
2022-01-06 22:33:07.775664 (Thread-4): 22:33:07  Began executing node model.jaffel_shop.fct_orders
2022-01-06 22:33:07.775755 (Thread-4): 22:33:07  finished collecting timing info
2022-01-06 22:33:07.775894 (Thread-4): 22:33:07  Finished running node model.jaffel_shop.fct_orders
2022-01-06 22:33:07.776631 (Thread-2): 22:33:07  Began running node model.jaffel_shop.dim_customers
2022-01-06 22:33:07.776782 (Thread-2): 22:33:07  Acquiring new redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:33:07.776862 (Thread-2): 22:33:07  Began compiling node model.jaffel_shop.dim_customers
2022-01-06 22:33:07.776936 (Thread-2): 22:33:07  Compiling model.jaffel_shop.dim_customers
2022-01-06 22:33:07.779166 (Thread-2): 22:33:07  Writing injected SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 22:33:07.792695 (Thread-2): 22:33:07  finished collecting timing info
2022-01-06 22:33:07.792823 (Thread-2): 22:33:07  Began executing node model.jaffel_shop.dim_customers
2022-01-06 22:33:07.792914 (Thread-2): 22:33:07  finished collecting timing info
2022-01-06 22:33:07.793044 (Thread-2): 22:33:07  Finished running node model.jaffel_shop.dim_customers
2022-01-06 22:33:07.794187 (MainThread): 22:33:07  Connection 'master' was properly closed.
2022-01-06 22:33:07.794296 (MainThread): 22:33:07  Connection 'model.jaffel_shop.stg_customers' was properly closed.
2022-01-06 22:33:07.794362 (MainThread): 22:33:07  Connection 'model.jaffel_shop.dim_customers' was properly closed.
2022-01-06 22:33:07.794422 (MainThread): 22:33:07  Connection 'model.jaffel_shop.stg_payments' was properly closed.
2022-01-06 22:33:07.794480 (MainThread): 22:33:07  Connection 'model.jaffel_shop.fct_orders' was properly closed.
2022-01-06 22:33:07.843515 (MainThread): 22:33:07  Done.
2022-01-06 22:33:07.913821 (MainThread): 22:33:07  Acquiring new redshift connection "generate_catalog"
2022-01-06 22:33:07.913940 (MainThread): 22:33:07  Building catalog
2022-01-06 22:33:07.915084 (ThreadPoolExecutor-1_0): 22:33:07  Acquiring new redshift connection "dev.information_schema"
2022-01-06 22:33:07.925853 (ThreadPoolExecutor-1_0): 22:33:07  Using redshift connection "dev.information_schema"
2022-01-06 22:33:07.925971 (ThreadPoolExecutor-1_0): 22:33:07  On dev.information_schema: BEGIN
2022-01-06 22:33:07.926054 (ThreadPoolExecutor-1_0): 22:33:07  Opening a new connection, currently in state init
2022-01-06 22:33:07.926133 (ThreadPoolExecutor-1_0): 22:33:07  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:33:07.944487 (ThreadPoolExecutor-1_0): 22:33:07  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:33:07.944598 (ThreadPoolExecutor-1_0): 22:33:07  Using redshift connection "dev.information_schema"
2022-01-06 22:33:07.944673 (ThreadPoolExecutor-1_0): 22:33:07  On dev.information_schema: 
    

    with late_binding as (
      select
        'dev'::varchar as table_database,
        table_schema,
        table_name,
        'LATE BINDING VIEW'::varchar as table_type,
        null::text as table_comment,

        column_name,
        column_index,
        column_type,
        null::text as column_comment
      from pg_get_late_binding_view_cols()
        cols(table_schema name, table_name name, column_name name,
             column_type varchar,
             column_index int)
        order by "column_index"
    ),

    early_binding as (
        select
            'dev'::varchar as table_database,
            sch.nspname as table_schema,
            tbl.relname as table_name,
            case tbl.relkind
                when 'v' then 'VIEW'
                else 'BASE TABLE'
            end as table_type,
            tbl_desc.description as table_comment,
            col.attname as column_name,
            col.attnum as column_index,
            pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
            col_desc.description as column_comment

        from pg_catalog.pg_namespace sch
        join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
        join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
        left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
        left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
        where (upper(sch.nspname) = upper('dbt_nobodozie'))
            and tbl.relkind in ('r', 'v', 'f', 'p')
            and col.attnum > 0
            and not col.attisdropped
    ),

    table_owners as (

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            tablename as table_name,
            tableowner as table_owner

        from pg_tables

        union all

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            viewname as table_name,
            viewowner as table_owner

        from pg_views

    ),

    unioned as (

        select *
        from early_binding

        union all

        select *
        from late_binding

    )

    select *,
        table_database || '.' || table_schema || '.' || table_name as table_id

    from unioned
    join table_owners using (table_database, table_schema, table_name)

    where (upper(table_schema) = upper('dbt_nobodozie'))

    order by "column_index"
2022-01-06 22:33:08.002307 (ThreadPoolExecutor-1_0): 22:33:08  SQL status: SELECT in 0.06 seconds
2022-01-06 22:33:08.006168 (ThreadPoolExecutor-1_0): 22:33:08  Using redshift connection "dev.information_schema"
2022-01-06 22:33:08.006276 (ThreadPoolExecutor-1_0): 22:33:08  On dev.information_schema: select has_table_privilege(current_user, 'svv_table_info', 'SELECT') as can_select
2022-01-06 22:33:08.008671 (ThreadPoolExecutor-1_0): 22:33:08  SQL status: SELECT in 0.0 seconds
2022-01-06 22:33:08.012435 (ThreadPoolExecutor-1_0): 22:33:08  Using redshift connection "dev.information_schema"
2022-01-06 22:33:08.012532 (ThreadPoolExecutor-1_0): 22:33:08  On dev.information_schema: select
        "database" || '.' || "schema" || '.' || "table" as table_id,

        'Encoded'::text as "stats:encoded:label",
        encoded as "stats:encoded:value",
        'Indicates whether any column in the table has compression encoding defined.'::text as "stats:encoded:description",
        true as "stats:encoded:include",

        'Dist Style' as "stats:diststyle:label",
        diststyle as "stats:diststyle:value",
        'Distribution style or distribution key column, if key distribution is defined.'::text as "stats:diststyle:description",
        true as "stats:diststyle:include",

        'Sort Key 1' as "stats:sortkey1:label",
        -- handle 0xFF byte in response for interleaved sort styles
        case
            when sortkey1 like 'INTERLEAVED%' then 'INTERLEAVED'::text
            else sortkey1
        end as "stats:sortkey1:value",
        'First column in the sort key.'::text as "stats:sortkey1:description",
        (sortkey1 is not null) as "stats:sortkey1:include",

        'Max Varchar' as "stats:max_varchar:label",
        max_varchar as "stats:max_varchar:value",
        'Size of the largest column that uses a VARCHAR data type.'::text as "stats:max_varchar:description",
        true as "stats:max_varchar:include",

        -- exclude this, as the data is strangely returned with null-byte characters
        'Sort Key 1 Encoding' as "stats:sortkey1_enc:label",
        sortkey1_enc as "stats:sortkey1_enc:value",
        'Compression encoding of the first column in the sort key.' as "stats:sortkey1_enc:description",
        false as "stats:sortkey1_enc:include",

        '# Sort Keys' as "stats:sortkey_num:label",
        sortkey_num as "stats:sortkey_num:value",
        'Number of columns defined as sort keys.' as "stats:sortkey_num:description",
        (sortkey_num > 0) as "stats:sortkey_num:include",

        'Approximate Size' as "stats:size:label",
        size * 1000000 as "stats:size:value",
        'Approximate size of the table, calculated from a count of 1MB blocks'::text as "stats:size:description",
        true as "stats:size:include",

        'Disk Utilization' as "stats:pct_used:label",
        pct_used / 100.0 as "stats:pct_used:value",
        'Percent of available space that is used by the table.'::text as "stats:pct_used:description",
        true as "stats:pct_used:include",

        'Unsorted %' as "stats:unsorted:label",
        unsorted / 100.0 as "stats:unsorted:value",
        'Percent of unsorted rows in the table.'::text as "stats:unsorted:description",
        (unsorted is not null) as "stats:unsorted:include",

        'Stats Off' as "stats:stats_off:label",
        stats_off as "stats:stats_off:value",
        'Number that indicates how stale the table statistics are; 0 is current, 100 is out of date.'::text as "stats:stats_off:description",
        true as "stats:stats_off:include",

        'Approximate Row Count' as "stats:rows:label",
        tbl_rows as "stats:rows:value",
        'Approximate number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed.'::text as "stats:rows:description",
        true as "stats:rows:include",

        'Sort Key Skew' as "stats:skew_sortkey1:label",
        skew_sortkey1 as "stats:skew_sortkey1:value",
        'Ratio of the size of the largest non-sort key column to the size of the first column of the sort key.'::text as "stats:skew_sortkey1:description",
        (skew_sortkey1 is not null) as "stats:skew_sortkey1:include",

        'Skew Rows' as "stats:skew_rows:label",
        skew_rows as "stats:skew_rows:value",
        'Ratio of the number of rows in the slice with the most rows to the number of rows in the slice with the fewest rows.'::text as "stats:skew_rows:description",
        (skew_rows is not null) as "stats:skew_rows:include"

    from svv_table_info
    where (upper(schema) = upper('dbt_nobodozie'))
2022-01-06 22:33:08.699666 (ThreadPoolExecutor-1_0): 22:33:08  SQL status: SELECT in 0.69 seconds
2022-01-06 22:33:08.711462 (ThreadPoolExecutor-1_0): 22:33:08  On dev.information_schema: ROLLBACK
2022-01-06 22:33:08.713635 (ThreadPoolExecutor-1_0): 22:33:08  On dev.information_schema: Close
2022-01-06 22:33:08.799720 (MainThread): 22:33:08  Catalog written to /usr/src/develop/user-52374/environment-57794/repository-46678/target/catalog.json
2022-01-06 22:33:09.079445 (Thread-1009): handling poll request
2022-01-06 22:33:09.079848 (Thread-1009): 22:33:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe846410d0>]}
2022-01-06 22:33:09.081266 (Thread-1009): sending response (<Response 37991 bytes [200 OK]>) to 10.0.16.23
2022-01-06 22:33:09.715571 (Thread-1010): handling status request
2022-01-06 22:33:09.715970 (Thread-1010): 22:33:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe846afa00>]}
2022-01-06 22:33:09.716526 (Thread-1010): sending response (<Response 1575 bytes [200 OK]>) to 10.0.13.200
2022-01-06 22:33:09.758094 (Thread-1011): handling status request
2022-01-06 22:33:09.758395 (Thread-1011): 22:33:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe846b7640>]}
2022-01-06 22:33:09.758815 (Thread-1011): sending response (<Response 1575 bytes [200 OK]>) to 10.0.15.38
2022-01-06 22:33:09.810387 (Thread-1012): handling status request
2022-01-06 22:33:09.810638 (Thread-1012): 22:33:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe846418b0>]}
2022-01-06 22:33:09.811020 (Thread-1012): sending response (<Response 1575 bytes [200 OK]>) to 10.0.29.201
2022-01-06 22:33:12.908880 (Thread-1013): handling status request
2022-01-06 22:33:12.909275 (Thread-1013): 22:33:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe84641b20>]}
2022-01-06 22:33:12.909760 (Thread-1013): sending response (<Response 1575 bytes [200 OK]>) to 10.0.34.75
2022-01-06 22:33:13.115219 (Thread-1014): handling status request
2022-01-06 22:33:13.115595 (Thread-1014): 22:33:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe84641d90>]}
2022-01-06 22:33:13.116062 (Thread-1014): sending response (<Response 1575 bytes [200 OK]>) to 10.0.9.169
2022-01-06 22:33:13.229486 (Thread-1015): handling docs.generate request
2022-01-06 22:33:13.229829 (Thread-1015): 22:33:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe84641fd0>]}
2022-01-06 22:33:15.285432 (Thread-1015): sending response (<Response 138 bytes [200 OK]>) to 10.0.40.103
2022-01-06 22:33:15.315276 (MainThread): 22:33:15  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '47f79791-5351-4237-90c0-93a49b569e65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce7a75f880>]}
2022-01-06 22:33:15.315564 (MainThread): 22:33:15  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:33:15.316652 (MainThread): 22:33:15  
2022-01-06 22:33:15.316797 (MainThread): 22:33:15  Acquiring new redshift connection "master"
2022-01-06 22:33:15.317568 (ThreadPoolExecutor-0_0): 22:33:15  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:33:15.329636 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/catalog.sql
2022-01-06 22:33:15.343229 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/adapters.sql
2022-01-06 22:33:15.370492 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/relations.sql
2022-01-06 22:33:15.371174 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 22:33:15.372092 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/catalog.sql
2022-01-06 22:33:15.374355 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/adapters.sql
2022-01-06 22:33:15.395209 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/relations.sql
2022-01-06 22:33:15.396564 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 22:33:15.399490 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-06 22:33:15.401047 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-06 22:33:15.402787 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-06 22:33:15.405440 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-06 22:33:15.406864 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/generic_test_sql/not_null.sql
2022-01-06 22:33:15.407574 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/generic_test_sql/relationships.sql
2022-01-06 22:33:15.408534 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/generic_test_sql/unique.sql
2022-01-06 22:33:15.409337 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/configs.sql
2022-01-06 22:33:15.411713 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/hooks.sql
2022-01-06 22:33:15.415575 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/snapshots/strategies.sql
2022-01-06 22:33:15.431584 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-06 22:33:15.433319 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-06 22:33:15.444665 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/snapshots/helpers.sql
2022-01-06 22:33:15.455324 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/seeds/seed.sql
2022-01-06 22:33:15.461205 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/seeds/helpers.sql
2022-01-06 22:33:15.476729 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-06 22:33:15.479093 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/models/view/view.sql
2022-01-06 22:33:15.485814 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-06 22:33:15.488438 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/models/view/helpers.sql
2022-01-06 22:33:15.489852 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/models/table/table.sql
2022-01-06 22:33:15.496839 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-06 22:33:15.499752 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/models/incremental/merge.sql
2022-01-06 22:33:15.510553 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-06 22:33:15.525327 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-06 22:33:15.529670 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-06 22:33:15.539309 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-06 22:33:15.540891 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/tests/test.sql
2022-01-06 22:33:15.545198 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/tests/where_subquery.sql
2022-01-06 22:33:15.547067 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/materializations/tests/helpers.sql
2022-01-06 22:33:15.548910 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/etc/statement.sql
2022-01-06 22:33:15.553247 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/etc/datetime.sql
2022-01-06 22:33:15.561247 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/adapters/indexes.sql
2022-01-06 22:33:15.563920 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/adapters/persist_docs.sql
2022-01-06 22:33:15.568192 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/adapters/freshness.sql
2022-01-06 22:33:15.571095 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/adapters/relation.sql
2022-01-06 22:33:15.580375 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/adapters/metadata.sql
2022-01-06 22:33:15.587557 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/adapters/columns.sql
2022-01-06 22:33:15.597141 (ThreadPoolExecutor-0_0): 22:33:15  Parsing macros/adapters/schema.sql
2022-01-06 22:33:15.609081 (ThreadPoolExecutor-0_0): 22:33:15  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:33:15.609199 (ThreadPoolExecutor-0_0): 22:33:15  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 22:33:15.609317 (ThreadPoolExecutor-0_0): 22:33:15  Opening a new connection, currently in state init
2022-01-06 22:33:15.609416 (ThreadPoolExecutor-0_0): 22:33:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:33:15.628420 (ThreadPoolExecutor-0_0): 22:33:15  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:33:15.628526 (ThreadPoolExecutor-0_0): 22:33:15  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:33:15.628599 (ThreadPoolExecutor-0_0): 22:33:15  On list_dev_dbt_nobodozie: select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 22:33:15.639637 (ThreadPoolExecutor-0_0): 22:33:15  SQL status: SELECT in 0.01 seconds
2022-01-06 22:33:15.640747 (ThreadPoolExecutor-0_0): 22:33:15  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 22:33:15.642581 (ThreadPoolExecutor-0_0): 22:33:15  On list_dev_dbt_nobodozie: Close
2022-01-06 22:33:15.646189 (MainThread): 22:33:15  Using redshift connection "master"
2022-01-06 22:33:15.646300 (MainThread): 22:33:15  On master: BEGIN
2022-01-06 22:33:15.646379 (MainThread): 22:33:15  Opening a new connection, currently in state init
2022-01-06 22:33:15.646454 (MainThread): 22:33:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:33:15.669317 (MainThread): 22:33:15  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:33:15.669433 (MainThread): 22:33:15  Using redshift connection "master"
2022-01-06 22:33:15.669506 (MainThread): 22:33:15  On master: with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 22:33:15.701168 (MainThread): 22:33:15  SQL status: SELECT in 0.03 seconds
2022-01-06 22:33:15.702304 (MainThread): 22:33:15  On master: ROLLBACK
2022-01-06 22:33:15.704236 (MainThread): 22:33:15  On master: Close
2022-01-06 22:33:15.704509 (MainThread): 22:33:15  Concurrency: 4 threads (target='default')
2022-01-06 22:33:15.704615 (MainThread): 22:33:15  
2022-01-06 22:33:15.706774 (Thread-1): 22:33:15  Began running node model.jaffel_shop.stg_customers
2022-01-06 22:33:15.706940 (Thread-1): 22:33:15  Acquiring new redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:33:15.707025 (Thread-1): 22:33:15  Began compiling node model.jaffel_shop.stg_customers
2022-01-06 22:33:15.707108 (Thread-1): 22:33:15  Compiling model.jaffel_shop.stg_customers
2022-01-06 22:33:15.708291 (Thread-1): 22:33:15  Writing injected SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 22:33:15.708507 (Thread-2): 22:33:15  Began running node model.jaffel_shop.stg_orders
2022-01-06 22:33:15.708680 (Thread-2): 22:33:15  Acquiring new redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:33:15.708781 (Thread-2): 22:33:15  Began compiling node model.jaffel_shop.stg_orders
2022-01-06 22:33:15.708856 (Thread-2): 22:33:15  Compiling model.jaffel_shop.stg_orders
2022-01-06 22:33:15.710011 (Thread-2): 22:33:15  Writing injected SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 22:33:15.710320 (Thread-3): 22:33:15  Began running node model.jaffel_shop.stg_payments
2022-01-06 22:33:15.710502 (Thread-3): 22:33:15  Acquiring new redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:33:15.710587 (Thread-3): 22:33:15  Began compiling node model.jaffel_shop.stg_payments
2022-01-06 22:33:15.710666 (Thread-3): 22:33:15  Compiling model.jaffel_shop.stg_payments
2022-01-06 22:33:15.711691 (Thread-3): 22:33:15  Writing injected SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 22:33:15.728302 (Thread-3): 22:33:15  finished collecting timing info
2022-01-06 22:33:15.728443 (Thread-3): 22:33:15  Began executing node model.jaffel_shop.stg_payments
2022-01-06 22:33:15.728542 (Thread-3): 22:33:15  finished collecting timing info
2022-01-06 22:33:15.728687 (Thread-3): 22:33:15  Finished running node model.jaffel_shop.stg_payments
2022-01-06 22:33:15.728857 (Thread-1): 22:33:15  finished collecting timing info
2022-01-06 22:33:15.728987 (Thread-1): 22:33:15  Began executing node model.jaffel_shop.stg_customers
2022-01-06 22:33:15.729075 (Thread-1): 22:33:15  finished collecting timing info
2022-01-06 22:33:15.729210 (Thread-1): 22:33:15  Finished running node model.jaffel_shop.stg_customers
2022-01-06 22:33:15.729501 (Thread-2): 22:33:15  finished collecting timing info
2022-01-06 22:33:15.729626 (Thread-2): 22:33:15  Began executing node model.jaffel_shop.stg_orders
2022-01-06 22:33:15.729715 (Thread-2): 22:33:15  finished collecting timing info
2022-01-06 22:33:15.729839 (Thread-2): 22:33:15  Finished running node model.jaffel_shop.stg_orders
2022-01-06 22:33:15.730533 (Thread-4): 22:33:15  Began running node model.jaffel_shop.fct_orders
2022-01-06 22:33:15.730697 (Thread-4): 22:33:15  Acquiring new redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:33:15.730776 (Thread-4): 22:33:15  Began compiling node model.jaffel_shop.fct_orders
2022-01-06 22:33:15.730854 (Thread-4): 22:33:15  Compiling model.jaffel_shop.fct_orders
2022-01-06 22:33:15.733523 (Thread-4): 22:33:15  Writing injected SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 22:33:15.748024 (Thread-4): 22:33:15  finished collecting timing info
2022-01-06 22:33:15.748153 (Thread-4): 22:33:15  Began executing node model.jaffel_shop.fct_orders
2022-01-06 22:33:15.748242 (Thread-4): 22:33:15  finished collecting timing info
2022-01-06 22:33:15.748369 (Thread-4): 22:33:15  Finished running node model.jaffel_shop.fct_orders
2022-01-06 22:33:15.749132 (Thread-1): 22:33:15  Began running node model.jaffel_shop.dim_customers
2022-01-06 22:33:15.749317 (Thread-1): 22:33:15  Acquiring new redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:33:15.749412 (Thread-1): 22:33:15  Began compiling node model.jaffel_shop.dim_customers
2022-01-06 22:33:15.749490 (Thread-1): 22:33:15  Compiling model.jaffel_shop.dim_customers
2022-01-06 22:33:15.751608 (Thread-1): 22:33:15  Writing injected SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 22:33:15.758672 (Thread-1016): handling poll request
2022-01-06 22:33:15.759030 (Thread-1016): 22:33:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe8465ad30>]}
2022-01-06 22:33:15.760755 (Thread-1016): sending response (<Response 41815 bytes [200 OK]>) to 10.0.29.201
2022-01-06 22:33:15.767556 (Thread-1): 22:33:15  finished collecting timing info
2022-01-06 22:33:15.767686 (Thread-1): 22:33:15  Began executing node model.jaffel_shop.dim_customers
2022-01-06 22:33:15.767773 (Thread-1): 22:33:15  finished collecting timing info
2022-01-06 22:33:15.767919 (Thread-1): 22:33:15  Finished running node model.jaffel_shop.dim_customers
2022-01-06 22:33:15.768929 (MainThread): 22:33:15  Connection 'master' was properly closed.
2022-01-06 22:33:15.769038 (MainThread): 22:33:15  Connection 'model.jaffel_shop.dim_customers' was properly closed.
2022-01-06 22:33:15.769105 (MainThread): 22:33:15  Connection 'model.jaffel_shop.stg_orders' was properly closed.
2022-01-06 22:33:15.769167 (MainThread): 22:33:15  Connection 'model.jaffel_shop.stg_payments' was properly closed.
2022-01-06 22:33:15.769253 (MainThread): 22:33:15  Connection 'model.jaffel_shop.fct_orders' was properly closed.
2022-01-06 22:33:15.822956 (MainThread): 22:33:15  Done.
2022-01-06 22:33:15.871493 (MainThread): 22:33:15  Acquiring new redshift connection "generate_catalog"
2022-01-06 22:33:15.871609 (MainThread): 22:33:15  Building catalog
2022-01-06 22:33:15.872856 (ThreadPoolExecutor-1_0): 22:33:15  Acquiring new redshift connection "dev.information_schema"
2022-01-06 22:33:15.883203 (ThreadPoolExecutor-1_0): 22:33:15  Using redshift connection "dev.information_schema"
2022-01-06 22:33:15.883306 (ThreadPoolExecutor-1_0): 22:33:15  On dev.information_schema: BEGIN
2022-01-06 22:33:15.883388 (ThreadPoolExecutor-1_0): 22:33:15  Opening a new connection, currently in state init
2022-01-06 22:33:15.883465 (ThreadPoolExecutor-1_0): 22:33:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:33:15.902464 (ThreadPoolExecutor-1_0): 22:33:15  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:33:15.902573 (ThreadPoolExecutor-1_0): 22:33:15  Using redshift connection "dev.information_schema"
2022-01-06 22:33:15.902648 (ThreadPoolExecutor-1_0): 22:33:15  On dev.information_schema: 
    

    with late_binding as (
      select
        'dev'::varchar as table_database,
        table_schema,
        table_name,
        'LATE BINDING VIEW'::varchar as table_type,
        null::text as table_comment,

        column_name,
        column_index,
        column_type,
        null::text as column_comment
      from pg_get_late_binding_view_cols()
        cols(table_schema name, table_name name, column_name name,
             column_type varchar,
             column_index int)
        order by "column_index"
    ),

    early_binding as (
        select
            'dev'::varchar as table_database,
            sch.nspname as table_schema,
            tbl.relname as table_name,
            case tbl.relkind
                when 'v' then 'VIEW'
                else 'BASE TABLE'
            end as table_type,
            tbl_desc.description as table_comment,
            col.attname as column_name,
            col.attnum as column_index,
            pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
            col_desc.description as column_comment

        from pg_catalog.pg_namespace sch
        join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
        join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
        left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
        left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
        where (upper(sch.nspname) = upper('dbt_nobodozie'))
            and tbl.relkind in ('r', 'v', 'f', 'p')
            and col.attnum > 0
            and not col.attisdropped
    ),

    table_owners as (

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            tablename as table_name,
            tableowner as table_owner

        from pg_tables

        union all

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            viewname as table_name,
            viewowner as table_owner

        from pg_views

    ),

    unioned as (

        select *
        from early_binding

        union all

        select *
        from late_binding

    )

    select *,
        table_database || '.' || table_schema || '.' || table_name as table_id

    from unioned
    join table_owners using (table_database, table_schema, table_name)

    where (upper(table_schema) = upper('dbt_nobodozie'))

    order by "column_index"
2022-01-06 22:33:15.959776 (ThreadPoolExecutor-1_0): 22:33:15  SQL status: SELECT in 0.06 seconds
2022-01-06 22:33:15.963548 (ThreadPoolExecutor-1_0): 22:33:15  Using redshift connection "dev.information_schema"
2022-01-06 22:33:15.963643 (ThreadPoolExecutor-1_0): 22:33:15  On dev.information_schema: select has_table_privilege(current_user, 'svv_table_info', 'SELECT') as can_select
2022-01-06 22:33:15.965995 (ThreadPoolExecutor-1_0): 22:33:15  SQL status: SELECT in 0.0 seconds
2022-01-06 22:33:15.969828 (ThreadPoolExecutor-1_0): 22:33:15  Using redshift connection "dev.information_schema"
2022-01-06 22:33:15.969922 (ThreadPoolExecutor-1_0): 22:33:15  On dev.information_schema: select
        "database" || '.' || "schema" || '.' || "table" as table_id,

        'Encoded'::text as "stats:encoded:label",
        encoded as "stats:encoded:value",
        'Indicates whether any column in the table has compression encoding defined.'::text as "stats:encoded:description",
        true as "stats:encoded:include",

        'Dist Style' as "stats:diststyle:label",
        diststyle as "stats:diststyle:value",
        'Distribution style or distribution key column, if key distribution is defined.'::text as "stats:diststyle:description",
        true as "stats:diststyle:include",

        'Sort Key 1' as "stats:sortkey1:label",
        -- handle 0xFF byte in response for interleaved sort styles
        case
            when sortkey1 like 'INTERLEAVED%' then 'INTERLEAVED'::text
            else sortkey1
        end as "stats:sortkey1:value",
        'First column in the sort key.'::text as "stats:sortkey1:description",
        (sortkey1 is not null) as "stats:sortkey1:include",

        'Max Varchar' as "stats:max_varchar:label",
        max_varchar as "stats:max_varchar:value",
        'Size of the largest column that uses a VARCHAR data type.'::text as "stats:max_varchar:description",
        true as "stats:max_varchar:include",

        -- exclude this, as the data is strangely returned with null-byte characters
        'Sort Key 1 Encoding' as "stats:sortkey1_enc:label",
        sortkey1_enc as "stats:sortkey1_enc:value",
        'Compression encoding of the first column in the sort key.' as "stats:sortkey1_enc:description",
        false as "stats:sortkey1_enc:include",

        '# Sort Keys' as "stats:sortkey_num:label",
        sortkey_num as "stats:sortkey_num:value",
        'Number of columns defined as sort keys.' as "stats:sortkey_num:description",
        (sortkey_num > 0) as "stats:sortkey_num:include",

        'Approximate Size' as "stats:size:label",
        size * 1000000 as "stats:size:value",
        'Approximate size of the table, calculated from a count of 1MB blocks'::text as "stats:size:description",
        true as "stats:size:include",

        'Disk Utilization' as "stats:pct_used:label",
        pct_used / 100.0 as "stats:pct_used:value",
        'Percent of available space that is used by the table.'::text as "stats:pct_used:description",
        true as "stats:pct_used:include",

        'Unsorted %' as "stats:unsorted:label",
        unsorted / 100.0 as "stats:unsorted:value",
        'Percent of unsorted rows in the table.'::text as "stats:unsorted:description",
        (unsorted is not null) as "stats:unsorted:include",

        'Stats Off' as "stats:stats_off:label",
        stats_off as "stats:stats_off:value",
        'Number that indicates how stale the table statistics are; 0 is current, 100 is out of date.'::text as "stats:stats_off:description",
        true as "stats:stats_off:include",

        'Approximate Row Count' as "stats:rows:label",
        tbl_rows as "stats:rows:value",
        'Approximate number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed.'::text as "stats:rows:description",
        true as "stats:rows:include",

        'Sort Key Skew' as "stats:skew_sortkey1:label",
        skew_sortkey1 as "stats:skew_sortkey1:value",
        'Ratio of the size of the largest non-sort key column to the size of the first column of the sort key.'::text as "stats:skew_sortkey1:description",
        (skew_sortkey1 is not null) as "stats:skew_sortkey1:include",

        'Skew Rows' as "stats:skew_rows:label",
        skew_rows as "stats:skew_rows:value",
        'Ratio of the number of rows in the slice with the most rows to the number of rows in the slice with the fewest rows.'::text as "stats:skew_rows:description",
        (skew_rows is not null) as "stats:skew_rows:include"

    from svv_table_info
    where (upper(schema) = upper('dbt_nobodozie'))
2022-01-06 22:33:16.607822 (ThreadPoolExecutor-1_0): 22:33:16  SQL status: SELECT in 0.64 seconds
2022-01-06 22:33:16.619509 (ThreadPoolExecutor-1_0): 22:33:16  On dev.information_schema: ROLLBACK
2022-01-06 22:33:16.621843 (ThreadPoolExecutor-1_0): 22:33:16  On dev.information_schema: Close
2022-01-06 22:33:16.706307 (MainThread): 22:33:16  Catalog written to /usr/src/develop/user-52374/environment-57794/repository-46678/target/catalog.json
2022-01-06 22:33:17.511083 (Thread-1017): handling poll request
2022-01-06 22:33:17.511451 (Thread-1017): 22:33:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe84670790>]}
2022-01-06 22:33:17.512527 (Thread-1017): sending response (<Response 20768 bytes [200 OK]>) to 10.0.34.75
2022-01-06 22:33:18.254117 (Thread-1018): handling status request
2022-01-06 22:33:18.254492 (Thread-1018): 22:33:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe84670940>]}
2022-01-06 22:33:18.255056 (Thread-1018): sending response (<Response 1575 bytes [200 OK]>) to 10.0.16.23
2022-01-06 22:33:18.299507 (Thread-1019): handling status request
2022-01-06 22:33:18.300120 (Thread-1019): 22:33:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe84670d00>]}
2022-01-06 22:33:18.300644 (Thread-1020): handling status request
2022-01-06 22:33:18.301170 (Thread-1019): sending response (<Response 1575 bytes [200 OK]>) to 10.0.15.38
2022-01-06 22:33:18.301518 (Thread-1020): 22:33:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe84661580>]}
2022-01-06 22:33:18.302185 (Thread-1020): sending response (<Response 1575 bytes [200 OK]>) to 10.0.8.124
2022-01-06 22:39:54.490550 (Thread-1021): 22:39:54  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 22:39:54.492321 (Thread-1021): 22:39:54  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 22:39:54.497372 (Thread-1021): 22:39:54  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe845ab490>]}
2022-01-06 22:39:55.094820 (Thread-1022): handling status request
2022-01-06 22:39:55.095191 (Thread-1022): 22:39:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe847d98b0>]}
2022-01-06 22:39:55.119011 (Thread-1022): sending response (<Response 1247 bytes [200 OK]>) to 10.0.40.103
2022-01-06 22:39:55.179258 (Thread-1023): handling status request
2022-01-06 22:39:55.179523 (Thread-1023): 22:39:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe845a5df0>]}
2022-01-06 22:39:55.179929 (Thread-1023): sending response (<Response 1247 bytes [200 OK]>) to 10.0.40.103
2022-01-06 22:39:57.601918 (Thread-1024): handling status request
2022-01-06 22:39:57.602306 (Thread-1024): 22:39:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe846619a0>]}
2022-01-06 22:39:57.602781 (Thread-1024): sending response (<Response 1247 bytes [200 OK]>) to 10.0.9.169
2022-01-06 22:39:57.820488 (Thread-1025): handling status request
2022-01-06 22:39:57.820742 (Thread-1025): 22:39:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe84614370>]}
2022-01-06 22:39:57.821140 (Thread-1025): sending response (<Response 1247 bytes [200 OK]>) to 10.0.14.166
2022-01-06 22:39:57.909586 (Thread-1026): handling docs.generate request
2022-01-06 22:39:57.909855 (Thread-1026): 22:39:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe84614bb0>]}
2022-01-06 22:39:59.944776 (Thread-1026): sending response (<Response 138 bytes [200 OK]>) to 10.0.7.0
2022-01-06 22:39:59.968008 (MainThread): 22:39:59  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '41bcfb01-69a7-46aa-a438-270ffce285d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0564db3820>]}
2022-01-06 22:39:59.968280 (MainThread): 22:39:59  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:39:59.969763 (MainThread): 22:39:59  
2022-01-06 22:39:59.969916 (MainThread): 22:39:59  Acquiring new redshift connection "master"
2022-01-06 22:39:59.970667 (ThreadPoolExecutor-0_0): 22:39:59  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:39:59.981966 (ThreadPoolExecutor-0_0): 22:39:59  Parsing macros/catalog.sql
2022-01-06 22:39:59.995567 (ThreadPoolExecutor-0_0): 22:39:59  Parsing macros/adapters.sql
2022-01-06 22:40:00.022631 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/relations.sql
2022-01-06 22:40:00.023326 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 22:40:00.024246 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/catalog.sql
2022-01-06 22:40:00.026469 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/adapters.sql
2022-01-06 22:40:00.047368 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/relations.sql
2022-01-06 22:40:00.048738 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 22:40:00.051626 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-06 22:40:00.053167 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-06 22:40:00.054813 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-06 22:40:00.057413 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-06 22:40:00.058843 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/generic_test_sql/not_null.sql
2022-01-06 22:40:00.059525 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/generic_test_sql/relationships.sql
2022-01-06 22:40:00.060477 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/generic_test_sql/unique.sql
2022-01-06 22:40:00.061295 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/configs.sql
2022-01-06 22:40:00.063612 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/hooks.sql
2022-01-06 22:40:00.067416 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/snapshots/strategies.sql
2022-01-06 22:40:00.083416 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-06 22:40:00.085116 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-06 22:40:00.096109 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/snapshots/helpers.sql
2022-01-06 22:40:00.106691 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/seeds/seed.sql
2022-01-06 22:40:00.112494 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/seeds/helpers.sql
2022-01-06 22:40:00.128211 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-06 22:40:00.130588 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/models/view/view.sql
2022-01-06 22:40:00.137236 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-06 22:40:00.139894 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/models/view/helpers.sql
2022-01-06 22:40:00.141317 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/models/table/table.sql
2022-01-06 22:40:00.148247 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-06 22:40:00.151225 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/models/incremental/merge.sql
2022-01-06 22:40:00.162033 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-06 22:40:00.177277 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-06 22:40:00.181675 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-06 22:40:00.191316 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-06 22:40:00.192889 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/tests/test.sql
2022-01-06 22:40:00.197193 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/tests/where_subquery.sql
2022-01-06 22:40:00.199069 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/materializations/tests/helpers.sql
2022-01-06 22:40:00.200950 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/etc/statement.sql
2022-01-06 22:40:00.205280 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/etc/datetime.sql
2022-01-06 22:40:00.213376 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/adapters/indexes.sql
2022-01-06 22:40:00.216046 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/adapters/persist_docs.sql
2022-01-06 22:40:00.220359 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/adapters/freshness.sql
2022-01-06 22:40:00.223756 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/adapters/relation.sql
2022-01-06 22:40:00.232957 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/adapters/metadata.sql
2022-01-06 22:40:00.239988 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/adapters/columns.sql
2022-01-06 22:40:00.249459 (ThreadPoolExecutor-0_0): 22:40:00  Parsing macros/adapters/schema.sql
2022-01-06 22:40:00.261050 (ThreadPoolExecutor-0_0): 22:40:00  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:40:00.261166 (ThreadPoolExecutor-0_0): 22:40:00  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 22:40:00.261270 (ThreadPoolExecutor-0_0): 22:40:00  Opening a new connection, currently in state init
2022-01-06 22:40:00.261352 (ThreadPoolExecutor-0_0): 22:40:00  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:40:00.281264 (Thread-1027): handling poll request
2022-01-06 22:40:00.280537 (ThreadPoolExecutor-0_0): 22:40:00  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:40:00.281819 (Thread-1027): 22:40:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe845c1850>]}
2022-01-06 22:40:00.280648 (ThreadPoolExecutor-0_0): 22:40:00  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 22:40:00.283304 (Thread-1027): sending response (<Response 17755 bytes [200 OK]>) to 10.0.28.107
2022-01-06 22:40:00.280723 (ThreadPoolExecutor-0_0): 22:40:00  On list_dev_dbt_nobodozie: select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 22:40:00.291973 (ThreadPoolExecutor-0_0): 22:40:00  SQL status: SELECT in 0.01 seconds
2022-01-06 22:40:00.293107 (ThreadPoolExecutor-0_0): 22:40:00  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 22:40:00.294985 (ThreadPoolExecutor-0_0): 22:40:00  On list_dev_dbt_nobodozie: Close
2022-01-06 22:40:00.298543 (MainThread): 22:40:00  Using redshift connection "master"
2022-01-06 22:40:00.298656 (MainThread): 22:40:00  On master: BEGIN
2022-01-06 22:40:00.298737 (MainThread): 22:40:00  Opening a new connection, currently in state init
2022-01-06 22:40:00.298812 (MainThread): 22:40:00  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:40:00.322516 (MainThread): 22:40:00  SQL status: BEGIN in 0.02 seconds
2022-01-06 22:40:00.322626 (MainThread): 22:40:00  Using redshift connection "master"
2022-01-06 22:40:00.322701 (MainThread): 22:40:00  On master: with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 22:40:00.351731 (MainThread): 22:40:00  SQL status: SELECT in 0.03 seconds
2022-01-06 22:40:00.352832 (MainThread): 22:40:00  On master: ROLLBACK
2022-01-06 22:40:00.354998 (MainThread): 22:40:00  On master: Close
2022-01-06 22:40:00.355260 (MainThread): 22:40:00  Concurrency: 4 threads (target='default')
2022-01-06 22:40:00.355370 (MainThread): 22:40:00  
2022-01-06 22:40:00.357511 (Thread-1): 22:40:00  Began running node model.jaffel_shop.stg_customers
2022-01-06 22:40:00.357680 (Thread-1): 22:40:00  Acquiring new redshift connection "model.jaffel_shop.stg_customers"
2022-01-06 22:40:00.357768 (Thread-1): 22:40:00  Began compiling node model.jaffel_shop.stg_customers
2022-01-06 22:40:00.357852 (Thread-1): 22:40:00  Compiling model.jaffel_shop.stg_customers
2022-01-06 22:40:00.359001 (Thread-1): 22:40:00  Writing injected SQL for node "model.jaffel_shop.stg_customers"
2022-01-06 22:40:00.359211 (Thread-2): 22:40:00  Began running node model.jaffel_shop.stg_orders
2022-01-06 22:40:00.359390 (Thread-2): 22:40:00  Acquiring new redshift connection "model.jaffel_shop.stg_orders"
2022-01-06 22:40:00.359472 (Thread-2): 22:40:00  Began compiling node model.jaffel_shop.stg_orders
2022-01-06 22:40:00.359550 (Thread-2): 22:40:00  Compiling model.jaffel_shop.stg_orders
2022-01-06 22:40:00.360658 (Thread-2): 22:40:00  Writing injected SQL for node "model.jaffel_shop.stg_orders"
2022-01-06 22:40:00.360986 (Thread-3): 22:40:00  Began running node model.jaffel_shop.stg_payments
2022-01-06 22:40:00.361152 (Thread-3): 22:40:00  Acquiring new redshift connection "model.jaffel_shop.stg_payments"
2022-01-06 22:40:00.361255 (Thread-3): 22:40:00  Began compiling node model.jaffel_shop.stg_payments
2022-01-06 22:40:00.361340 (Thread-3): 22:40:00  Compiling model.jaffel_shop.stg_payments
2022-01-06 22:40:00.362387 (Thread-3): 22:40:00  Writing injected SQL for node "model.jaffel_shop.stg_payments"
2022-01-06 22:40:00.374215 (Thread-1): 22:40:00  finished collecting timing info
2022-01-06 22:40:00.374348 (Thread-1): 22:40:00  Began executing node model.jaffel_shop.stg_customers
2022-01-06 22:40:00.374443 (Thread-1): 22:40:00  finished collecting timing info
2022-01-06 22:40:00.374590 (Thread-1): 22:40:00  Finished running node model.jaffel_shop.stg_customers
2022-01-06 22:40:00.376231 (Thread-3): 22:40:00  finished collecting timing info
2022-01-06 22:40:00.376342 (Thread-3): 22:40:00  Began executing node model.jaffel_shop.stg_payments
2022-01-06 22:40:00.376426 (Thread-3): 22:40:00  finished collecting timing info
2022-01-06 22:40:00.376545 (Thread-3): 22:40:00  Finished running node model.jaffel_shop.stg_payments
2022-01-06 22:40:00.376760 (Thread-2): 22:40:00  finished collecting timing info
2022-01-06 22:40:00.376886 (Thread-2): 22:40:00  Began executing node model.jaffel_shop.stg_orders
2022-01-06 22:40:00.376973 (Thread-2): 22:40:00  finished collecting timing info
2022-01-06 22:40:00.377100 (Thread-2): 22:40:00  Finished running node model.jaffel_shop.stg_orders
2022-01-06 22:40:00.377897 (Thread-4): 22:40:00  Began running node model.jaffel_shop.fct_orders
2022-01-06 22:40:00.378067 (Thread-4): 22:40:00  Acquiring new redshift connection "model.jaffel_shop.fct_orders"
2022-01-06 22:40:00.378148 (Thread-4): 22:40:00  Began compiling node model.jaffel_shop.fct_orders
2022-01-06 22:40:00.378224 (Thread-4): 22:40:00  Compiling model.jaffel_shop.fct_orders
2022-01-06 22:40:00.380409 (Thread-4): 22:40:00  Writing injected SQL for node "model.jaffel_shop.fct_orders"
2022-01-06 22:40:00.394317 (Thread-4): 22:40:00  finished collecting timing info
2022-01-06 22:40:00.394448 (Thread-4): 22:40:00  Began executing node model.jaffel_shop.fct_orders
2022-01-06 22:40:00.394539 (Thread-4): 22:40:00  finished collecting timing info
2022-01-06 22:40:00.394663 (Thread-4): 22:40:00  Finished running node model.jaffel_shop.fct_orders
2022-01-06 22:40:00.395251 (Thread-3): 22:40:00  Began running node model.jaffel_shop.dim_customers
2022-01-06 22:40:00.395387 (Thread-3): 22:40:00  Acquiring new redshift connection "model.jaffel_shop.dim_customers"
2022-01-06 22:40:00.395462 (Thread-3): 22:40:00  Began compiling node model.jaffel_shop.dim_customers
2022-01-06 22:40:00.395533 (Thread-3): 22:40:00  Compiling model.jaffel_shop.dim_customers
2022-01-06 22:40:00.398232 (Thread-3): 22:40:00  Writing injected SQL for node "model.jaffel_shop.dim_customers"
2022-01-06 22:40:00.414055 (Thread-3): 22:40:00  finished collecting timing info
2022-01-06 22:40:00.414179 (Thread-3): 22:40:00  Began executing node model.jaffel_shop.dim_customers
2022-01-06 22:40:00.414269 (Thread-3): 22:40:00  finished collecting timing info
2022-01-06 22:40:00.414392 (Thread-3): 22:40:00  Finished running node model.jaffel_shop.dim_customers
2022-01-06 22:40:00.415353 (MainThread): 22:40:00  Connection 'master' was properly closed.
2022-01-06 22:40:00.415461 (MainThread): 22:40:00  Connection 'model.jaffel_shop.stg_customers' was properly closed.
2022-01-06 22:40:00.415531 (MainThread): 22:40:00  Connection 'model.jaffel_shop.stg_orders' was properly closed.
2022-01-06 22:40:00.415614 (MainThread): 22:40:00  Connection 'model.jaffel_shop.dim_customers' was properly closed.
2022-01-06 22:40:00.415679 (MainThread): 22:40:00  Connection 'model.jaffel_shop.fct_orders' was properly closed.
2022-01-06 22:40:00.471569 (MainThread): 22:40:00  Done.
2022-01-06 22:40:00.515713 (MainThread): 22:40:00  Acquiring new redshift connection "generate_catalog"
2022-01-06 22:40:00.515823 (MainThread): 22:40:00  Building catalog
2022-01-06 22:40:00.516994 (ThreadPoolExecutor-1_0): 22:40:00  Acquiring new redshift connection "dev.information_schema"
2022-01-06 22:40:00.527335 (ThreadPoolExecutor-1_0): 22:40:00  Using redshift connection "dev.information_schema"
2022-01-06 22:40:00.527435 (ThreadPoolExecutor-1_0): 22:40:00  On dev.information_schema: BEGIN
2022-01-06 22:40:00.527515 (ThreadPoolExecutor-1_0): 22:40:00  Opening a new connection, currently in state init
2022-01-06 22:40:00.527590 (ThreadPoolExecutor-1_0): 22:40:00  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:40:00.842941 (ThreadPoolExecutor-1_0): 22:40:00  SQL status: BEGIN in 0.32 seconds
2022-01-06 22:40:00.843167 (ThreadPoolExecutor-1_0): 22:40:00  Using redshift connection "dev.information_schema"
2022-01-06 22:40:00.843290 (ThreadPoolExecutor-1_0): 22:40:00  On dev.information_schema: 
    

    with late_binding as (
      select
        'dev'::varchar as table_database,
        table_schema,
        table_name,
        'LATE BINDING VIEW'::varchar as table_type,
        null::text as table_comment,

        column_name,
        column_index,
        column_type,
        null::text as column_comment
      from pg_get_late_binding_view_cols()
        cols(table_schema name, table_name name, column_name name,
             column_type varchar,
             column_index int)
        order by "column_index"
    ),

    early_binding as (
        select
            'dev'::varchar as table_database,
            sch.nspname as table_schema,
            tbl.relname as table_name,
            case tbl.relkind
                when 'v' then 'VIEW'
                else 'BASE TABLE'
            end as table_type,
            tbl_desc.description as table_comment,
            col.attname as column_name,
            col.attnum as column_index,
            pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
            col_desc.description as column_comment

        from pg_catalog.pg_namespace sch
        join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
        join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
        left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
        left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
        where (upper(sch.nspname) = upper('dbt_nobodozie'))
            and tbl.relkind in ('r', 'v', 'f', 'p')
            and col.attnum > 0
            and not col.attisdropped
    ),

    table_owners as (

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            tablename as table_name,
            tableowner as table_owner

        from pg_tables

        union all

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            viewname as table_name,
            viewowner as table_owner

        from pg_views

    ),

    unioned as (

        select *
        from early_binding

        union all

        select *
        from late_binding

    )

    select *,
        table_database || '.' || table_schema || '.' || table_name as table_id

    from unioned
    join table_owners using (table_database, table_schema, table_name)

    where (upper(table_schema) = upper('dbt_nobodozie'))

    order by "column_index"
2022-01-06 22:40:00.900554 (ThreadPoolExecutor-1_0): 22:40:00  SQL status: SELECT in 0.06 seconds
2022-01-06 22:40:00.905116 (ThreadPoolExecutor-1_0): 22:40:00  Using redshift connection "dev.information_schema"
2022-01-06 22:40:00.905260 (ThreadPoolExecutor-1_0): 22:40:00  On dev.information_schema: select has_table_privilege(current_user, 'svv_table_info', 'SELECT') as can_select
2022-01-06 22:40:00.907605 (ThreadPoolExecutor-1_0): 22:40:00  SQL status: SELECT in 0.0 seconds
2022-01-06 22:40:00.911496 (ThreadPoolExecutor-1_0): 22:40:00  Using redshift connection "dev.information_schema"
2022-01-06 22:40:00.911596 (ThreadPoolExecutor-1_0): 22:40:00  On dev.information_schema: select
        "database" || '.' || "schema" || '.' || "table" as table_id,

        'Encoded'::text as "stats:encoded:label",
        encoded as "stats:encoded:value",
        'Indicates whether any column in the table has compression encoding defined.'::text as "stats:encoded:description",
        true as "stats:encoded:include",

        'Dist Style' as "stats:diststyle:label",
        diststyle as "stats:diststyle:value",
        'Distribution style or distribution key column, if key distribution is defined.'::text as "stats:diststyle:description",
        true as "stats:diststyle:include",

        'Sort Key 1' as "stats:sortkey1:label",
        -- handle 0xFF byte in response for interleaved sort styles
        case
            when sortkey1 like 'INTERLEAVED%' then 'INTERLEAVED'::text
            else sortkey1
        end as "stats:sortkey1:value",
        'First column in the sort key.'::text as "stats:sortkey1:description",
        (sortkey1 is not null) as "stats:sortkey1:include",

        'Max Varchar' as "stats:max_varchar:label",
        max_varchar as "stats:max_varchar:value",
        'Size of the largest column that uses a VARCHAR data type.'::text as "stats:max_varchar:description",
        true as "stats:max_varchar:include",

        -- exclude this, as the data is strangely returned with null-byte characters
        'Sort Key 1 Encoding' as "stats:sortkey1_enc:label",
        sortkey1_enc as "stats:sortkey1_enc:value",
        'Compression encoding of the first column in the sort key.' as "stats:sortkey1_enc:description",
        false as "stats:sortkey1_enc:include",

        '# Sort Keys' as "stats:sortkey_num:label",
        sortkey_num as "stats:sortkey_num:value",
        'Number of columns defined as sort keys.' as "stats:sortkey_num:description",
        (sortkey_num > 0) as "stats:sortkey_num:include",

        'Approximate Size' as "stats:size:label",
        size * 1000000 as "stats:size:value",
        'Approximate size of the table, calculated from a count of 1MB blocks'::text as "stats:size:description",
        true as "stats:size:include",

        'Disk Utilization' as "stats:pct_used:label",
        pct_used / 100.0 as "stats:pct_used:value",
        'Percent of available space that is used by the table.'::text as "stats:pct_used:description",
        true as "stats:pct_used:include",

        'Unsorted %' as "stats:unsorted:label",
        unsorted / 100.0 as "stats:unsorted:value",
        'Percent of unsorted rows in the table.'::text as "stats:unsorted:description",
        (unsorted is not null) as "stats:unsorted:include",

        'Stats Off' as "stats:stats_off:label",
        stats_off as "stats:stats_off:value",
        'Number that indicates how stale the table statistics are; 0 is current, 100 is out of date.'::text as "stats:stats_off:description",
        true as "stats:stats_off:include",

        'Approximate Row Count' as "stats:rows:label",
        tbl_rows as "stats:rows:value",
        'Approximate number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed.'::text as "stats:rows:description",
        true as "stats:rows:include",

        'Sort Key Skew' as "stats:skew_sortkey1:label",
        skew_sortkey1 as "stats:skew_sortkey1:value",
        'Ratio of the size of the largest non-sort key column to the size of the first column of the sort key.'::text as "stats:skew_sortkey1:description",
        (skew_sortkey1 is not null) as "stats:skew_sortkey1:include",

        'Skew Rows' as "stats:skew_rows:label",
        skew_rows as "stats:skew_rows:value",
        'Ratio of the number of rows in the slice with the most rows to the number of rows in the slice with the fewest rows.'::text as "stats:skew_rows:description",
        (skew_rows is not null) as "stats:skew_rows:include"

    from svv_table_info
    where (upper(schema) = upper('dbt_nobodozie'))
2022-01-06 22:40:01.588785 (ThreadPoolExecutor-1_0): 22:40:01  SQL status: SELECT in 0.68 seconds
2022-01-06 22:40:01.600560 (ThreadPoolExecutor-1_0): 22:40:01  On dev.information_schema: ROLLBACK
2022-01-06 22:40:01.602733 (ThreadPoolExecutor-1_0): 22:40:01  On dev.information_schema: Close
2022-01-06 22:40:01.687599 (MainThread): 22:40:01  Catalog written to /usr/src/develop/user-52374/environment-57794/repository-46678/target/catalog.json
2022-01-06 22:40:01.744068 (Thread-1028): handling poll request
2022-01-06 22:40:01.744437 (Thread-1028): 22:40:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe845b5cd0>]}
2022-01-06 22:40:01.745883 (Thread-1028): sending response (<Response 40610 bytes [200 OK]>) to 10.0.40.103
2022-01-06 22:40:03.073361 (Thread-1029): handling poll request
2022-01-06 22:40:03.073741 (Thread-1029): 22:40:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe845b5c70>]}
2022-01-06 22:40:03.074534 (Thread-1029): sending response (<Response 4514 bytes [200 OK]>) to 10.0.34.75
2022-01-06 22:40:03.341870 (Thread-1030): 22:40:03  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 22:40:03.342091 (Thread-1030): 22:40:03  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 22:40:03.347661 (Thread-1030): 22:40:03  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe844ddfa0>]}
2022-01-06 22:40:03.666426 (Thread-1031): handling status request
2022-01-06 22:40:03.666806 (Thread-1031): 22:40:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe845298e0>]}
2022-01-06 22:40:03.667305 (Thread-1031): sending response (<Response 1247 bytes [200 OK]>) to 10.0.9.169
2022-01-06 22:40:03.704714 (Thread-1032): handling status request
2022-01-06 22:40:03.705060 (Thread-1032): 22:40:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe845295b0>]}
2022-01-06 22:40:03.705549 (Thread-1032): sending response (<Response 1247 bytes [200 OK]>) to 10.0.34.75
2022-01-06 22:40:03.856726 (Thread-1033): handling status request
2022-01-06 22:40:03.857254 (Thread-1033): 22:40:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe84529340>]}
2022-01-06 22:40:03.857916 (Thread-1033): sending response (<Response 1247 bytes [200 OK]>) to 10.0.29.201
2022-01-06 22:40:03.862010 (Thread-1034): handling status request
2022-01-06 22:40:03.862380 (Thread-1034): 22:40:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe84529100>]}
2022-01-06 22:40:03.862801 (Thread-1034): sending response (<Response 1247 bytes [200 OK]>) to 10.0.13.200
2022-01-06 22:40:04.763940 (Thread-1035): handling status request
2022-01-06 22:40:04.764342 (Thread-1035): 22:40:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe845a9460>]}
2022-01-06 22:40:04.764920 (Thread-1035): sending response (<Response 1247 bytes [200 OK]>) to 10.0.25.198
2022-01-06 22:40:05.036812 (Thread-1036): handling status request
2022-01-06 22:40:05.037193 (Thread-1036): 22:40:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe845a96a0>]}
2022-01-06 22:40:05.037703 (Thread-1036): sending response (<Response 1247 bytes [200 OK]>) to 10.0.8.124
2022-01-06 22:40:05.379401 (Thread-1037): handling run_sql request
2022-01-06 22:40:05.379726 (Thread-1037): 22:40:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe845a9b20>]}
2022-01-06 22:40:07.414245 (Thread-1037): sending response (<Response 138 bytes [200 OK]>) to 10.0.27.183
2022-01-06 22:40:07.439054 (MainThread): 22:40:07  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3804d898-5553-48eb-9415-dbd8419f9077', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f715e9d8760>]}
2022-01-06 22:40:07.439592 (MainThread): 22:40:07  Found 5 models, 0 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 22:40:07.440150 (Thread-1): 22:40:07  Acquiring new redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:40:07.440281 (Thread-1): 22:40:07  Began compiling node rpc.jaffel_shop.request
2022-01-06 22:40:07.440378 (Thread-1): 22:40:07  Compiling rpc.jaffel_shop.request
2022-01-06 22:40:07.442659 (Thread-1): 22:40:07  finished collecting timing info
2022-01-06 22:40:07.442781 (Thread-1): 22:40:07  Began executing node rpc.jaffel_shop.request
2022-01-06 22:40:07.442874 (Thread-1): 22:40:07  Using redshift connection "rpc.jaffel_shop.request"
2022-01-06 22:40:07.442947 (Thread-1): 22:40:07  On rpc.jaffel_shop.request: with orders as (

    select * from "dev"."dbt_nobodozie"."stg_orders"

),

payment as (

    select * from "dev"."dbt_nobodozie"."stg_payments"
),


order_payments as (
    select
        order_id,
        sum(case when status = 'success' then amount end ) as amount
    from payment
    group by 1
),



final as (

    select
        orders.order_id as order_id,
        orders.customer_id,
        orders.order_date,
        coalesce(order_payments.amount, 0) as amount

    from orders
    left join order_payments using (order_id)
   
)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 22:40:07.443022 (Thread-1): 22:40:07  Opening a new connection, currently in state init
2022-01-06 22:40:07.443098 (Thread-1): 22:40:07  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 22:40:07.952599 (Thread-1038): handling poll request
2022-01-06 22:40:07.953068 (Thread-1038): 22:40:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe84543160>]}
2022-01-06 22:40:07.954026 (Thread-1038): sending response (<Response 4627 bytes [200 OK]>) to 10.0.8.124
2022-01-06 22:40:08.575889 (Thread-1): 22:40:08  SQL status: SELECT in 1.13 seconds
2022-01-06 22:40:08.578912 (Thread-1): 22:40:08  finished collecting timing info
2022-01-06 22:40:08.579088 (Thread-1): 22:40:08  On rpc.jaffel_shop.request: Close
2022-01-06 22:40:09.274139 (Thread-1039): handling poll request
2022-01-06 22:40:09.274518 (Thread-1039): 22:40:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe844dea60>]}
2022-01-06 22:40:09.275868 (Thread-1039): sending response (<Response 9095 bytes [200 OK]>) to 10.0.14.166
2022-01-06 22:47:02.802224 (Thread-1040): handling status request
2022-01-06 22:47:02.803995 (Thread-1040): 22:47:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efe844de640>]}
2022-01-06 22:47:02.804491 (Thread-1040): sending response (<Response 1247 bytes [200 OK]>) to 10.0.16.23
