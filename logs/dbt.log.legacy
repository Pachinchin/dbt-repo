2022-01-05 08:51:08.011330 (MainThread): Running with dbt=1.0.1
2022-01-05 08:51:08.120177 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-05 08:51:08.136975 (MainThread): Tracking: tracking
2022-01-05 08:51:08.146317 (Thread-12): 08:51:08  Partial parse save file not found. Starting full parse.
2022-01-05 08:51:08.146870 (Thread-12): 08:51:08  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9045bf70>]}
2022-01-05 08:51:08.148317 (MainThread): 08:51:08  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7da4ee1be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9045bf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d903c2430>]}
2022-01-05 08:51:08.148595 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-05 08:51:08.148841 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-05 08:51:08.148974 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-05 08:51:08.177208 (Thread-12): 08:51:08  Parsing macros/catalog.sql
2022-01-05 08:51:08.190330 (Thread-12): 08:51:08  Parsing macros/adapters.sql
2022-01-05 08:51:08.218041 (Thread-12): 08:51:08  Parsing macros/relations.sql
2022-01-05 08:51:08.218589 (Thread-12): 08:51:08  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 08:51:08.219192 (Thread-12): 08:51:08  Parsing macros/catalog.sql
2022-01-05 08:51:08.221235 (Thread-12): 08:51:08  Parsing macros/adapters.sql
2022-01-05 08:51:08.242320 (Thread-12): 08:51:08  Parsing macros/relations.sql
2022-01-05 08:51:08.243557 (Thread-12): 08:51:08  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 08:51:08.245127 (Thread-12): 08:51:08  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-05 08:51:08.246577 (Thread-12): 08:51:08  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-05 08:51:08.248079 (Thread-12): 08:51:08  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-05 08:51:08.250469 (Thread-12): 08:51:08  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-05 08:51:08.251790 (Thread-12): 08:51:08  Parsing macros/generic_test_sql/not_null.sql
2022-01-05 08:51:08.252341 (Thread-12): 08:51:08  Parsing macros/generic_test_sql/relationships.sql
2022-01-05 08:51:08.253171 (Thread-12): 08:51:08  Parsing macros/generic_test_sql/unique.sql
2022-01-05 08:51:08.253896 (Thread-12): 08:51:08  Parsing macros/materializations/configs.sql
2022-01-05 08:51:08.256180 (Thread-12): 08:51:08  Parsing macros/materializations/hooks.sql
2022-01-05 08:51:08.260026 (Thread-12): 08:51:08  Parsing macros/materializations/snapshots/strategies.sql
2022-01-05 08:51:08.276370 (Thread-12): 08:51:08  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-05 08:51:08.278102 (Thread-12): 08:51:08  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-05 08:51:08.289092 (Thread-12): 08:51:08  Parsing macros/materializations/snapshots/helpers.sql
2022-01-05 08:51:08.299645 (Thread-12): 08:51:08  Parsing macros/materializations/seeds/seed.sql
2022-01-05 08:51:08.305575 (Thread-12): 08:51:08  Parsing macros/materializations/seeds/helpers.sql
2022-01-05 08:51:08.321519 (Thread-12): 08:51:08  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-05 08:51:08.323757 (Thread-12): 08:51:08  Parsing macros/materializations/models/view/view.sql
2022-01-05 08:51:08.330394 (Thread-12): 08:51:08  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-05 08:51:08.332952 (Thread-12): 08:51:08  Parsing macros/materializations/models/view/helpers.sql
2022-01-05 08:51:08.334258 (Thread-12): 08:51:08  Parsing macros/materializations/models/table/table.sql
2022-01-05 08:51:08.341177 (Thread-12): 08:51:08  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-05 08:51:08.344053 (Thread-12): 08:51:08  Parsing macros/materializations/models/incremental/merge.sql
2022-01-05 08:51:08.354876 (Thread-12): 08:51:08  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-05 08:51:08.369575 (Thread-12): 08:51:08  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-05 08:51:08.373951 (Thread-12): 08:51:08  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-05 08:51:08.384028 (Thread-12): 08:51:08  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-05 08:51:08.384949 (Thread-13): handling status request
2022-01-05 08:51:08.386552 (Thread-12): 08:51:08  Parsing macros/materializations/tests/test.sql
2022-01-05 08:51:08.386843 (Thread-13): 08:51:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9042ebe0>]}
2022-01-05 08:51:08.391133 (Thread-12): 08:51:08  Parsing macros/materializations/tests/where_subquery.sql
2022-01-05 08:51:08.391683 (Thread-13): sending response (<Response 185 bytes [200 OK]>) to 10.0.46.191
2022-01-05 08:51:08.393552 (Thread-12): 08:51:08  Parsing macros/materializations/tests/helpers.sql
2022-01-05 08:51:08.395827 (Thread-12): 08:51:08  Parsing macros/etc/statement.sql
2022-01-05 08:51:08.400347 (Thread-12): 08:51:08  Parsing macros/etc/datetime.sql
2022-01-05 08:51:08.408395 (Thread-12): 08:51:08  Parsing macros/adapters/indexes.sql
2022-01-05 08:51:08.411105 (Thread-12): 08:51:08  Parsing macros/adapters/persist_docs.sql
2022-01-05 08:51:08.415428 (Thread-12): 08:51:08  Parsing macros/adapters/freshness.sql
2022-01-05 08:51:08.418304 (Thread-12): 08:51:08  Parsing macros/adapters/relation.sql
2022-01-05 08:51:08.427537 (Thread-12): 08:51:08  Parsing macros/adapters/metadata.sql
2022-01-05 08:51:08.434440 (Thread-12): 08:51:08  Parsing macros/adapters/columns.sql
2022-01-05 08:51:08.444094 (Thread-12): 08:51:08  Parsing macros/adapters/schema.sql
2022-01-05 08:51:08.446260 (Thread-12): 08:51:08  Parsing tests/generic/builtin.sql
2022-01-05 08:51:08.563263 (Thread-14): handling status request
2022-01-05 08:51:08.583890 (Thread-14): 08:51:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d903a28e0>]}
2022-01-05 08:51:08.589446 (Thread-14): sending response (<Response 185 bytes [200 OK]>) to 10.0.40.203
2022-01-05 08:51:08.647813 (Thread-12): 08:51:08  1699: static parser successfully parsed example/my_second_dbt_model.sql
2022-01-05 08:51:08.659991 (Thread-12): 08:51:08  1699: static parser successfully parsed example/my_first_dbt_model.sql
2022-01-05 08:51:08.742064 (Thread-12): 08:51:08  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900f4520>]}
2022-01-05 08:51:09.755583 (Thread-15): handling status request
2022-01-05 08:51:09.755916 (Thread-15): 08:51:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d90108c40>]}
2022-01-05 08:51:09.756769 (Thread-15): sending response (<Response 15479 bytes [200 OK]>) to 10.0.46.191
2022-01-05 08:51:09.990366 (Thread-16): handling status request
2022-01-05 08:51:09.990688 (Thread-16): 08:51:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d904437c0>]}
2022-01-05 08:51:09.991516 (Thread-16): sending response (<Response 15479 bytes [200 OK]>) to 10.0.41.88
2022-01-05 08:51:59.578565 (Thread-17): handling status request
2022-01-05 08:51:59.580516 (Thread-17): 08:51:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900f45e0>]}
2022-01-05 08:51:59.581332 (Thread-17): sending response (<Response 15479 bytes [200 OK]>) to 10.0.28.79
2022-01-05 08:52:01.823634 (Thread-18): 08:52:01  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 08:52:01.823819 (Thread-18): 08:52:01  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 08:52:01.828713 (Thread-18): 08:52:01  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9006bb80>]}
2022-01-05 08:52:02.470383 (Thread-19): handling status request
2022-01-05 08:52:02.470708 (Thread-19): 08:52:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900812b0>]}
2022-01-05 08:52:02.471163 (Thread-19): sending response (<Response 1241 bytes [200 OK]>) to 10.0.8.202
2022-01-05 08:52:02.486184 (Thread-20): handling status request
2022-01-05 08:52:02.486451 (Thread-20): 08:52:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d90062be0>]}
2022-01-05 08:52:02.486868 (Thread-20): sending response (<Response 1241 bytes [200 OK]>) to 10.0.8.202
2022-01-05 08:52:19.316700 (Thread-21): handling status request
2022-01-05 08:52:19.317027 (Thread-21): 08:52:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d90062dc0>]}
2022-01-05 08:52:19.317502 (Thread-21): sending response (<Response 1241 bytes [200 OK]>) to 10.0.23.251
2022-01-05 08:52:19.347521 (Thread-22): handling status request
2022-01-05 08:52:19.347755 (Thread-22): 08:52:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d90062a60>]}
2022-01-05 08:52:19.348148 (Thread-22): sending response (<Response 1241 bytes [200 OK]>) to 10.0.43.0
2022-01-05 08:52:19.386192 (Thread-23): handling status request
2022-01-05 08:52:19.386409 (Thread-23): 08:52:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900622e0>]}
2022-01-05 08:52:19.386790 (Thread-23): sending response (<Response 1241 bytes [200 OK]>) to 10.0.28.79
2022-01-05 08:52:19.396619 (Thread-24): handling ps request
2022-01-05 08:52:19.396829 (Thread-24): 08:52:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9040c1c0>]}
2022-01-05 08:52:19.397167 (Thread-24): sending response (<Response 105 bytes [200 OK]>) to 10.0.9.20
2022-01-05 08:52:20.122437 (Thread-25): handling status request
2022-01-05 08:52:20.122798 (Thread-25): 08:52:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9045b340>]}
2022-01-05 08:52:20.123265 (Thread-25): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 08:52:20.129072 (Thread-26): handling list request
2022-01-05 08:52:20.129284 (Thread-26): 08:52:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d90441d60>]}
2022-01-05 08:52:20.157288 (Thread-26): 08:52:20  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900eee20>]}
2022-01-05 08:52:20.157639 (Thread-26): 08:52:20  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 08:52:20.161548 (Thread-26): 08:52:20  The selection criterion '+1641370237724/__unsaved/Statement' does not match any nodes
2022-01-05 08:52:20.161741 (Thread-26): 08:52:20  The selection criterion '1.sql+' does not match any nodes
2022-01-05 08:52:20.161842 (Thread-26): 08:52:20  No nodes selected!
2022-01-05 08:52:20.163275 (Thread-26): sending response (<Response 2348 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:02:37.322806 (Thread-27): handling status request
2022-01-05 09:02:37.324268 (Thread-27): 09:02:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900621c0>]}
2022-01-05 09:02:37.324725 (Thread-27): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:02:37.336332 (Thread-28): handling list request
2022-01-05 09:02:37.336559 (Thread-28): 09:02:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9006d880>]}
2022-01-05 09:02:37.364380 (Thread-28): 09:02:37  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9006df70>]}
2022-01-05 09:02:37.364642 (Thread-28): 09:02:37  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:02:37.372442 (Thread-28): sending response (<Response 5008 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:03:12.543069 (Thread-29): handling status request
2022-01-05 09:03:12.544560 (Thread-29): 09:03:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9006b8e0>]}
2022-01-05 09:03:12.545041 (Thread-29): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:03:12.555852 (Thread-30): handling list request
2022-01-05 09:03:12.556058 (Thread-30): 09:03:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9006df40>]}
2022-01-05 09:03:12.585449 (Thread-30): 09:03:12  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1c6f40>]}
2022-01-05 09:03:12.585700 (Thread-30): 09:03:12  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:03:12.589315 (Thread-30): sending response (<Response 5008 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:03:14.157262 (Thread-31): handling status request
2022-01-05 09:03:14.157613 (Thread-31): 09:03:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1cca30>]}
2022-01-05 09:03:14.158055 (Thread-31): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:03:14.163783 (Thread-32): handling list request
2022-01-05 09:03:14.163987 (Thread-32): 09:03:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1cccd0>]}
2022-01-05 09:03:14.192632 (Thread-32): 09:03:14  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1cca60>]}
2022-01-05 09:03:14.192877 (Thread-32): 09:03:14  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:03:14.196089 (Thread-32): sending response (<Response 5008 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:03:16.843650 (Thread-33): handling status request
2022-01-05 09:03:16.843979 (Thread-33): 09:03:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1d6550>]}
2022-01-05 09:03:16.844436 (Thread-33): sending response (<Response 1241 bytes [200 OK]>) to 10.0.41.88
2022-01-05 09:03:17.249854 (Thread-34): handling run_sql request
2022-01-05 09:03:17.250176 (Thread-34): 09:03:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1d61c0>]}
2022-01-05 09:03:19.341231 (Thread-34): sending response (<Response 138 bytes [200 OK]>) to 10.0.3.189
2022-01-05 09:03:19.366656 (MainThread): 09:03:19  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '58794d9e-e72f-42cc-a6ba-525420adedff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c0ab1bc70>]}
2022-01-05 09:03:19.367186 (MainThread): 09:03:19  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:03:19.367743 (Thread-1): 09:03:19  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:03:19.367876 (Thread-1): 09:03:19  Began compiling node rpc.my_new_project.request
2022-01-05 09:03:19.367966 (Thread-1): 09:03:19  Compiling rpc.my_new_project.request
2022-01-05 09:03:19.369986 (Thread-1): 09:03:19  finished collecting timing info
2022-01-05 09:03:19.370114 (Thread-1): 09:03:19  Began executing node rpc.my_new_project.request
2022-01-05 09:03:19.370209 (Thread-1): 09:03:19  Using redshift connection "rpc.my_new_project.request"
2022-01-05 09:03:19.370283 (Thread-1): 09:03:19  On rpc.my_new_project.request: -- Use the `ref` function to select from other models

select *
from "analytics"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:03:19.370358 (Thread-1): 09:03:19  Opening a new connection, currently in state init
2022-01-05 09:03:19.370436 (Thread-1): 09:03:19  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:03:19.385650 (Thread-1): 09:03:19  Postgres adapter: Got an error when attempting to open a postgres connection: 'FATAL:  database "analytics" does not exist
'
2022-01-05 09:03:19.385790 (Thread-1): 09:03:19  Postgres adapter: Error running SQL: -- Use the `ref` function to select from other models

select *
from "analytics"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:03:19.385867 (Thread-1): 09:03:19  Postgres adapter: Rolling back transaction.
2022-01-05 09:03:19.385961 (Thread-1): 09:03:19  finished collecting timing info
2022-01-05 09:03:19.386068 (Thread-1): 09:03:19  On rpc.my_new_project.request: No close available on handle
2022-01-05 09:03:19.386130 (Thread-1): Got an exception: Database Error
  FATAL:  database "analytics" does not exist
  
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 121, in open
    handle = psycopg2.connect(
  File "/usr/local/lib/python3.8/dist-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: FATAL:  database "analytics" does not exist


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 73, in add_query
    cursor = connection.handle.cursor()
  File "/usr/local/lib/python3.8/dist-packages/dbt/contracts/connection.py", line 83, in handle
    self._handle.resolve(self)
  File "/usr/local/lib/python3.8/dist-packages/dbt/contracts/connection.py", line 106, in resolve
    return self.opener(connection)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 143, in open
    raise dbt.exceptions.FailedToConnectException(str(e))
dbt.exceptions.FailedToConnectException: Database Error
  FATAL:  database "analytics" does not exist
2022-01-05 09:03:19.387286 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'FailedToConnectException', 'message': 'Database Error in rpc request (from remote system)\n  FATAL:  database "analytics" does not exist\n  ', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "analytics"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'FailedToConnectException', 'message': 'Database Error in rpc request (from remote system)\n  FATAL:  database "analytics" does not exist\n  ', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "analytics"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 09:03:19.708666 (Thread-35): handling poll request
2022-01-05 09:03:19.709078 (Thread-35): 09:03:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1d6610>]}
2022-01-05 09:03:19.737619 (Thread-35): sending response (<Response 10666 bytes [200 OK]>) to 10.0.8.124
2022-01-05 09:04:11.409852 (MainThread): Running with dbt=1.0.1
2022-01-05 09:04:11.512021 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-05 09:04:11.519046 (MainThread): Tracking: tracking
2022-01-05 09:04:11.539288 (MainThread): 09:04:11  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f501bf4cc40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4889a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee488cd0>]}
2022-01-05 09:04:11.539672 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-05 09:04:11.539911 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-05 09:04:11.540043 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-05 09:04:11.549989 (Thread-12): 09:04:11  Unable to do partial parsing because profile has changed
2022-01-05 09:04:11.550312 (Thread-12): 09:04:11  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee488bb0>]}
2022-01-05 09:04:11.591674 (Thread-12): 09:04:11  Parsing macros/catalog.sql
2022-01-05 09:04:11.604631 (Thread-12): 09:04:11  Parsing macros/adapters.sql
2022-01-05 09:04:11.632278 (Thread-12): 09:04:11  Parsing macros/relations.sql
2022-01-05 09:04:11.633008 (Thread-12): 09:04:11  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 09:04:11.633670 (Thread-12): 09:04:11  Parsing macros/catalog.sql
2022-01-05 09:04:11.635756 (Thread-12): 09:04:11  Parsing macros/adapters.sql
2022-01-05 09:04:11.656938 (Thread-12): 09:04:11  Parsing macros/relations.sql
2022-01-05 09:04:11.658228 (Thread-12): 09:04:11  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 09:04:11.659842 (Thread-12): 09:04:11  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-05 09:04:11.661346 (Thread-12): 09:04:11  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-05 09:04:11.662876 (Thread-12): 09:04:11  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-05 09:04:11.665320 (Thread-12): 09:04:11  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-05 09:04:11.666705 (Thread-12): 09:04:11  Parsing macros/generic_test_sql/not_null.sql
2022-01-05 09:04:11.667273 (Thread-12): 09:04:11  Parsing macros/generic_test_sql/relationships.sql
2022-01-05 09:04:11.668130 (Thread-12): 09:04:11  Parsing macros/generic_test_sql/unique.sql
2022-01-05 09:04:11.668873 (Thread-12): 09:04:11  Parsing macros/materializations/configs.sql
2022-01-05 09:04:11.671125 (Thread-12): 09:04:11  Parsing macros/materializations/hooks.sql
2022-01-05 09:04:11.674988 (Thread-12): 09:04:11  Parsing macros/materializations/snapshots/strategies.sql
2022-01-05 09:04:11.691247 (Thread-12): 09:04:11  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-05 09:04:11.693018 (Thread-12): 09:04:11  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-05 09:04:11.704072 (Thread-12): 09:04:11  Parsing macros/materializations/snapshots/helpers.sql
2022-01-05 09:04:11.714904 (Thread-12): 09:04:11  Parsing macros/materializations/seeds/seed.sql
2022-01-05 09:04:11.720799 (Thread-12): 09:04:11  Parsing macros/materializations/seeds/helpers.sql
2022-01-05 09:04:11.736629 (Thread-12): 09:04:11  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-05 09:04:11.738975 (Thread-12): 09:04:11  Parsing macros/materializations/models/view/view.sql
2022-01-05 09:04:11.745673 (Thread-12): 09:04:11  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-05 09:04:11.748277 (Thread-12): 09:04:11  Parsing macros/materializations/models/view/helpers.sql
2022-01-05 09:04:11.749619 (Thread-12): 09:04:11  Parsing macros/materializations/models/table/table.sql
2022-01-05 09:04:11.756688 (Thread-12): 09:04:11  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-05 09:04:11.759484 (Thread-12): 09:04:11  Parsing macros/materializations/models/incremental/merge.sql
2022-01-05 09:04:11.770604 (Thread-12): 09:04:11  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-05 09:04:11.785628 (Thread-12): 09:04:11  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-05 09:04:11.790144 (Thread-12): 09:04:11  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-05 09:04:11.800038 (Thread-12): 09:04:11  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-05 09:04:11.801725 (Thread-12): 09:04:11  Parsing macros/materializations/tests/test.sql
2022-01-05 09:04:11.806220 (Thread-12): 09:04:11  Parsing macros/materializations/tests/where_subquery.sql
2022-01-05 09:04:11.808034 (Thread-12): 09:04:11  Parsing macros/materializations/tests/helpers.sql
2022-01-05 09:04:11.809814 (Thread-12): 09:04:11  Parsing macros/etc/statement.sql
2022-01-05 09:04:11.814144 (Thread-12): 09:04:11  Parsing macros/etc/datetime.sql
2022-01-05 09:04:11.822725 (Thread-12): 09:04:11  Parsing macros/adapters/indexes.sql
2022-01-05 09:04:11.825672 (Thread-12): 09:04:11  Parsing macros/adapters/persist_docs.sql
2022-01-05 09:04:11.830083 (Thread-12): 09:04:11  Parsing macros/adapters/freshness.sql
2022-01-05 09:04:11.833006 (Thread-12): 09:04:11  Parsing macros/adapters/relation.sql
2022-01-05 09:04:11.842797 (Thread-12): 09:04:11  Parsing macros/adapters/metadata.sql
2022-01-05 09:04:11.849992 (Thread-12): 09:04:11  Parsing macros/adapters/columns.sql
2022-01-05 09:04:11.859752 (Thread-12): 09:04:11  Parsing macros/adapters/schema.sql
2022-01-05 09:04:11.862089 (Thread-12): 09:04:11  Parsing tests/generic/builtin.sql
2022-01-05 09:04:12.056049 (Thread-12): 09:04:12  1699: static parser successfully parsed example/my_second_dbt_model.sql
2022-01-05 09:04:12.071674 (Thread-12): 09:04:12  1699: static parser successfully parsed example/my_first_dbt_model.sql
2022-01-05 09:04:12.160181 (Thread-12): 09:04:12  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fed458220>]}
2022-01-05 09:04:13.915456 (Thread-13): handling status request
2022-01-05 09:04:13.915832 (Thread-13): 09:04:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4d0d30>]}
2022-01-05 09:04:13.916831 (Thread-13): sending response (<Response 15522 bytes [200 OK]>) to 10.0.1.185
2022-01-05 09:04:13.991280 (Thread-14): handling status request
2022-01-05 09:04:13.991676 (Thread-14): 09:04:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4ec670>]}
2022-01-05 09:04:13.992889 (Thread-14): sending response (<Response 15522 bytes [200 OK]>) to 10.0.9.20
2022-01-05 09:04:13.994304 (Thread-15): handling ps request
2022-01-05 09:04:13.994676 (Thread-15): 09:04:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee534340>]}
2022-01-05 09:04:13.995094 (Thread-15): sending response (<Response 105 bytes [200 OK]>) to 10.0.23.251
2022-01-05 09:04:14.000271 (Thread-16): handling status request
2022-01-05 09:04:14.000547 (Thread-16): 09:04:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1b74f0>]}
2022-01-05 09:04:14.001420 (Thread-16): sending response (<Response 15522 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:04:22.189781 (Thread-17): handling status request
2022-01-05 09:04:22.191647 (Thread-17): 09:04:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1b7bb0>]}
2022-01-05 09:04:22.192590 (Thread-17): sending response (<Response 15522 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:04:22.523700 (Thread-18): handling run_sql request
2022-01-05 09:04:22.524068 (Thread-18): 09:04:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1b7970>]}
2022-01-05 09:04:24.664280 (Thread-18): sending response (<Response 138 bytes [200 OK]>) to 10.0.22.146
2022-01-05 09:04:24.690177 (MainThread): 09:04:24  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '89d1a01a-870b-4d87-81f6-72548cd1c1b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbee73e610>]}
2022-01-05 09:04:24.690780 (MainThread): 09:04:24  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:04:24.691387 (Thread-1): 09:04:24  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:04:24.691519 (Thread-1): 09:04:24  Began compiling node rpc.my_new_project.request
2022-01-05 09:04:24.691618 (Thread-1): 09:04:24  Compiling rpc.my_new_project.request
2022-01-05 09:04:24.693739 (Thread-1): 09:04:24  finished collecting timing info
2022-01-05 09:04:24.693885 (Thread-1): 09:04:24  Began executing node rpc.my_new_project.request
2022-01-05 09:04:24.693988 (Thread-1): 09:04:24  Using redshift connection "rpc.my_new_project.request"
2022-01-05 09:04:24.694065 (Thread-1): 09:04:24  On rpc.my_new_project.request: -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:04:24.694144 (Thread-1): 09:04:24  Opening a new connection, currently in state init
2022-01-05 09:04:24.694225 (Thread-1): 09:04:24  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:04:24.713806 (Thread-1): 09:04:24  Postgres adapter: Postgres error: Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".

2022-01-05 09:04:24.714045 (Thread-1): 09:04:24  finished collecting timing info
2022-01-05 09:04:24.714202 (Thread-1): 09:04:24  On rpc.my_new_project.request: Close
2022-01-05 09:04:24.714535 (Thread-1): Got an exception: Database Error
  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InternalError_: Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".
2022-01-05 09:04:24.715633 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "dev"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "dev"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 09:04:25.015250 (Thread-19): handling poll request
2022-01-05 09:04:25.015713 (Thread-19): 09:04:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1b7100>]}
2022-01-05 09:04:25.016611 (Thread-19): sending response (<Response 9862 bytes [200 OK]>) to 10.0.18.33
2022-01-05 09:04:54.409698 (Thread-20): handling status request
2022-01-05 09:04:54.411835 (Thread-20): 09:04:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1bcb50>]}
2022-01-05 09:04:54.412898 (Thread-20): sending response (<Response 15522 bytes [200 OK]>) to 10.0.43.0
2022-01-05 09:04:54.781767 (Thread-21): handling run_sql request
2022-01-05 09:04:54.782138 (Thread-21): 09:04:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1bc520>]}
2022-01-05 09:04:56.916885 (Thread-21): sending response (<Response 138 bytes [200 OK]>) to 10.0.18.33
2022-01-05 09:04:56.946111 (MainThread): 09:04:56  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '324af820-22ff-48a5-98c8-39e0f6b53e87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe96c63d700>]}
2022-01-05 09:04:56.946707 (MainThread): 09:04:56  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:04:56.947327 (Thread-1): 09:04:56  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:04:56.947462 (Thread-1): 09:04:56  Began compiling node rpc.my_new_project.request
2022-01-05 09:04:56.947557 (Thread-1): 09:04:56  Compiling rpc.my_new_project.request
2022-01-05 09:04:56.949641 (Thread-1): 09:04:56  finished collecting timing info
2022-01-05 09:04:56.949774 (Thread-1): 09:04:56  Began executing node rpc.my_new_project.request
2022-01-05 09:04:56.949875 (Thread-1): 09:04:56  Using redshift connection "rpc.my_new_project.request"
2022-01-05 09:04:56.949950 (Thread-1): 09:04:56  On rpc.my_new_project.request: /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:04:56.950028 (Thread-1): 09:04:56  Opening a new connection, currently in state init
2022-01-05 09:04:56.950107 (Thread-1): 09:04:56  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:04:56.969208 (Thread-1): 09:04:56  SQL status: SELECT in 0.02 seconds
2022-01-05 09:04:56.970292 (Thread-1): 09:04:56  finished collecting timing info
2022-01-05 09:04:56.970446 (Thread-1): 09:04:56  On rpc.my_new_project.request: Close
2022-01-05 09:04:57.242792 (Thread-22): handling poll request
2022-01-05 09:04:57.243226 (Thread-22): 09:04:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1cb3d0>]}
2022-01-05 09:04:57.244488 (Thread-22): sending response (<Response 9360 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:05:06.113750 (Thread-23): handling status request
2022-01-05 09:05:06.114136 (Thread-23): 09:05:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1cb820>]}
2022-01-05 09:05:06.115081 (Thread-23): sending response (<Response 15522 bytes [200 OK]>) to 10.0.8.124
2022-01-05 09:05:06.451010 (Thread-24): handling run_sql request
2022-01-05 09:05:06.451395 (Thread-24): 09:05:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fed4244c0>]}
2022-01-05 09:05:08.580355 (Thread-24): sending response (<Response 138 bytes [200 OK]>) to 10.0.3.45
2022-01-05 09:05:08.606974 (MainThread): 09:05:08  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3af1ed36-2cb4-40ad-bc65-29c40b3ce858', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa05a4b2790>]}
2022-01-05 09:05:08.607592 (MainThread): 09:05:08  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:05:08.608220 (Thread-1): 09:05:08  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:05:08.608356 (Thread-1): 09:05:08  Began compiling node rpc.my_new_project.request
2022-01-05 09:05:08.608450 (Thread-1): 09:05:08  Compiling rpc.my_new_project.request
2022-01-05 09:05:08.610677 (Thread-1): 09:05:08  finished collecting timing info
2022-01-05 09:05:08.610814 (Thread-1): 09:05:08  Began executing node rpc.my_new_project.request
2022-01-05 09:05:08.610918 (Thread-1): 09:05:08  Using redshift connection "rpc.my_new_project.request"
2022-01-05 09:05:08.610998 (Thread-1): 09:05:08  On rpc.my_new_project.request: -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:05:08.611078 (Thread-1): 09:05:08  Opening a new connection, currently in state init
2022-01-05 09:05:08.611160 (Thread-1): 09:05:08  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:05:08.629183 (Thread-1): 09:05:08  Postgres adapter: Postgres error: Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".

2022-01-05 09:05:08.629421 (Thread-1): 09:05:08  finished collecting timing info
2022-01-05 09:05:08.629558 (Thread-1): 09:05:08  On rpc.my_new_project.request: Close
2022-01-05 09:05:08.629857 (Thread-1): Got an exception: Database Error
  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InternalError_: Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".
2022-01-05 09:05:08.630962 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "dev"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "dev"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 09:05:08.979242 (Thread-25): handling poll request
2022-01-05 09:05:08.980012 (Thread-25): 09:05:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fed4248e0>]}
2022-01-05 09:05:08.980844 (Thread-25): sending response (<Response 9862 bytes [200 OK]>) to 10.0.8.124
2022-01-05 09:06:13.735816 (Thread-26): handling ps request
2022-01-05 09:06:13.736229 (Thread-26): 09:06:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4c4100>]}
2022-01-05 09:06:13.736947 (Thread-26): sending response (<Response 1640 bytes [200 OK]>) to 10.0.19.22
2022-01-05 09:06:13.755989 (Thread-27): handling status request
2022-01-05 09:06:13.756354 (Thread-27): 09:06:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4c43a0>]}
2022-01-05 09:06:13.757345 (Thread-27): sending response (<Response 15522 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:06:13.821135 (Thread-28): handling status request
2022-01-05 09:06:13.821499 (Thread-28): 09:06:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4c4130>]}
2022-01-05 09:06:13.822340 (Thread-28): sending response (<Response 15522 bytes [200 OK]>) to 10.0.43.0
2022-01-05 09:06:13.863141 (Thread-29): handling status request
2022-01-05 09:06:13.863551 (Thread-29): 09:06:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec185640>]}
2022-01-05 09:06:13.864426 (Thread-29): sending response (<Response 15522 bytes [200 OK]>) to 10.0.3.45
2022-01-05 09:06:14.953143 (Thread-30): handling status request
2022-01-05 09:06:14.953763 (Thread-30): 09:06:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1853d0>]}
2022-01-05 09:06:14.954734 (Thread-30): sending response (<Response 15500 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:14.955270 (Thread-31): handling status request
2022-01-05 09:06:14.956322 (Thread-32): handling status request
2022-01-05 09:06:14.956786 (Thread-31): 09:06:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec185fd0>]}
2022-01-05 09:06:14.957117 (Thread-32): 09:06:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4c44f0>]}
2022-01-05 09:06:14.958001 (Thread-31): sending response (<Response 15500 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:14.958908 (Thread-32): sending response (<Response 15500 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:14.962866 (Thread-33): handling list request
2022-01-05 09:06:14.963121 (Thread-33): 09:06:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1851f0>]}
2022-01-05 09:06:14.967226 (Thread-34): handling list request
2022-01-05 09:06:15.017078 (Thread-35): sending response (<Response 214 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:16.371885 (Thread-36): handling status request
2022-01-05 09:06:16.372264 (Thread-36): 09:06:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fed41c580>]}
2022-01-05 09:06:16.396600 (Thread-36): sending response (<Response 15500 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:16.402751 (Thread-37): handling list request
2022-01-05 09:06:16.403061 (Thread-37): 09:06:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1ce250>]}
2022-01-05 09:06:16.433529 (Thread-37): 09:06:16  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0e87f0>]}
2022-01-05 09:06:16.433897 (Thread-37): 09:06:16  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:06:16.436616 (Thread-37): sending response (<Response 5006 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:21.670744 (Thread-38): handling status request
2022-01-05 09:06:21.671124 (Thread-38): 09:06:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0e8f40>]}
2022-01-05 09:06:21.671998 (Thread-38): sending response (<Response 15500 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:21.677522 (Thread-39): handling list request
2022-01-05 09:06:21.677822 (Thread-39): 09:06:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec15f250>]}
2022-01-05 09:06:21.705736 (Thread-39): 09:06:21  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0e80d0>]}
2022-01-05 09:06:21.706132 (Thread-39): 09:06:21  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:06:21.706989 (Thread-39): 09:06:21  The selection criterion '+1641370237724/__unsaved/Statement' does not match any nodes
2022-01-05 09:06:21.707205 (Thread-39): 09:06:21  The selection criterion '1.sql+' does not match any nodes
2022-01-05 09:06:21.707317 (Thread-39): 09:06:21  No nodes selected!
2022-01-05 09:06:21.708960 (Thread-39): sending response (<Response 2343 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:23.571235 (Thread-40): handling status request
2022-01-05 09:06:23.571625 (Thread-40): 09:06:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec15fc70>]}
2022-01-05 09:06:23.572502 (Thread-40): sending response (<Response 15522 bytes [200 OK]>) to 10.0.40.203
2022-01-05 09:06:23.925543 (Thread-41): handling run_sql request
2022-01-05 09:06:23.925910 (Thread-41): 09:06:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec15fee0>]}
2022-01-05 09:06:26.097478 (Thread-41): sending response (<Response 138 bytes [200 OK]>) to 10.0.22.146
2022-01-05 09:06:26.123748 (MainThread): 09:06:26  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a7aa97a1-f89b-4a75-9529-d7fcbab33bbf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752814a970>]}
2022-01-05 09:06:26.124341 (MainThread): 09:06:26  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:06:26.124964 (Thread-1): 09:06:26  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:06:26.125092 (Thread-1): 09:06:26  Began compiling node rpc.my_new_project.request
2022-01-05 09:06:26.125184 (Thread-1): 09:06:26  Compiling rpc.my_new_project.request
2022-01-05 09:06:26.127816 (Thread-1): 09:06:26  finished collecting timing info
2022-01-05 09:06:26.127948 (Thread-1): 09:06:26  Began executing node rpc.my_new_project.request
2022-01-05 09:06:26.128049 (Thread-1): 09:06:26  Using redshift connection "rpc.my_new_project.request"
2022-01-05 09:06:26.128125 (Thread-1): 09:06:26  On rpc.my_new_project.request: 

  select 0 as number  union all 



  select 1 as number  union all 



  select 2 as number  union all 



  select 3 as number  union all 



  select 4 as number  union all 



  select 5 as number  union all 



  select 6 as number  union all 



  select 7 as number  union all 



  select 8 as number  union all 



  select 9 as number 


limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:06:26.128205 (Thread-1): 09:06:26  Opening a new connection, currently in state init
2022-01-05 09:06:26.128286 (Thread-1): 09:06:26  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:06:26.147532 (Thread-1): 09:06:26  SQL status: SELECT in 0.02 seconds
2022-01-05 09:06:26.148790 (Thread-1): 09:06:26  finished collecting timing info
2022-01-05 09:06:26.148961 (Thread-1): 09:06:26  On rpc.my_new_project.request: Close
2022-01-05 09:06:26.504522 (Thread-42): handling poll request
2022-01-05 09:06:26.504980 (Thread-42): 09:06:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec10d3a0>]}
2022-01-05 09:06:26.506218 (Thread-42): sending response (<Response 8387 bytes [200 OK]>) to 10.0.41.88
2022-01-05 09:13:02.276770 (Thread-43): handling status request
2022-01-05 09:13:02.278899 (Thread-43): 09:13:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec10d550>]}
2022-01-05 09:13:02.279948 (Thread-43): sending response (<Response 15522 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:13:02.703429 (Thread-44): handling compile_sql request
2022-01-05 09:13:02.703827 (Thread-44): 09:13:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec10d940>]}
2022-01-05 09:13:04.869826 (Thread-44): sending response (<Response 138 bytes [200 OK]>) to 10.0.19.22
2022-01-05 09:13:04.899073 (MainThread): 09:13:04  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1a6ba891-5ee6-436c-af81-f6ab818da749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ba0fa1f10>]}
2022-01-05 09:13:04.899729 (MainThread): 09:13:04  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:13:04.900396 (Thread-1): 09:13:04  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:13:04.900571 (Thread-1): 09:13:04  Began compiling node rpc.my_new_project.request
2022-01-05 09:13:04.900669 (Thread-1): 09:13:04  Compiling rpc.my_new_project.request
2022-01-05 09:13:04.902031 (Thread-1): 09:13:04  finished collecting timing info
2022-01-05 09:13:04.902163 (Thread-1): 09:13:04  Began executing node rpc.my_new_project.request
2022-01-05 09:13:04.902271 (Thread-1): 09:13:04  finished collecting timing info
2022-01-05 09:13:05.221887 (Thread-45): handling poll request
2022-01-05 09:13:05.222340 (Thread-45): 09:13:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec10d490>]}
2022-01-05 09:13:05.223397 (Thread-45): sending response (<Response 7164 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:18:22.647626 (Thread-46): handling status request
2022-01-05 09:18:22.649759 (Thread-46): 09:18:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1c4970>]}
2022-01-05 09:18:22.650800 (Thread-46): sending response (<Response 15522 bytes [200 OK]>) to 10.0.23.251
2022-01-05 09:18:22.888748 (Thread-47): handling status request
2022-01-05 09:18:22.889117 (Thread-47): 09:18:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fed442700>]}
2022-01-05 09:18:22.889993 (Thread-47): sending response (<Response 15522 bytes [200 OK]>) to 10.0.9.20
2022-01-05 09:18:22.991082 (Thread-48): handling cli_args request
2022-01-05 09:18:22.991456 (Thread-48): 09:18:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1106d0>]}
2022-01-05 09:18:25.164595 (Thread-48): sending response (<Response 138 bytes [200 OK]>) to 10.0.41.88
2022-01-05 09:18:25.262928 (MainThread): 09:18:25  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 09:18:25.263373 (MainThread): 09:18:25  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 09:18:25.269715 (MainThread): 09:18:25  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0ffdc471-2794-4ba4-a05d-6e70a316dfc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd62777a60>]}
2022-01-05 09:18:25.304676 (MainThread): 09:18:25  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0ffdc471-2794-4ba4-a05d-6e70a316dfc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd627d7a00>]}
2022-01-05 09:18:25.305019 (MainThread): 09:18:25  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:18:25.306193 (MainThread): 09:18:25  
2022-01-05 09:18:25.306547 (MainThread): 09:18:25  Acquiring new redshift connection "master"
2022-01-05 09:18:25.307511 (ThreadPoolExecutor-0_0): 09:18:25  Acquiring new redshift connection "list_dev"
2022-01-05 09:18:25.318203 (ThreadPoolExecutor-0_0): 09:18:25  Using redshift connection "list_dev"
2022-01-05 09:18:25.318333 (ThreadPoolExecutor-0_0): 09:18:25  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-05 09:18:25.318424 (ThreadPoolExecutor-0_0): 09:18:25  Opening a new connection, currently in state init
2022-01-05 09:18:25.318511 (ThreadPoolExecutor-0_0): 09:18:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:25.337776 (ThreadPoolExecutor-0_0): 09:18:25  SQL status: SELECT in 0.02 seconds
2022-01-05 09:18:25.339009 (ThreadPoolExecutor-0_0): 09:18:25  On list_dev: Close
2022-01-05 09:18:25.339871 (ThreadPoolExecutor-0_0): 09:18:25  Acquiring new redshift connection "create_dev_dbt_nobodozie"
2022-01-05 09:18:25.340133 (ThreadPoolExecutor-0_0): 09:18:25  Acquiring new redshift connection "create_dev_dbt_nobodozie"
2022-01-05 09:18:25.340305 (ThreadPoolExecutor-0_0): 09:18:25  Creating schema "_ReferenceKey(database='dev', schema='dbt_nobodozie', identifier=None)"
2022-01-05 09:18:25.346396 (ThreadPoolExecutor-0_0): 09:18:25  Using redshift connection "create_dev_dbt_nobodozie"
2022-01-05 09:18:25.346507 (ThreadPoolExecutor-0_0): 09:18:25  On create_dev_dbt_nobodozie: BEGIN
2022-01-05 09:18:25.346591 (ThreadPoolExecutor-0_0): 09:18:25  Opening a new connection, currently in state closed
2022-01-05 09:18:25.346672 (ThreadPoolExecutor-0_0): 09:18:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:25.367572 (ThreadPoolExecutor-0_0): 09:18:25  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:25.367750 (ThreadPoolExecutor-0_0): 09:18:25  Using redshift connection "create_dev_dbt_nobodozie"
2022-01-05 09:18:25.367836 (ThreadPoolExecutor-0_0): 09:18:25  On create_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "create_dev_dbt_nobodozie"} */
create schema if not exists "dbt_nobodozie"
2022-01-05 09:18:25.369985 (ThreadPoolExecutor-0_0): 09:18:25  SQL status: CREATE SCHEMA in 0.0 seconds
2022-01-05 09:18:25.370819 (ThreadPoolExecutor-0_0): 09:18:25  On create_dev_dbt_nobodozie: COMMIT
2022-01-05 09:18:25.370926 (ThreadPoolExecutor-0_0): 09:18:25  Using redshift connection "create_dev_dbt_nobodozie"
2022-01-05 09:18:25.371003 (ThreadPoolExecutor-0_0): 09:18:25  On create_dev_dbt_nobodozie: COMMIT
2022-01-05 09:18:25.427178 (ThreadPoolExecutor-0_0): 09:18:25  SQL status: COMMIT in 0.06 seconds
2022-01-05 09:18:25.427396 (ThreadPoolExecutor-0_0): 09:18:25  On create_dev_dbt_nobodozie: Close
2022-01-05 09:18:25.428905 (ThreadPoolExecutor-1_0): 09:18:25  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:25.436213 (ThreadPoolExecutor-1_0): 09:18:25  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:25.436381 (ThreadPoolExecutor-1_0): 09:18:25  On list_dev_dbt_nobodozie: BEGIN
2022-01-05 09:18:25.436510 (ThreadPoolExecutor-1_0): 09:18:25  Opening a new connection, currently in state closed
2022-01-05 09:18:25.436599 (ThreadPoolExecutor-1_0): 09:18:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:25.456921 (ThreadPoolExecutor-1_0): 09:18:25  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:25.457092 (ThreadPoolExecutor-1_0): 09:18:25  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:25.457177 (ThreadPoolExecutor-1_0): 09:18:25  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-05 09:18:25.467943 (ThreadPoolExecutor-1_0): 09:18:25  SQL status: SELECT in 0.01 seconds
2022-01-05 09:18:25.469178 (ThreadPoolExecutor-1_0): 09:18:25  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-05 09:18:25.470906 (ThreadPoolExecutor-1_0): 09:18:25  On list_dev_dbt_nobodozie: Close
2022-01-05 09:18:25.475191 (MainThread): 09:18:25  Using redshift connection "master"
2022-01-05 09:18:25.475320 (MainThread): 09:18:25  On master: BEGIN
2022-01-05 09:18:25.475409 (MainThread): 09:18:25  Opening a new connection, currently in state init
2022-01-05 09:18:25.475492 (MainThread): 09:18:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:25.498583 (MainThread): 09:18:25  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:25.498752 (MainThread): 09:18:25  Using redshift connection "master"
2022-01-05 09:18:25.498835 (MainThread): 09:18:25  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-05 09:18:25.517349 (MainThread): 09:18:25  SQL status: SELECT in 0.02 seconds
2022-01-05 09:18:25.518479 (MainThread): 09:18:25  On master: ROLLBACK
2022-01-05 09:18:25.520307 (MainThread): 09:18:25  Using redshift connection "master"
2022-01-05 09:18:25.520418 (MainThread): 09:18:25  On master: BEGIN
2022-01-05 09:18:25.523663 (MainThread): 09:18:25  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:25.523780 (MainThread): 09:18:25  On master: COMMIT
2022-01-05 09:18:25.523855 (MainThread): 09:18:25  Using redshift connection "master"
2022-01-05 09:18:25.523926 (MainThread): 09:18:25  On master: COMMIT
2022-01-05 09:18:25.525547 (MainThread): 09:18:25  SQL status: COMMIT in 0.0 seconds
2022-01-05 09:18:25.525699 (MainThread): 09:18:25  On master: Close
2022-01-05 09:18:25.526232 (MainThread): 09:18:25  Concurrency: 4 threads (target='default')
2022-01-05 09:18:25.526354 (MainThread): 09:18:25  
2022-01-05 09:18:25.528953 (Thread-1): 09:18:25  Began running node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:25.529254 (Thread-1): 09:18:25  1 of 2 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-05 09:18:25.529539 (Thread-1): 09:18:25  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:25.529635 (Thread-1): 09:18:25  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:25.529728 (Thread-1): 09:18:25  Compiling model.my_new_project.my_first_dbt_model
2022-01-05 09:18:25.532149 (Thread-1): 09:18:25  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:25.565934 (Thread-1): 09:18:25  finished collecting timing info
2022-01-05 09:18:25.566166 (Thread-1): 09:18:25  Began executing node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:25.581588 (Thread-49): handling poll request
2022-01-05 09:18:25.581983 (Thread-49): 09:18:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0b90d0>]}
2022-01-05 09:18:25.583329 (Thread-49): sending response (<Response 24818 bytes [200 OK]>) to 10.0.43.175
2022-01-05 09:18:25.599705 (Thread-1): 09:18:25  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:25.641364 (Thread-1): 09:18:25  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:25.641542 (Thread-1): 09:18:25  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:25.641635 (Thread-1): 09:18:25  Opening a new connection, currently in state closed
2022-01-05 09:18:25.641720 (Thread-1): 09:18:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:25.660944 (Thread-1): 09:18:25  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:25.661123 (Thread-1): 09:18:25  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:25.661209 (Thread-1): 09:18:25  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-05 09:18:26.162640 (Thread-1): 09:18:26  SQL status: SELECT in 0.5 seconds
2022-01-05 09:18:26.168886 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.169025 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-05 09:18:26.171582 (Thread-1): 09:18:26  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 09:18:26.182098 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:26.182245 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.182325 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:26.223482 (Thread-1): 09:18:26  SQL status: COMMIT in 0.04 seconds
2022-01-05 09:18:26.223827 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.223920 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:26.225886 (Thread-1): 09:18:26  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:26.230573 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.230682 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-05 09:18:26.232557 (Thread-1): 09:18:26  SQL status: DROP TABLE in 0.0 seconds
2022-01-05 09:18:26.233295 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:26.233396 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.233472 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:26.237263 (Thread-1): 09:18:26  SQL status: COMMIT in 0.0 seconds
2022-01-05 09:18:26.237369 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.237441 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:26.239204 (Thread-1): 09:18:26  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:26.239682 (Thread-1): 09:18:26  finished collecting timing info
2022-01-05 09:18:26.239836 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-05 09:18:26.241470 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: Close
2022-01-05 09:18:26.241995 (Thread-1): 09:18:26  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ffdc471-2794-4ba4-a05d-6e70a316dfc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd60691f70>]}
2022-01-05 09:18:26.242348 (Thread-1): 09:18:26  1 of 2 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.71s]
2022-01-05 09:18:26.242464 (Thread-1): 09:18:26  Finished running node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:26.243359 (Thread-3): 09:18:26  Began running node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:26.243577 (Thread-3): 09:18:26  2 of 2 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-05 09:18:26.243836 (Thread-3): 09:18:26  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.243923 (Thread-3): 09:18:26  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:26.244011 (Thread-3): 09:18:26  Compiling model.my_new_project.my_second_dbt_model
2022-01-05 09:18:26.246404 (Thread-3): 09:18:26  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.259815 (Thread-3): 09:18:26  finished collecting timing info
2022-01-05 09:18:26.259973 (Thread-3): 09:18:26  Began executing node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:26.276594 (Thread-3): 09:18:26  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.289891 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.290043 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:26.290136 (Thread-3): 09:18:26  Opening a new connection, currently in state init
2022-01-05 09:18:26.290223 (Thread-3): 09:18:26  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:26.307730 (Thread-3): 09:18:26  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:26.307898 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.307983 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-05 09:18:26.312746 (Thread-3): 09:18:26  SQL status: CREATE VIEW in 0.0 seconds
2022-01-05 09:18:26.315068 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.315188 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-05 09:18:26.317162 (Thread-3): 09:18:26  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 09:18:26.318262 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:26.318362 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.318436 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:26.346717 (Thread-3): 09:18:26  SQL status: COMMIT in 0.03 seconds
2022-01-05 09:18:26.347044 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.347134 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:26.349041 (Thread-3): 09:18:26  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:26.351775 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.351878 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-05 09:18:26.353615 (Thread-3): 09:18:26  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 09:18:26.354346 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:26.354444 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.354519 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:26.377998 (Thread-3): 09:18:26  SQL status: COMMIT in 0.02 seconds
2022-01-05 09:18:26.378154 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.378233 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:26.380065 (Thread-3): 09:18:26  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:26.380623 (Thread-3): 09:18:26  finished collecting timing info
2022-01-05 09:18:26.380772 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-05 09:18:26.382359 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: Close
2022-01-05 09:18:26.382877 (Thread-3): 09:18:26  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ffdc471-2794-4ba4-a05d-6e70a316dfc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd6060df70>]}
2022-01-05 09:18:26.383239 (Thread-3): 09:18:26  2 of 2 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.14s]
2022-01-05 09:18:26.383353 (Thread-3): 09:18:26  Finished running node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:26.384785 (MainThread): 09:18:26  Acquiring new redshift connection "master"
2022-01-05 09:18:26.384945 (MainThread): 09:18:26  Using redshift connection "master"
2022-01-05 09:18:26.385026 (MainThread): 09:18:26  On master: BEGIN
2022-01-05 09:18:26.385104 (MainThread): 09:18:26  Opening a new connection, currently in state closed
2022-01-05 09:18:26.385184 (MainThread): 09:18:26  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:26.407190 (MainThread): 09:18:26  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:26.407382 (MainThread): 09:18:26  On master: COMMIT
2022-01-05 09:18:26.407463 (MainThread): 09:18:26  Using redshift connection "master"
2022-01-05 09:18:26.407539 (MainThread): 09:18:26  On master: COMMIT
2022-01-05 09:18:26.409081 (MainThread): 09:18:26  SQL status: COMMIT in 0.0 seconds
2022-01-05 09:18:26.409215 (MainThread): 09:18:26  On master: Close
2022-01-05 09:18:26.409732 (MainThread): 09:18:26  
2022-01-05 09:18:26.409856 (MainThread): 09:18:26  Finished running 1 table model, 1 view model in 1.10s.
2022-01-05 09:18:26.409942 (MainThread): 09:18:26  Connection 'master' was properly closed.
2022-01-05 09:18:26.410010 (MainThread): 09:18:26  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-05 09:18:26.410075 (MainThread): 09:18:26  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-05 09:18:26.449477 (MainThread): 09:18:26  
2022-01-05 09:18:26.449709 (MainThread): 09:18:26  Completed successfully
2022-01-05 09:18:26.449809 (MainThread): 09:18:26  
2022-01-05 09:18:26.449898 (MainThread): 09:18:26  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2022-01-05 09:18:26.919047 (Thread-50): handling poll request
2022-01-05 09:18:26.919431 (Thread-50): 09:18:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0a1ca0>]}
2022-01-05 09:18:26.921227 (Thread-50): sending response (<Response 43307 bytes [200 OK]>) to 10.0.35.228
2022-01-05 09:18:27.567455 (Thread-51): handling status request
2022-01-05 09:18:27.567831 (Thread-51): 09:18:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0d2250>]}
2022-01-05 09:18:27.568763 (Thread-51): sending response (<Response 15522 bytes [200 OK]>) to 10.0.8.124
2022-01-05 09:18:27.603137 (Thread-52): handling status request
2022-01-05 09:18:27.603511 (Thread-52): 09:18:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0d2af0>]}
2022-01-05 09:18:27.604306 (Thread-52): sending response (<Response 15522 bytes [200 OK]>) to 10.0.31.49
2022-01-05 09:18:37.291148 (Thread-53): handling status request
2022-01-05 09:18:37.291535 (Thread-53): 09:18:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0d2d60>]}
2022-01-05 09:18:37.292333 (Thread-53): sending response (<Response 15522 bytes [200 OK]>) to 10.0.31.49
2022-01-05 09:18:37.579995 (Thread-54): handling status request
2022-01-05 09:18:37.580401 (Thread-54): 09:18:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0d2fd0>]}
2022-01-05 09:18:37.581277 (Thread-54): sending response (<Response 15522 bytes [200 OK]>) to 10.0.46.191
2022-01-05 09:18:37.608557 (Thread-55): handling cli_args request
2022-01-05 09:18:37.608936 (Thread-55): 09:18:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec055280>]}
2022-01-05 09:18:39.756760 (Thread-55): sending response (<Response 138 bytes [200 OK]>) to 10.0.8.202
2022-01-05 09:18:39.846940 (MainThread): 09:18:39  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 09:18:39.847414 (MainThread): 09:18:39  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 09:18:39.853523 (MainThread): 09:18:39  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'caf0dcfa-b066-47c3-bd15-7998fbb6cdfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39b80d6a90>]}
2022-01-05 09:18:39.883275 (MainThread): 09:18:39  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'caf0dcfa-b066-47c3-bd15-7998fbb6cdfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39b8136a30>]}
2022-01-05 09:18:39.883614 (MainThread): 09:18:39  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:18:39.884782 (MainThread): 09:18:39  
2022-01-05 09:18:39.885129 (MainThread): 09:18:39  Acquiring new redshift connection "master"
2022-01-05 09:18:39.886087 (ThreadPoolExecutor-0_0): 09:18:39  Acquiring new redshift connection "list_dev"
2022-01-05 09:18:39.896644 (ThreadPoolExecutor-0_0): 09:18:39  Using redshift connection "list_dev"
2022-01-05 09:18:39.896778 (ThreadPoolExecutor-0_0): 09:18:39  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-05 09:18:39.896869 (ThreadPoolExecutor-0_0): 09:18:39  Opening a new connection, currently in state init
2022-01-05 09:18:39.896956 (ThreadPoolExecutor-0_0): 09:18:39  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:39.918688 (ThreadPoolExecutor-0_0): 09:18:39  SQL status: SELECT in 0.02 seconds
2022-01-05 09:18:39.919919 (ThreadPoolExecutor-0_0): 09:18:39  On list_dev: Close
2022-01-05 09:18:39.921204 (ThreadPoolExecutor-1_0): 09:18:39  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:39.927731 (ThreadPoolExecutor-1_0): 09:18:39  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:39.927843 (ThreadPoolExecutor-1_0): 09:18:39  On list_dev_dbt_nobodozie: BEGIN
2022-01-05 09:18:39.927930 (ThreadPoolExecutor-1_0): 09:18:39  Opening a new connection, currently in state closed
2022-01-05 09:18:39.928011 (ThreadPoolExecutor-1_0): 09:18:39  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:39.950427 (ThreadPoolExecutor-1_0): 09:18:39  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:39.950602 (ThreadPoolExecutor-1_0): 09:18:39  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:39.950684 (ThreadPoolExecutor-1_0): 09:18:39  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-05 09:18:39.961819 (ThreadPoolExecutor-1_0): 09:18:39  SQL status: SELECT in 0.01 seconds
2022-01-05 09:18:39.963223 (ThreadPoolExecutor-1_0): 09:18:39  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-05 09:18:39.965011 (ThreadPoolExecutor-1_0): 09:18:39  On list_dev_dbt_nobodozie: Close
2022-01-05 09:18:39.969952 (MainThread): 09:18:39  Using redshift connection "master"
2022-01-05 09:18:39.970087 (MainThread): 09:18:39  On master: BEGIN
2022-01-05 09:18:39.970175 (MainThread): 09:18:39  Opening a new connection, currently in state init
2022-01-05 09:18:39.970259 (MainThread): 09:18:39  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:40.116326 (Thread-56): handling poll request
2022-01-05 09:18:40.116822 (Thread-56): 09:18:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec055640>]}
2022-01-05 09:18:40.117878 (Thread-56): sending response (<Response 9949 bytes [200 OK]>) to 10.0.23.251
2022-01-05 09:18:40.510973 (MainThread): 09:18:40  SQL status: BEGIN in 0.54 seconds
2022-01-05 09:18:40.511152 (MainThread): 09:18:40  Using redshift connection "master"
2022-01-05 09:18:40.511238 (MainThread): 09:18:40  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-05 09:18:40.539720 (MainThread): 09:18:40  SQL status: SELECT in 0.03 seconds
2022-01-05 09:18:40.541032 (MainThread): 09:18:40  On master: ROLLBACK
2022-01-05 09:18:40.542921 (MainThread): 09:18:40  Using redshift connection "master"
2022-01-05 09:18:40.543039 (MainThread): 09:18:40  On master: BEGIN
2022-01-05 09:18:40.546333 (MainThread): 09:18:40  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:40.546462 (MainThread): 09:18:40  On master: COMMIT
2022-01-05 09:18:40.546542 (MainThread): 09:18:40  Using redshift connection "master"
2022-01-05 09:18:40.546617 (MainThread): 09:18:40  On master: COMMIT
2022-01-05 09:18:40.548215 (MainThread): 09:18:40  SQL status: COMMIT in 0.0 seconds
2022-01-05 09:18:40.548343 (MainThread): 09:18:40  On master: Close
2022-01-05 09:18:40.548919 (MainThread): 09:18:40  Concurrency: 4 threads (target='default')
2022-01-05 09:18:40.549081 (MainThread): 09:18:40  
2022-01-05 09:18:40.551527 (Thread-1): 09:18:40  Began running node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:40.552061 (Thread-1): 09:18:40  1 of 2 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-05 09:18:40.552372 (Thread-1): 09:18:40  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.552520 (Thread-1): 09:18:40  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:40.552621 (Thread-1): 09:18:40  Compiling model.my_new_project.my_first_dbt_model
2022-01-05 09:18:40.555098 (Thread-1): 09:18:40  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.571373 (Thread-1): 09:18:40  finished collecting timing info
2022-01-05 09:18:40.571586 (Thread-1): 09:18:40  Began executing node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:40.608485 (Thread-1): 09:18:40  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.624558 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.624730 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:40.624830 (Thread-1): 09:18:40  Opening a new connection, currently in state closed
2022-01-05 09:18:40.624916 (Thread-1): 09:18:40  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:40.642447 (Thread-1): 09:18:40  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:40.642629 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.642714 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-05 09:18:40.689110 (Thread-1): 09:18:40  SQL status: SELECT in 0.05 seconds
2022-01-05 09:18:40.695566 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.695710 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-05 09:18:40.698156 (Thread-1): 09:18:40  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 09:18:40.700158 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.700267 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-05 09:18:40.702591 (Thread-1): 09:18:40  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 09:18:40.713224 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:40.713363 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.713442 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:40.746959 (Thread-1): 09:18:40  SQL status: COMMIT in 0.03 seconds
2022-01-05 09:18:40.747310 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.747404 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:40.749450 (Thread-1): 09:18:40  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:40.753989 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.754096 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-05 09:18:40.758877 (Thread-1): 09:18:40  SQL status: DROP TABLE in 0.0 seconds
2022-01-05 09:18:40.759610 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:40.759711 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.759787 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:40.785211 (Thread-1): 09:18:40  SQL status: COMMIT in 0.03 seconds
2022-01-05 09:18:40.785378 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.785461 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:40.787424 (Thread-1): 09:18:40  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:40.787973 (Thread-1): 09:18:40  finished collecting timing info
2022-01-05 09:18:40.788116 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-05 09:18:40.789786 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: Close
2022-01-05 09:18:40.790335 (Thread-1): 09:18:40  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'caf0dcfa-b066-47c3-bd15-7998fbb6cdfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39b7029370>]}
2022-01-05 09:18:40.790719 (Thread-1): 09:18:40  1 of 2 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.24s]
2022-01-05 09:18:40.790856 (Thread-1): 09:18:40  Finished running node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:40.791754 (Thread-3): 09:18:40  Began running node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:40.792029 (Thread-3): 09:18:40  2 of 2 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-05 09:18:40.792321 (Thread-3): 09:18:40  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:40.792416 (Thread-3): 09:18:40  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:40.792538 (Thread-3): 09:18:40  Compiling model.my_new_project.my_second_dbt_model
2022-01-05 09:18:40.795042 (Thread-3): 09:18:40  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:40.810254 (Thread-3): 09:18:40  finished collecting timing info
2022-01-05 09:18:40.810455 (Thread-3): 09:18:40  Began executing node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:40.827545 (Thread-3): 09:18:40  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:40.843252 (Thread-3): 09:18:40  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:40.843423 (Thread-3): 09:18:40  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:40.843519 (Thread-3): 09:18:40  Opening a new connection, currently in state init
2022-01-05 09:18:40.843605 (Thread-3): 09:18:40  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:41.285691 (Thread-3): 09:18:41  SQL status: BEGIN in 0.44 seconds
2022-01-05 09:18:41.285875 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.285961 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-05 09:18:41.290681 (Thread-3): 09:18:41  SQL status: CREATE VIEW in 0.0 seconds
2022-01-05 09:18:41.292998 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.293127 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-05 09:18:41.295243 (Thread-3): 09:18:41  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 09:18:41.296386 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:41.296525 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.296605 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:41.324686 (Thread-3): 09:18:41  SQL status: COMMIT in 0.03 seconds
2022-01-05 09:18:41.325018 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.325109 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:41.327081 (Thread-3): 09:18:41  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:41.328653 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.328759 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-05 09:18:41.330536 (Thread-3): 09:18:41  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 09:18:41.331290 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:41.331390 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.331464 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:41.356932 (Thread-3): 09:18:41  SQL status: COMMIT in 0.03 seconds
2022-01-05 09:18:41.357099 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.357179 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:41.359241 (Thread-3): 09:18:41  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:41.359789 (Thread-3): 09:18:41  finished collecting timing info
2022-01-05 09:18:41.359933 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-05 09:18:41.361515 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: Close
2022-01-05 09:18:41.362047 (Thread-3): 09:18:41  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'caf0dcfa-b066-47c3-bd15-7998fbb6cdfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3997fa6070>]}
2022-01-05 09:18:41.362403 (Thread-3): 09:18:41  2 of 2 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.57s]
2022-01-05 09:18:41.362521 (Thread-3): 09:18:41  Finished running node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:41.364021 (MainThread): 09:18:41  Acquiring new redshift connection "master"
2022-01-05 09:18:41.364179 (MainThread): 09:18:41  Using redshift connection "master"
2022-01-05 09:18:41.364261 (MainThread): 09:18:41  On master: BEGIN
2022-01-05 09:18:41.364345 (MainThread): 09:18:41  Opening a new connection, currently in state closed
2022-01-05 09:18:41.364428 (MainThread): 09:18:41  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:41.388057 (MainThread): 09:18:41  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:41.388246 (MainThread): 09:18:41  On master: COMMIT
2022-01-05 09:18:41.388332 (MainThread): 09:18:41  Using redshift connection "master"
2022-01-05 09:18:41.388411 (MainThread): 09:18:41  On master: COMMIT
2022-01-05 09:18:41.390025 (MainThread): 09:18:41  SQL status: COMMIT in 0.0 seconds
2022-01-05 09:18:41.390170 (MainThread): 09:18:41  On master: Close
2022-01-05 09:18:41.390711 (MainThread): 09:18:41  
2022-01-05 09:18:41.390840 (MainThread): 09:18:41  Finished running 1 table model, 1 view model in 1.51s.
2022-01-05 09:18:41.390926 (MainThread): 09:18:41  Connection 'master' was properly closed.
2022-01-05 09:18:41.390997 (MainThread): 09:18:41  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-05 09:18:41.391062 (MainThread): 09:18:41  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-05 09:18:41.451709 (MainThread): 09:18:41  
2022-01-05 09:18:41.451936 (MainThread): 09:18:41  Completed successfully
2022-01-05 09:18:41.452035 (MainThread): 09:18:41  
2022-01-05 09:18:41.452123 (MainThread): 09:18:41  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2022-01-05 09:18:41.457290 (Thread-57): handling poll request
2022-01-05 09:18:41.457615 (Thread-57): 09:18:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec11c3a0>]}
2022-01-05 09:18:41.459158 (Thread-57): sending response (<Response 48497 bytes [200 OK]>) to 10.0.43.175
2022-01-05 09:18:42.836873 (Thread-58): handling poll request
2022-01-05 09:18:42.837274 (Thread-58): 09:18:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec11c940>]}
2022-01-05 09:18:42.838212 (Thread-58): sending response (<Response 6210 bytes [200 OK]>) to 10.0.9.20
2022-01-05 09:18:43.445916 (Thread-59): handling status request
2022-01-05 09:18:43.446332 (Thread-59): 09:18:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec07f580>]}
2022-01-05 09:18:43.447356 (Thread-59): sending response (<Response 15522 bytes [200 OK]>) to 10.0.40.203
2022-01-05 09:18:43.552650 (Thread-60): handling status request
2022-01-05 09:18:43.553053 (Thread-60): 09:18:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec07f970>]}
2022-01-05 09:18:43.553961 (Thread-60): sending response (<Response 15522 bytes [200 OK]>) to 10.0.18.33
2022-01-05 16:18:58.393119 (MainThread): Running with dbt=1.0.1
2022-01-05 16:18:58.494275 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-05 16:18:58.501451 (MainThread): Tracking: tracking
2022-01-05 16:18:58.521656 (MainThread): 16:18:58  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cdfb33c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0071a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0071d90>]}
2022-01-05 16:18:58.522055 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-05 16:18:58.522291 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-05 16:18:58.522425 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-05 16:18:58.566695 (Thread-12): 16:18:58  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 16:18:58.566930 (Thread-12): 16:18:58  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 16:18:58.573259 (Thread-12): 16:18:58  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fdf2e0>]}
2022-01-05 16:19:01.218865 (Thread-13): handling ps request
2022-01-05 16:19:01.219288 (Thread-13): 16:19:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd00d75b0>]}
2022-01-05 16:19:01.219847 (Thread-13): sending response (<Response 105 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:19:01.222694 (Thread-14): handling status request
2022-01-05 16:19:01.222956 (Thread-14): 16:19:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd00d7250>]}
2022-01-05 16:19:01.223385 (Thread-14): sending response (<Response 1241 bytes [200 OK]>) to 10.0.42.119
2022-01-05 16:19:01.307931 (Thread-15): handling status request
2022-01-05 16:19:01.308307 (Thread-15): 16:19:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd00d7070>]}
2022-01-05 16:19:01.308796 (Thread-15): sending response (<Response 1241 bytes [200 OK]>) to 10.0.38.111
2022-01-05 16:19:01.517449 (Thread-16): handling status request
2022-01-05 16:19:01.517826 (Thread-16): 16:19:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0119b20>]}
2022-01-05 16:19:01.518282 (Thread-16): sending response (<Response 1241 bytes [200 OK]>) to 10.0.46.191
2022-01-05 16:19:02.605573 (Thread-17): handling status request
2022-01-05 16:19:02.605950 (Thread-17): 16:19:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0071f40>]}
2022-01-05 16:19:02.606440 (Thread-17): sending response (<Response 1219 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:19:02.612856 (Thread-18): handling list request
2022-01-05 16:19:02.613183 (Thread-18): 16:19:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0071ac0>]}
2022-01-05 16:19:02.646100 (Thread-18): 16:19:02  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd00d7850>]}
2022-01-05 16:19:02.646497 (Thread-18): 16:19:02  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:19:02.649596 (Thread-18): 16:19:02  The selection criterion '+1641399542329/__unsaved/Statement' does not match any nodes
2022-01-05 16:19:02.649839 (Thread-18): 16:19:02  The selection criterion '1.sql+' does not match any nodes
2022-01-05 16:19:02.649956 (Thread-18): 16:19:02  No nodes selected!
2022-01-05 16:19:02.651784 (Thread-18): sending response (<Response 2343 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:19:35.647741 (Thread-19): handling status request
2022-01-05 16:19:35.648121 (Thread-19): 16:19:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fdf7c0>]}
2022-01-05 16:19:35.648644 (Thread-19): sending response (<Response 1241 bytes [200 OK]>) to 10.0.30.3
2022-01-05 16:19:35.666335 (Thread-20): handling status request
2022-01-05 16:19:35.666677 (Thread-20): 16:19:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fe81c0>]}
2022-01-05 16:19:35.667130 (Thread-20): sending response (<Response 1241 bytes [200 OK]>) to 10.0.19.216
2022-01-05 16:19:35.677318 (Thread-21): handling ps request
2022-01-05 16:19:35.677623 (Thread-21): 16:19:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fe8220>]}
2022-01-05 16:19:35.678125 (Thread-21): sending response (<Response 393 bytes [200 OK]>) to 10.0.42.85
2022-01-05 16:19:35.694513 (Thread-22): handling status request
2022-01-05 16:19:35.694872 (Thread-22): 16:19:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fe83d0>]}
2022-01-05 16:19:35.695325 (Thread-22): sending response (<Response 1241 bytes [200 OK]>) to 10.0.38.111
2022-01-05 16:19:36.553649 (Thread-23): handling status request
2022-01-05 16:19:36.554048 (Thread-23): 16:19:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fe88b0>]}
2022-01-05 16:19:36.554504 (Thread-23): sending response (<Response 1219 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:19:36.560954 (Thread-24): handling list request
2022-01-05 16:19:36.561286 (Thread-24): 16:19:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fe8b80>]}
2022-01-05 16:19:36.591181 (Thread-24): 16:19:36  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0071cd0>]}
2022-01-05 16:19:36.591719 (Thread-24): 16:19:36  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:19:36.595207 (Thread-24): 16:19:36  The selection criterion '+1641399576289/__unsaved/Statement' does not match any nodes
2022-01-05 16:19:36.595550 (Thread-24): 16:19:36  The selection criterion '1.sql+' does not match any nodes
2022-01-05 16:19:36.595730 (Thread-24): 16:19:36  No nodes selected!
2022-01-05 16:19:36.598319 (Thread-24): sending response (<Response 2343 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:20:08.480526 (Thread-25): handling status request
2022-01-05 16:20:08.480909 (Thread-25): 16:20:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb61c0>]}
2022-01-05 16:20:08.481362 (Thread-25): sending response (<Response 1219 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:20:08.495496 (Thread-26): handling list request
2022-01-05 16:20:08.495851 (Thread-26): 16:20:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb66d0>]}
2022-01-05 16:20:08.528099 (Thread-26): 16:20:08  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb8040>]}
2022-01-05 16:20:08.528507 (Thread-26): 16:20:08  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:20:08.532627 (Thread-26): 16:20:08  The selection criterion '+1641399576289/__unsaved/Statement' does not match any nodes
2022-01-05 16:20:08.532846 (Thread-26): 16:20:08  The selection criterion '1.sql+' does not match any nodes
2022-01-05 16:20:08.532962 (Thread-26): 16:20:08  No nodes selected!
2022-01-05 16:20:08.534640 (Thread-26): sending response (<Response 2343 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:20:13.521856 (Thread-27): handling status request
2022-01-05 16:20:13.522235 (Thread-27): 16:20:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb6f40>]}
2022-01-05 16:20:13.522717 (Thread-27): sending response (<Response 1241 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:20:13.969781 (Thread-28): handling run_sql request
2022-01-05 16:20:13.970165 (Thread-28): 16:20:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb8850>]}
2022-01-05 16:20:16.178208 (Thread-28): sending response (<Response 138 bytes [200 OK]>) to 10.0.19.216
2022-01-05 16:20:16.204513 (MainThread): 16:20:16  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2b6730dd-1335-4de8-b990-36a56e7cdccc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956d50aeb0>]}
2022-01-05 16:20:16.205166 (MainThread): 16:20:16  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:20:16.205816 (Thread-1): 16:20:16  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:20:16.205952 (Thread-1): 16:20:16  Began compiling node rpc.my_new_project.request
2022-01-05 16:20:16.206044 (Thread-1): 16:20:16  Compiling rpc.my_new_project.request
2022-01-05 16:20:16.207452 (Thread-1): 16:20:16  finished collecting timing info
2022-01-05 16:20:16.207592 (Thread-1): 16:20:16  Began executing node rpc.my_new_project.request
2022-01-05 16:20:16.207701 (Thread-1): 16:20:16  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:20:16.207788 (Thread-1): 16:20:16  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:20:16.207871 (Thread-1): 16:20:16  Opening a new connection, currently in state init
2022-01-05 16:20:16.207957 (Thread-1): 16:20:16  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:20:16.227781 (Thread-1): 16:20:16  Postgres adapter: Postgres error: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^

2022-01-05 16:20:16.228023 (Thread-1): 16:20:16  finished collecting timing info
2022-01-05 16:20:16.228174 (Thread-1): 16:20:16  On rpc.my_new_project.request: Close
2022-01-05 16:20:16.228526 (Thread-1): Got an exception: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
2022-01-05 16:20:16.229676 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 16:20:16.542413 (Thread-29): handling poll request
2022-01-05 16:20:16.542899 (Thread-29): 16:20:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0740be0>]}
2022-01-05 16:20:16.543773 (Thread-29): sending response (<Response 15966 bytes [200 OK]>) to 10.0.46.191
2022-01-05 16:27:27.433511 (Thread-30): 16:27:27  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-01-05 16:27:27.436013 (Thread-30): 16:27:27  Partial parsing: added file: my_new_project://models/dim_customers.sql
2022-01-05 16:27:27.447705 (Thread-30): 16:27:27  1699: static parser successfully parsed dim_customers.sql
2022-01-05 16:27:27.522204 (Thread-30): 16:27:27  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb06b57c0>]}
2022-01-05 16:27:28.015977 (Thread-31): handling status request
2022-01-05 16:27:28.016348 (Thread-31): 16:27:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd00d7b80>]}
2022-01-05 16:27:28.016881 (Thread-31): sending response (<Response 1550 bytes [200 OK]>) to 10.0.32.47
2022-01-05 16:27:28.080616 (Thread-32): handling status request
2022-01-05 16:27:28.080992 (Thread-32): 16:27:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb8d30>]}
2022-01-05 16:27:28.081472 (Thread-32): sending response (<Response 1550 bytes [200 OK]>) to 10.0.32.47
2022-01-05 16:27:49.104245 (Thread-33): handling status request
2022-01-05 16:27:49.104668 (Thread-33): 16:27:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0100b50>]}
2022-01-05 16:27:49.105150 (Thread-33): sending response (<Response 1550 bytes [200 OK]>) to 10.0.10.137
2022-01-05 16:27:49.493307 (Thread-34): handling run_sql request
2022-01-05 16:27:49.493676 (Thread-34): 16:27:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb07548b0>]}
2022-01-05 16:27:51.661758 (Thread-34): sending response (<Response 138 bytes [200 OK]>) to 10.0.32.67
2022-01-05 16:27:51.687151 (MainThread): 16:27:51  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1f0a8b83-a905-4338-b9f4-9aede296d085', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f027f8a3160>]}
2022-01-05 16:27:51.687783 (MainThread): 16:27:51  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:27:51.688437 (Thread-1): 16:27:51  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:27:51.688614 (Thread-1): 16:27:51  Began compiling node rpc.my_new_project.request
2022-01-05 16:27:51.688717 (Thread-1): 16:27:51  Compiling rpc.my_new_project.request
2022-01-05 16:27:51.690111 (Thread-1): 16:27:51  finished collecting timing info
2022-01-05 16:27:51.690255 (Thread-1): 16:27:51  Began executing node rpc.my_new_project.request
2022-01-05 16:27:51.690375 (Thread-1): 16:27:51  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:27:51.690462 (Thread-1): 16:27:51  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:27:51.690553 (Thread-1): 16:27:51  Opening a new connection, currently in state init
2022-01-05 16:27:51.690641 (Thread-1): 16:27:51  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:27:51.709561 (Thread-1): 16:27:51  Postgres adapter: Postgres error: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^

2022-01-05 16:27:51.709799 (Thread-1): 16:27:51  finished collecting timing info
2022-01-05 16:27:51.709959 (Thread-1): 16:27:51  On rpc.my_new_project.request: Close
2022-01-05 16:27:51.710231 (Thread-1): Got an exception: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
2022-01-05 16:27:51.711336 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 16:27:52.059880 (Thread-35): handling poll request
2022-01-05 16:27:52.060336 (Thread-35): 16:27:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb06b1490>]}
2022-01-05 16:27:52.061229 (Thread-35): sending response (<Response 15951 bytes [200 OK]>) to 10.0.38.111
2022-01-05 16:30:42.878891 (MainThread): Running with dbt=1.0.1
2022-01-05 16:30:42.976404 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-05 16:30:42.983115 (MainThread): Tracking: tracking
2022-01-05 16:30:43.003156 (MainThread): 16:30:43  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bf2b0bb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7be404f520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7be404f280>]}
2022-01-05 16:30:43.003512 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-05 16:30:43.003821 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-05 16:30:43.003957 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-05 16:30:43.018552 (Thread-12): 16:30:43  Unable to do partial parsing because profile has changed
2022-01-05 16:30:43.018843 (Thread-12): 16:30:43  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7be404fd00>]}
2022-01-05 16:30:43.055555 (Thread-12): 16:30:43  Parsing macros/catalog.sql
2022-01-05 16:30:43.068110 (Thread-12): 16:30:43  Parsing macros/adapters.sql
2022-01-05 16:30:43.095307 (Thread-12): 16:30:43  Parsing macros/relations.sql
2022-01-05 16:30:43.095891 (Thread-12): 16:30:43  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 16:30:43.096521 (Thread-12): 16:30:43  Parsing macros/catalog.sql
2022-01-05 16:30:43.098590 (Thread-12): 16:30:43  Parsing macros/adapters.sql
2022-01-05 16:30:43.119563 (Thread-12): 16:30:43  Parsing macros/relations.sql
2022-01-05 16:30:43.120863 (Thread-12): 16:30:43  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 16:30:43.122444 (Thread-12): 16:30:43  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-05 16:30:43.123904 (Thread-12): 16:30:43  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-05 16:30:43.125429 (Thread-12): 16:30:43  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-05 16:30:43.127813 (Thread-12): 16:30:43  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-05 16:30:43.129169 (Thread-12): 16:30:43  Parsing macros/generic_test_sql/not_null.sql
2022-01-05 16:30:43.129739 (Thread-12): 16:30:43  Parsing macros/generic_test_sql/relationships.sql
2022-01-05 16:30:43.130613 (Thread-12): 16:30:43  Parsing macros/generic_test_sql/unique.sql
2022-01-05 16:30:43.131339 (Thread-12): 16:30:43  Parsing macros/materializations/configs.sql
2022-01-05 16:30:43.133657 (Thread-12): 16:30:43  Parsing macros/materializations/hooks.sql
2022-01-05 16:30:43.137487 (Thread-12): 16:30:43  Parsing macros/materializations/snapshots/strategies.sql
2022-01-05 16:30:43.153319 (Thread-12): 16:30:43  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-05 16:30:43.154894 (Thread-12): 16:30:43  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-05 16:30:43.165571 (Thread-12): 16:30:43  Parsing macros/materializations/snapshots/helpers.sql
2022-01-05 16:30:43.176088 (Thread-12): 16:30:43  Parsing macros/materializations/seeds/seed.sql
2022-01-05 16:30:43.181729 (Thread-12): 16:30:43  Parsing macros/materializations/seeds/helpers.sql
2022-01-05 16:30:43.196895 (Thread-12): 16:30:43  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-05 16:30:43.199103 (Thread-12): 16:30:43  Parsing macros/materializations/models/view/view.sql
2022-01-05 16:30:43.205581 (Thread-12): 16:30:43  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-05 16:30:43.208160 (Thread-12): 16:30:43  Parsing macros/materializations/models/view/helpers.sql
2022-01-05 16:30:43.209445 (Thread-12): 16:30:43  Parsing macros/materializations/models/table/table.sql
2022-01-05 16:30:43.216297 (Thread-12): 16:30:43  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-05 16:30:43.219061 (Thread-12): 16:30:43  Parsing macros/materializations/models/incremental/merge.sql
2022-01-05 16:30:43.229668 (Thread-12): 16:30:43  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-05 16:30:43.244218 (Thread-12): 16:30:43  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-05 16:30:43.248474 (Thread-12): 16:30:43  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-05 16:30:43.257913 (Thread-12): 16:30:43  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-05 16:30:43.259393 (Thread-12): 16:30:43  Parsing macros/materializations/tests/test.sql
2022-01-05 16:30:43.263580 (Thread-12): 16:30:43  Parsing macros/materializations/tests/where_subquery.sql
2022-01-05 16:30:43.265308 (Thread-12): 16:30:43  Parsing macros/materializations/tests/helpers.sql
2022-01-05 16:30:43.266981 (Thread-12): 16:30:43  Parsing macros/etc/statement.sql
2022-01-05 16:30:43.271230 (Thread-12): 16:30:43  Parsing macros/etc/datetime.sql
2022-01-05 16:30:43.279336 (Thread-12): 16:30:43  Parsing macros/adapters/indexes.sql
2022-01-05 16:30:43.281928 (Thread-12): 16:30:43  Parsing macros/adapters/persist_docs.sql
2022-01-05 16:30:43.286130 (Thread-12): 16:30:43  Parsing macros/adapters/freshness.sql
2022-01-05 16:30:43.288969 (Thread-12): 16:30:43  Parsing macros/adapters/relation.sql
2022-01-05 16:30:43.298016 (Thread-12): 16:30:43  Parsing macros/adapters/metadata.sql
2022-01-05 16:30:43.304840 (Thread-12): 16:30:43  Parsing macros/adapters/columns.sql
2022-01-05 16:30:43.314256 (Thread-12): 16:30:43  Parsing macros/adapters/schema.sql
2022-01-05 16:30:43.316415 (Thread-12): 16:30:43  Parsing tests/generic/builtin.sql
2022-01-05 16:30:43.505433 (Thread-12): 16:30:43  1699: static parser successfully parsed dim_customers.sql
2022-01-05 16:30:43.517300 (Thread-12): 16:30:43  1699: static parser successfully parsed example/my_second_dbt_model.sql
2022-01-05 16:30:43.519507 (Thread-12): 16:30:43  1699: static parser successfully parsed example/my_first_dbt_model.sql
2022-01-05 16:30:43.611272 (Thread-12): 16:30:43  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc7ba0d0>]}
2022-01-05 16:30:44.812352 (Thread-13): handling status request
2022-01-05 16:30:44.812725 (Thread-13): 16:30:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc183970>]}
2022-01-05 16:30:44.813673 (Thread-13): sending response (<Response 15820 bytes [200 OK]>) to 10.0.30.3
2022-01-05 16:30:44.847893 (Thread-14): handling status request
2022-01-05 16:30:44.848502 (Thread-14): 16:30:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc183460>]}
2022-01-05 16:30:44.849342 (Thread-14): sending response (<Response 15820 bytes [200 OK]>) to 10.0.46.191
2022-01-05 16:30:44.860788 (Thread-15): handling ps request
2022-01-05 16:30:44.876475 (Thread-15): 16:30:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc183850>]}
2022-01-05 16:30:44.876938 (Thread-15): sending response (<Response 105 bytes [200 OK]>) to 10.0.5.1
2022-01-05 16:30:44.976647 (Thread-16): handling status request
2022-01-05 16:30:44.977031 (Thread-16): 16:30:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7be40b4e20>]}
2022-01-05 16:30:44.977865 (Thread-16): sending response (<Response 15820 bytes [200 OK]>) to 10.0.20.28
2022-01-05 16:31:12.937901 (Thread-17): handling status request
2022-01-05 16:31:12.939374 (Thread-17): 16:31:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc183f10>]}
2022-01-05 16:31:12.940283 (Thread-17): sending response (<Response 15820 bytes [200 OK]>) to 10.0.6.188
2022-01-05 16:31:13.297265 (Thread-18): handling run_sql request
2022-01-05 16:31:13.297618 (Thread-18): 16:31:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7be40885e0>]}
2022-01-05 16:31:15.373069 (Thread-18): sending response (<Response 138 bytes [200 OK]>) to 10.0.32.47
2022-01-05 16:31:15.397039 (MainThread): 16:31:15  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8f1d7668-1c99-48ae-8386-4f145f2c2b67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6151640e80>]}
2022-01-05 16:31:15.397583 (MainThread): 16:31:15  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:31:15.398163 (Thread-1): 16:31:15  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:31:15.398293 (Thread-1): 16:31:15  Began compiling node rpc.my_new_project.request
2022-01-05 16:31:15.398383 (Thread-1): 16:31:15  Compiling rpc.my_new_project.request
2022-01-05 16:31:15.399580 (Thread-1): 16:31:15  finished collecting timing info
2022-01-05 16:31:15.399708 (Thread-1): 16:31:15  Began executing node rpc.my_new_project.request
2022-01-05 16:31:15.399809 (Thread-1): 16:31:15  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:31:15.399888 (Thread-1): 16:31:15  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:31:15.399967 (Thread-1): 16:31:15  Opening a new connection, currently in state init
2022-01-05 16:31:15.400047 (Thread-1): 16:31:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:31:15.411891 (Thread-1): 16:31:15  Postgres adapter: Got an error when attempting to open a postgres connection: 'FATAL:  database "Serverless/dev" does not exist
'
2022-01-05 16:31:15.412031 (Thread-1): 16:31:15  Postgres adapter: Error running SQL: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:31:15.412105 (Thread-1): 16:31:15  Postgres adapter: Rolling back transaction.
2022-01-05 16:31:15.412201 (Thread-1): 16:31:15  finished collecting timing info
2022-01-05 16:31:15.412319 (Thread-1): 16:31:15  On rpc.my_new_project.request: No close available on handle
2022-01-05 16:31:15.412383 (Thread-1): Got an exception: Database Error
  FATAL:  database "Serverless/dev" does not exist
  
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 121, in open
    handle = psycopg2.connect(
  File "/usr/local/lib/python3.8/dist-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: FATAL:  database "Serverless/dev" does not exist


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 73, in add_query
    cursor = connection.handle.cursor()
  File "/usr/local/lib/python3.8/dist-packages/dbt/contracts/connection.py", line 83, in handle
    self._handle.resolve(self)
  File "/usr/local/lib/python3.8/dist-packages/dbt/contracts/connection.py", line 106, in resolve
    return self.opener(connection)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 143, in open
    raise dbt.exceptions.FailedToConnectException(str(e))
dbt.exceptions.FailedToConnectException: Database Error
  FATAL:  database "Serverless/dev" does not exist
2022-01-05 16:31:15.413610 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'FailedToConnectException', 'message': 'Database Error in rpc request (from remote system)\n  FATAL:  database "Serverless/dev" does not exist\n  ', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'FailedToConnectException', 'message': 'Database Error in rpc request (from remote system)\n  FATAL:  database "Serverless/dev" does not exist\n  ', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 16:31:15.717223 (Thread-19): handling poll request
2022-01-05 16:31:15.717656 (Thread-19): 16:31:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc183460>]}
2022-01-05 16:31:15.718527 (Thread-19): sending response (<Response 17444 bytes [200 OK]>) to 10.0.42.85
2022-01-05 16:39:15.648211 (MainThread): Running with dbt=1.0.1
2022-01-05 16:39:15.739482 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-05 16:39:15.745897 (MainThread): Tracking: tracking
2022-01-05 16:39:15.765400 (MainThread): 16:39:15  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0af913fcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae46471c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4647250>]}
2022-01-05 16:39:15.765818 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-05 16:39:15.766128 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-05 16:39:15.766375 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-05 16:39:15.783436 (Thread-12): 16:39:15  Unable to do partial parsing because profile has changed
2022-01-05 16:39:15.783721 (Thread-12): 16:39:15  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4647f40>]}
2022-01-05 16:39:15.812470 (Thread-12): 16:39:15  Parsing macros/catalog.sql
2022-01-05 16:39:15.824739 (Thread-12): 16:39:15  Parsing macros/adapters.sql
2022-01-05 16:39:15.851320 (Thread-12): 16:39:15  Parsing macros/relations.sql
2022-01-05 16:39:15.851874 (Thread-12): 16:39:15  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 16:39:15.852476 (Thread-12): 16:39:15  Parsing macros/catalog.sql
2022-01-05 16:39:15.854502 (Thread-12): 16:39:15  Parsing macros/adapters.sql
2022-01-05 16:39:15.875090 (Thread-12): 16:39:15  Parsing macros/relations.sql
2022-01-05 16:39:15.876314 (Thread-12): 16:39:15  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 16:39:15.877872 (Thread-12): 16:39:15  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-05 16:39:15.879272 (Thread-12): 16:39:15  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-05 16:39:15.880838 (Thread-12): 16:39:15  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-05 16:39:15.883157 (Thread-12): 16:39:15  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-05 16:39:15.884458 (Thread-12): 16:39:15  Parsing macros/generic_test_sql/not_null.sql
2022-01-05 16:39:15.885006 (Thread-12): 16:39:15  Parsing macros/generic_test_sql/relationships.sql
2022-01-05 16:39:15.885848 (Thread-12): 16:39:15  Parsing macros/generic_test_sql/unique.sql
2022-01-05 16:39:15.886517 (Thread-12): 16:39:15  Parsing macros/materializations/configs.sql
2022-01-05 16:39:15.888675 (Thread-12): 16:39:15  Parsing macros/materializations/hooks.sql
2022-01-05 16:39:15.892643 (Thread-12): 16:39:15  Parsing macros/materializations/snapshots/strategies.sql
2022-01-05 16:39:15.908294 (Thread-12): 16:39:15  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-05 16:39:15.909915 (Thread-12): 16:39:15  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-05 16:39:15.920676 (Thread-12): 16:39:15  Parsing macros/materializations/snapshots/helpers.sql
2022-01-05 16:39:15.930922 (Thread-12): 16:39:15  Parsing macros/materializations/seeds/seed.sql
2022-01-05 16:39:15.936404 (Thread-12): 16:39:15  Parsing macros/materializations/seeds/helpers.sql
2022-01-05 16:39:15.951479 (Thread-12): 16:39:15  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-05 16:39:15.953669 (Thread-12): 16:39:15  Parsing macros/materializations/models/view/view.sql
2022-01-05 16:39:15.960107 (Thread-12): 16:39:15  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-05 16:39:15.962643 (Thread-12): 16:39:15  Parsing macros/materializations/models/view/helpers.sql
2022-01-05 16:39:15.963902 (Thread-12): 16:39:15  Parsing macros/materializations/models/table/table.sql
2022-01-05 16:39:15.970722 (Thread-12): 16:39:15  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-05 16:39:15.973406 (Thread-12): 16:39:15  Parsing macros/materializations/models/incremental/merge.sql
2022-01-05 16:39:15.983881 (Thread-12): 16:39:15  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-05 16:39:15.998085 (Thread-12): 16:39:15  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-05 16:39:16.002311 (Thread-12): 16:39:16  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-05 16:39:16.011674 (Thread-12): 16:39:16  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-05 16:39:16.013090 (Thread-12): 16:39:16  Parsing macros/materializations/tests/test.sql
2022-01-05 16:39:16.017173 (Thread-12): 16:39:16  Parsing macros/materializations/tests/where_subquery.sql
2022-01-05 16:39:16.018889 (Thread-12): 16:39:16  Parsing macros/materializations/tests/helpers.sql
2022-01-05 16:39:16.020625 (Thread-12): 16:39:16  Parsing macros/etc/statement.sql
2022-01-05 16:39:16.024741 (Thread-12): 16:39:16  Parsing macros/etc/datetime.sql
2022-01-05 16:39:16.032723 (Thread-12): 16:39:16  Parsing macros/adapters/indexes.sql
2022-01-05 16:39:16.035236 (Thread-12): 16:39:16  Parsing macros/adapters/persist_docs.sql
2022-01-05 16:39:16.039379 (Thread-12): 16:39:16  Parsing macros/adapters/freshness.sql
2022-01-05 16:39:16.042166 (Thread-12): 16:39:16  Parsing macros/adapters/relation.sql
2022-01-05 16:39:16.051134 (Thread-12): 16:39:16  Parsing macros/adapters/metadata.sql
2022-01-05 16:39:16.057781 (Thread-12): 16:39:16  Parsing macros/adapters/columns.sql
2022-01-05 16:39:16.067020 (Thread-12): 16:39:16  Parsing macros/adapters/schema.sql
2022-01-05 16:39:16.069128 (Thread-12): 16:39:16  Parsing tests/generic/builtin.sql
2022-01-05 16:39:16.256897 (Thread-12): 16:39:16  1699: static parser successfully parsed dim_customers.sql
2022-01-05 16:39:16.268697 (Thread-12): 16:39:16  1699: static parser successfully parsed example/my_second_dbt_model.sql
2022-01-05 16:39:16.271022 (Thread-12): 16:39:16  1699: static parser successfully parsed example/my_first_dbt_model.sql
2022-01-05 16:39:16.370848 (Thread-12): 16:39:16  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae46209a0>]}
2022-01-05 16:39:17.928096 (Thread-13): handling status request
2022-01-05 16:39:17.928624 (Thread-13): 16:39:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45eb7c0>]}
2022-01-05 16:39:17.929847 (Thread-13): sending response (<Response 15820 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:39:17.939921 (Thread-14): handling status request
2022-01-05 16:39:17.940168 (Thread-14): 16:39:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4631c40>]}
2022-01-05 16:39:17.940913 (Thread-14): sending response (<Response 15820 bytes [200 OK]>) to 10.0.26.162
2022-01-05 16:39:17.949081 (Thread-15): handling ps request
2022-01-05 16:39:17.949360 (Thread-15): 16:39:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45c5820>]}
2022-01-05 16:39:17.949756 (Thread-15): sending response (<Response 105 bytes [200 OK]>) to 10.0.17.156
2022-01-05 16:39:17.964225 (Thread-16): handling status request
2022-01-05 16:39:17.964478 (Thread-16): 16:39:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae461e250>]}
2022-01-05 16:39:17.965217 (Thread-16): sending response (<Response 15820 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:39:50.871565 (Thread-17): handling status request
2022-01-05 16:39:50.872878 (Thread-17): 16:39:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae468f820>]}
2022-01-05 16:39:50.873813 (Thread-17): sending response (<Response 15820 bytes [200 OK]>) to 10.0.10.137
2022-01-05 16:39:51.223488 (Thread-18): handling run_sql request
2022-01-05 16:39:51.223867 (Thread-18): 16:39:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae468f670>]}
2022-01-05 16:39:53.278617 (Thread-18): sending response (<Response 138 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:39:53.303559 (MainThread): 16:39:53  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f31d62f7-8c41-42e9-8cf0-fa130dfe55ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22c0a841c0>]}
2022-01-05 16:39:53.304112 (MainThread): 16:39:53  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:39:53.304713 (Thread-1): 16:39:53  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:39:53.304846 (Thread-1): 16:39:53  Began compiling node rpc.my_new_project.request
2022-01-05 16:39:53.304936 (Thread-1): 16:39:53  Compiling rpc.my_new_project.request
2022-01-05 16:39:53.306112 (Thread-1): 16:39:53  finished collecting timing info
2022-01-05 16:39:53.306239 (Thread-1): 16:39:53  Began executing node rpc.my_new_project.request
2022-01-05 16:39:53.306337 (Thread-1): 16:39:53  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:39:53.306416 (Thread-1): 16:39:53  On rpc.my_new_project.request: create table jaffle_shop.customers(
  id integer,
  first_name varchar(50),
  last_name varchar(50)
);
	
create table jaffle_shop.orders(
  id integer,
  user_id integer,
  order_date date,
  status varchar(50),
  _etl_loaded_at timestamp default current_timestamp
);
	
create table stripe.payment(
  id integer,
  orderid integer,
  paymentmethod varchar(50),
  status varchar(50),
  amount integer,
  created date,
  _batched_at timestamp default current_timestamp
);




copy jaffle_shop.customers( id, first_name, last_name)
from 's3://dbt-tutorial-public/jaffle_shop_customers.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;



copy jaffle_shop.orders(id, user_id, order_date, status)
from 's3://dbt-tutorial-public/jaffle_shop_orders.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;

copy stripe.payment(id, orderid, paymentmethod, status, amount, created)
from 's3://dbt-tutorial-public/stripe_payments.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:39:53.306497 (Thread-1): 16:39:53  Opening a new connection, currently in state init
2022-01-05 16:39:53.306582 (Thread-1): 16:39:53  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:39:53.328406 (Thread-1): 16:39:53  Postgres adapter: Postgres error: schema "jaffle_shop" does not exist

2022-01-05 16:39:53.328568 (Thread-1): 16:39:53  finished collecting timing info
2022-01-05 16:39:53.328701 (Thread-1): 16:39:53  On rpc.my_new_project.request: Close
2022-01-05 16:39:53.328891 (Thread-1): Got an exception: Database Error
  schema "jaffle_shop" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidSchemaName: schema "jaffle_shop" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  schema "jaffle_shop" does not exist
2022-01-05 16:39:53.330092 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-01-05 16:39:53.700224 (Thread-19): handling poll request
2022-01-05 16:39:53.700677 (Thread-19): 16:39:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4631a30>]}
2022-01-05 16:39:53.701577 (Thread-19): sending response (<Response 18587 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:41:40.881062 (Thread-20): handling status request
2022-01-05 16:41:40.882660 (Thread-20): 16:41:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4183520>]}
2022-01-05 16:41:40.883603 (Thread-20): sending response (<Response 15820 bytes [200 OK]>) to 10.0.18.253
2022-01-05 16:41:41.485872 (Thread-21): handling run_sql request
2022-01-05 16:41:41.486261 (Thread-21): 16:41:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4183df0>]}
2022-01-05 16:41:43.559538 (Thread-21): sending response (<Response 138 bytes [200 OK]>) to 10.0.17.156
2022-01-05 16:41:43.586034 (MainThread): 16:41:43  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6665cc01-c3d7-4ede-9785-71af86e1a55f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29e0344280>]}
2022-01-05 16:41:43.586594 (MainThread): 16:41:43  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:41:43.587195 (Thread-1): 16:41:43  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:41:43.587325 (Thread-1): 16:41:43  Began compiling node rpc.my_new_project.request
2022-01-05 16:41:43.587415 (Thread-1): 16:41:43  Compiling rpc.my_new_project.request
2022-01-05 16:41:43.588545 (Thread-1): 16:41:43  finished collecting timing info
2022-01-05 16:41:43.588668 (Thread-1): 16:41:43  Began executing node rpc.my_new_project.request
2022-01-05 16:41:43.588769 (Thread-1): 16:41:43  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:41:43.588846 (Thread-1): 16:41:43  On rpc.my_new_project.request: create schema if not exists jaffle_shop;
	
create schema if not exists stripe;


create table jaffle_shop.customers(
  id integer,
  first_name varchar(50),
  last_name varchar(50)
);
	
create table jaffle_shop.orders(
  id integer,
  user_id integer,
  order_date date,
  status varchar(50),
  _etl_loaded_at timestamp default current_timestamp
);
	
create table stripe.payment(
  id integer,
  orderid integer,
  paymentmethod varchar(50),
  status varchar(50),
  amount integer,
  created date,
  _batched_at timestamp default current_timestamp
);




copy jaffle_shop.customers( id, first_name, last_name)
from 's3://dbt-tutorial-public/jaffle_shop_customers.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;



copy jaffle_shop.orders(id, user_id, order_date, status)
from 's3://dbt-tutorial-public/jaffle_shop_orders.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;

copy stripe.payment(id, orderid, paymentmethod, status, amount, created)
from 's3://dbt-tutorial-public/stripe_payments.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:41:43.588924 (Thread-1): 16:41:43  Opening a new connection, currently in state init
2022-01-05 16:41:43.589006 (Thread-1): 16:41:43  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:41:43.615589 (Thread-1): 16:41:43  Postgres adapter: Postgres error: schema "jaffle_shop" does not exist

2022-01-05 16:41:43.615751 (Thread-1): 16:41:43  finished collecting timing info
2022-01-05 16:41:43.615878 (Thread-1): 16:41:43  On rpc.my_new_project.request: Close
2022-01-05 16:41:43.616053 (Thread-1): Got an exception: Database Error
  schema "jaffle_shop" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidSchemaName: schema "jaffle_shop" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  schema "jaffle_shop" does not exist
2022-01-05 16:41:43.617146 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create schema if not exists jaffle_shop;\n\t\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create schema if not exists jaffle_shop;\n\t\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create schema if not exists jaffle_shop;\n\t\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create schema if not exists jaffle_shop;\n\t\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-01-05 16:41:44.027452 (Thread-22): handling poll request
2022-01-05 16:41:44.027905 (Thread-22): 16:41:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae46ab610>]}
2022-01-05 16:41:44.028771 (Thread-22): sending response (<Response 19220 bytes [200 OK]>) to 10.0.20.28
2022-01-05 16:42:09.542678 (Thread-23): handling status request
2022-01-05 16:42:09.544284 (Thread-23): 16:42:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae46abf10>]}
2022-01-05 16:42:09.545242 (Thread-23): sending response (<Response 15820 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:42:09.929808 (Thread-24): handling run_sql request
2022-01-05 16:42:09.930081 (Thread-24): 16:42:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45d3100>]}
2022-01-05 16:42:11.984256 (Thread-24): sending response (<Response 138 bytes [200 OK]>) to 10.0.30.3
2022-01-05 16:42:12.008081 (MainThread): 16:42:12  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '516653f5-0fc2-427c-8606-9f8e141f7c4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f580ad1d280>]}
2022-01-05 16:42:12.008607 (MainThread): 16:42:12  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:42:12.009187 (Thread-1): 16:42:12  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:42:12.009368 (Thread-1): 16:42:12  Began compiling node rpc.my_new_project.request
2022-01-05 16:42:12.009535 (Thread-1): 16:42:12  Compiling rpc.my_new_project.request
2022-01-05 16:42:12.010738 (Thread-1): 16:42:12  finished collecting timing info
2022-01-05 16:42:12.010865 (Thread-1): 16:42:12  Began executing node rpc.my_new_project.request
2022-01-05 16:42:12.010980 (Thread-1): 16:42:12  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:42:12.011066 (Thread-1): 16:42:12  On rpc.my_new_project.request: create schema if not exists jaffle_shop;
create schema if not exists stripe;


create table jaffle_shop.customers(
  id integer,
  first_name varchar(50),
  last_name varchar(50)
);
	
create table jaffle_shop.orders(
  id integer,
  user_id integer,
  order_date date,
  status varchar(50),
  _etl_loaded_at timestamp default current_timestamp
);
	
create table stripe.payment(
  id integer,
  orderid integer,
  paymentmethod varchar(50),
  status varchar(50),
  amount integer,
  created date,
  _batched_at timestamp default current_timestamp
);




copy jaffle_shop.customers( id, first_name, last_name)
from 's3://dbt-tutorial-public/jaffle_shop_customers.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;



copy jaffle_shop.orders(id, user_id, order_date, status)
from 's3://dbt-tutorial-public/jaffle_shop_orders.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;

copy stripe.payment(id, orderid, paymentmethod, status, amount, created)
from 's3://dbt-tutorial-public/stripe_payments.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:42:12.011150 (Thread-1): 16:42:12  Opening a new connection, currently in state init
2022-01-05 16:42:12.011236 (Thread-1): 16:42:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:42:12.034460 (Thread-1): 16:42:12  Postgres adapter: Postgres error: schema "jaffle_shop" does not exist

2022-01-05 16:42:12.034643 (Thread-1): 16:42:12  finished collecting timing info
2022-01-05 16:42:12.034784 (Thread-1): 16:42:12  On rpc.my_new_project.request: Close
2022-01-05 16:42:12.035078 (Thread-1): Got an exception: Database Error
  schema "jaffle_shop" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidSchemaName: schema "jaffle_shop" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  schema "jaffle_shop" does not exist
2022-01-05 16:42:12.036085 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create schema if not exists jaffle_shop;\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create schema if not exists jaffle_shop;\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create schema if not exists jaffle_shop;\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create schema if not exists jaffle_shop;\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-01-05 16:42:12.369185 (Thread-25): handling poll request
2022-01-05 16:42:12.369671 (Thread-25): 16:42:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae46222e0>]}
2022-01-05 16:42:12.370502 (Thread-25): sending response (<Response 19184 bytes [200 OK]>) to 10.0.32.67
2022-01-05 16:45:55.591816 (Thread-26): handling status request
2022-01-05 16:45:55.593518 (Thread-26): 16:45:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45be6a0>]}
2022-01-05 16:45:55.594475 (Thread-26): sending response (<Response 15820 bytes [200 OK]>) to 10.0.26.162
2022-01-05 16:45:56.024551 (Thread-27): handling run_sql request
2022-01-05 16:45:56.024960 (Thread-27): 16:45:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45befa0>]}
2022-01-05 16:45:58.156122 (Thread-27): sending response (<Response 138 bytes [200 OK]>) to 10.0.10.137
2022-01-05 16:45:58.181584 (MainThread): 16:45:58  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ba7393da-844d-4c5b-b182-0a0f9652e91c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ecd0001f0>]}
2022-01-05 16:45:58.182121 (MainThread): 16:45:58  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:45:58.182733 (Thread-1): 16:45:58  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:45:58.182865 (Thread-1): 16:45:58  Began compiling node rpc.my_new_project.request
2022-01-05 16:45:58.182953 (Thread-1): 16:45:58  Compiling rpc.my_new_project.request
2022-01-05 16:45:58.184088 (Thread-1): 16:45:58  finished collecting timing info
2022-01-05 16:45:58.184214 (Thread-1): 16:45:58  Began executing node rpc.my_new_project.request
2022-01-05 16:45:58.184312 (Thread-1): 16:45:58  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:45:58.184395 (Thread-1): 16:45:58  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:45:58.184475 (Thread-1): 16:45:58  Opening a new connection, currently in state init
2022-01-05 16:45:58.184557 (Thread-1): 16:45:58  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:45:58.212360 (Thread-1): 16:45:58  Postgres adapter: Postgres error: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^

2022-01-05 16:45:58.212560 (Thread-1): 16:45:58  finished collecting timing info
2022-01-05 16:45:58.212704 (Thread-1): 16:45:58  On rpc.my_new_project.request: Close
2022-01-05 16:45:58.212904 (Thread-1): Got an exception: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
2022-01-05 16:45:58.214091 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 16:45:58.558893 (Thread-28): handling poll request
2022-01-05 16:45:58.559396 (Thread-28): 16:45:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45eed00>]}
2022-01-05 16:45:58.560262 (Thread-28): sending response (<Response 15951 bytes [200 OK]>) to 10.0.38.111
2022-01-05 16:46:45.865147 (Thread-29): handling status request
2022-01-05 16:46:45.865585 (Thread-29): 16:46:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae41525b0>]}
2022-01-05 16:46:45.866555 (Thread-29): sending response (<Response 15820 bytes [200 OK]>) to 10.0.6.188
2022-01-05 16:46:46.311105 (Thread-30): handling run_sql request
2022-01-05 16:46:46.311512 (Thread-30): 16:46:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45ee400>]}
2022-01-05 16:46:48.377682 (Thread-30): sending response (<Response 138 bytes [200 OK]>) to 10.0.19.216
2022-01-05 16:46:48.401169 (MainThread): 16:46:48  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dd52ea4c-3fa5-4ce4-a507-e05bdb90f89a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d75e3a1c0>]}
2022-01-05 16:46:48.401730 (MainThread): 16:46:48  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:46:48.402302 (Thread-1): 16:46:48  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:46:48.402431 (Thread-1): 16:46:48  Began compiling node rpc.my_new_project.request
2022-01-05 16:46:48.402522 (Thread-1): 16:46:48  Compiling rpc.my_new_project.request
2022-01-05 16:46:48.403672 (Thread-1): 16:46:48  finished collecting timing info
2022-01-05 16:46:48.403801 (Thread-1): 16:46:48  Began executing node rpc.my_new_project.request
2022-01-05 16:46:48.403904 (Thread-1): 16:46:48  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:46:48.403982 (Thread-1): 16:46:48  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from dev.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from dev.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:46:48.404061 (Thread-1): 16:46:48  Opening a new connection, currently in state init
2022-01-05 16:46:48.404143 (Thread-1): 16:46:48  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:46:48.710458 (Thread-1): 16:46:48  SQL status: SELECT in 0.31 seconds
2022-01-05 16:46:48.711577 (Thread-1): 16:46:48  finished collecting timing info
2022-01-05 16:46:48.711747 (Thread-1): 16:46:48  On rpc.my_new_project.request: Close
2022-01-05 16:46:48.771036 (Thread-31): handling poll request
2022-01-05 16:46:48.771480 (Thread-31): 16:46:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4191850>]}
2022-01-05 16:46:48.772345 (Thread-31): sending response (<Response 5941 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:46:50.210348 (Thread-32): handling poll request
2022-01-05 16:46:50.210730 (Thread-32): 16:46:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4191910>]}
2022-01-05 16:46:50.211890 (Thread-32): sending response (<Response 6204 bytes [200 OK]>) to 10.0.10.137
2022-01-05 16:47:06.349240 (Thread-33): handling status request
2022-01-05 16:47:06.349704 (Thread-33): 16:47:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4191a30>]}
2022-01-05 16:47:06.350656 (Thread-33): sending response (<Response 15820 bytes [200 OK]>) to 10.0.30.3
2022-01-05 16:47:06.795521 (Thread-34): handling run_sql request
2022-01-05 16:47:06.795892 (Thread-34): 16:47:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae414d3d0>]}
2022-01-05 16:47:08.863842 (Thread-34): sending response (<Response 138 bytes [200 OK]>) to 10.0.32.67
2022-01-05 16:47:08.890748 (MainThread): 16:47:08  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cc0580c8-00ce-45ae-b957-d7d4dc307db9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7848df8280>]}
2022-01-05 16:47:08.891308 (MainThread): 16:47:08  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:47:08.891883 (Thread-1): 16:47:08  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:47:08.892013 (Thread-1): 16:47:08  Began compiling node rpc.my_new_project.request
2022-01-05 16:47:08.892101 (Thread-1): 16:47:08  Compiling rpc.my_new_project.request
2022-01-05 16:47:08.893311 (Thread-1): 16:47:08  finished collecting timing info
2022-01-05 16:47:08.893513 (Thread-1): 16:47:08  Began executing node rpc.my_new_project.request
2022-01-05 16:47:08.893652 (Thread-1): 16:47:08  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:47:08.893739 (Thread-1): 16:47:08  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from dev.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from dev.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:47:08.893848 (Thread-1): 16:47:08  Opening a new connection, currently in state init
2022-01-05 16:47:08.893941 (Thread-1): 16:47:08  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:47:08.916921 (Thread-1): 16:47:08  SQL status: SELECT in 0.02 seconds
2022-01-05 16:47:08.917927 (Thread-1): 16:47:08  finished collecting timing info
2022-01-05 16:47:08.918066 (Thread-1): 16:47:08  On rpc.my_new_project.request: Close
2022-01-05 16:47:09.255197 (Thread-35): handling poll request
2022-01-05 16:47:09.255629 (Thread-35): 16:47:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae415abb0>]}
2022-01-05 16:47:09.256752 (Thread-35): sending response (<Response 11760 bytes [200 OK]>) to 10.0.17.156
2022-01-05 16:52:53.345938 (Thread-36): handling status request
2022-01-05 16:52:53.347350 (Thread-36): 16:52:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae415a700>]}
2022-01-05 16:52:53.348294 (Thread-36): sending response (<Response 15820 bytes [200 OK]>) to 10.0.26.162
2022-01-05 16:52:54.265808 (Thread-37): handling run_sql request
2022-01-05 16:52:54.266188 (Thread-37): 16:52:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae415a4c0>]}
2022-01-05 16:52:56.353889 (Thread-37): sending response (<Response 138 bytes [200 OK]>) to 10.0.42.85
2022-01-05 16:52:56.380688 (MainThread): 16:52:56  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2788a387-77ee-4871-8262-f407dcbea91b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a0f8b220>]}
2022-01-05 16:52:56.381259 (MainThread): 16:52:56  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:52:56.381889 (Thread-1): 16:52:56  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:52:56.382020 (Thread-1): 16:52:56  Began compiling node rpc.my_new_project.request
2022-01-05 16:52:56.382119 (Thread-1): 16:52:56  Compiling rpc.my_new_project.request
2022-01-05 16:52:56.383264 (Thread-1): 16:52:56  finished collecting timing info
2022-01-05 16:52:56.383389 (Thread-1): 16:52:56  Began executing node rpc.my_new_project.request
2022-01-05 16:52:56.383487 (Thread-1): 16:52:56  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:52:56.383564 (Thread-1): 16:52:56  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:52:56.383643 (Thread-1): 16:52:56  Opening a new connection, currently in state init
2022-01-05 16:52:56.383727 (Thread-1): 16:52:56  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:52:56.406748 (Thread-1): 16:52:56  SQL status: SELECT in 0.02 seconds
2022-01-05 16:52:56.407735 (Thread-1): 16:52:56  finished collecting timing info
2022-01-05 16:52:56.407872 (Thread-1): 16:52:56  On rpc.my_new_project.request: Close
2022-01-05 16:52:56.807903 (Thread-38): handling poll request
2022-01-05 16:52:56.808340 (Thread-38): 16:52:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4125cd0>]}
2022-01-05 16:52:56.809566 (Thread-38): sending response (<Response 11720 bytes [200 OK]>) to 10.0.42.119
2022-01-05 16:53:05.020856 (Thread-39): handling ps request
2022-01-05 16:53:05.021235 (Thread-39): 16:53:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4125e80>]}
2022-01-05 16:53:05.024387 (Thread-40): handling status request
2022-01-05 16:53:05.024659 (Thread-40): 16:53:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4191100>]}
2022-01-05 16:53:05.033217 (Thread-41): handling status request
2022-01-05 16:53:05.033542 (Thread-41): 16:53:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4135520>]}
2022-01-05 16:53:05.052842 (Thread-39): sending response (<Response 3642 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:53:05.054062 (Thread-40): sending response (<Response 15820 bytes [200 OK]>) to 10.0.26.162
2022-01-05 16:53:05.055097 (Thread-41): sending response (<Response 15820 bytes [200 OK]>) to 10.0.18.253
2022-01-05 16:53:05.131998 (Thread-42): handling status request
2022-01-05 16:53:05.132357 (Thread-42): 16:53:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4125a30>]}
2022-01-05 16:53:05.133225 (Thread-42): sending response (<Response 15820 bytes [200 OK]>) to 10.0.5.1
2022-01-05 16:56:14.676625 (Thread-43): handling status request
2022-01-05 16:56:14.677878 (Thread-43): 16:56:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae412d7f0>]}
2022-01-05 16:56:14.678718 (Thread-43): sending response (<Response 15820 bytes [200 OK]>) to 10.0.10.137
2022-01-05 16:56:15.022745 (Thread-44): handling run_sql request
2022-01-05 16:56:15.023120 (Thread-44): 16:56:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae412db50>]}
2022-01-05 16:56:17.110459 (Thread-44): sending response (<Response 138 bytes [200 OK]>) to 10.0.17.156
2022-01-05 16:56:17.128067 (MainThread): 16:56:17  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '33eee4ca-108c-4402-9729-865713de7d25', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7ece0e2b0>]}
2022-01-05 16:56:17.128648 (MainThread): 16:56:17  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:56:17.129292 (Thread-1): 16:56:17  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:56:17.129455 (Thread-1): 16:56:17  Began compiling node rpc.my_new_project.request
2022-01-05 16:56:17.129557 (Thread-1): 16:56:17  Compiling rpc.my_new_project.request
2022-01-05 16:56:17.130838 (Thread-1): 16:56:17  finished collecting timing info
2022-01-05 16:56:17.130966 (Thread-1): 16:56:17  Began executing node rpc.my_new_project.request
2022-01-05 16:56:17.131072 (Thread-1): 16:56:17  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:56:17.131155 (Thread-1): 16:56:17  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:56:17.131236 (Thread-1): 16:56:17  Opening a new connection, currently in state init
2022-01-05 16:56:17.131323 (Thread-1): 16:56:17  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:56:17.191739 (Thread-1): 16:56:17  SQL status: SELECT in 0.06 seconds
2022-01-05 16:56:17.194886 (Thread-1): 16:56:17  finished collecting timing info
2022-01-05 16:56:17.195066 (Thread-1): 16:56:17  On rpc.my_new_project.request: Close
2022-01-05 16:56:17.526557 (Thread-45): handling poll request
2022-01-05 16:56:17.526992 (Thread-45): 16:56:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4135fd0>]}
2022-01-05 16:56:17.528603 (Thread-45): sending response (<Response 16788 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:57:13.672284 (Thread-46): 16:57:13  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 16:57:13.672516 (Thread-46): 16:57:13  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 16:57:13.678234 (Thread-46): 16:57:13  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac03b8a90>]}
2022-01-05 16:57:14.178227 (Thread-47): handling status request
2022-01-05 16:57:14.178600 (Thread-47): 16:57:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40b55b0>]}
2022-01-05 16:57:14.179127 (Thread-47): sending response (<Response 1241 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:57:14.245483 (Thread-48): handling status request
2022-01-05 16:57:14.245856 (Thread-48): 16:57:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40b51f0>]}
2022-01-05 16:57:14.246318 (Thread-48): sending response (<Response 1241 bytes [200 OK]>) to 10.0.42.85
2022-01-05 16:57:31.730616 (Thread-49): 16:57:31  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 16:57:31.730823 (Thread-49): 16:57:31  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 16:57:31.735672 (Thread-49): 16:57:31  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac034b970>]}
2022-01-05 16:57:32.334140 (Thread-50): handling status request
2022-01-05 16:57:32.334509 (Thread-50): 16:57:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae41913a0>]}
2022-01-05 16:57:32.334979 (Thread-50): sending response (<Response 1241 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:57:32.348009 (Thread-51): handling status request
2022-01-05 16:57:32.348379 (Thread-51): 16:57:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40d5310>]}
2022-01-05 16:57:32.348838 (Thread-51): sending response (<Response 1241 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:20:28.712209 (Thread-52): handling status request
2022-01-05 17:20:28.713633 (Thread-52): 17:20:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0376130>]}
2022-01-05 17:20:28.714135 (Thread-52): sending response (<Response 1241 bytes [200 OK]>) to 10.0.46.191
2022-01-05 17:20:28.789091 (Thread-53): handling status request
2022-01-05 17:20:28.789391 (Thread-53): 17:20:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0345cd0>]}
2022-01-05 17:20:28.789864 (Thread-53): sending response (<Response 1241 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:20:29.253632 (Thread-54): handling cli_args request
2022-01-05 17:20:29.253946 (Thread-54): 17:20:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0345c10>]}
2022-01-05 17:20:31.285207 (Thread-54): sending response (<Response 138 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:20:31.368158 (MainThread): 17:20:31  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 17:20:31.368548 (MainThread): 17:20:31  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 17:20:31.374483 (MainThread): 17:20:31  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3b071c71-0f21-4aec-a155-15949817d20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffaca2fdeb0>]}
2022-01-05 17:20:31.405575 (MainThread): 17:20:31  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3b071c71-0f21-4aec-a155-15949817d20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffaca4134c0>]}
2022-01-05 17:20:31.405805 (MainThread): 17:20:31  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:20:31.406772 (MainThread): 17:20:31  
2022-01-05 17:20:31.407040 (MainThread): 17:20:31  Acquiring new redshift connection "master"
2022-01-05 17:20:31.407820 (ThreadPoolExecutor-0_0): 17:20:31  Acquiring new redshift connection "list_dev"
2022-01-05 17:20:31.417518 (ThreadPoolExecutor-0_0): 17:20:31  Using redshift connection "list_dev"
2022-01-05 17:20:31.417619 (ThreadPoolExecutor-0_0): 17:20:31  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-05 17:20:31.417701 (ThreadPoolExecutor-0_0): 17:20:31  Opening a new connection, currently in state init
2022-01-05 17:20:31.417784 (ThreadPoolExecutor-0_0): 17:20:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:31.439471 (ThreadPoolExecutor-0_0): 17:20:31  SQL status: SELECT in 0.02 seconds
2022-01-05 17:20:31.440494 (ThreadPoolExecutor-0_0): 17:20:31  On list_dev: Close
2022-01-05 17:20:31.441532 (ThreadPoolExecutor-1_0): 17:20:31  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:20:31.447487 (ThreadPoolExecutor-1_0): 17:20:31  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:20:31.447585 (ThreadPoolExecutor-1_0): 17:20:31  On list_dev_dbt_nobodozie: BEGIN
2022-01-05 17:20:31.447666 (ThreadPoolExecutor-1_0): 17:20:31  Opening a new connection, currently in state closed
2022-01-05 17:20:31.447740 (ThreadPoolExecutor-1_0): 17:20:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:31.471806 (ThreadPoolExecutor-1_0): 17:20:31  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:20:31.471917 (ThreadPoolExecutor-1_0): 17:20:31  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:20:31.471991 (ThreadPoolExecutor-1_0): 17:20:31  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-05 17:20:31.488612 (ThreadPoolExecutor-1_0): 17:20:31  SQL status: SELECT in 0.02 seconds
2022-01-05 17:20:31.489727 (ThreadPoolExecutor-1_0): 17:20:31  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-05 17:20:31.492228 (ThreadPoolExecutor-1_0): 17:20:31  On list_dev_dbt_nobodozie: Close
2022-01-05 17:20:31.496455 (MainThread): 17:20:31  Using redshift connection "master"
2022-01-05 17:20:31.496567 (MainThread): 17:20:31  On master: BEGIN
2022-01-05 17:20:31.496649 (MainThread): 17:20:31  Opening a new connection, currently in state init
2022-01-05 17:20:31.496726 (MainThread): 17:20:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:31.649291 (Thread-55): handling poll request
2022-01-05 17:20:31.649733 (Thread-55): 17:20:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae412dc40>]}
2022-01-05 17:20:31.650759 (Thread-55): sending response (<Response 9949 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:20:32.186409 (MainThread): 17:20:32  SQL status: BEGIN in 0.69 seconds
2022-01-05 17:20:32.186572 (MainThread): 17:20:32  Using redshift connection "master"
2022-01-05 17:20:32.186655 (MainThread): 17:20:32  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-05 17:20:32.215191 (MainThread): 17:20:32  SQL status: SELECT in 0.03 seconds
2022-01-05 17:20:32.216314 (MainThread): 17:20:32  On master: ROLLBACK
2022-01-05 17:20:32.218517 (MainThread): 17:20:32  Using redshift connection "master"
2022-01-05 17:20:32.218629 (MainThread): 17:20:32  On master: BEGIN
2022-01-05 17:20:32.222972 (MainThread): 17:20:32  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:20:32.223083 (MainThread): 17:20:32  On master: COMMIT
2022-01-05 17:20:32.223154 (MainThread): 17:20:32  Using redshift connection "master"
2022-01-05 17:20:32.223222 (MainThread): 17:20:32  On master: COMMIT
2022-01-05 17:20:32.225162 (MainThread): 17:20:32  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:20:32.225270 (MainThread): 17:20:32  On master: Close
2022-01-05 17:20:32.225755 (MainThread): 17:20:32  Concurrency: 4 threads (target='default')
2022-01-05 17:20:32.225872 (MainThread): 17:20:32  
2022-01-05 17:20:32.227999 (Thread-1): 17:20:32  Began running node model.my_new_project.my_first_dbt_model
2022-01-05 17:20:32.228471 (Thread-1): 17:20:32  1 of 2 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-05 17:20:32.228760 (Thread-1): 17:20:32  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.228861 (Thread-1): 17:20:32  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-05 17:20:32.228955 (Thread-1): 17:20:32  Compiling model.my_new_project.my_first_dbt_model
2022-01-05 17:20:32.231288 (Thread-1): 17:20:32  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.249528 (Thread-1): 17:20:32  finished collecting timing info
2022-01-05 17:20:32.249671 (Thread-1): 17:20:32  Began executing node model.my_new_project.my_first_dbt_model
2022-01-05 17:20:32.280773 (Thread-1): 17:20:32  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.298262 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.298371 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:20:32.298454 (Thread-1): 17:20:32  Opening a new connection, currently in state closed
2022-01-05 17:20:32.298536 (Thread-1): 17:20:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:32.318595 (Thread-1): 17:20:32  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:20:32.318714 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.318810 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-05 17:20:32.365613 (Thread-1): 17:20:32  SQL status: SELECT in 0.05 seconds
2022-01-05 17:20:32.370908 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.371008 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-05 17:20:32.373565 (Thread-1): 17:20:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:20:32.375258 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.375353 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-05 17:20:32.377893 (Thread-1): 17:20:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:20:32.387953 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:20:32.388052 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.388125 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:20:32.428113 (Thread-1): 17:20:32  SQL status: COMMIT in 0.04 seconds
2022-01-05 17:20:32.428310 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.428388 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:20:32.430521 (Thread-1): 17:20:32  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:20:32.434356 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.434455 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-05 17:20:32.439373 (Thread-1): 17:20:32  SQL status: DROP TABLE in 0.0 seconds
2022-01-05 17:20:32.440326 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:20:32.440469 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.440591 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:20:32.470350 (Thread-1): 17:20:32  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:20:32.470467 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.470543 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:20:32.472715 (Thread-1): 17:20:32  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:20:32.473097 (Thread-1): 17:20:32  finished collecting timing info
2022-01-05 17:20:32.473222 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-05 17:20:32.475059 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: Close
2022-01-05 17:20:32.475486 (Thread-1): 17:20:32  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b071c71-0f21-4aec-a155-15949817d20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffac9ac1dc0>]}
2022-01-05 17:20:32.475800 (Thread-1): 17:20:32  1 of 2 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.25s]
2022-01-05 17:20:32.475912 (Thread-1): 17:20:32  Finished running node model.my_new_project.my_first_dbt_model
2022-01-05 17:20:32.476696 (Thread-3): 17:20:32  Began running node model.my_new_project.my_second_dbt_model
2022-01-05 17:20:32.476960 (Thread-3): 17:20:32  2 of 2 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-05 17:20:32.477221 (Thread-3): 17:20:32  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.477326 (Thread-3): 17:20:32  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-05 17:20:32.477439 (Thread-3): 17:20:32  Compiling model.my_new_project.my_second_dbt_model
2022-01-05 17:20:32.479411 (Thread-3): 17:20:32  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.500240 (Thread-3): 17:20:32  finished collecting timing info
2022-01-05 17:20:32.500380 (Thread-3): 17:20:32  Began executing node model.my_new_project.my_second_dbt_model
2022-01-05 17:20:32.516039 (Thread-3): 17:20:32  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.529333 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.529467 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:20:32.529556 (Thread-3): 17:20:32  Opening a new connection, currently in state init
2022-01-05 17:20:32.529638 (Thread-3): 17:20:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:32.548735 (Thread-3): 17:20:32  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:20:32.548852 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.548934 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-05 17:20:32.553734 (Thread-3): 17:20:32  SQL status: CREATE VIEW in 0.0 seconds
2022-01-05 17:20:32.555485 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.555584 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-05 17:20:32.557800 (Thread-3): 17:20:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:20:32.558745 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:20:32.558844 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.558920 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:20:32.587529 (Thread-3): 17:20:32  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:20:32.587743 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.587826 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:20:32.590380 (Thread-3): 17:20:32  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:20:32.591557 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.591654 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-05 17:20:32.593649 (Thread-3): 17:20:32  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 17:20:32.594260 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:20:32.594354 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.594429 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:20:32.618770 (Thread-3): 17:20:32  SQL status: COMMIT in 0.02 seconds
2022-01-05 17:20:32.618888 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.618963 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:20:32.621265 (Thread-3): 17:20:32  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:20:32.621658 (Thread-3): 17:20:32  finished collecting timing info
2022-01-05 17:20:32.621785 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-05 17:20:32.623930 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: Close
2022-01-05 17:20:32.624352 (Thread-3): 17:20:32  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b071c71-0f21-4aec-a155-15949817d20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffac81fd280>]}
2022-01-05 17:20:32.624653 (Thread-3): 17:20:32  2 of 2 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.15s]
2022-01-05 17:20:32.624762 (Thread-3): 17:20:32  Finished running node model.my_new_project.my_second_dbt_model
2022-01-05 17:20:32.626130 (MainThread): 17:20:32  Acquiring new redshift connection "master"
2022-01-05 17:20:32.626270 (MainThread): 17:20:32  Using redshift connection "master"
2022-01-05 17:20:32.626347 (MainThread): 17:20:32  On master: BEGIN
2022-01-05 17:20:32.626423 (MainThread): 17:20:32  Opening a new connection, currently in state closed
2022-01-05 17:20:32.626498 (MainThread): 17:20:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:32.649292 (MainThread): 17:20:32  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:20:32.649433 (MainThread): 17:20:32  On master: COMMIT
2022-01-05 17:20:32.649517 (MainThread): 17:20:32  Using redshift connection "master"
2022-01-05 17:20:32.649588 (MainThread): 17:20:32  On master: COMMIT
2022-01-05 17:20:32.651287 (MainThread): 17:20:32  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:20:32.651393 (MainThread): 17:20:32  On master: Close
2022-01-05 17:20:32.651758 (MainThread): 17:20:32  
2022-01-05 17:20:32.651867 (MainThread): 17:20:32  Finished running 1 table model, 1 view model in 1.24s.
2022-01-05 17:20:32.651946 (MainThread): 17:20:32  Connection 'master' was properly closed.
2022-01-05 17:20:32.652010 (MainThread): 17:20:32  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-05 17:20:32.652070 (MainThread): 17:20:32  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-05 17:20:32.722715 (MainThread): 17:20:32  
2022-01-05 17:20:32.722924 (MainThread): 17:20:32  Completed successfully
2022-01-05 17:20:32.723064 (MainThread): 17:20:32  
2022-01-05 17:20:32.723186 (MainThread): 17:20:32  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2022-01-05 17:20:33.191965 (Thread-56): handling poll request
2022-01-05 17:20:33.192318 (Thread-56): 17:20:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40e4c70>]}
2022-01-05 17:20:33.194331 (Thread-56): sending response (<Response 54422 bytes [200 OK]>) to 10.0.38.111
2022-01-05 17:20:33.906276 (Thread-57): handling status request
2022-01-05 17:20:33.906641 (Thread-57): 17:20:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40b5f40>]}
2022-01-05 17:20:33.907131 (Thread-57): sending response (<Response 1241 bytes [200 OK]>) to 10.0.9.25
2022-01-05 17:20:33.935630 (Thread-58): handling status request
2022-01-05 17:20:33.935882 (Thread-58): 17:20:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac034c670>]}
2022-01-05 17:20:33.936254 (Thread-58): sending response (<Response 1241 bytes [200 OK]>) to 10.0.12.39
2022-01-05 17:21:08.517276 (Thread-59): 17:21:08  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-05 17:21:08.517725 (Thread-59): 17:21:08  Partial parsing: updated file: my_new_project://models/dim_customers.sql
2022-01-05 17:21:08.522572 (Thread-59): 17:21:08  1699: static parser successfully parsed dim_customers.sql
2022-01-05 17:21:08.580279 (Thread-59): 17:21:08  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02cfdf0>]}
2022-01-05 17:21:09.322528 (Thread-60): handling status request
2022-01-05 17:21:09.322934 (Thread-60): 17:21:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40f6550>]}
2022-01-05 17:21:09.323407 (Thread-60): sending response (<Response 1552 bytes [200 OK]>) to 10.0.9.25
2022-01-05 17:21:09.397491 (Thread-61): handling status request
2022-01-05 17:21:09.397810 (Thread-61): 17:21:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac031d820>]}
2022-01-05 17:21:09.398263 (Thread-61): sending response (<Response 1552 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:21:12.432246 (Thread-62): handling status request
2022-01-05 17:21:12.432612 (Thread-62): 17:21:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40b5fa0>]}
2022-01-05 17:21:12.433097 (Thread-62): sending response (<Response 1552 bytes [200 OK]>) to 10.0.6.188
2022-01-05 17:21:12.667933 (Thread-63): handling status request
2022-01-05 17:21:12.668245 (Thread-63): 17:21:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40d57f0>]}
2022-01-05 17:21:12.668718 (Thread-63): sending response (<Response 1552 bytes [200 OK]>) to 10.0.17.156
2022-01-05 17:21:12.810381 (Thread-64): handling cli_args request
2022-01-05 17:21:12.810674 (Thread-64): 17:21:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40d5130>]}
2022-01-05 17:21:14.836598 (Thread-64): sending response (<Response 138 bytes [200 OK]>) to 10.0.5.1
2022-01-05 17:21:14.907400 (MainThread): 17:21:14  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 17:21:14.907770 (MainThread): 17:21:14  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 17:21:14.913252 (MainThread): 17:21:14  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '16de0e09-5bb9-4497-9935-603c3bf9fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1274c1df40>]}
2022-01-05 17:21:14.955618 (MainThread): 17:21:14  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '16de0e09-5bb9-4497-9935-603c3bf9fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1274c9af70>]}
2022-01-05 17:21:14.955872 (MainThread): 17:21:14  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:21:14.956878 (MainThread): 17:21:14  
2022-01-05 17:21:14.957142 (MainThread): 17:21:14  Acquiring new redshift connection "master"
2022-01-05 17:21:14.957973 (ThreadPoolExecutor-0_0): 17:21:14  Acquiring new redshift connection "list_dev"
2022-01-05 17:21:14.967709 (ThreadPoolExecutor-0_0): 17:21:14  Using redshift connection "list_dev"
2022-01-05 17:21:14.967805 (ThreadPoolExecutor-0_0): 17:21:14  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-05 17:21:14.967886 (ThreadPoolExecutor-0_0): 17:21:14  Opening a new connection, currently in state init
2022-01-05 17:21:14.968121 (ThreadPoolExecutor-0_0): 17:21:14  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:14.993579 (ThreadPoolExecutor-0_0): 17:21:14  SQL status: SELECT in 0.03 seconds
2022-01-05 17:21:14.994574 (ThreadPoolExecutor-0_0): 17:21:14  On list_dev: Close
2022-01-05 17:21:14.995625 (ThreadPoolExecutor-1_0): 17:21:14  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:21:15.001679 (ThreadPoolExecutor-1_0): 17:21:15  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:21:15.001775 (ThreadPoolExecutor-1_0): 17:21:15  On list_dev_dbt_nobodozie: BEGIN
2022-01-05 17:21:15.001850 (ThreadPoolExecutor-1_0): 17:21:15  Opening a new connection, currently in state closed
2022-01-05 17:21:15.001925 (ThreadPoolExecutor-1_0): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.031186 (ThreadPoolExecutor-1_0): 17:21:15  SQL status: BEGIN in 0.03 seconds
2022-01-05 17:21:15.031293 (ThreadPoolExecutor-1_0): 17:21:15  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:21:15.031365 (ThreadPoolExecutor-1_0): 17:21:15  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-05 17:21:15.042641 (ThreadPoolExecutor-1_0): 17:21:15  SQL status: SELECT in 0.01 seconds
2022-01-05 17:21:15.043583 (ThreadPoolExecutor-1_0): 17:21:15  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-05 17:21:15.045371 (ThreadPoolExecutor-1_0): 17:21:15  On list_dev_dbt_nobodozie: Close
2022-01-05 17:21:15.049242 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.049367 (MainThread): 17:21:15  On master: BEGIN
2022-01-05 17:21:15.049473 (MainThread): 17:21:15  Opening a new connection, currently in state init
2022-01-05 17:21:15.049553 (MainThread): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.073686 (MainThread): 17:21:15  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:21:15.073793 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.073867 (MainThread): 17:21:15  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-05 17:21:15.102599 (MainThread): 17:21:15  SQL status: SELECT in 0.03 seconds
2022-01-05 17:21:15.103507 (MainThread): 17:21:15  On master: ROLLBACK
2022-01-05 17:21:15.105431 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.105526 (MainThread): 17:21:15  On master: BEGIN
2022-01-05 17:21:15.109090 (MainThread): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.109193 (MainThread): 17:21:15  On master: COMMIT
2022-01-05 17:21:15.109264 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.109331 (MainThread): 17:21:15  On master: COMMIT
2022-01-05 17:21:15.111104 (MainThread): 17:21:15  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:21:15.111214 (MainThread): 17:21:15  On master: Close
2022-01-05 17:21:15.111559 (MainThread): 17:21:15  Concurrency: 4 threads (target='default')
2022-01-05 17:21:15.111668 (MainThread): 17:21:15  
2022-01-05 17:21:15.113807 (Thread-1): 17:21:15  Began running node model.my_new_project.dim_customers
2022-01-05 17:21:15.114049 (Thread-1): 17:21:15  1 of 3 START view model dbt_nobodozie.dim_customers............................. [RUN]
2022-01-05 17:21:15.114268 (Thread-1): 17:21:15  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.114355 (Thread-1): 17:21:15  Began compiling node model.my_new_project.dim_customers
2022-01-05 17:21:15.114440 (Thread-1): 17:21:15  Compiling model.my_new_project.dim_customers
2022-01-05 17:21:15.115450 (Thread-1): 17:21:15  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-05 17:21:15.115782 (Thread-2): 17:21:15  Began running node model.my_new_project.my_first_dbt_model
2022-01-05 17:21:15.116001 (Thread-2): 17:21:15  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-05 17:21:15.116228 (Thread-2): 17:21:15  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.116310 (Thread-2): 17:21:15  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-05 17:21:15.116387 (Thread-2): 17:21:15  Compiling model.my_new_project.my_first_dbt_model
2022-01-05 17:21:15.118220 (Thread-2): 17:21:15  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.127341 (Thread-1): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.127477 (Thread-1): 17:21:15  Began executing node model.my_new_project.dim_customers
2022-01-05 17:21:15.132653 (Thread-2): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.132777 (Thread-2): 17:21:15  Began executing node model.my_new_project.my_first_dbt_model
2022-01-05 17:21:15.164712 (Thread-1): 17:21:15  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-05 17:21:15.175278 (Thread-2): 17:21:15  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.180254 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.180361 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:21:15.180437 (Thread-1): 17:21:15  Opening a new connection, currently in state closed
2022-01-05 17:21:15.180511 (Thread-1): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.188069 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.188170 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:21:15.188244 (Thread-2): 17:21:15  Opening a new connection, currently in state init
2022-01-05 17:21:15.188316 (Thread-2): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.198488 (Thread-65): handling poll request
2022-01-05 17:21:15.198873 (Thread-65): 17:21:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02cbb80>]}
2022-01-05 17:21:15.200311 (Thread-65): sending response (<Response 26535 bytes [200 OK]>) to 10.0.42.119
2022-01-05 17:21:15.453858 (Thread-2): 17:21:15  SQL status: BEGIN in 0.27 seconds
2022-01-05 17:21:15.454013 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.454094 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-05 17:21:15.454468 (Thread-1): 17:21:15  SQL status: BEGIN in 0.27 seconds
2022-01-05 17:21:15.454593 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.454666 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create view "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  ) ;

2022-01-05 17:21:15.466507 (Thread-1): 17:21:15  SQL status: CREATE VIEW in 0.01 seconds
2022-01-05 17:21:15.471982 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.472081 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-05 17:21:15.475492 (Thread-1): 17:21:15  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:21:15.482025 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:21:15.482129 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.482201 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:21:15.515913 (Thread-2): 17:21:15  SQL status: SELECT in 0.06 seconds
2022-01-05 17:21:15.517827 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.517918 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-05 17:21:15.520834 (Thread-2): 17:21:15  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:21:15.522576 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.522667 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-05 17:21:15.525960 (Thread-2): 17:21:15  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:21:15.530338 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:21:15.530433 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.530503 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:21:15.530730 (Thread-1): 17:21:15  SQL status: COMMIT in 0.05 seconds
2022-01-05 17:21:15.530940 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.531016 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:21:15.533666 (Thread-1): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.537485 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.537579 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop view if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-05 17:21:15.541588 (Thread-1): 17:21:15  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 17:21:15.542182 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:21:15.542271 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.542341 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:21:15.590726 (Thread-2): 17:21:15  SQL status: COMMIT in 0.06 seconds
2022-01-05 17:21:15.591076 (Thread-1): 17:21:15  SQL status: COMMIT in 0.05 seconds
2022-01-05 17:21:15.591194 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.591265 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:21:15.593510 (Thread-1): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.593931 (Thread-1): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.594058 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: ROLLBACK
2022-01-05 17:21:15.594268 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.594364 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:21:15.595971 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: Close
2022-01-05 17:21:15.596416 (Thread-1): 17:21:15  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16de0e09-5bb9-4497-9935-603c3bf9fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12743f73d0>]}
2022-01-05 17:21:15.596734 (Thread-1): 17:21:15  1 of 3 OK created view model dbt_nobodozie.dim_customers........................ [CREATE VIEW in 0.48s]
2022-01-05 17:21:15.596880 (Thread-1): 17:21:15  Finished running node model.my_new_project.dim_customers
2022-01-05 17:21:15.597173 (Thread-2): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.598412 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.598503 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-05 17:21:15.604548 (Thread-2): 17:21:15  SQL status: DROP TABLE in 0.01 seconds
2022-01-05 17:21:15.605187 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:21:15.605278 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.605348 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:21:15.637193 (Thread-2): 17:21:15  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:21:15.637298 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.637366 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:21:15.639689 (Thread-2): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.640075 (Thread-2): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.640205 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-05 17:21:15.642097 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: Close
2022-01-05 17:21:15.642485 (Thread-2): 17:21:15  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16de0e09-5bb9-4497-9935-603c3bf9fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1274341730>]}
2022-01-05 17:21:15.642768 (Thread-2): 17:21:15  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.53s]
2022-01-05 17:21:15.642869 (Thread-2): 17:21:15  Finished running node model.my_new_project.my_first_dbt_model
2022-01-05 17:21:15.643640 (Thread-4): 17:21:15  Began running node model.my_new_project.my_second_dbt_model
2022-01-05 17:21:15.643873 (Thread-4): 17:21:15  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-05 17:21:15.644118 (Thread-4): 17:21:15  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.644200 (Thread-4): 17:21:15  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-05 17:21:15.644282 (Thread-4): 17:21:15  Compiling model.my_new_project.my_second_dbt_model
2022-01-05 17:21:15.647097 (Thread-4): 17:21:15  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.661218 (Thread-4): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.661345 (Thread-4): 17:21:15  Began executing node model.my_new_project.my_second_dbt_model
2022-01-05 17:21:15.663136 (Thread-4): 17:21:15  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.677988 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.678094 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:21:15.678175 (Thread-4): 17:21:15  Opening a new connection, currently in state init
2022-01-05 17:21:15.678254 (Thread-4): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.700850 (Thread-4): 17:21:15  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:21:15.700959 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.701032 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-05 17:21:15.705749 (Thread-4): 17:21:15  SQL status: CREATE VIEW in 0.0 seconds
2022-01-05 17:21:15.707442 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.707535 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-05 17:21:15.709641 (Thread-4): 17:21:15  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:21:15.710585 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:21:15.710676 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.710745 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:21:15.740617 (Thread-4): 17:21:15  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:21:15.740830 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.741071 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:21:15.743080 (Thread-4): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.744153 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.744248 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-05 17:21:15.746149 (Thread-4): 17:21:15  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 17:21:15.746749 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:21:15.746839 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.746910 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:21:15.772685 (Thread-4): 17:21:15  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:21:15.772799 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.772870 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:21:15.774836 (Thread-4): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.775204 (Thread-4): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.775327 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-05 17:21:15.776977 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: Close
2022-01-05 17:21:15.777381 (Thread-4): 17:21:15  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16de0e09-5bb9-4497-9935-603c3bf9fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12742ad820>]}
2022-01-05 17:21:15.777728 (Thread-4): 17:21:15  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.13s]
2022-01-05 17:21:15.777840 (Thread-4): 17:21:15  Finished running node model.my_new_project.my_second_dbt_model
2022-01-05 17:21:15.779138 (MainThread): 17:21:15  Acquiring new redshift connection "master"
2022-01-05 17:21:15.779276 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.779351 (MainThread): 17:21:15  On master: BEGIN
2022-01-05 17:21:15.779426 (MainThread): 17:21:15  Opening a new connection, currently in state closed
2022-01-05 17:21:15.779503 (MainThread): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.804313 (MainThread): 17:21:15  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:21:15.804426 (MainThread): 17:21:15  On master: COMMIT
2022-01-05 17:21:15.804497 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.804564 (MainThread): 17:21:15  On master: COMMIT
2022-01-05 17:21:15.806395 (MainThread): 17:21:15  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:21:15.806500 (MainThread): 17:21:15  On master: Close
2022-01-05 17:21:15.806886 (MainThread): 17:21:15  
2022-01-05 17:21:15.807008 (MainThread): 17:21:15  Finished running 2 view models, 1 table model in 0.85s.
2022-01-05 17:21:15.807090 (MainThread): 17:21:15  Connection 'master' was properly closed.
2022-01-05 17:21:15.807155 (MainThread): 17:21:15  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-05 17:21:15.807215 (MainThread): 17:21:15  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-05 17:21:15.807272 (MainThread): 17:21:15  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-05 17:21:15.870751 (MainThread): 17:21:15  
2022-01-05 17:21:15.870896 (MainThread): 17:21:15  Completed successfully
2022-01-05 17:21:15.870988 (MainThread): 17:21:15  
2022-01-05 17:21:15.871070 (MainThread): 17:21:15  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-05 17:21:16.602203 (Thread-66): handling poll request
2022-01-05 17:21:16.602577 (Thread-66): 17:21:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02ebee0>]}
2022-01-05 17:21:16.604615 (Thread-66): sending response (<Response 59270 bytes [200 OK]>) to 10.0.17.156
2022-01-05 17:21:17.208435 (Thread-67): handling status request
2022-01-05 17:21:17.208840 (Thread-67): 17:21:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02730d0>]}
2022-01-05 17:21:17.209350 (Thread-67): sending response (<Response 1552 bytes [200 OK]>) to 10.0.19.216
2022-01-05 17:21:17.264120 (Thread-68): handling status request
2022-01-05 17:21:17.264387 (Thread-68): 17:21:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02734c0>]}
2022-01-05 17:21:17.264801 (Thread-68): sending response (<Response 1552 bytes [200 OK]>) to 10.0.30.3
2022-01-05 17:24:05.359963 (Thread-69): handling status request
2022-01-05 17:24:05.361452 (Thread-69): 17:24:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0273700>]}
2022-01-05 17:24:05.389785 (Thread-69): sending response (<Response 1552 bytes [200 OK]>) to 10.0.20.28
2022-01-05 17:24:05.727924 (Thread-70): handling run_sql request
2022-01-05 17:24:05.728282 (Thread-70): 17:24:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02739a0>]}
2022-01-05 17:24:07.785613 (Thread-70): sending response (<Response 138 bytes [200 OK]>) to 10.0.42.119
2022-01-05 17:24:07.811994 (MainThread): 17:24:07  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '61ff180e-508c-425b-a6f6-868e8f8d5663', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81257eb100>]}
2022-01-05 17:24:07.812516 (MainThread): 17:24:07  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:24:07.813063 (Thread-1): 17:24:07  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 17:24:07.813187 (Thread-1): 17:24:07  Began compiling node rpc.my_new_project.request
2022-01-05 17:24:07.813274 (Thread-1): 17:24:07  Compiling rpc.my_new_project.request
2022-01-05 17:24:07.814403 (Thread-1): 17:24:07  finished collecting timing info
2022-01-05 17:24:07.814527 (Thread-1): 17:24:07  Began executing node rpc.my_new_project.request
2022-01-05 17:24:07.814632 (Thread-1): 17:24:07  Using redshift connection "rpc.my_new_project.request"
2022-01-05 17:24:07.814709 (Thread-1): 17:24:07  On rpc.my_new_project.request: SELECT *
FROM dev.dbt_nobodozie.my_second_dbt_model
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 17:24:07.814782 (Thread-1): 17:24:07  Opening a new connection, currently in state init
2022-01-05 17:24:07.814862 (Thread-1): 17:24:07  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:24:07.981462 (Thread-1): 17:24:07  SQL status: SELECT in 0.17 seconds
2022-01-05 17:24:07.982469 (Thread-1): 17:24:07  finished collecting timing info
2022-01-05 17:24:07.982625 (Thread-1): 17:24:07  On rpc.my_new_project.request: Close
2022-01-05 17:24:08.233339 (Thread-71): handling poll request
2022-01-05 17:24:08.233787 (Thread-71): 17:24:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac027a250>]}
2022-01-05 17:24:08.234931 (Thread-71): sending response (<Response 7182 bytes [200 OK]>) to 10.0.42.85
2022-01-05 17:24:33.494206 (Thread-72): handling status request
2022-01-05 17:24:33.494587 (Thread-72): 17:24:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac027a700>]}
2022-01-05 17:24:33.495097 (Thread-72): sending response (<Response 1552 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:24:33.931156 (Thread-73): handling run_sql request
2022-01-05 17:24:33.931520 (Thread-73): 17:24:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac027ab50>]}
2022-01-05 17:24:35.973403 (Thread-73): sending response (<Response 138 bytes [200 OK]>) to 10.0.5.1
2022-01-05 17:24:35.996999 (MainThread): 17:24:35  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '81b316fc-66b7-49fb-9cc8-45d7869fba76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd8fd3b280>]}
2022-01-05 17:24:35.997535 (MainThread): 17:24:35  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:24:35.998112 (Thread-1): 17:24:35  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 17:24:35.998245 (Thread-1): 17:24:35  Began compiling node rpc.my_new_project.request
2022-01-05 17:24:35.998337 (Thread-1): 17:24:35  Compiling rpc.my_new_project.request
2022-01-05 17:24:35.999529 (Thread-1): 17:24:35  finished collecting timing info
2022-01-05 17:24:35.999658 (Thread-1): 17:24:35  Began executing node rpc.my_new_project.request
2022-01-05 17:24:35.999761 (Thread-1): 17:24:35  Using redshift connection "rpc.my_new_project.request"
2022-01-05 17:24:35.999841 (Thread-1): 17:24:35  On rpc.my_new_project.request: SELECT *
FROM dev.dbt_nobodozie.dim_customers
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 17:24:35.999928 (Thread-1): 17:24:35  Opening a new connection, currently in state init
2022-01-05 17:24:36.000017 (Thread-1): 17:24:35  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:24:36.061063 (Thread-1): 17:24:36  SQL status: SELECT in 0.06 seconds
2022-01-05 17:24:36.064123 (Thread-1): 17:24:36  finished collecting timing info
2022-01-05 17:24:36.064287 (Thread-1): 17:24:36  On rpc.my_new_project.request: Close
2022-01-05 17:24:36.397917 (Thread-74): handling poll request
2022-01-05 17:24:36.398401 (Thread-74): 17:24:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac031dd00>]}
2022-01-05 17:24:36.400027 (Thread-74): sending response (<Response 12318 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:26:20.628671 (Thread-75): handling status request
2022-01-05 17:26:20.630305 (Thread-75): 17:26:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0275f40>]}
2022-01-05 17:26:20.630809 (Thread-75): sending response (<Response 1552 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:26:20.970191 (Thread-76): handling run_sql request
2022-01-05 17:26:20.970562 (Thread-76): 17:26:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02754c0>]}
2022-01-05 17:26:23.079128 (Thread-76): sending response (<Response 138 bytes [200 OK]>) to 10.0.46.191
2022-01-05 17:26:23.106146 (MainThread): 17:26:23  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '005825a7-53c0-4d65-ae4a-e7e45b153d38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0da7e48610>]}
2022-01-05 17:26:23.106687 (MainThread): 17:26:23  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:26:23.107244 (Thread-1): 17:26:23  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 17:26:23.107373 (Thread-1): 17:26:23  Began compiling node rpc.my_new_project.request
2022-01-05 17:26:23.107463 (Thread-1): 17:26:23  Compiling rpc.my_new_project.request
2022-01-05 17:26:23.109528 (Thread-1): 17:26:23  finished collecting timing info
2022-01-05 17:26:23.109661 (Thread-1): 17:26:23  Began executing node rpc.my_new_project.request
2022-01-05 17:26:23.109759 (Thread-1): 17:26:23  Using redshift connection "rpc.my_new_project.request"
2022-01-05 17:26:23.109845 (Thread-1): 17:26:23  On rpc.my_new_project.request: 

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 17:26:23.109919 (Thread-1): 17:26:23  Opening a new connection, currently in state init
2022-01-05 17:26:23.109995 (Thread-1): 17:26:23  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:23.143521 (Thread-1): 17:26:23  SQL status: SELECT in 0.03 seconds
2022-01-05 17:26:23.146588 (Thread-1): 17:26:23  finished collecting timing info
2022-01-05 17:26:23.146736 (Thread-1): 17:26:23  On rpc.my_new_project.request: Close
2022-01-05 17:26:23.530944 (Thread-77): handling poll request
2022-01-05 17:26:23.531383 (Thread-77): 17:26:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02976a0>]}
2022-01-05 17:26:23.532941 (Thread-77): sending response (<Response 16918 bytes [200 OK]>) to 10.0.12.39
2022-01-05 17:26:29.593023 (Thread-78): 17:26:29  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-05 17:26:29.593451 (Thread-78): 17:26:29  Partial parsing: updated file: my_new_project://models/dim_customers.sql
2022-01-05 17:26:29.597400 (Thread-78): 17:26:29  1699: static parser successfully parsed dim_customers.sql
2022-01-05 17:26:29.641716 (Thread-78): 17:26:29  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01e9a60>]}
2022-01-05 17:26:30.116418 (Thread-79): handling status request
2022-01-05 17:26:30.116791 (Thread-79): 17:26:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01bd760>]}
2022-01-05 17:26:30.117299 (Thread-79): sending response (<Response 1552 bytes [200 OK]>) to 10.0.6.188
2022-01-05 17:26:30.153082 (Thread-80): handling status request
2022-01-05 17:26:30.153389 (Thread-80): 17:26:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01bd4f0>]}
2022-01-05 17:26:30.153866 (Thread-80): sending response (<Response 1552 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:26:31.142331 (Thread-81): handling status request
2022-01-05 17:26:31.142705 (Thread-81): 17:26:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01bd280>]}
2022-01-05 17:26:31.143178 (Thread-81): sending response (<Response 1552 bytes [200 OK]>) to 10.0.9.25
2022-01-05 17:26:31.294467 (Thread-82): handling status request
2022-01-05 17:26:31.294852 (Thread-82): 17:26:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01bd070>]}
2022-01-05 17:26:31.295341 (Thread-82): sending response (<Response 1552 bytes [200 OK]>) to 10.0.19.216
2022-01-05 17:26:31.473115 (Thread-83): handling cli_args request
2022-01-05 17:26:31.473536 (Thread-83): 17:26:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0275100>]}
2022-01-05 17:26:33.515373 (Thread-83): sending response (<Response 138 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:26:33.592844 (MainThread): 17:26:33  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 17:26:33.593259 (MainThread): 17:26:33  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 17:26:33.598950 (MainThread): 17:26:33  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7559c76e-442f-4452-bf2d-d52ec843e089', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9cfe84fa0>]}
2022-01-05 17:26:33.633174 (MainThread): 17:26:33  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7559c76e-442f-4452-bf2d-d52ec843e089', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9cfef3fd0>]}
2022-01-05 17:26:33.633462 (MainThread): 17:26:33  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:26:33.634555 (MainThread): 17:26:33  
2022-01-05 17:26:33.634847 (MainThread): 17:26:33  Acquiring new redshift connection "master"
2022-01-05 17:26:33.635761 (ThreadPoolExecutor-0_0): 17:26:33  Acquiring new redshift connection "list_dev"
2022-01-05 17:26:33.645827 (ThreadPoolExecutor-0_0): 17:26:33  Using redshift connection "list_dev"
2022-01-05 17:26:33.645934 (ThreadPoolExecutor-0_0): 17:26:33  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-05 17:26:33.646017 (ThreadPoolExecutor-0_0): 17:26:33  Opening a new connection, currently in state init
2022-01-05 17:26:33.646097 (ThreadPoolExecutor-0_0): 17:26:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:33.667123 (ThreadPoolExecutor-0_0): 17:26:33  SQL status: SELECT in 0.02 seconds
2022-01-05 17:26:33.668166 (ThreadPoolExecutor-0_0): 17:26:33  On list_dev: Close
2022-01-05 17:26:33.669383 (ThreadPoolExecutor-1_0): 17:26:33  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:26:33.675534 (ThreadPoolExecutor-1_0): 17:26:33  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:26:33.675633 (ThreadPoolExecutor-1_0): 17:26:33  On list_dev_dbt_nobodozie: BEGIN
2022-01-05 17:26:33.675711 (ThreadPoolExecutor-1_0): 17:26:33  Opening a new connection, currently in state closed
2022-01-05 17:26:33.675786 (ThreadPoolExecutor-1_0): 17:26:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:33.699517 (ThreadPoolExecutor-1_0): 17:26:33  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:33.699635 (ThreadPoolExecutor-1_0): 17:26:33  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:26:33.699713 (ThreadPoolExecutor-1_0): 17:26:33  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-05 17:26:33.710913 (ThreadPoolExecutor-1_0): 17:26:33  SQL status: SELECT in 0.01 seconds
2022-01-05 17:26:33.711973 (ThreadPoolExecutor-1_0): 17:26:33  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-05 17:26:33.713848 (ThreadPoolExecutor-1_0): 17:26:33  On list_dev_dbt_nobodozie: Close
2022-01-05 17:26:33.718202 (MainThread): 17:26:33  Using redshift connection "master"
2022-01-05 17:26:33.718314 (MainThread): 17:26:33  On master: BEGIN
2022-01-05 17:26:33.718395 (MainThread): 17:26:33  Opening a new connection, currently in state init
2022-01-05 17:26:33.718472 (MainThread): 17:26:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:33.742645 (MainThread): 17:26:33  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:33.742760 (MainThread): 17:26:33  Using redshift connection "master"
2022-01-05 17:26:33.742838 (MainThread): 17:26:33  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-05 17:26:33.771943 (MainThread): 17:26:33  SQL status: SELECT in 0.03 seconds
2022-01-05 17:26:33.773031 (MainThread): 17:26:33  On master: ROLLBACK
2022-01-05 17:26:33.774950 (MainThread): 17:26:33  Using redshift connection "master"
2022-01-05 17:26:33.775047 (MainThread): 17:26:33  On master: BEGIN
2022-01-05 17:26:33.778761 (MainThread): 17:26:33  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:33.778866 (MainThread): 17:26:33  On master: COMMIT
2022-01-05 17:26:33.778938 (MainThread): 17:26:33  Using redshift connection "master"
2022-01-05 17:26:33.779007 (MainThread): 17:26:33  On master: COMMIT
2022-01-05 17:26:33.780800 (MainThread): 17:26:33  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:26:33.780906 (MainThread): 17:26:33  On master: Close
2022-01-05 17:26:33.781331 (MainThread): 17:26:33  Concurrency: 4 threads (target='default')
2022-01-05 17:26:33.781468 (MainThread): 17:26:33  
2022-01-05 17:26:33.783834 (Thread-1): 17:26:33  Began running node model.my_new_project.dim_customers
2022-01-05 17:26:33.784105 (Thread-1): 17:26:33  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-05 17:26:33.784355 (Thread-1): 17:26:33  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:33.784449 (Thread-1): 17:26:33  Began compiling node model.my_new_project.dim_customers
2022-01-05 17:26:33.784536 (Thread-1): 17:26:33  Compiling model.my_new_project.dim_customers
2022-01-05 17:26:33.786746 (Thread-1): 17:26:33  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-05 17:26:33.786971 (Thread-2): 17:26:33  Began running node model.my_new_project.my_first_dbt_model
2022-01-05 17:26:33.787198 (Thread-2): 17:26:33  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-05 17:26:33.787442 (Thread-2): 17:26:33  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.787525 (Thread-2): 17:26:33  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-05 17:26:33.787603 (Thread-2): 17:26:33  Compiling model.my_new_project.my_first_dbt_model
2022-01-05 17:26:33.789730 (Thread-2): 17:26:33  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.804175 (Thread-2): 17:26:33  finished collecting timing info
2022-01-05 17:26:33.804315 (Thread-2): 17:26:33  Began executing node model.my_new_project.my_first_dbt_model
2022-01-05 17:26:33.809433 (Thread-1): 17:26:33  finished collecting timing info
2022-01-05 17:26:33.809579 (Thread-1): 17:26:33  Began executing node model.my_new_project.dim_customers
2022-01-05 17:26:33.858912 (Thread-1): 17:26:33  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-05 17:26:33.860586 (Thread-2): 17:26:33  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.874136 (Thread-1): 17:26:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:33.874250 (Thread-1): 17:26:33  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:26:33.874334 (Thread-1): 17:26:33  Opening a new connection, currently in state closed
2022-01-05 17:26:33.874415 (Thread-1): 17:26:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:33.874730 (Thread-2): 17:26:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.874829 (Thread-2): 17:26:33  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:26:33.874911 (Thread-2): 17:26:33  Opening a new connection, currently in state init
2022-01-05 17:26:33.874988 (Thread-2): 17:26:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:33.898822 (Thread-1): 17:26:33  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:33.898943 (Thread-1): 17:26:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:33.899024 (Thread-1): 17:26:33  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-05 17:26:33.899718 (Thread-2): 17:26:33  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:33.899834 (Thread-2): 17:26:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.899921 (Thread-2): 17:26:33  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-05 17:26:33.958504 (Thread-84): handling poll request
2022-01-05 17:26:33.958937 (Thread-84): 17:26:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01e7a60>]}
2022-01-05 17:26:33.960390 (Thread-84): sending response (<Response 30570 bytes [200 OK]>) to 10.0.42.85
2022-01-05 17:26:33.987004 (Thread-2): 17:26:33  SQL status: SELECT in 0.09 seconds
2022-01-05 17:26:33.992960 (Thread-2): 17:26:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.993077 (Thread-2): 17:26:33  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-05 17:26:33.997300 (Thread-2): 17:26:33  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:26:33.999115 (Thread-2): 17:26:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.999212 (Thread-2): 17:26:33  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-05 17:26:34.002063 (Thread-2): 17:26:34  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:26:34.012080 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:26:34.012179 (Thread-2): 17:26:34  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:34.012251 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:26:34.064143 (Thread-2): 17:26:34  SQL status: COMMIT in 0.05 seconds
2022-01-05 17:26:34.064368 (Thread-2): 17:26:34  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:34.064449 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:26:34.067215 (Thread-2): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.071247 (Thread-2): 17:26:34  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:34.071342 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-05 17:26:34.076423 (Thread-2): 17:26:34  SQL status: DROP TABLE in 0.0 seconds
2022-01-05 17:26:34.077048 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:26:34.077139 (Thread-2): 17:26:34  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:34.077211 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:26:34.114712 (Thread-2): 17:26:34  SQL status: COMMIT in 0.04 seconds
2022-01-05 17:26:34.114823 (Thread-2): 17:26:34  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:34.114896 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:26:34.119364 (Thread-2): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.119803 (Thread-2): 17:26:34  finished collecting timing info
2022-01-05 17:26:34.119945 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-05 17:26:34.122629 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: Close
2022-01-05 17:26:34.123105 (Thread-2): 17:26:34  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7559c76e-442f-4452-bf2d-d52ec843e089', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9cf6412b0>]}
2022-01-05 17:26:34.123434 (Thread-2): 17:26:34  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.34s]
2022-01-05 17:26:34.123548 (Thread-2): 17:26:34  Finished running node model.my_new_project.my_first_dbt_model
2022-01-05 17:26:34.124103 (Thread-4): 17:26:34  Began running node model.my_new_project.my_second_dbt_model
2022-01-05 17:26:34.124340 (Thread-4): 17:26:34  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-05 17:26:34.124590 (Thread-4): 17:26:34  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.124678 (Thread-4): 17:26:34  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-05 17:26:34.124762 (Thread-4): 17:26:34  Compiling model.my_new_project.my_second_dbt_model
2022-01-05 17:26:34.127770 (Thread-4): 17:26:34  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.141733 (Thread-4): 17:26:34  finished collecting timing info
2022-01-05 17:26:34.141867 (Thread-4): 17:26:34  Began executing node model.my_new_project.my_second_dbt_model
2022-01-05 17:26:34.157163 (Thread-4): 17:26:34  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.174705 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.174813 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:26:34.174895 (Thread-4): 17:26:34  Opening a new connection, currently in state init
2022-01-05 17:26:34.174976 (Thread-4): 17:26:34  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:34.199508 (Thread-4): 17:26:34  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:34.199623 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.199701 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-05 17:26:34.206621 (Thread-4): 17:26:34  SQL status: CREATE VIEW in 0.01 seconds
2022-01-05 17:26:34.208961 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.209057 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-05 17:26:34.212263 (Thread-4): 17:26:34  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:26:34.213221 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:26:34.213314 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.213385 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:26:34.256152 (Thread-4): 17:26:34  SQL status: COMMIT in 0.04 seconds
2022-01-05 17:26:34.256383 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.256464 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:26:34.259599 (Thread-4): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.260936 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.261028 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-05 17:26:34.263961 (Thread-4): 17:26:34  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 17:26:34.264590 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:26:34.264678 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.264750 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:26:34.301626 (Thread-4): 17:26:34  SQL status: COMMIT in 0.04 seconds
2022-01-05 17:26:34.301747 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.301823 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:26:34.304859 (Thread-4): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.305280 (Thread-4): 17:26:34  finished collecting timing info
2022-01-05 17:26:34.305440 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-05 17:26:34.307905 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: Close
2022-01-05 17:26:34.308362 (Thread-4): 17:26:34  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7559c76e-442f-4452-bf2d-d52ec843e089', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9cf65e4c0>]}
2022-01-05 17:26:34.308723 (Thread-4): 17:26:34  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.18s]
2022-01-05 17:26:34.308838 (Thread-4): 17:26:34  Finished running node model.my_new_project.my_second_dbt_model
2022-01-05 17:26:34.719046 (Thread-1): 17:26:34  SQL status: SELECT in 0.82 seconds
2022-01-05 17:26:34.721364 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.721530 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-05 17:26:34.724371 (Thread-1): 17:26:34  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:26:34.726361 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.726459 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-05 17:26:34.728985 (Thread-1): 17:26:34  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:26:34.730173 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:26:34.730268 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.730338 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:26:34.779927 (Thread-1): 17:26:34  SQL status: COMMIT in 0.05 seconds
2022-01-05 17:26:34.780171 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.780253 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:26:34.782426 (Thread-1): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.783733 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.783827 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop view if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-05 17:26:34.788113 (Thread-1): 17:26:34  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 17:26:34.788839 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:26:34.788932 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.789006 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:26:34.823722 (Thread-1): 17:26:34  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:26:34.823850 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.823925 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:26:34.826064 (Thread-1): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.826516 (Thread-1): 17:26:34  finished collecting timing info
2022-01-05 17:26:34.826649 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: ROLLBACK
2022-01-05 17:26:34.828564 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: Close
2022-01-05 17:26:34.829147 (Thread-1): 17:26:34  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7559c76e-442f-4452-bf2d-d52ec843e089', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9cf65e070>]}
2022-01-05 17:26:34.829535 (Thread-1): 17:26:34  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 1.04s]
2022-01-05 17:26:34.829654 (Thread-1): 17:26:34  Finished running node model.my_new_project.dim_customers
2022-01-05 17:26:34.831057 (MainThread): 17:26:34  Acquiring new redshift connection "master"
2022-01-05 17:26:34.831201 (MainThread): 17:26:34  Using redshift connection "master"
2022-01-05 17:26:34.831276 (MainThread): 17:26:34  On master: BEGIN
2022-01-05 17:26:34.831352 (MainThread): 17:26:34  Opening a new connection, currently in state closed
2022-01-05 17:26:34.831432 (MainThread): 17:26:34  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:34.856096 (MainThread): 17:26:34  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:34.856216 (MainThread): 17:26:34  On master: COMMIT
2022-01-05 17:26:34.856290 (MainThread): 17:26:34  Using redshift connection "master"
2022-01-05 17:26:34.856359 (MainThread): 17:26:34  On master: COMMIT
2022-01-05 17:26:34.858098 (MainThread): 17:26:34  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:26:34.858206 (MainThread): 17:26:34  On master: Close
2022-01-05 17:26:34.858663 (MainThread): 17:26:34  
2022-01-05 17:26:34.858777 (MainThread): 17:26:34  Finished running 2 table models, 1 view model in 1.22s.
2022-01-05 17:26:34.858858 (MainThread): 17:26:34  Connection 'master' was properly closed.
2022-01-05 17:26:34.858924 (MainThread): 17:26:34  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-05 17:26:34.858985 (MainThread): 17:26:34  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-05 17:26:34.859046 (MainThread): 17:26:34  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-05 17:26:34.929737 (MainThread): 17:26:34  
2022-01-05 17:26:34.929944 (MainThread): 17:26:34  Completed successfully
2022-01-05 17:26:34.930039 (MainThread): 17:26:34  
2022-01-05 17:26:34.930123 (MainThread): 17:26:34  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-05 17:26:35.380716 (Thread-85): handling poll request
2022-01-05 17:26:35.381089 (Thread-85): 17:26:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02479d0>]}
2022-01-05 17:26:35.383114 (Thread-85): sending response (<Response 56622 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:26:36.089452 (Thread-86): handling status request
2022-01-05 17:26:36.089823 (Thread-86): 17:26:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0247220>]}
2022-01-05 17:26:36.090327 (Thread-86): sending response (<Response 1552 bytes [200 OK]>) to 10.0.46.191
2022-01-05 17:26:36.245259 (Thread-87): handling status request
2022-01-05 17:26:36.245677 (Thread-87): 17:26:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01bda30>]}
2022-01-05 17:26:36.246143 (Thread-87): sending response (<Response 1552 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:37:36.466305 (Thread-88): handling status request
2022-01-05 17:37:36.467732 (Thread-88): 17:37:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01e8340>]}
2022-01-05 17:37:36.468223 (Thread-88): sending response (<Response 1552 bytes [200 OK]>) to 10.0.30.3
