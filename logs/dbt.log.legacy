2022-01-05 08:51:08.011330 (MainThread): Running with dbt=1.0.1
2022-01-05 08:51:08.120177 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-05 08:51:08.136975 (MainThread): Tracking: tracking
2022-01-05 08:51:08.146317 (Thread-12): 08:51:08  Partial parse save file not found. Starting full parse.
2022-01-05 08:51:08.146870 (Thread-12): 08:51:08  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9045bf70>]}
2022-01-05 08:51:08.148317 (MainThread): 08:51:08  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7da4ee1be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9045bf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d903c2430>]}
2022-01-05 08:51:08.148595 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-05 08:51:08.148841 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-05 08:51:08.148974 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-05 08:51:08.177208 (Thread-12): 08:51:08  Parsing macros/catalog.sql
2022-01-05 08:51:08.190330 (Thread-12): 08:51:08  Parsing macros/adapters.sql
2022-01-05 08:51:08.218041 (Thread-12): 08:51:08  Parsing macros/relations.sql
2022-01-05 08:51:08.218589 (Thread-12): 08:51:08  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 08:51:08.219192 (Thread-12): 08:51:08  Parsing macros/catalog.sql
2022-01-05 08:51:08.221235 (Thread-12): 08:51:08  Parsing macros/adapters.sql
2022-01-05 08:51:08.242320 (Thread-12): 08:51:08  Parsing macros/relations.sql
2022-01-05 08:51:08.243557 (Thread-12): 08:51:08  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 08:51:08.245127 (Thread-12): 08:51:08  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-05 08:51:08.246577 (Thread-12): 08:51:08  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-05 08:51:08.248079 (Thread-12): 08:51:08  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-05 08:51:08.250469 (Thread-12): 08:51:08  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-05 08:51:08.251790 (Thread-12): 08:51:08  Parsing macros/generic_test_sql/not_null.sql
2022-01-05 08:51:08.252341 (Thread-12): 08:51:08  Parsing macros/generic_test_sql/relationships.sql
2022-01-05 08:51:08.253171 (Thread-12): 08:51:08  Parsing macros/generic_test_sql/unique.sql
2022-01-05 08:51:08.253896 (Thread-12): 08:51:08  Parsing macros/materializations/configs.sql
2022-01-05 08:51:08.256180 (Thread-12): 08:51:08  Parsing macros/materializations/hooks.sql
2022-01-05 08:51:08.260026 (Thread-12): 08:51:08  Parsing macros/materializations/snapshots/strategies.sql
2022-01-05 08:51:08.276370 (Thread-12): 08:51:08  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-05 08:51:08.278102 (Thread-12): 08:51:08  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-05 08:51:08.289092 (Thread-12): 08:51:08  Parsing macros/materializations/snapshots/helpers.sql
2022-01-05 08:51:08.299645 (Thread-12): 08:51:08  Parsing macros/materializations/seeds/seed.sql
2022-01-05 08:51:08.305575 (Thread-12): 08:51:08  Parsing macros/materializations/seeds/helpers.sql
2022-01-05 08:51:08.321519 (Thread-12): 08:51:08  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-05 08:51:08.323757 (Thread-12): 08:51:08  Parsing macros/materializations/models/view/view.sql
2022-01-05 08:51:08.330394 (Thread-12): 08:51:08  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-05 08:51:08.332952 (Thread-12): 08:51:08  Parsing macros/materializations/models/view/helpers.sql
2022-01-05 08:51:08.334258 (Thread-12): 08:51:08  Parsing macros/materializations/models/table/table.sql
2022-01-05 08:51:08.341177 (Thread-12): 08:51:08  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-05 08:51:08.344053 (Thread-12): 08:51:08  Parsing macros/materializations/models/incremental/merge.sql
2022-01-05 08:51:08.354876 (Thread-12): 08:51:08  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-05 08:51:08.369575 (Thread-12): 08:51:08  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-05 08:51:08.373951 (Thread-12): 08:51:08  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-05 08:51:08.384028 (Thread-12): 08:51:08  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-05 08:51:08.384949 (Thread-13): handling status request
2022-01-05 08:51:08.386552 (Thread-12): 08:51:08  Parsing macros/materializations/tests/test.sql
2022-01-05 08:51:08.386843 (Thread-13): 08:51:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9042ebe0>]}
2022-01-05 08:51:08.391133 (Thread-12): 08:51:08  Parsing macros/materializations/tests/where_subquery.sql
2022-01-05 08:51:08.391683 (Thread-13): sending response (<Response 185 bytes [200 OK]>) to 10.0.46.191
2022-01-05 08:51:08.393552 (Thread-12): 08:51:08  Parsing macros/materializations/tests/helpers.sql
2022-01-05 08:51:08.395827 (Thread-12): 08:51:08  Parsing macros/etc/statement.sql
2022-01-05 08:51:08.400347 (Thread-12): 08:51:08  Parsing macros/etc/datetime.sql
2022-01-05 08:51:08.408395 (Thread-12): 08:51:08  Parsing macros/adapters/indexes.sql
2022-01-05 08:51:08.411105 (Thread-12): 08:51:08  Parsing macros/adapters/persist_docs.sql
2022-01-05 08:51:08.415428 (Thread-12): 08:51:08  Parsing macros/adapters/freshness.sql
2022-01-05 08:51:08.418304 (Thread-12): 08:51:08  Parsing macros/adapters/relation.sql
2022-01-05 08:51:08.427537 (Thread-12): 08:51:08  Parsing macros/adapters/metadata.sql
2022-01-05 08:51:08.434440 (Thread-12): 08:51:08  Parsing macros/adapters/columns.sql
2022-01-05 08:51:08.444094 (Thread-12): 08:51:08  Parsing macros/adapters/schema.sql
2022-01-05 08:51:08.446260 (Thread-12): 08:51:08  Parsing tests/generic/builtin.sql
2022-01-05 08:51:08.563263 (Thread-14): handling status request
2022-01-05 08:51:08.583890 (Thread-14): 08:51:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d903a28e0>]}
2022-01-05 08:51:08.589446 (Thread-14): sending response (<Response 185 bytes [200 OK]>) to 10.0.40.203
2022-01-05 08:51:08.647813 (Thread-12): 08:51:08  1699: static parser successfully parsed example/my_second_dbt_model.sql
2022-01-05 08:51:08.659991 (Thread-12): 08:51:08  1699: static parser successfully parsed example/my_first_dbt_model.sql
2022-01-05 08:51:08.742064 (Thread-12): 08:51:08  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900f4520>]}
2022-01-05 08:51:09.755583 (Thread-15): handling status request
2022-01-05 08:51:09.755916 (Thread-15): 08:51:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d90108c40>]}
2022-01-05 08:51:09.756769 (Thread-15): sending response (<Response 15479 bytes [200 OK]>) to 10.0.46.191
2022-01-05 08:51:09.990366 (Thread-16): handling status request
2022-01-05 08:51:09.990688 (Thread-16): 08:51:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d904437c0>]}
2022-01-05 08:51:09.991516 (Thread-16): sending response (<Response 15479 bytes [200 OK]>) to 10.0.41.88
2022-01-05 08:51:59.578565 (Thread-17): handling status request
2022-01-05 08:51:59.580516 (Thread-17): 08:51:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900f45e0>]}
2022-01-05 08:51:59.581332 (Thread-17): sending response (<Response 15479 bytes [200 OK]>) to 10.0.28.79
2022-01-05 08:52:01.823634 (Thread-18): 08:52:01  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 08:52:01.823819 (Thread-18): 08:52:01  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 08:52:01.828713 (Thread-18): 08:52:01  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9006bb80>]}
2022-01-05 08:52:02.470383 (Thread-19): handling status request
2022-01-05 08:52:02.470708 (Thread-19): 08:52:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900812b0>]}
2022-01-05 08:52:02.471163 (Thread-19): sending response (<Response 1241 bytes [200 OK]>) to 10.0.8.202
2022-01-05 08:52:02.486184 (Thread-20): handling status request
2022-01-05 08:52:02.486451 (Thread-20): 08:52:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d90062be0>]}
2022-01-05 08:52:02.486868 (Thread-20): sending response (<Response 1241 bytes [200 OK]>) to 10.0.8.202
2022-01-05 08:52:19.316700 (Thread-21): handling status request
2022-01-05 08:52:19.317027 (Thread-21): 08:52:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d90062dc0>]}
2022-01-05 08:52:19.317502 (Thread-21): sending response (<Response 1241 bytes [200 OK]>) to 10.0.23.251
2022-01-05 08:52:19.347521 (Thread-22): handling status request
2022-01-05 08:52:19.347755 (Thread-22): 08:52:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d90062a60>]}
2022-01-05 08:52:19.348148 (Thread-22): sending response (<Response 1241 bytes [200 OK]>) to 10.0.43.0
2022-01-05 08:52:19.386192 (Thread-23): handling status request
2022-01-05 08:52:19.386409 (Thread-23): 08:52:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900622e0>]}
2022-01-05 08:52:19.386790 (Thread-23): sending response (<Response 1241 bytes [200 OK]>) to 10.0.28.79
2022-01-05 08:52:19.396619 (Thread-24): handling ps request
2022-01-05 08:52:19.396829 (Thread-24): 08:52:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9040c1c0>]}
2022-01-05 08:52:19.397167 (Thread-24): sending response (<Response 105 bytes [200 OK]>) to 10.0.9.20
2022-01-05 08:52:20.122437 (Thread-25): handling status request
2022-01-05 08:52:20.122798 (Thread-25): 08:52:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9045b340>]}
2022-01-05 08:52:20.123265 (Thread-25): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 08:52:20.129072 (Thread-26): handling list request
2022-01-05 08:52:20.129284 (Thread-26): 08:52:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d90441d60>]}
2022-01-05 08:52:20.157288 (Thread-26): 08:52:20  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900eee20>]}
2022-01-05 08:52:20.157639 (Thread-26): 08:52:20  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 08:52:20.161548 (Thread-26): 08:52:20  The selection criterion '+1641370237724/__unsaved/Statement' does not match any nodes
2022-01-05 08:52:20.161741 (Thread-26): 08:52:20  The selection criterion '1.sql+' does not match any nodes
2022-01-05 08:52:20.161842 (Thread-26): 08:52:20  No nodes selected!
2022-01-05 08:52:20.163275 (Thread-26): sending response (<Response 2348 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:02:37.322806 (Thread-27): handling status request
2022-01-05 09:02:37.324268 (Thread-27): 09:02:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d900621c0>]}
2022-01-05 09:02:37.324725 (Thread-27): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:02:37.336332 (Thread-28): handling list request
2022-01-05 09:02:37.336559 (Thread-28): 09:02:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9006d880>]}
2022-01-05 09:02:37.364380 (Thread-28): 09:02:37  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9006df70>]}
2022-01-05 09:02:37.364642 (Thread-28): 09:02:37  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:02:37.372442 (Thread-28): sending response (<Response 5008 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:03:12.543069 (Thread-29): handling status request
2022-01-05 09:03:12.544560 (Thread-29): 09:03:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9006b8e0>]}
2022-01-05 09:03:12.545041 (Thread-29): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:03:12.555852 (Thread-30): handling list request
2022-01-05 09:03:12.556058 (Thread-30): 09:03:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9006df40>]}
2022-01-05 09:03:12.585449 (Thread-30): 09:03:12  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1c6f40>]}
2022-01-05 09:03:12.585700 (Thread-30): 09:03:12  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:03:12.589315 (Thread-30): sending response (<Response 5008 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:03:14.157262 (Thread-31): handling status request
2022-01-05 09:03:14.157613 (Thread-31): 09:03:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1cca30>]}
2022-01-05 09:03:14.158055 (Thread-31): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:03:14.163783 (Thread-32): handling list request
2022-01-05 09:03:14.163987 (Thread-32): 09:03:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1cccd0>]}
2022-01-05 09:03:14.192632 (Thread-32): 09:03:14  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1cca60>]}
2022-01-05 09:03:14.192877 (Thread-32): 09:03:14  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:03:14.196089 (Thread-32): sending response (<Response 5008 bytes [200 OK]>) to 10.0.18.120
2022-01-05 09:03:16.843650 (Thread-33): handling status request
2022-01-05 09:03:16.843979 (Thread-33): 09:03:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1d6550>]}
2022-01-05 09:03:16.844436 (Thread-33): sending response (<Response 1241 bytes [200 OK]>) to 10.0.41.88
2022-01-05 09:03:17.249854 (Thread-34): handling run_sql request
2022-01-05 09:03:17.250176 (Thread-34): 09:03:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1d61c0>]}
2022-01-05 09:03:19.341231 (Thread-34): sending response (<Response 138 bytes [200 OK]>) to 10.0.3.189
2022-01-05 09:03:19.366656 (MainThread): 09:03:19  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '58794d9e-e72f-42cc-a6ba-525420adedff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c0ab1bc70>]}
2022-01-05 09:03:19.367186 (MainThread): 09:03:19  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:03:19.367743 (Thread-1): 09:03:19  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:03:19.367876 (Thread-1): 09:03:19  Began compiling node rpc.my_new_project.request
2022-01-05 09:03:19.367966 (Thread-1): 09:03:19  Compiling rpc.my_new_project.request
2022-01-05 09:03:19.369986 (Thread-1): 09:03:19  finished collecting timing info
2022-01-05 09:03:19.370114 (Thread-1): 09:03:19  Began executing node rpc.my_new_project.request
2022-01-05 09:03:19.370209 (Thread-1): 09:03:19  Using redshift connection "rpc.my_new_project.request"
2022-01-05 09:03:19.370283 (Thread-1): 09:03:19  On rpc.my_new_project.request: -- Use the `ref` function to select from other models

select *
from "analytics"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:03:19.370358 (Thread-1): 09:03:19  Opening a new connection, currently in state init
2022-01-05 09:03:19.370436 (Thread-1): 09:03:19  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:03:19.385650 (Thread-1): 09:03:19  Postgres adapter: Got an error when attempting to open a postgres connection: 'FATAL:  database "analytics" does not exist
'
2022-01-05 09:03:19.385790 (Thread-1): 09:03:19  Postgres adapter: Error running SQL: -- Use the `ref` function to select from other models

select *
from "analytics"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:03:19.385867 (Thread-1): 09:03:19  Postgres adapter: Rolling back transaction.
2022-01-05 09:03:19.385961 (Thread-1): 09:03:19  finished collecting timing info
2022-01-05 09:03:19.386068 (Thread-1): 09:03:19  On rpc.my_new_project.request: No close available on handle
2022-01-05 09:03:19.386130 (Thread-1): Got an exception: Database Error
  FATAL:  database "analytics" does not exist
  
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 121, in open
    handle = psycopg2.connect(
  File "/usr/local/lib/python3.8/dist-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: FATAL:  database "analytics" does not exist


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 73, in add_query
    cursor = connection.handle.cursor()
  File "/usr/local/lib/python3.8/dist-packages/dbt/contracts/connection.py", line 83, in handle
    self._handle.resolve(self)
  File "/usr/local/lib/python3.8/dist-packages/dbt/contracts/connection.py", line 106, in resolve
    return self.opener(connection)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 143, in open
    raise dbt.exceptions.FailedToConnectException(str(e))
dbt.exceptions.FailedToConnectException: Database Error
  FATAL:  database "analytics" does not exist
2022-01-05 09:03:19.387286 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'FailedToConnectException', 'message': 'Database Error in rpc request (from remote system)\n  FATAL:  database "analytics" does not exist\n  ', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "analytics"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'FailedToConnectException', 'message': 'Database Error in rpc request (from remote system)\n  FATAL:  database "analytics" does not exist\n  ', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "analytics"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 09:03:19.708666 (Thread-35): handling poll request
2022-01-05 09:03:19.709078 (Thread-35): 09:03:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '5d237c83-31a5-456d-b8d6-6891f07a3bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d6c1d6610>]}
2022-01-05 09:03:19.737619 (Thread-35): sending response (<Response 10666 bytes [200 OK]>) to 10.0.8.124
2022-01-05 09:04:11.409852 (MainThread): Running with dbt=1.0.1
2022-01-05 09:04:11.512021 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-05 09:04:11.519046 (MainThread): Tracking: tracking
2022-01-05 09:04:11.539288 (MainThread): 09:04:11  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f501bf4cc40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4889a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee488cd0>]}
2022-01-05 09:04:11.539672 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-05 09:04:11.539911 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-05 09:04:11.540043 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-05 09:04:11.549989 (Thread-12): 09:04:11  Unable to do partial parsing because profile has changed
2022-01-05 09:04:11.550312 (Thread-12): 09:04:11  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee488bb0>]}
2022-01-05 09:04:11.591674 (Thread-12): 09:04:11  Parsing macros/catalog.sql
2022-01-05 09:04:11.604631 (Thread-12): 09:04:11  Parsing macros/adapters.sql
2022-01-05 09:04:11.632278 (Thread-12): 09:04:11  Parsing macros/relations.sql
2022-01-05 09:04:11.633008 (Thread-12): 09:04:11  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 09:04:11.633670 (Thread-12): 09:04:11  Parsing macros/catalog.sql
2022-01-05 09:04:11.635756 (Thread-12): 09:04:11  Parsing macros/adapters.sql
2022-01-05 09:04:11.656938 (Thread-12): 09:04:11  Parsing macros/relations.sql
2022-01-05 09:04:11.658228 (Thread-12): 09:04:11  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 09:04:11.659842 (Thread-12): 09:04:11  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-05 09:04:11.661346 (Thread-12): 09:04:11  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-05 09:04:11.662876 (Thread-12): 09:04:11  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-05 09:04:11.665320 (Thread-12): 09:04:11  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-05 09:04:11.666705 (Thread-12): 09:04:11  Parsing macros/generic_test_sql/not_null.sql
2022-01-05 09:04:11.667273 (Thread-12): 09:04:11  Parsing macros/generic_test_sql/relationships.sql
2022-01-05 09:04:11.668130 (Thread-12): 09:04:11  Parsing macros/generic_test_sql/unique.sql
2022-01-05 09:04:11.668873 (Thread-12): 09:04:11  Parsing macros/materializations/configs.sql
2022-01-05 09:04:11.671125 (Thread-12): 09:04:11  Parsing macros/materializations/hooks.sql
2022-01-05 09:04:11.674988 (Thread-12): 09:04:11  Parsing macros/materializations/snapshots/strategies.sql
2022-01-05 09:04:11.691247 (Thread-12): 09:04:11  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-05 09:04:11.693018 (Thread-12): 09:04:11  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-05 09:04:11.704072 (Thread-12): 09:04:11  Parsing macros/materializations/snapshots/helpers.sql
2022-01-05 09:04:11.714904 (Thread-12): 09:04:11  Parsing macros/materializations/seeds/seed.sql
2022-01-05 09:04:11.720799 (Thread-12): 09:04:11  Parsing macros/materializations/seeds/helpers.sql
2022-01-05 09:04:11.736629 (Thread-12): 09:04:11  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-05 09:04:11.738975 (Thread-12): 09:04:11  Parsing macros/materializations/models/view/view.sql
2022-01-05 09:04:11.745673 (Thread-12): 09:04:11  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-05 09:04:11.748277 (Thread-12): 09:04:11  Parsing macros/materializations/models/view/helpers.sql
2022-01-05 09:04:11.749619 (Thread-12): 09:04:11  Parsing macros/materializations/models/table/table.sql
2022-01-05 09:04:11.756688 (Thread-12): 09:04:11  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-05 09:04:11.759484 (Thread-12): 09:04:11  Parsing macros/materializations/models/incremental/merge.sql
2022-01-05 09:04:11.770604 (Thread-12): 09:04:11  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-05 09:04:11.785628 (Thread-12): 09:04:11  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-05 09:04:11.790144 (Thread-12): 09:04:11  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-05 09:04:11.800038 (Thread-12): 09:04:11  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-05 09:04:11.801725 (Thread-12): 09:04:11  Parsing macros/materializations/tests/test.sql
2022-01-05 09:04:11.806220 (Thread-12): 09:04:11  Parsing macros/materializations/tests/where_subquery.sql
2022-01-05 09:04:11.808034 (Thread-12): 09:04:11  Parsing macros/materializations/tests/helpers.sql
2022-01-05 09:04:11.809814 (Thread-12): 09:04:11  Parsing macros/etc/statement.sql
2022-01-05 09:04:11.814144 (Thread-12): 09:04:11  Parsing macros/etc/datetime.sql
2022-01-05 09:04:11.822725 (Thread-12): 09:04:11  Parsing macros/adapters/indexes.sql
2022-01-05 09:04:11.825672 (Thread-12): 09:04:11  Parsing macros/adapters/persist_docs.sql
2022-01-05 09:04:11.830083 (Thread-12): 09:04:11  Parsing macros/adapters/freshness.sql
2022-01-05 09:04:11.833006 (Thread-12): 09:04:11  Parsing macros/adapters/relation.sql
2022-01-05 09:04:11.842797 (Thread-12): 09:04:11  Parsing macros/adapters/metadata.sql
2022-01-05 09:04:11.849992 (Thread-12): 09:04:11  Parsing macros/adapters/columns.sql
2022-01-05 09:04:11.859752 (Thread-12): 09:04:11  Parsing macros/adapters/schema.sql
2022-01-05 09:04:11.862089 (Thread-12): 09:04:11  Parsing tests/generic/builtin.sql
2022-01-05 09:04:12.056049 (Thread-12): 09:04:12  1699: static parser successfully parsed example/my_second_dbt_model.sql
2022-01-05 09:04:12.071674 (Thread-12): 09:04:12  1699: static parser successfully parsed example/my_first_dbt_model.sql
2022-01-05 09:04:12.160181 (Thread-12): 09:04:12  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fed458220>]}
2022-01-05 09:04:13.915456 (Thread-13): handling status request
2022-01-05 09:04:13.915832 (Thread-13): 09:04:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4d0d30>]}
2022-01-05 09:04:13.916831 (Thread-13): sending response (<Response 15522 bytes [200 OK]>) to 10.0.1.185
2022-01-05 09:04:13.991280 (Thread-14): handling status request
2022-01-05 09:04:13.991676 (Thread-14): 09:04:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4ec670>]}
2022-01-05 09:04:13.992889 (Thread-14): sending response (<Response 15522 bytes [200 OK]>) to 10.0.9.20
2022-01-05 09:04:13.994304 (Thread-15): handling ps request
2022-01-05 09:04:13.994676 (Thread-15): 09:04:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee534340>]}
2022-01-05 09:04:13.995094 (Thread-15): sending response (<Response 105 bytes [200 OK]>) to 10.0.23.251
2022-01-05 09:04:14.000271 (Thread-16): handling status request
2022-01-05 09:04:14.000547 (Thread-16): 09:04:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1b74f0>]}
2022-01-05 09:04:14.001420 (Thread-16): sending response (<Response 15522 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:04:22.189781 (Thread-17): handling status request
2022-01-05 09:04:22.191647 (Thread-17): 09:04:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1b7bb0>]}
2022-01-05 09:04:22.192590 (Thread-17): sending response (<Response 15522 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:04:22.523700 (Thread-18): handling run_sql request
2022-01-05 09:04:22.524068 (Thread-18): 09:04:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1b7970>]}
2022-01-05 09:04:24.664280 (Thread-18): sending response (<Response 138 bytes [200 OK]>) to 10.0.22.146
2022-01-05 09:04:24.690177 (MainThread): 09:04:24  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '89d1a01a-870b-4d87-81f6-72548cd1c1b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbee73e610>]}
2022-01-05 09:04:24.690780 (MainThread): 09:04:24  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:04:24.691387 (Thread-1): 09:04:24  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:04:24.691519 (Thread-1): 09:04:24  Began compiling node rpc.my_new_project.request
2022-01-05 09:04:24.691618 (Thread-1): 09:04:24  Compiling rpc.my_new_project.request
2022-01-05 09:04:24.693739 (Thread-1): 09:04:24  finished collecting timing info
2022-01-05 09:04:24.693885 (Thread-1): 09:04:24  Began executing node rpc.my_new_project.request
2022-01-05 09:04:24.693988 (Thread-1): 09:04:24  Using redshift connection "rpc.my_new_project.request"
2022-01-05 09:04:24.694065 (Thread-1): 09:04:24  On rpc.my_new_project.request: -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:04:24.694144 (Thread-1): 09:04:24  Opening a new connection, currently in state init
2022-01-05 09:04:24.694225 (Thread-1): 09:04:24  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:04:24.713806 (Thread-1): 09:04:24  Postgres adapter: Postgres error: Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".

2022-01-05 09:04:24.714045 (Thread-1): 09:04:24  finished collecting timing info
2022-01-05 09:04:24.714202 (Thread-1): 09:04:24  On rpc.my_new_project.request: Close
2022-01-05 09:04:24.714535 (Thread-1): Got an exception: Database Error
  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InternalError_: Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".
2022-01-05 09:04:24.715633 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "dev"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "dev"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 09:04:25.015250 (Thread-19): handling poll request
2022-01-05 09:04:25.015713 (Thread-19): 09:04:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1b7100>]}
2022-01-05 09:04:25.016611 (Thread-19): sending response (<Response 9862 bytes [200 OK]>) to 10.0.18.33
2022-01-05 09:04:54.409698 (Thread-20): handling status request
2022-01-05 09:04:54.411835 (Thread-20): 09:04:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1bcb50>]}
2022-01-05 09:04:54.412898 (Thread-20): sending response (<Response 15522 bytes [200 OK]>) to 10.0.43.0
2022-01-05 09:04:54.781767 (Thread-21): handling run_sql request
2022-01-05 09:04:54.782138 (Thread-21): 09:04:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1bc520>]}
2022-01-05 09:04:56.916885 (Thread-21): sending response (<Response 138 bytes [200 OK]>) to 10.0.18.33
2022-01-05 09:04:56.946111 (MainThread): 09:04:56  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '324af820-22ff-48a5-98c8-39e0f6b53e87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe96c63d700>]}
2022-01-05 09:04:56.946707 (MainThread): 09:04:56  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:04:56.947327 (Thread-1): 09:04:56  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:04:56.947462 (Thread-1): 09:04:56  Began compiling node rpc.my_new_project.request
2022-01-05 09:04:56.947557 (Thread-1): 09:04:56  Compiling rpc.my_new_project.request
2022-01-05 09:04:56.949641 (Thread-1): 09:04:56  finished collecting timing info
2022-01-05 09:04:56.949774 (Thread-1): 09:04:56  Began executing node rpc.my_new_project.request
2022-01-05 09:04:56.949875 (Thread-1): 09:04:56  Using redshift connection "rpc.my_new_project.request"
2022-01-05 09:04:56.949950 (Thread-1): 09:04:56  On rpc.my_new_project.request: /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:04:56.950028 (Thread-1): 09:04:56  Opening a new connection, currently in state init
2022-01-05 09:04:56.950107 (Thread-1): 09:04:56  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:04:56.969208 (Thread-1): 09:04:56  SQL status: SELECT in 0.02 seconds
2022-01-05 09:04:56.970292 (Thread-1): 09:04:56  finished collecting timing info
2022-01-05 09:04:56.970446 (Thread-1): 09:04:56  On rpc.my_new_project.request: Close
2022-01-05 09:04:57.242792 (Thread-22): handling poll request
2022-01-05 09:04:57.243226 (Thread-22): 09:04:57  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1cb3d0>]}
2022-01-05 09:04:57.244488 (Thread-22): sending response (<Response 9360 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:05:06.113750 (Thread-23): handling status request
2022-01-05 09:05:06.114136 (Thread-23): 09:05:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1cb820>]}
2022-01-05 09:05:06.115081 (Thread-23): sending response (<Response 15522 bytes [200 OK]>) to 10.0.8.124
2022-01-05 09:05:06.451010 (Thread-24): handling run_sql request
2022-01-05 09:05:06.451395 (Thread-24): 09:05:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fed4244c0>]}
2022-01-05 09:05:08.580355 (Thread-24): sending response (<Response 138 bytes [200 OK]>) to 10.0.3.45
2022-01-05 09:05:08.606974 (MainThread): 09:05:08  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3af1ed36-2cb4-40ad-bc65-29c40b3ce858', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa05a4b2790>]}
2022-01-05 09:05:08.607592 (MainThread): 09:05:08  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:05:08.608220 (Thread-1): 09:05:08  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:05:08.608356 (Thread-1): 09:05:08  Began compiling node rpc.my_new_project.request
2022-01-05 09:05:08.608450 (Thread-1): 09:05:08  Compiling rpc.my_new_project.request
2022-01-05 09:05:08.610677 (Thread-1): 09:05:08  finished collecting timing info
2022-01-05 09:05:08.610814 (Thread-1): 09:05:08  Began executing node rpc.my_new_project.request
2022-01-05 09:05:08.610918 (Thread-1): 09:05:08  Using redshift connection "rpc.my_new_project.request"
2022-01-05 09:05:08.610998 (Thread-1): 09:05:08  On rpc.my_new_project.request: -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:05:08.611078 (Thread-1): 09:05:08  Opening a new connection, currently in state init
2022-01-05 09:05:08.611160 (Thread-1): 09:05:08  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:05:08.629183 (Thread-1): 09:05:08  Postgres adapter: Postgres error: Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".

2022-01-05 09:05:08.629421 (Thread-1): 09:05:08  finished collecting timing info
2022-01-05 09:05:08.629558 (Thread-1): 09:05:08  On rpc.my_new_project.request: Close
2022-01-05 09:05:08.629857 (Thread-1): Got an exception: Database Error
  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InternalError_: Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".
2022-01-05 09:05:08.630962 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "dev"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Could not find parent table for alias "dev.dbt_nobodozie.my_first_dbt_model".', 'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '-- Use the `ref` function to select from other models\n\nselect *\nfrom "dev"."dbt_nobodozie"."my_first_dbt_model"\nwhere id = 1\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 09:05:08.979242 (Thread-25): handling poll request
2022-01-05 09:05:08.980012 (Thread-25): 09:05:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fed4248e0>]}
2022-01-05 09:05:08.980844 (Thread-25): sending response (<Response 9862 bytes [200 OK]>) to 10.0.8.124
2022-01-05 09:06:13.735816 (Thread-26): handling ps request
2022-01-05 09:06:13.736229 (Thread-26): 09:06:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4c4100>]}
2022-01-05 09:06:13.736947 (Thread-26): sending response (<Response 1640 bytes [200 OK]>) to 10.0.19.22
2022-01-05 09:06:13.755989 (Thread-27): handling status request
2022-01-05 09:06:13.756354 (Thread-27): 09:06:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4c43a0>]}
2022-01-05 09:06:13.757345 (Thread-27): sending response (<Response 15522 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:06:13.821135 (Thread-28): handling status request
2022-01-05 09:06:13.821499 (Thread-28): 09:06:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4c4130>]}
2022-01-05 09:06:13.822340 (Thread-28): sending response (<Response 15522 bytes [200 OK]>) to 10.0.43.0
2022-01-05 09:06:13.863141 (Thread-29): handling status request
2022-01-05 09:06:13.863551 (Thread-29): 09:06:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec185640>]}
2022-01-05 09:06:13.864426 (Thread-29): sending response (<Response 15522 bytes [200 OK]>) to 10.0.3.45
2022-01-05 09:06:14.953143 (Thread-30): handling status request
2022-01-05 09:06:14.953763 (Thread-30): 09:06:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1853d0>]}
2022-01-05 09:06:14.954734 (Thread-30): sending response (<Response 15500 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:14.955270 (Thread-31): handling status request
2022-01-05 09:06:14.956322 (Thread-32): handling status request
2022-01-05 09:06:14.956786 (Thread-31): 09:06:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec185fd0>]}
2022-01-05 09:06:14.957117 (Thread-32): 09:06:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fee4c44f0>]}
2022-01-05 09:06:14.958001 (Thread-31): sending response (<Response 15500 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:14.958908 (Thread-32): sending response (<Response 15500 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:14.962866 (Thread-33): handling list request
2022-01-05 09:06:14.963121 (Thread-33): 09:06:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1851f0>]}
2022-01-05 09:06:14.967226 (Thread-34): handling list request
2022-01-05 09:06:15.017078 (Thread-35): sending response (<Response 214 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:16.371885 (Thread-36): handling status request
2022-01-05 09:06:16.372264 (Thread-36): 09:06:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fed41c580>]}
2022-01-05 09:06:16.396600 (Thread-36): sending response (<Response 15500 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:16.402751 (Thread-37): handling list request
2022-01-05 09:06:16.403061 (Thread-37): 09:06:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1ce250>]}
2022-01-05 09:06:16.433529 (Thread-37): 09:06:16  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0e87f0>]}
2022-01-05 09:06:16.433897 (Thread-37): 09:06:16  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:06:16.436616 (Thread-37): sending response (<Response 5006 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:21.670744 (Thread-38): handling status request
2022-01-05 09:06:21.671124 (Thread-38): 09:06:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0e8f40>]}
2022-01-05 09:06:21.671998 (Thread-38): sending response (<Response 15500 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:21.677522 (Thread-39): handling list request
2022-01-05 09:06:21.677822 (Thread-39): 09:06:21  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec15f250>]}
2022-01-05 09:06:21.705736 (Thread-39): 09:06:21  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0e80d0>]}
2022-01-05 09:06:21.706132 (Thread-39): 09:06:21  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:06:21.706989 (Thread-39): 09:06:21  The selection criterion '+1641370237724/__unsaved/Statement' does not match any nodes
2022-01-05 09:06:21.707205 (Thread-39): 09:06:21  The selection criterion '1.sql+' does not match any nodes
2022-01-05 09:06:21.707317 (Thread-39): 09:06:21  No nodes selected!
2022-01-05 09:06:21.708960 (Thread-39): sending response (<Response 2343 bytes [200 OK]>) to 10.0.35.58
2022-01-05 09:06:23.571235 (Thread-40): handling status request
2022-01-05 09:06:23.571625 (Thread-40): 09:06:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec15fc70>]}
2022-01-05 09:06:23.572502 (Thread-40): sending response (<Response 15522 bytes [200 OK]>) to 10.0.40.203
2022-01-05 09:06:23.925543 (Thread-41): handling run_sql request
2022-01-05 09:06:23.925910 (Thread-41): 09:06:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec15fee0>]}
2022-01-05 09:06:26.097478 (Thread-41): sending response (<Response 138 bytes [200 OK]>) to 10.0.22.146
2022-01-05 09:06:26.123748 (MainThread): 09:06:26  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a7aa97a1-f89b-4a75-9529-d7fcbab33bbf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752814a970>]}
2022-01-05 09:06:26.124341 (MainThread): 09:06:26  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:06:26.124964 (Thread-1): 09:06:26  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:06:26.125092 (Thread-1): 09:06:26  Began compiling node rpc.my_new_project.request
2022-01-05 09:06:26.125184 (Thread-1): 09:06:26  Compiling rpc.my_new_project.request
2022-01-05 09:06:26.127816 (Thread-1): 09:06:26  finished collecting timing info
2022-01-05 09:06:26.127948 (Thread-1): 09:06:26  Began executing node rpc.my_new_project.request
2022-01-05 09:06:26.128049 (Thread-1): 09:06:26  Using redshift connection "rpc.my_new_project.request"
2022-01-05 09:06:26.128125 (Thread-1): 09:06:26  On rpc.my_new_project.request: 

  select 0 as number  union all 



  select 1 as number  union all 



  select 2 as number  union all 



  select 3 as number  union all 



  select 4 as number  union all 



  select 5 as number  union all 



  select 6 as number  union all 



  select 7 as number  union all 



  select 8 as number  union all 



  select 9 as number 


limit 500
/* limit added automatically by dbt cloud */
2022-01-05 09:06:26.128205 (Thread-1): 09:06:26  Opening a new connection, currently in state init
2022-01-05 09:06:26.128286 (Thread-1): 09:06:26  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:06:26.147532 (Thread-1): 09:06:26  SQL status: SELECT in 0.02 seconds
2022-01-05 09:06:26.148790 (Thread-1): 09:06:26  finished collecting timing info
2022-01-05 09:06:26.148961 (Thread-1): 09:06:26  On rpc.my_new_project.request: Close
2022-01-05 09:06:26.504522 (Thread-42): handling poll request
2022-01-05 09:06:26.504980 (Thread-42): 09:06:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec10d3a0>]}
2022-01-05 09:06:26.506218 (Thread-42): sending response (<Response 8387 bytes [200 OK]>) to 10.0.41.88
2022-01-05 09:13:02.276770 (Thread-43): handling status request
2022-01-05 09:13:02.278899 (Thread-43): 09:13:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec10d550>]}
2022-01-05 09:13:02.279948 (Thread-43): sending response (<Response 15522 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:13:02.703429 (Thread-44): handling compile_sql request
2022-01-05 09:13:02.703827 (Thread-44): 09:13:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec10d940>]}
2022-01-05 09:13:04.869826 (Thread-44): sending response (<Response 138 bytes [200 OK]>) to 10.0.19.22
2022-01-05 09:13:04.899073 (MainThread): 09:13:04  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1a6ba891-5ee6-436c-af81-f6ab818da749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ba0fa1f10>]}
2022-01-05 09:13:04.899729 (MainThread): 09:13:04  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:13:04.900396 (Thread-1): 09:13:04  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 09:13:04.900571 (Thread-1): 09:13:04  Began compiling node rpc.my_new_project.request
2022-01-05 09:13:04.900669 (Thread-1): 09:13:04  Compiling rpc.my_new_project.request
2022-01-05 09:13:04.902031 (Thread-1): 09:13:04  finished collecting timing info
2022-01-05 09:13:04.902163 (Thread-1): 09:13:04  Began executing node rpc.my_new_project.request
2022-01-05 09:13:04.902271 (Thread-1): 09:13:04  finished collecting timing info
2022-01-05 09:13:05.221887 (Thread-45): handling poll request
2022-01-05 09:13:05.222340 (Thread-45): 09:13:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec10d490>]}
2022-01-05 09:13:05.223397 (Thread-45): sending response (<Response 7164 bytes [200 OK]>) to 10.0.28.79
2022-01-05 09:18:22.647626 (Thread-46): handling status request
2022-01-05 09:18:22.649759 (Thread-46): 09:18:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1c4970>]}
2022-01-05 09:18:22.650800 (Thread-46): sending response (<Response 15522 bytes [200 OK]>) to 10.0.23.251
2022-01-05 09:18:22.888748 (Thread-47): handling status request
2022-01-05 09:18:22.889117 (Thread-47): 09:18:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fed442700>]}
2022-01-05 09:18:22.889993 (Thread-47): sending response (<Response 15522 bytes [200 OK]>) to 10.0.9.20
2022-01-05 09:18:22.991082 (Thread-48): handling cli_args request
2022-01-05 09:18:22.991456 (Thread-48): 09:18:22  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec1106d0>]}
2022-01-05 09:18:25.164595 (Thread-48): sending response (<Response 138 bytes [200 OK]>) to 10.0.41.88
2022-01-05 09:18:25.262928 (MainThread): 09:18:25  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 09:18:25.263373 (MainThread): 09:18:25  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 09:18:25.269715 (MainThread): 09:18:25  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0ffdc471-2794-4ba4-a05d-6e70a316dfc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd62777a60>]}
2022-01-05 09:18:25.304676 (MainThread): 09:18:25  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0ffdc471-2794-4ba4-a05d-6e70a316dfc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd627d7a00>]}
2022-01-05 09:18:25.305019 (MainThread): 09:18:25  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:18:25.306193 (MainThread): 09:18:25  
2022-01-05 09:18:25.306547 (MainThread): 09:18:25  Acquiring new redshift connection "master"
2022-01-05 09:18:25.307511 (ThreadPoolExecutor-0_0): 09:18:25  Acquiring new redshift connection "list_dev"
2022-01-05 09:18:25.318203 (ThreadPoolExecutor-0_0): 09:18:25  Using redshift connection "list_dev"
2022-01-05 09:18:25.318333 (ThreadPoolExecutor-0_0): 09:18:25  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-05 09:18:25.318424 (ThreadPoolExecutor-0_0): 09:18:25  Opening a new connection, currently in state init
2022-01-05 09:18:25.318511 (ThreadPoolExecutor-0_0): 09:18:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:25.337776 (ThreadPoolExecutor-0_0): 09:18:25  SQL status: SELECT in 0.02 seconds
2022-01-05 09:18:25.339009 (ThreadPoolExecutor-0_0): 09:18:25  On list_dev: Close
2022-01-05 09:18:25.339871 (ThreadPoolExecutor-0_0): 09:18:25  Acquiring new redshift connection "create_dev_dbt_nobodozie"
2022-01-05 09:18:25.340133 (ThreadPoolExecutor-0_0): 09:18:25  Acquiring new redshift connection "create_dev_dbt_nobodozie"
2022-01-05 09:18:25.340305 (ThreadPoolExecutor-0_0): 09:18:25  Creating schema "_ReferenceKey(database='dev', schema='dbt_nobodozie', identifier=None)"
2022-01-05 09:18:25.346396 (ThreadPoolExecutor-0_0): 09:18:25  Using redshift connection "create_dev_dbt_nobodozie"
2022-01-05 09:18:25.346507 (ThreadPoolExecutor-0_0): 09:18:25  On create_dev_dbt_nobodozie: BEGIN
2022-01-05 09:18:25.346591 (ThreadPoolExecutor-0_0): 09:18:25  Opening a new connection, currently in state closed
2022-01-05 09:18:25.346672 (ThreadPoolExecutor-0_0): 09:18:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:25.367572 (ThreadPoolExecutor-0_0): 09:18:25  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:25.367750 (ThreadPoolExecutor-0_0): 09:18:25  Using redshift connection "create_dev_dbt_nobodozie"
2022-01-05 09:18:25.367836 (ThreadPoolExecutor-0_0): 09:18:25  On create_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "create_dev_dbt_nobodozie"} */
create schema if not exists "dbt_nobodozie"
2022-01-05 09:18:25.369985 (ThreadPoolExecutor-0_0): 09:18:25  SQL status: CREATE SCHEMA in 0.0 seconds
2022-01-05 09:18:25.370819 (ThreadPoolExecutor-0_0): 09:18:25  On create_dev_dbt_nobodozie: COMMIT
2022-01-05 09:18:25.370926 (ThreadPoolExecutor-0_0): 09:18:25  Using redshift connection "create_dev_dbt_nobodozie"
2022-01-05 09:18:25.371003 (ThreadPoolExecutor-0_0): 09:18:25  On create_dev_dbt_nobodozie: COMMIT
2022-01-05 09:18:25.427178 (ThreadPoolExecutor-0_0): 09:18:25  SQL status: COMMIT in 0.06 seconds
2022-01-05 09:18:25.427396 (ThreadPoolExecutor-0_0): 09:18:25  On create_dev_dbt_nobodozie: Close
2022-01-05 09:18:25.428905 (ThreadPoolExecutor-1_0): 09:18:25  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:25.436213 (ThreadPoolExecutor-1_0): 09:18:25  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:25.436381 (ThreadPoolExecutor-1_0): 09:18:25  On list_dev_dbt_nobodozie: BEGIN
2022-01-05 09:18:25.436510 (ThreadPoolExecutor-1_0): 09:18:25  Opening a new connection, currently in state closed
2022-01-05 09:18:25.436599 (ThreadPoolExecutor-1_0): 09:18:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:25.456921 (ThreadPoolExecutor-1_0): 09:18:25  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:25.457092 (ThreadPoolExecutor-1_0): 09:18:25  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:25.457177 (ThreadPoolExecutor-1_0): 09:18:25  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-05 09:18:25.467943 (ThreadPoolExecutor-1_0): 09:18:25  SQL status: SELECT in 0.01 seconds
2022-01-05 09:18:25.469178 (ThreadPoolExecutor-1_0): 09:18:25  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-05 09:18:25.470906 (ThreadPoolExecutor-1_0): 09:18:25  On list_dev_dbt_nobodozie: Close
2022-01-05 09:18:25.475191 (MainThread): 09:18:25  Using redshift connection "master"
2022-01-05 09:18:25.475320 (MainThread): 09:18:25  On master: BEGIN
2022-01-05 09:18:25.475409 (MainThread): 09:18:25  Opening a new connection, currently in state init
2022-01-05 09:18:25.475492 (MainThread): 09:18:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:25.498583 (MainThread): 09:18:25  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:25.498752 (MainThread): 09:18:25  Using redshift connection "master"
2022-01-05 09:18:25.498835 (MainThread): 09:18:25  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-05 09:18:25.517349 (MainThread): 09:18:25  SQL status: SELECT in 0.02 seconds
2022-01-05 09:18:25.518479 (MainThread): 09:18:25  On master: ROLLBACK
2022-01-05 09:18:25.520307 (MainThread): 09:18:25  Using redshift connection "master"
2022-01-05 09:18:25.520418 (MainThread): 09:18:25  On master: BEGIN
2022-01-05 09:18:25.523663 (MainThread): 09:18:25  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:25.523780 (MainThread): 09:18:25  On master: COMMIT
2022-01-05 09:18:25.523855 (MainThread): 09:18:25  Using redshift connection "master"
2022-01-05 09:18:25.523926 (MainThread): 09:18:25  On master: COMMIT
2022-01-05 09:18:25.525547 (MainThread): 09:18:25  SQL status: COMMIT in 0.0 seconds
2022-01-05 09:18:25.525699 (MainThread): 09:18:25  On master: Close
2022-01-05 09:18:25.526232 (MainThread): 09:18:25  Concurrency: 4 threads (target='default')
2022-01-05 09:18:25.526354 (MainThread): 09:18:25  
2022-01-05 09:18:25.528953 (Thread-1): 09:18:25  Began running node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:25.529254 (Thread-1): 09:18:25  1 of 2 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-05 09:18:25.529539 (Thread-1): 09:18:25  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:25.529635 (Thread-1): 09:18:25  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:25.529728 (Thread-1): 09:18:25  Compiling model.my_new_project.my_first_dbt_model
2022-01-05 09:18:25.532149 (Thread-1): 09:18:25  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:25.565934 (Thread-1): 09:18:25  finished collecting timing info
2022-01-05 09:18:25.566166 (Thread-1): 09:18:25  Began executing node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:25.581588 (Thread-49): handling poll request
2022-01-05 09:18:25.581983 (Thread-49): 09:18:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0b90d0>]}
2022-01-05 09:18:25.583329 (Thread-49): sending response (<Response 24818 bytes [200 OK]>) to 10.0.43.175
2022-01-05 09:18:25.599705 (Thread-1): 09:18:25  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:25.641364 (Thread-1): 09:18:25  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:25.641542 (Thread-1): 09:18:25  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:25.641635 (Thread-1): 09:18:25  Opening a new connection, currently in state closed
2022-01-05 09:18:25.641720 (Thread-1): 09:18:25  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:25.660944 (Thread-1): 09:18:25  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:25.661123 (Thread-1): 09:18:25  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:25.661209 (Thread-1): 09:18:25  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-05 09:18:26.162640 (Thread-1): 09:18:26  SQL status: SELECT in 0.5 seconds
2022-01-05 09:18:26.168886 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.169025 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-05 09:18:26.171582 (Thread-1): 09:18:26  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 09:18:26.182098 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:26.182245 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.182325 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:26.223482 (Thread-1): 09:18:26  SQL status: COMMIT in 0.04 seconds
2022-01-05 09:18:26.223827 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.223920 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:26.225886 (Thread-1): 09:18:26  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:26.230573 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.230682 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-05 09:18:26.232557 (Thread-1): 09:18:26  SQL status: DROP TABLE in 0.0 seconds
2022-01-05 09:18:26.233295 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:26.233396 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.233472 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:26.237263 (Thread-1): 09:18:26  SQL status: COMMIT in 0.0 seconds
2022-01-05 09:18:26.237369 (Thread-1): 09:18:26  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:26.237441 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:26.239204 (Thread-1): 09:18:26  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:26.239682 (Thread-1): 09:18:26  finished collecting timing info
2022-01-05 09:18:26.239836 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-05 09:18:26.241470 (Thread-1): 09:18:26  On model.my_new_project.my_first_dbt_model: Close
2022-01-05 09:18:26.241995 (Thread-1): 09:18:26  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ffdc471-2794-4ba4-a05d-6e70a316dfc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd60691f70>]}
2022-01-05 09:18:26.242348 (Thread-1): 09:18:26  1 of 2 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.71s]
2022-01-05 09:18:26.242464 (Thread-1): 09:18:26  Finished running node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:26.243359 (Thread-3): 09:18:26  Began running node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:26.243577 (Thread-3): 09:18:26  2 of 2 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-05 09:18:26.243836 (Thread-3): 09:18:26  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.243923 (Thread-3): 09:18:26  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:26.244011 (Thread-3): 09:18:26  Compiling model.my_new_project.my_second_dbt_model
2022-01-05 09:18:26.246404 (Thread-3): 09:18:26  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.259815 (Thread-3): 09:18:26  finished collecting timing info
2022-01-05 09:18:26.259973 (Thread-3): 09:18:26  Began executing node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:26.276594 (Thread-3): 09:18:26  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.289891 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.290043 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:26.290136 (Thread-3): 09:18:26  Opening a new connection, currently in state init
2022-01-05 09:18:26.290223 (Thread-3): 09:18:26  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:26.307730 (Thread-3): 09:18:26  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:26.307898 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.307983 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-05 09:18:26.312746 (Thread-3): 09:18:26  SQL status: CREATE VIEW in 0.0 seconds
2022-01-05 09:18:26.315068 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.315188 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-05 09:18:26.317162 (Thread-3): 09:18:26  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 09:18:26.318262 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:26.318362 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.318436 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:26.346717 (Thread-3): 09:18:26  SQL status: COMMIT in 0.03 seconds
2022-01-05 09:18:26.347044 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.347134 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:26.349041 (Thread-3): 09:18:26  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:26.351775 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.351878 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-05 09:18:26.353615 (Thread-3): 09:18:26  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 09:18:26.354346 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:26.354444 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.354519 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:26.377998 (Thread-3): 09:18:26  SQL status: COMMIT in 0.02 seconds
2022-01-05 09:18:26.378154 (Thread-3): 09:18:26  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:26.378233 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:26.380065 (Thread-3): 09:18:26  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:26.380623 (Thread-3): 09:18:26  finished collecting timing info
2022-01-05 09:18:26.380772 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-05 09:18:26.382359 (Thread-3): 09:18:26  On model.my_new_project.my_second_dbt_model: Close
2022-01-05 09:18:26.382877 (Thread-3): 09:18:26  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ffdc471-2794-4ba4-a05d-6e70a316dfc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd6060df70>]}
2022-01-05 09:18:26.383239 (Thread-3): 09:18:26  2 of 2 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.14s]
2022-01-05 09:18:26.383353 (Thread-3): 09:18:26  Finished running node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:26.384785 (MainThread): 09:18:26  Acquiring new redshift connection "master"
2022-01-05 09:18:26.384945 (MainThread): 09:18:26  Using redshift connection "master"
2022-01-05 09:18:26.385026 (MainThread): 09:18:26  On master: BEGIN
2022-01-05 09:18:26.385104 (MainThread): 09:18:26  Opening a new connection, currently in state closed
2022-01-05 09:18:26.385184 (MainThread): 09:18:26  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:26.407190 (MainThread): 09:18:26  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:26.407382 (MainThread): 09:18:26  On master: COMMIT
2022-01-05 09:18:26.407463 (MainThread): 09:18:26  Using redshift connection "master"
2022-01-05 09:18:26.407539 (MainThread): 09:18:26  On master: COMMIT
2022-01-05 09:18:26.409081 (MainThread): 09:18:26  SQL status: COMMIT in 0.0 seconds
2022-01-05 09:18:26.409215 (MainThread): 09:18:26  On master: Close
2022-01-05 09:18:26.409732 (MainThread): 09:18:26  
2022-01-05 09:18:26.409856 (MainThread): 09:18:26  Finished running 1 table model, 1 view model in 1.10s.
2022-01-05 09:18:26.409942 (MainThread): 09:18:26  Connection 'master' was properly closed.
2022-01-05 09:18:26.410010 (MainThread): 09:18:26  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-05 09:18:26.410075 (MainThread): 09:18:26  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-05 09:18:26.449477 (MainThread): 09:18:26  
2022-01-05 09:18:26.449709 (MainThread): 09:18:26  Completed successfully
2022-01-05 09:18:26.449809 (MainThread): 09:18:26  
2022-01-05 09:18:26.449898 (MainThread): 09:18:26  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2022-01-05 09:18:26.919047 (Thread-50): handling poll request
2022-01-05 09:18:26.919431 (Thread-50): 09:18:26  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0a1ca0>]}
2022-01-05 09:18:26.921227 (Thread-50): sending response (<Response 43307 bytes [200 OK]>) to 10.0.35.228
2022-01-05 09:18:27.567455 (Thread-51): handling status request
2022-01-05 09:18:27.567831 (Thread-51): 09:18:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0d2250>]}
2022-01-05 09:18:27.568763 (Thread-51): sending response (<Response 15522 bytes [200 OK]>) to 10.0.8.124
2022-01-05 09:18:27.603137 (Thread-52): handling status request
2022-01-05 09:18:27.603511 (Thread-52): 09:18:27  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0d2af0>]}
2022-01-05 09:18:27.604306 (Thread-52): sending response (<Response 15522 bytes [200 OK]>) to 10.0.31.49
2022-01-05 09:18:37.291148 (Thread-53): handling status request
2022-01-05 09:18:37.291535 (Thread-53): 09:18:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0d2d60>]}
2022-01-05 09:18:37.292333 (Thread-53): sending response (<Response 15522 bytes [200 OK]>) to 10.0.31.49
2022-01-05 09:18:37.579995 (Thread-54): handling status request
2022-01-05 09:18:37.580401 (Thread-54): 09:18:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec0d2fd0>]}
2022-01-05 09:18:37.581277 (Thread-54): sending response (<Response 15522 bytes [200 OK]>) to 10.0.46.191
2022-01-05 09:18:37.608557 (Thread-55): handling cli_args request
2022-01-05 09:18:37.608936 (Thread-55): 09:18:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec055280>]}
2022-01-05 09:18:39.756760 (Thread-55): sending response (<Response 138 bytes [200 OK]>) to 10.0.8.202
2022-01-05 09:18:39.846940 (MainThread): 09:18:39  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 09:18:39.847414 (MainThread): 09:18:39  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 09:18:39.853523 (MainThread): 09:18:39  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'caf0dcfa-b066-47c3-bd15-7998fbb6cdfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39b80d6a90>]}
2022-01-05 09:18:39.883275 (MainThread): 09:18:39  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'caf0dcfa-b066-47c3-bd15-7998fbb6cdfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39b8136a30>]}
2022-01-05 09:18:39.883614 (MainThread): 09:18:39  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 09:18:39.884782 (MainThread): 09:18:39  
2022-01-05 09:18:39.885129 (MainThread): 09:18:39  Acquiring new redshift connection "master"
2022-01-05 09:18:39.886087 (ThreadPoolExecutor-0_0): 09:18:39  Acquiring new redshift connection "list_dev"
2022-01-05 09:18:39.896644 (ThreadPoolExecutor-0_0): 09:18:39  Using redshift connection "list_dev"
2022-01-05 09:18:39.896778 (ThreadPoolExecutor-0_0): 09:18:39  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-05 09:18:39.896869 (ThreadPoolExecutor-0_0): 09:18:39  Opening a new connection, currently in state init
2022-01-05 09:18:39.896956 (ThreadPoolExecutor-0_0): 09:18:39  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:39.918688 (ThreadPoolExecutor-0_0): 09:18:39  SQL status: SELECT in 0.02 seconds
2022-01-05 09:18:39.919919 (ThreadPoolExecutor-0_0): 09:18:39  On list_dev: Close
2022-01-05 09:18:39.921204 (ThreadPoolExecutor-1_0): 09:18:39  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:39.927731 (ThreadPoolExecutor-1_0): 09:18:39  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:39.927843 (ThreadPoolExecutor-1_0): 09:18:39  On list_dev_dbt_nobodozie: BEGIN
2022-01-05 09:18:39.927930 (ThreadPoolExecutor-1_0): 09:18:39  Opening a new connection, currently in state closed
2022-01-05 09:18:39.928011 (ThreadPoolExecutor-1_0): 09:18:39  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:39.950427 (ThreadPoolExecutor-1_0): 09:18:39  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:39.950602 (ThreadPoolExecutor-1_0): 09:18:39  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 09:18:39.950684 (ThreadPoolExecutor-1_0): 09:18:39  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-05 09:18:39.961819 (ThreadPoolExecutor-1_0): 09:18:39  SQL status: SELECT in 0.01 seconds
2022-01-05 09:18:39.963223 (ThreadPoolExecutor-1_0): 09:18:39  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-05 09:18:39.965011 (ThreadPoolExecutor-1_0): 09:18:39  On list_dev_dbt_nobodozie: Close
2022-01-05 09:18:39.969952 (MainThread): 09:18:39  Using redshift connection "master"
2022-01-05 09:18:39.970087 (MainThread): 09:18:39  On master: BEGIN
2022-01-05 09:18:39.970175 (MainThread): 09:18:39  Opening a new connection, currently in state init
2022-01-05 09:18:39.970259 (MainThread): 09:18:39  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:40.116326 (Thread-56): handling poll request
2022-01-05 09:18:40.116822 (Thread-56): 09:18:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec055640>]}
2022-01-05 09:18:40.117878 (Thread-56): sending response (<Response 9949 bytes [200 OK]>) to 10.0.23.251
2022-01-05 09:18:40.510973 (MainThread): 09:18:40  SQL status: BEGIN in 0.54 seconds
2022-01-05 09:18:40.511152 (MainThread): 09:18:40  Using redshift connection "master"
2022-01-05 09:18:40.511238 (MainThread): 09:18:40  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-05 09:18:40.539720 (MainThread): 09:18:40  SQL status: SELECT in 0.03 seconds
2022-01-05 09:18:40.541032 (MainThread): 09:18:40  On master: ROLLBACK
2022-01-05 09:18:40.542921 (MainThread): 09:18:40  Using redshift connection "master"
2022-01-05 09:18:40.543039 (MainThread): 09:18:40  On master: BEGIN
2022-01-05 09:18:40.546333 (MainThread): 09:18:40  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:40.546462 (MainThread): 09:18:40  On master: COMMIT
2022-01-05 09:18:40.546542 (MainThread): 09:18:40  Using redshift connection "master"
2022-01-05 09:18:40.546617 (MainThread): 09:18:40  On master: COMMIT
2022-01-05 09:18:40.548215 (MainThread): 09:18:40  SQL status: COMMIT in 0.0 seconds
2022-01-05 09:18:40.548343 (MainThread): 09:18:40  On master: Close
2022-01-05 09:18:40.548919 (MainThread): 09:18:40  Concurrency: 4 threads (target='default')
2022-01-05 09:18:40.549081 (MainThread): 09:18:40  
2022-01-05 09:18:40.551527 (Thread-1): 09:18:40  Began running node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:40.552061 (Thread-1): 09:18:40  1 of 2 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-05 09:18:40.552372 (Thread-1): 09:18:40  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.552520 (Thread-1): 09:18:40  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:40.552621 (Thread-1): 09:18:40  Compiling model.my_new_project.my_first_dbt_model
2022-01-05 09:18:40.555098 (Thread-1): 09:18:40  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.571373 (Thread-1): 09:18:40  finished collecting timing info
2022-01-05 09:18:40.571586 (Thread-1): 09:18:40  Began executing node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:40.608485 (Thread-1): 09:18:40  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.624558 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.624730 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:40.624830 (Thread-1): 09:18:40  Opening a new connection, currently in state closed
2022-01-05 09:18:40.624916 (Thread-1): 09:18:40  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:40.642447 (Thread-1): 09:18:40  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:40.642629 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.642714 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-05 09:18:40.689110 (Thread-1): 09:18:40  SQL status: SELECT in 0.05 seconds
2022-01-05 09:18:40.695566 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.695710 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-05 09:18:40.698156 (Thread-1): 09:18:40  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 09:18:40.700158 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.700267 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-05 09:18:40.702591 (Thread-1): 09:18:40  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 09:18:40.713224 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:40.713363 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.713442 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:40.746959 (Thread-1): 09:18:40  SQL status: COMMIT in 0.03 seconds
2022-01-05 09:18:40.747310 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.747404 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:40.749450 (Thread-1): 09:18:40  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:40.753989 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.754096 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-05 09:18:40.758877 (Thread-1): 09:18:40  SQL status: DROP TABLE in 0.0 seconds
2022-01-05 09:18:40.759610 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:40.759711 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.759787 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 09:18:40.785211 (Thread-1): 09:18:40  SQL status: COMMIT in 0.03 seconds
2022-01-05 09:18:40.785378 (Thread-1): 09:18:40  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 09:18:40.785461 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 09:18:40.787424 (Thread-1): 09:18:40  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:40.787973 (Thread-1): 09:18:40  finished collecting timing info
2022-01-05 09:18:40.788116 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-05 09:18:40.789786 (Thread-1): 09:18:40  On model.my_new_project.my_first_dbt_model: Close
2022-01-05 09:18:40.790335 (Thread-1): 09:18:40  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'caf0dcfa-b066-47c3-bd15-7998fbb6cdfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39b7029370>]}
2022-01-05 09:18:40.790719 (Thread-1): 09:18:40  1 of 2 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.24s]
2022-01-05 09:18:40.790856 (Thread-1): 09:18:40  Finished running node model.my_new_project.my_first_dbt_model
2022-01-05 09:18:40.791754 (Thread-3): 09:18:40  Began running node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:40.792029 (Thread-3): 09:18:40  2 of 2 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-05 09:18:40.792321 (Thread-3): 09:18:40  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:40.792416 (Thread-3): 09:18:40  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:40.792538 (Thread-3): 09:18:40  Compiling model.my_new_project.my_second_dbt_model
2022-01-05 09:18:40.795042 (Thread-3): 09:18:40  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:40.810254 (Thread-3): 09:18:40  finished collecting timing info
2022-01-05 09:18:40.810455 (Thread-3): 09:18:40  Began executing node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:40.827545 (Thread-3): 09:18:40  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:40.843252 (Thread-3): 09:18:40  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:40.843423 (Thread-3): 09:18:40  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:40.843519 (Thread-3): 09:18:40  Opening a new connection, currently in state init
2022-01-05 09:18:40.843605 (Thread-3): 09:18:40  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:41.285691 (Thread-3): 09:18:41  SQL status: BEGIN in 0.44 seconds
2022-01-05 09:18:41.285875 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.285961 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-05 09:18:41.290681 (Thread-3): 09:18:41  SQL status: CREATE VIEW in 0.0 seconds
2022-01-05 09:18:41.292998 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.293127 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-05 09:18:41.295243 (Thread-3): 09:18:41  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 09:18:41.296386 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:41.296525 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.296605 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:41.324686 (Thread-3): 09:18:41  SQL status: COMMIT in 0.03 seconds
2022-01-05 09:18:41.325018 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.325109 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:41.327081 (Thread-3): 09:18:41  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:41.328653 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.328759 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-05 09:18:41.330536 (Thread-3): 09:18:41  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 09:18:41.331290 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:41.331390 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.331464 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 09:18:41.356932 (Thread-3): 09:18:41  SQL status: COMMIT in 0.03 seconds
2022-01-05 09:18:41.357099 (Thread-3): 09:18:41  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 09:18:41.357179 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 09:18:41.359241 (Thread-3): 09:18:41  SQL status: BEGIN in 0.0 seconds
2022-01-05 09:18:41.359789 (Thread-3): 09:18:41  finished collecting timing info
2022-01-05 09:18:41.359933 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-05 09:18:41.361515 (Thread-3): 09:18:41  On model.my_new_project.my_second_dbt_model: Close
2022-01-05 09:18:41.362047 (Thread-3): 09:18:41  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'caf0dcfa-b066-47c3-bd15-7998fbb6cdfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3997fa6070>]}
2022-01-05 09:18:41.362403 (Thread-3): 09:18:41  2 of 2 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.57s]
2022-01-05 09:18:41.362521 (Thread-3): 09:18:41  Finished running node model.my_new_project.my_second_dbt_model
2022-01-05 09:18:41.364021 (MainThread): 09:18:41  Acquiring new redshift connection "master"
2022-01-05 09:18:41.364179 (MainThread): 09:18:41  Using redshift connection "master"
2022-01-05 09:18:41.364261 (MainThread): 09:18:41  On master: BEGIN
2022-01-05 09:18:41.364345 (MainThread): 09:18:41  Opening a new connection, currently in state closed
2022-01-05 09:18:41.364428 (MainThread): 09:18:41  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 09:18:41.388057 (MainThread): 09:18:41  SQL status: BEGIN in 0.02 seconds
2022-01-05 09:18:41.388246 (MainThread): 09:18:41  On master: COMMIT
2022-01-05 09:18:41.388332 (MainThread): 09:18:41  Using redshift connection "master"
2022-01-05 09:18:41.388411 (MainThread): 09:18:41  On master: COMMIT
2022-01-05 09:18:41.390025 (MainThread): 09:18:41  SQL status: COMMIT in 0.0 seconds
2022-01-05 09:18:41.390170 (MainThread): 09:18:41  On master: Close
2022-01-05 09:18:41.390711 (MainThread): 09:18:41  
2022-01-05 09:18:41.390840 (MainThread): 09:18:41  Finished running 1 table model, 1 view model in 1.51s.
2022-01-05 09:18:41.390926 (MainThread): 09:18:41  Connection 'master' was properly closed.
2022-01-05 09:18:41.390997 (MainThread): 09:18:41  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-05 09:18:41.391062 (MainThread): 09:18:41  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-05 09:18:41.451709 (MainThread): 09:18:41  
2022-01-05 09:18:41.451936 (MainThread): 09:18:41  Completed successfully
2022-01-05 09:18:41.452035 (MainThread): 09:18:41  
2022-01-05 09:18:41.452123 (MainThread): 09:18:41  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2022-01-05 09:18:41.457290 (Thread-57): handling poll request
2022-01-05 09:18:41.457615 (Thread-57): 09:18:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec11c3a0>]}
2022-01-05 09:18:41.459158 (Thread-57): sending response (<Response 48497 bytes [200 OK]>) to 10.0.43.175
2022-01-05 09:18:42.836873 (Thread-58): handling poll request
2022-01-05 09:18:42.837274 (Thread-58): 09:18:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec11c940>]}
2022-01-05 09:18:42.838212 (Thread-58): sending response (<Response 6210 bytes [200 OK]>) to 10.0.9.20
2022-01-05 09:18:43.445916 (Thread-59): handling status request
2022-01-05 09:18:43.446332 (Thread-59): 09:18:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec07f580>]}
2022-01-05 09:18:43.447356 (Thread-59): sending response (<Response 15522 bytes [200 OK]>) to 10.0.40.203
2022-01-05 09:18:43.552650 (Thread-60): handling status request
2022-01-05 09:18:43.553053 (Thread-60): 09:18:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '48391e14-7430-4dea-b9ca-f2ad53861007', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fec07f970>]}
2022-01-05 09:18:43.553961 (Thread-60): sending response (<Response 15522 bytes [200 OK]>) to 10.0.18.33
2022-01-05 16:18:58.393119 (MainThread): Running with dbt=1.0.1
2022-01-05 16:18:58.494275 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-05 16:18:58.501451 (MainThread): Tracking: tracking
2022-01-05 16:18:58.521656 (MainThread): 16:18:58  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cdfb33c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0071a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0071d90>]}
2022-01-05 16:18:58.522055 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-05 16:18:58.522291 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-05 16:18:58.522425 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-05 16:18:58.566695 (Thread-12): 16:18:58  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 16:18:58.566930 (Thread-12): 16:18:58  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 16:18:58.573259 (Thread-12): 16:18:58  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fdf2e0>]}
2022-01-05 16:19:01.218865 (Thread-13): handling ps request
2022-01-05 16:19:01.219288 (Thread-13): 16:19:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd00d75b0>]}
2022-01-05 16:19:01.219847 (Thread-13): sending response (<Response 105 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:19:01.222694 (Thread-14): handling status request
2022-01-05 16:19:01.222956 (Thread-14): 16:19:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd00d7250>]}
2022-01-05 16:19:01.223385 (Thread-14): sending response (<Response 1241 bytes [200 OK]>) to 10.0.42.119
2022-01-05 16:19:01.307931 (Thread-15): handling status request
2022-01-05 16:19:01.308307 (Thread-15): 16:19:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd00d7070>]}
2022-01-05 16:19:01.308796 (Thread-15): sending response (<Response 1241 bytes [200 OK]>) to 10.0.38.111
2022-01-05 16:19:01.517449 (Thread-16): handling status request
2022-01-05 16:19:01.517826 (Thread-16): 16:19:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0119b20>]}
2022-01-05 16:19:01.518282 (Thread-16): sending response (<Response 1241 bytes [200 OK]>) to 10.0.46.191
2022-01-05 16:19:02.605573 (Thread-17): handling status request
2022-01-05 16:19:02.605950 (Thread-17): 16:19:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0071f40>]}
2022-01-05 16:19:02.606440 (Thread-17): sending response (<Response 1219 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:19:02.612856 (Thread-18): handling list request
2022-01-05 16:19:02.613183 (Thread-18): 16:19:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0071ac0>]}
2022-01-05 16:19:02.646100 (Thread-18): 16:19:02  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd00d7850>]}
2022-01-05 16:19:02.646497 (Thread-18): 16:19:02  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:19:02.649596 (Thread-18): 16:19:02  The selection criterion '+1641399542329/__unsaved/Statement' does not match any nodes
2022-01-05 16:19:02.649839 (Thread-18): 16:19:02  The selection criterion '1.sql+' does not match any nodes
2022-01-05 16:19:02.649956 (Thread-18): 16:19:02  No nodes selected!
2022-01-05 16:19:02.651784 (Thread-18): sending response (<Response 2343 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:19:35.647741 (Thread-19): handling status request
2022-01-05 16:19:35.648121 (Thread-19): 16:19:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fdf7c0>]}
2022-01-05 16:19:35.648644 (Thread-19): sending response (<Response 1241 bytes [200 OK]>) to 10.0.30.3
2022-01-05 16:19:35.666335 (Thread-20): handling status request
2022-01-05 16:19:35.666677 (Thread-20): 16:19:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fe81c0>]}
2022-01-05 16:19:35.667130 (Thread-20): sending response (<Response 1241 bytes [200 OK]>) to 10.0.19.216
2022-01-05 16:19:35.677318 (Thread-21): handling ps request
2022-01-05 16:19:35.677623 (Thread-21): 16:19:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fe8220>]}
2022-01-05 16:19:35.678125 (Thread-21): sending response (<Response 393 bytes [200 OK]>) to 10.0.42.85
2022-01-05 16:19:35.694513 (Thread-22): handling status request
2022-01-05 16:19:35.694872 (Thread-22): 16:19:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fe83d0>]}
2022-01-05 16:19:35.695325 (Thread-22): sending response (<Response 1241 bytes [200 OK]>) to 10.0.38.111
2022-01-05 16:19:36.553649 (Thread-23): handling status request
2022-01-05 16:19:36.554048 (Thread-23): 16:19:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fe88b0>]}
2022-01-05 16:19:36.554504 (Thread-23): sending response (<Response 1219 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:19:36.560954 (Thread-24): handling list request
2022-01-05 16:19:36.561286 (Thread-24): 16:19:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fe8b80>]}
2022-01-05 16:19:36.591181 (Thread-24): 16:19:36  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0071cd0>]}
2022-01-05 16:19:36.591719 (Thread-24): 16:19:36  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:19:36.595207 (Thread-24): 16:19:36  The selection criterion '+1641399576289/__unsaved/Statement' does not match any nodes
2022-01-05 16:19:36.595550 (Thread-24): 16:19:36  The selection criterion '1.sql+' does not match any nodes
2022-01-05 16:19:36.595730 (Thread-24): 16:19:36  No nodes selected!
2022-01-05 16:19:36.598319 (Thread-24): sending response (<Response 2343 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:20:08.480526 (Thread-25): handling status request
2022-01-05 16:20:08.480909 (Thread-25): 16:20:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb61c0>]}
2022-01-05 16:20:08.481362 (Thread-25): sending response (<Response 1219 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:20:08.495496 (Thread-26): handling list request
2022-01-05 16:20:08.495851 (Thread-26): 16:20:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb66d0>]}
2022-01-05 16:20:08.528099 (Thread-26): 16:20:08  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb8040>]}
2022-01-05 16:20:08.528507 (Thread-26): 16:20:08  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:20:08.532627 (Thread-26): 16:20:08  The selection criterion '+1641399576289/__unsaved/Statement' does not match any nodes
2022-01-05 16:20:08.532846 (Thread-26): 16:20:08  The selection criterion '1.sql+' does not match any nodes
2022-01-05 16:20:08.532962 (Thread-26): 16:20:08  No nodes selected!
2022-01-05 16:20:08.534640 (Thread-26): sending response (<Response 2343 bytes [200 OK]>) to 10.0.35.58
2022-01-05 16:20:13.521856 (Thread-27): handling status request
2022-01-05 16:20:13.522235 (Thread-27): 16:20:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb6f40>]}
2022-01-05 16:20:13.522717 (Thread-27): sending response (<Response 1241 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:20:13.969781 (Thread-28): handling run_sql request
2022-01-05 16:20:13.970165 (Thread-28): 16:20:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb8850>]}
2022-01-05 16:20:16.178208 (Thread-28): sending response (<Response 138 bytes [200 OK]>) to 10.0.19.216
2022-01-05 16:20:16.204513 (MainThread): 16:20:16  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2b6730dd-1335-4de8-b990-36a56e7cdccc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956d50aeb0>]}
2022-01-05 16:20:16.205166 (MainThread): 16:20:16  Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:20:16.205816 (Thread-1): 16:20:16  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:20:16.205952 (Thread-1): 16:20:16  Began compiling node rpc.my_new_project.request
2022-01-05 16:20:16.206044 (Thread-1): 16:20:16  Compiling rpc.my_new_project.request
2022-01-05 16:20:16.207452 (Thread-1): 16:20:16  finished collecting timing info
2022-01-05 16:20:16.207592 (Thread-1): 16:20:16  Began executing node rpc.my_new_project.request
2022-01-05 16:20:16.207701 (Thread-1): 16:20:16  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:20:16.207788 (Thread-1): 16:20:16  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:20:16.207871 (Thread-1): 16:20:16  Opening a new connection, currently in state init
2022-01-05 16:20:16.207957 (Thread-1): 16:20:16  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:20:16.227781 (Thread-1): 16:20:16  Postgres adapter: Postgres error: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^

2022-01-05 16:20:16.228023 (Thread-1): 16:20:16  finished collecting timing info
2022-01-05 16:20:16.228174 (Thread-1): 16:20:16  On rpc.my_new_project.request: Close
2022-01-05 16:20:16.228526 (Thread-1): Got an exception: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
2022-01-05 16:20:16.229676 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 16:20:16.542413 (Thread-29): handling poll request
2022-01-05 16:20:16.542899 (Thread-29): 16:20:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0740be0>]}
2022-01-05 16:20:16.543773 (Thread-29): sending response (<Response 15966 bytes [200 OK]>) to 10.0.46.191
2022-01-05 16:27:27.433511 (Thread-30): 16:27:27  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-01-05 16:27:27.436013 (Thread-30): 16:27:27  Partial parsing: added file: my_new_project://models/dim_customers.sql
2022-01-05 16:27:27.447705 (Thread-30): 16:27:27  1699: static parser successfully parsed dim_customers.sql
2022-01-05 16:27:27.522204 (Thread-30): 16:27:27  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb06b57c0>]}
2022-01-05 16:27:28.015977 (Thread-31): handling status request
2022-01-05 16:27:28.016348 (Thread-31): 16:27:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd00d7b80>]}
2022-01-05 16:27:28.016881 (Thread-31): sending response (<Response 1550 bytes [200 OK]>) to 10.0.32.47
2022-01-05 16:27:28.080616 (Thread-32): handling status request
2022-01-05 16:27:28.080992 (Thread-32): 16:27:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb0fb8d30>]}
2022-01-05 16:27:28.081472 (Thread-32): sending response (<Response 1550 bytes [200 OK]>) to 10.0.32.47
2022-01-05 16:27:49.104245 (Thread-33): handling status request
2022-01-05 16:27:49.104668 (Thread-33): 16:27:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cd0100b50>]}
2022-01-05 16:27:49.105150 (Thread-33): sending response (<Response 1550 bytes [200 OK]>) to 10.0.10.137
2022-01-05 16:27:49.493307 (Thread-34): handling run_sql request
2022-01-05 16:27:49.493676 (Thread-34): 16:27:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb07548b0>]}
2022-01-05 16:27:51.661758 (Thread-34): sending response (<Response 138 bytes [200 OK]>) to 10.0.32.67
2022-01-05 16:27:51.687151 (MainThread): 16:27:51  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1f0a8b83-a905-4338-b9f4-9aede296d085', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f027f8a3160>]}
2022-01-05 16:27:51.687783 (MainThread): 16:27:51  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:27:51.688437 (Thread-1): 16:27:51  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:27:51.688614 (Thread-1): 16:27:51  Began compiling node rpc.my_new_project.request
2022-01-05 16:27:51.688717 (Thread-1): 16:27:51  Compiling rpc.my_new_project.request
2022-01-05 16:27:51.690111 (Thread-1): 16:27:51  finished collecting timing info
2022-01-05 16:27:51.690255 (Thread-1): 16:27:51  Began executing node rpc.my_new_project.request
2022-01-05 16:27:51.690375 (Thread-1): 16:27:51  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:27:51.690462 (Thread-1): 16:27:51  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:27:51.690553 (Thread-1): 16:27:51  Opening a new connection, currently in state init
2022-01-05 16:27:51.690641 (Thread-1): 16:27:51  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:27:51.709561 (Thread-1): 16:27:51  Postgres adapter: Postgres error: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^

2022-01-05 16:27:51.709799 (Thread-1): 16:27:51  finished collecting timing info
2022-01-05 16:27:51.709959 (Thread-1): 16:27:51  On rpc.my_new_project.request: Close
2022-01-05 16:27:51.710231 (Thread-1): Got an exception: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
2022-01-05 16:27:51.711336 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 16:27:52.059880 (Thread-35): handling poll request
2022-01-05 16:27:52.060336 (Thread-35): 16:27:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'ca392427-c8c5-4edd-95a2-2edbed184993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cb06b1490>]}
2022-01-05 16:27:52.061229 (Thread-35): sending response (<Response 15951 bytes [200 OK]>) to 10.0.38.111
2022-01-05 16:30:42.878891 (MainThread): Running with dbt=1.0.1
2022-01-05 16:30:42.976404 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-05 16:30:42.983115 (MainThread): Tracking: tracking
2022-01-05 16:30:43.003156 (MainThread): 16:30:43  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bf2b0bb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7be404f520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7be404f280>]}
2022-01-05 16:30:43.003512 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-05 16:30:43.003821 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-05 16:30:43.003957 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-05 16:30:43.018552 (Thread-12): 16:30:43  Unable to do partial parsing because profile has changed
2022-01-05 16:30:43.018843 (Thread-12): 16:30:43  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7be404fd00>]}
2022-01-05 16:30:43.055555 (Thread-12): 16:30:43  Parsing macros/catalog.sql
2022-01-05 16:30:43.068110 (Thread-12): 16:30:43  Parsing macros/adapters.sql
2022-01-05 16:30:43.095307 (Thread-12): 16:30:43  Parsing macros/relations.sql
2022-01-05 16:30:43.095891 (Thread-12): 16:30:43  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 16:30:43.096521 (Thread-12): 16:30:43  Parsing macros/catalog.sql
2022-01-05 16:30:43.098590 (Thread-12): 16:30:43  Parsing macros/adapters.sql
2022-01-05 16:30:43.119563 (Thread-12): 16:30:43  Parsing macros/relations.sql
2022-01-05 16:30:43.120863 (Thread-12): 16:30:43  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 16:30:43.122444 (Thread-12): 16:30:43  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-05 16:30:43.123904 (Thread-12): 16:30:43  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-05 16:30:43.125429 (Thread-12): 16:30:43  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-05 16:30:43.127813 (Thread-12): 16:30:43  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-05 16:30:43.129169 (Thread-12): 16:30:43  Parsing macros/generic_test_sql/not_null.sql
2022-01-05 16:30:43.129739 (Thread-12): 16:30:43  Parsing macros/generic_test_sql/relationships.sql
2022-01-05 16:30:43.130613 (Thread-12): 16:30:43  Parsing macros/generic_test_sql/unique.sql
2022-01-05 16:30:43.131339 (Thread-12): 16:30:43  Parsing macros/materializations/configs.sql
2022-01-05 16:30:43.133657 (Thread-12): 16:30:43  Parsing macros/materializations/hooks.sql
2022-01-05 16:30:43.137487 (Thread-12): 16:30:43  Parsing macros/materializations/snapshots/strategies.sql
2022-01-05 16:30:43.153319 (Thread-12): 16:30:43  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-05 16:30:43.154894 (Thread-12): 16:30:43  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-05 16:30:43.165571 (Thread-12): 16:30:43  Parsing macros/materializations/snapshots/helpers.sql
2022-01-05 16:30:43.176088 (Thread-12): 16:30:43  Parsing macros/materializations/seeds/seed.sql
2022-01-05 16:30:43.181729 (Thread-12): 16:30:43  Parsing macros/materializations/seeds/helpers.sql
2022-01-05 16:30:43.196895 (Thread-12): 16:30:43  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-05 16:30:43.199103 (Thread-12): 16:30:43  Parsing macros/materializations/models/view/view.sql
2022-01-05 16:30:43.205581 (Thread-12): 16:30:43  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-05 16:30:43.208160 (Thread-12): 16:30:43  Parsing macros/materializations/models/view/helpers.sql
2022-01-05 16:30:43.209445 (Thread-12): 16:30:43  Parsing macros/materializations/models/table/table.sql
2022-01-05 16:30:43.216297 (Thread-12): 16:30:43  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-05 16:30:43.219061 (Thread-12): 16:30:43  Parsing macros/materializations/models/incremental/merge.sql
2022-01-05 16:30:43.229668 (Thread-12): 16:30:43  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-05 16:30:43.244218 (Thread-12): 16:30:43  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-05 16:30:43.248474 (Thread-12): 16:30:43  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-05 16:30:43.257913 (Thread-12): 16:30:43  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-05 16:30:43.259393 (Thread-12): 16:30:43  Parsing macros/materializations/tests/test.sql
2022-01-05 16:30:43.263580 (Thread-12): 16:30:43  Parsing macros/materializations/tests/where_subquery.sql
2022-01-05 16:30:43.265308 (Thread-12): 16:30:43  Parsing macros/materializations/tests/helpers.sql
2022-01-05 16:30:43.266981 (Thread-12): 16:30:43  Parsing macros/etc/statement.sql
2022-01-05 16:30:43.271230 (Thread-12): 16:30:43  Parsing macros/etc/datetime.sql
2022-01-05 16:30:43.279336 (Thread-12): 16:30:43  Parsing macros/adapters/indexes.sql
2022-01-05 16:30:43.281928 (Thread-12): 16:30:43  Parsing macros/adapters/persist_docs.sql
2022-01-05 16:30:43.286130 (Thread-12): 16:30:43  Parsing macros/adapters/freshness.sql
2022-01-05 16:30:43.288969 (Thread-12): 16:30:43  Parsing macros/adapters/relation.sql
2022-01-05 16:30:43.298016 (Thread-12): 16:30:43  Parsing macros/adapters/metadata.sql
2022-01-05 16:30:43.304840 (Thread-12): 16:30:43  Parsing macros/adapters/columns.sql
2022-01-05 16:30:43.314256 (Thread-12): 16:30:43  Parsing macros/adapters/schema.sql
2022-01-05 16:30:43.316415 (Thread-12): 16:30:43  Parsing tests/generic/builtin.sql
2022-01-05 16:30:43.505433 (Thread-12): 16:30:43  1699: static parser successfully parsed dim_customers.sql
2022-01-05 16:30:43.517300 (Thread-12): 16:30:43  1699: static parser successfully parsed example/my_second_dbt_model.sql
2022-01-05 16:30:43.519507 (Thread-12): 16:30:43  1699: static parser successfully parsed example/my_first_dbt_model.sql
2022-01-05 16:30:43.611272 (Thread-12): 16:30:43  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc7ba0d0>]}
2022-01-05 16:30:44.812352 (Thread-13): handling status request
2022-01-05 16:30:44.812725 (Thread-13): 16:30:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc183970>]}
2022-01-05 16:30:44.813673 (Thread-13): sending response (<Response 15820 bytes [200 OK]>) to 10.0.30.3
2022-01-05 16:30:44.847893 (Thread-14): handling status request
2022-01-05 16:30:44.848502 (Thread-14): 16:30:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc183460>]}
2022-01-05 16:30:44.849342 (Thread-14): sending response (<Response 15820 bytes [200 OK]>) to 10.0.46.191
2022-01-05 16:30:44.860788 (Thread-15): handling ps request
2022-01-05 16:30:44.876475 (Thread-15): 16:30:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc183850>]}
2022-01-05 16:30:44.876938 (Thread-15): sending response (<Response 105 bytes [200 OK]>) to 10.0.5.1
2022-01-05 16:30:44.976647 (Thread-16): handling status request
2022-01-05 16:30:44.977031 (Thread-16): 16:30:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7be40b4e20>]}
2022-01-05 16:30:44.977865 (Thread-16): sending response (<Response 15820 bytes [200 OK]>) to 10.0.20.28
2022-01-05 16:31:12.937901 (Thread-17): handling status request
2022-01-05 16:31:12.939374 (Thread-17): 16:31:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc183f10>]}
2022-01-05 16:31:12.940283 (Thread-17): sending response (<Response 15820 bytes [200 OK]>) to 10.0.6.188
2022-01-05 16:31:13.297265 (Thread-18): handling run_sql request
2022-01-05 16:31:13.297618 (Thread-18): 16:31:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7be40885e0>]}
2022-01-05 16:31:15.373069 (Thread-18): sending response (<Response 138 bytes [200 OK]>) to 10.0.32.47
2022-01-05 16:31:15.397039 (MainThread): 16:31:15  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8f1d7668-1c99-48ae-8386-4f145f2c2b67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6151640e80>]}
2022-01-05 16:31:15.397583 (MainThread): 16:31:15  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:31:15.398163 (Thread-1): 16:31:15  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:31:15.398293 (Thread-1): 16:31:15  Began compiling node rpc.my_new_project.request
2022-01-05 16:31:15.398383 (Thread-1): 16:31:15  Compiling rpc.my_new_project.request
2022-01-05 16:31:15.399580 (Thread-1): 16:31:15  finished collecting timing info
2022-01-05 16:31:15.399708 (Thread-1): 16:31:15  Began executing node rpc.my_new_project.request
2022-01-05 16:31:15.399809 (Thread-1): 16:31:15  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:31:15.399888 (Thread-1): 16:31:15  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:31:15.399967 (Thread-1): 16:31:15  Opening a new connection, currently in state init
2022-01-05 16:31:15.400047 (Thread-1): 16:31:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:31:15.411891 (Thread-1): 16:31:15  Postgres adapter: Got an error when attempting to open a postgres connection: 'FATAL:  database "Serverless/dev" does not exist
'
2022-01-05 16:31:15.412031 (Thread-1): 16:31:15  Postgres adapter: Error running SQL: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:31:15.412105 (Thread-1): 16:31:15  Postgres adapter: Rolling back transaction.
2022-01-05 16:31:15.412201 (Thread-1): 16:31:15  finished collecting timing info
2022-01-05 16:31:15.412319 (Thread-1): 16:31:15  On rpc.my_new_project.request: No close available on handle
2022-01-05 16:31:15.412383 (Thread-1): Got an exception: Database Error
  FATAL:  database "Serverless/dev" does not exist
  
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 121, in open
    handle = psycopg2.connect(
  File "/usr/local/lib/python3.8/dist-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: FATAL:  database "Serverless/dev" does not exist


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 73, in add_query
    cursor = connection.handle.cursor()
  File "/usr/local/lib/python3.8/dist-packages/dbt/contracts/connection.py", line 83, in handle
    self._handle.resolve(self)
  File "/usr/local/lib/python3.8/dist-packages/dbt/contracts/connection.py", line 106, in resolve
    return self.opener(connection)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 143, in open
    raise dbt.exceptions.FailedToConnectException(str(e))
dbt.exceptions.FailedToConnectException: Database Error
  FATAL:  database "Serverless/dev" does not exist
2022-01-05 16:31:15.413610 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'FailedToConnectException', 'message': 'Database Error in rpc request (from remote system)\n  FATAL:  database "Serverless/dev" does not exist\n  ', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'FailedToConnectException', 'message': 'Database Error in rpc request (from remote system)\n  FATAL:  database "Serverless/dev" does not exist\n  ', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 16:31:15.717223 (Thread-19): handling poll request
2022-01-05 16:31:15.717656 (Thread-19): 16:31:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'a3210eea-8517-40a4-87a2-4fa1a0213256', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bcc183460>]}
2022-01-05 16:31:15.718527 (Thread-19): sending response (<Response 17444 bytes [200 OK]>) to 10.0.42.85
2022-01-05 16:39:15.648211 (MainThread): Running with dbt=1.0.1
2022-01-05 16:39:15.739482 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-05 16:39:15.745897 (MainThread): Tracking: tracking
2022-01-05 16:39:15.765400 (MainThread): 16:39:15  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0af913fcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae46471c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4647250>]}
2022-01-05 16:39:15.765818 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-05 16:39:15.766128 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-05 16:39:15.766375 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-05 16:39:15.783436 (Thread-12): 16:39:15  Unable to do partial parsing because profile has changed
2022-01-05 16:39:15.783721 (Thread-12): 16:39:15  Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4647f40>]}
2022-01-05 16:39:15.812470 (Thread-12): 16:39:15  Parsing macros/catalog.sql
2022-01-05 16:39:15.824739 (Thread-12): 16:39:15  Parsing macros/adapters.sql
2022-01-05 16:39:15.851320 (Thread-12): 16:39:15  Parsing macros/relations.sql
2022-01-05 16:39:15.851874 (Thread-12): 16:39:15  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 16:39:15.852476 (Thread-12): 16:39:15  Parsing macros/catalog.sql
2022-01-05 16:39:15.854502 (Thread-12): 16:39:15  Parsing macros/adapters.sql
2022-01-05 16:39:15.875090 (Thread-12): 16:39:15  Parsing macros/relations.sql
2022-01-05 16:39:15.876314 (Thread-12): 16:39:15  Parsing macros/materializations/snapshot_merge.sql
2022-01-05 16:39:15.877872 (Thread-12): 16:39:15  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-05 16:39:15.879272 (Thread-12): 16:39:15  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-05 16:39:15.880838 (Thread-12): 16:39:15  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-05 16:39:15.883157 (Thread-12): 16:39:15  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-05 16:39:15.884458 (Thread-12): 16:39:15  Parsing macros/generic_test_sql/not_null.sql
2022-01-05 16:39:15.885006 (Thread-12): 16:39:15  Parsing macros/generic_test_sql/relationships.sql
2022-01-05 16:39:15.885848 (Thread-12): 16:39:15  Parsing macros/generic_test_sql/unique.sql
2022-01-05 16:39:15.886517 (Thread-12): 16:39:15  Parsing macros/materializations/configs.sql
2022-01-05 16:39:15.888675 (Thread-12): 16:39:15  Parsing macros/materializations/hooks.sql
2022-01-05 16:39:15.892643 (Thread-12): 16:39:15  Parsing macros/materializations/snapshots/strategies.sql
2022-01-05 16:39:15.908294 (Thread-12): 16:39:15  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-05 16:39:15.909915 (Thread-12): 16:39:15  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-05 16:39:15.920676 (Thread-12): 16:39:15  Parsing macros/materializations/snapshots/helpers.sql
2022-01-05 16:39:15.930922 (Thread-12): 16:39:15  Parsing macros/materializations/seeds/seed.sql
2022-01-05 16:39:15.936404 (Thread-12): 16:39:15  Parsing macros/materializations/seeds/helpers.sql
2022-01-05 16:39:15.951479 (Thread-12): 16:39:15  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-05 16:39:15.953669 (Thread-12): 16:39:15  Parsing macros/materializations/models/view/view.sql
2022-01-05 16:39:15.960107 (Thread-12): 16:39:15  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-05 16:39:15.962643 (Thread-12): 16:39:15  Parsing macros/materializations/models/view/helpers.sql
2022-01-05 16:39:15.963902 (Thread-12): 16:39:15  Parsing macros/materializations/models/table/table.sql
2022-01-05 16:39:15.970722 (Thread-12): 16:39:15  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-05 16:39:15.973406 (Thread-12): 16:39:15  Parsing macros/materializations/models/incremental/merge.sql
2022-01-05 16:39:15.983881 (Thread-12): 16:39:15  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-05 16:39:15.998085 (Thread-12): 16:39:15  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-05 16:39:16.002311 (Thread-12): 16:39:16  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-05 16:39:16.011674 (Thread-12): 16:39:16  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-05 16:39:16.013090 (Thread-12): 16:39:16  Parsing macros/materializations/tests/test.sql
2022-01-05 16:39:16.017173 (Thread-12): 16:39:16  Parsing macros/materializations/tests/where_subquery.sql
2022-01-05 16:39:16.018889 (Thread-12): 16:39:16  Parsing macros/materializations/tests/helpers.sql
2022-01-05 16:39:16.020625 (Thread-12): 16:39:16  Parsing macros/etc/statement.sql
2022-01-05 16:39:16.024741 (Thread-12): 16:39:16  Parsing macros/etc/datetime.sql
2022-01-05 16:39:16.032723 (Thread-12): 16:39:16  Parsing macros/adapters/indexes.sql
2022-01-05 16:39:16.035236 (Thread-12): 16:39:16  Parsing macros/adapters/persist_docs.sql
2022-01-05 16:39:16.039379 (Thread-12): 16:39:16  Parsing macros/adapters/freshness.sql
2022-01-05 16:39:16.042166 (Thread-12): 16:39:16  Parsing macros/adapters/relation.sql
2022-01-05 16:39:16.051134 (Thread-12): 16:39:16  Parsing macros/adapters/metadata.sql
2022-01-05 16:39:16.057781 (Thread-12): 16:39:16  Parsing macros/adapters/columns.sql
2022-01-05 16:39:16.067020 (Thread-12): 16:39:16  Parsing macros/adapters/schema.sql
2022-01-05 16:39:16.069128 (Thread-12): 16:39:16  Parsing tests/generic/builtin.sql
2022-01-05 16:39:16.256897 (Thread-12): 16:39:16  1699: static parser successfully parsed dim_customers.sql
2022-01-05 16:39:16.268697 (Thread-12): 16:39:16  1699: static parser successfully parsed example/my_second_dbt_model.sql
2022-01-05 16:39:16.271022 (Thread-12): 16:39:16  1699: static parser successfully parsed example/my_first_dbt_model.sql
2022-01-05 16:39:16.370848 (Thread-12): 16:39:16  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae46209a0>]}
2022-01-05 16:39:17.928096 (Thread-13): handling status request
2022-01-05 16:39:17.928624 (Thread-13): 16:39:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45eb7c0>]}
2022-01-05 16:39:17.929847 (Thread-13): sending response (<Response 15820 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:39:17.939921 (Thread-14): handling status request
2022-01-05 16:39:17.940168 (Thread-14): 16:39:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4631c40>]}
2022-01-05 16:39:17.940913 (Thread-14): sending response (<Response 15820 bytes [200 OK]>) to 10.0.26.162
2022-01-05 16:39:17.949081 (Thread-15): handling ps request
2022-01-05 16:39:17.949360 (Thread-15): 16:39:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45c5820>]}
2022-01-05 16:39:17.949756 (Thread-15): sending response (<Response 105 bytes [200 OK]>) to 10.0.17.156
2022-01-05 16:39:17.964225 (Thread-16): handling status request
2022-01-05 16:39:17.964478 (Thread-16): 16:39:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae461e250>]}
2022-01-05 16:39:17.965217 (Thread-16): sending response (<Response 15820 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:39:50.871565 (Thread-17): handling status request
2022-01-05 16:39:50.872878 (Thread-17): 16:39:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae468f820>]}
2022-01-05 16:39:50.873813 (Thread-17): sending response (<Response 15820 bytes [200 OK]>) to 10.0.10.137
2022-01-05 16:39:51.223488 (Thread-18): handling run_sql request
2022-01-05 16:39:51.223867 (Thread-18): 16:39:51  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae468f670>]}
2022-01-05 16:39:53.278617 (Thread-18): sending response (<Response 138 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:39:53.303559 (MainThread): 16:39:53  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f31d62f7-8c41-42e9-8cf0-fa130dfe55ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22c0a841c0>]}
2022-01-05 16:39:53.304112 (MainThread): 16:39:53  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:39:53.304713 (Thread-1): 16:39:53  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:39:53.304846 (Thread-1): 16:39:53  Began compiling node rpc.my_new_project.request
2022-01-05 16:39:53.304936 (Thread-1): 16:39:53  Compiling rpc.my_new_project.request
2022-01-05 16:39:53.306112 (Thread-1): 16:39:53  finished collecting timing info
2022-01-05 16:39:53.306239 (Thread-1): 16:39:53  Began executing node rpc.my_new_project.request
2022-01-05 16:39:53.306337 (Thread-1): 16:39:53  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:39:53.306416 (Thread-1): 16:39:53  On rpc.my_new_project.request: create table jaffle_shop.customers(
  id integer,
  first_name varchar(50),
  last_name varchar(50)
);
	
create table jaffle_shop.orders(
  id integer,
  user_id integer,
  order_date date,
  status varchar(50),
  _etl_loaded_at timestamp default current_timestamp
);
	
create table stripe.payment(
  id integer,
  orderid integer,
  paymentmethod varchar(50),
  status varchar(50),
  amount integer,
  created date,
  _batched_at timestamp default current_timestamp
);




copy jaffle_shop.customers( id, first_name, last_name)
from 's3://dbt-tutorial-public/jaffle_shop_customers.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;



copy jaffle_shop.orders(id, user_id, order_date, status)
from 's3://dbt-tutorial-public/jaffle_shop_orders.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;

copy stripe.payment(id, orderid, paymentmethod, status, amount, created)
from 's3://dbt-tutorial-public/stripe_payments.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:39:53.306497 (Thread-1): 16:39:53  Opening a new connection, currently in state init
2022-01-05 16:39:53.306582 (Thread-1): 16:39:53  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:39:53.328406 (Thread-1): 16:39:53  Postgres adapter: Postgres error: schema "jaffle_shop" does not exist

2022-01-05 16:39:53.328568 (Thread-1): 16:39:53  finished collecting timing info
2022-01-05 16:39:53.328701 (Thread-1): 16:39:53  On rpc.my_new_project.request: Close
2022-01-05 16:39:53.328891 (Thread-1): Got an exception: Database Error
  schema "jaffle_shop" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidSchemaName: schema "jaffle_shop" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  schema "jaffle_shop" does not exist
2022-01-05 16:39:53.330092 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-01-05 16:39:53.700224 (Thread-19): handling poll request
2022-01-05 16:39:53.700677 (Thread-19): 16:39:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4631a30>]}
2022-01-05 16:39:53.701577 (Thread-19): sending response (<Response 18587 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:41:40.881062 (Thread-20): handling status request
2022-01-05 16:41:40.882660 (Thread-20): 16:41:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4183520>]}
2022-01-05 16:41:40.883603 (Thread-20): sending response (<Response 15820 bytes [200 OK]>) to 10.0.18.253
2022-01-05 16:41:41.485872 (Thread-21): handling run_sql request
2022-01-05 16:41:41.486261 (Thread-21): 16:41:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4183df0>]}
2022-01-05 16:41:43.559538 (Thread-21): sending response (<Response 138 bytes [200 OK]>) to 10.0.17.156
2022-01-05 16:41:43.586034 (MainThread): 16:41:43  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6665cc01-c3d7-4ede-9785-71af86e1a55f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29e0344280>]}
2022-01-05 16:41:43.586594 (MainThread): 16:41:43  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:41:43.587195 (Thread-1): 16:41:43  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:41:43.587325 (Thread-1): 16:41:43  Began compiling node rpc.my_new_project.request
2022-01-05 16:41:43.587415 (Thread-1): 16:41:43  Compiling rpc.my_new_project.request
2022-01-05 16:41:43.588545 (Thread-1): 16:41:43  finished collecting timing info
2022-01-05 16:41:43.588668 (Thread-1): 16:41:43  Began executing node rpc.my_new_project.request
2022-01-05 16:41:43.588769 (Thread-1): 16:41:43  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:41:43.588846 (Thread-1): 16:41:43  On rpc.my_new_project.request: create schema if not exists jaffle_shop;
	
create schema if not exists stripe;


create table jaffle_shop.customers(
  id integer,
  first_name varchar(50),
  last_name varchar(50)
);
	
create table jaffle_shop.orders(
  id integer,
  user_id integer,
  order_date date,
  status varchar(50),
  _etl_loaded_at timestamp default current_timestamp
);
	
create table stripe.payment(
  id integer,
  orderid integer,
  paymentmethod varchar(50),
  status varchar(50),
  amount integer,
  created date,
  _batched_at timestamp default current_timestamp
);




copy jaffle_shop.customers( id, first_name, last_name)
from 's3://dbt-tutorial-public/jaffle_shop_customers.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;



copy jaffle_shop.orders(id, user_id, order_date, status)
from 's3://dbt-tutorial-public/jaffle_shop_orders.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;

copy stripe.payment(id, orderid, paymentmethod, status, amount, created)
from 's3://dbt-tutorial-public/stripe_payments.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:41:43.588924 (Thread-1): 16:41:43  Opening a new connection, currently in state init
2022-01-05 16:41:43.589006 (Thread-1): 16:41:43  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:41:43.615589 (Thread-1): 16:41:43  Postgres adapter: Postgres error: schema "jaffle_shop" does not exist

2022-01-05 16:41:43.615751 (Thread-1): 16:41:43  finished collecting timing info
2022-01-05 16:41:43.615878 (Thread-1): 16:41:43  On rpc.my_new_project.request: Close
2022-01-05 16:41:43.616053 (Thread-1): Got an exception: Database Error
  schema "jaffle_shop" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidSchemaName: schema "jaffle_shop" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  schema "jaffle_shop" does not exist
2022-01-05 16:41:43.617146 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create schema if not exists jaffle_shop;\n\t\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create schema if not exists jaffle_shop;\n\t\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create schema if not exists jaffle_shop;\n\t\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create schema if not exists jaffle_shop;\n\t\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-01-05 16:41:44.027452 (Thread-22): handling poll request
2022-01-05 16:41:44.027905 (Thread-22): 16:41:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae46ab610>]}
2022-01-05 16:41:44.028771 (Thread-22): sending response (<Response 19220 bytes [200 OK]>) to 10.0.20.28
2022-01-05 16:42:09.542678 (Thread-23): handling status request
2022-01-05 16:42:09.544284 (Thread-23): 16:42:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae46abf10>]}
2022-01-05 16:42:09.545242 (Thread-23): sending response (<Response 15820 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:42:09.929808 (Thread-24): handling run_sql request
2022-01-05 16:42:09.930081 (Thread-24): 16:42:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45d3100>]}
2022-01-05 16:42:11.984256 (Thread-24): sending response (<Response 138 bytes [200 OK]>) to 10.0.30.3
2022-01-05 16:42:12.008081 (MainThread): 16:42:12  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '516653f5-0fc2-427c-8606-9f8e141f7c4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f580ad1d280>]}
2022-01-05 16:42:12.008607 (MainThread): 16:42:12  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:42:12.009187 (Thread-1): 16:42:12  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:42:12.009368 (Thread-1): 16:42:12  Began compiling node rpc.my_new_project.request
2022-01-05 16:42:12.009535 (Thread-1): 16:42:12  Compiling rpc.my_new_project.request
2022-01-05 16:42:12.010738 (Thread-1): 16:42:12  finished collecting timing info
2022-01-05 16:42:12.010865 (Thread-1): 16:42:12  Began executing node rpc.my_new_project.request
2022-01-05 16:42:12.010980 (Thread-1): 16:42:12  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:42:12.011066 (Thread-1): 16:42:12  On rpc.my_new_project.request: create schema if not exists jaffle_shop;
create schema if not exists stripe;


create table jaffle_shop.customers(
  id integer,
  first_name varchar(50),
  last_name varchar(50)
);
	
create table jaffle_shop.orders(
  id integer,
  user_id integer,
  order_date date,
  status varchar(50),
  _etl_loaded_at timestamp default current_timestamp
);
	
create table stripe.payment(
  id integer,
  orderid integer,
  paymentmethod varchar(50),
  status varchar(50),
  amount integer,
  created date,
  _batched_at timestamp default current_timestamp
);




copy jaffle_shop.customers( id, first_name, last_name)
from 's3://dbt-tutorial-public/jaffle_shop_customers.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;



copy jaffle_shop.orders(id, user_id, order_date, status)
from 's3://dbt-tutorial-public/jaffle_shop_orders.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars;

copy stripe.payment(id, orderid, paymentmethod, status, amount, created)
from 's3://dbt-tutorial-public/stripe_payments.csv'
iam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'
region 'us-west-2'
delimiter ','
ignoreheader 1
acceptinvchars
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:42:12.011150 (Thread-1): 16:42:12  Opening a new connection, currently in state init
2022-01-05 16:42:12.011236 (Thread-1): 16:42:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:42:12.034460 (Thread-1): 16:42:12  Postgres adapter: Postgres error: schema "jaffle_shop" does not exist

2022-01-05 16:42:12.034643 (Thread-1): 16:42:12  finished collecting timing info
2022-01-05 16:42:12.034784 (Thread-1): 16:42:12  On rpc.my_new_project.request: Close
2022-01-05 16:42:12.035078 (Thread-1): Got an exception: Database Error
  schema "jaffle_shop" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidSchemaName: schema "jaffle_shop" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  schema "jaffle_shop" does not exist
2022-01-05 16:42:12.036085 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create schema if not exists jaffle_shop;\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create schema if not exists jaffle_shop;\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  schema "jaffle_shop" does not exist', 'raw_sql': "create schema if not exists jaffle_shop;\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': "create schema if not exists jaffle_shop;\ncreate schema if not exists stripe;\n\n\ncreate table jaffle_shop.customers(\n  id integer,\n  first_name varchar(50),\n  last_name varchar(50)\n);\n\t\ncreate table jaffle_shop.orders(\n  id integer,\n  user_id integer,\n  order_date date,\n  status varchar(50),\n  _etl_loaded_at timestamp default current_timestamp\n);\n\t\ncreate table stripe.payment(\n  id integer,\n  orderid integer,\n  paymentmethod varchar(50),\n  status varchar(50),\n  amount integer,\n  created date,\n  _batched_at timestamp default current_timestamp\n);\n\n\n\n\ncopy jaffle_shop.customers( id, first_name, last_name)\nfrom 's3://dbt-tutorial-public/jaffle_shop_customers.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\n\n\ncopy jaffle_shop.orders(id, user_id, order_date, status)\nfrom 's3://dbt-tutorial-public/jaffle_shop_orders.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars;\n\ncopy stripe.payment(id, orderid, paymentmethod, status, amount, created)\nfrom 's3://dbt-tutorial-public/stripe_payments.csv'\niam_role 'arn:aws:iam::342412686791:role/service-role/AmazonRedshift-CommandsAccessRole-20220105T004634'\nregion 'us-west-2'\ndelimiter ','\nignoreheader 1\nacceptinvchars\nlimit 500\n/* limit added automatically by dbt cloud */", 'tags': None}, None)
2022-01-05 16:42:12.369185 (Thread-25): handling poll request
2022-01-05 16:42:12.369671 (Thread-25): 16:42:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae46222e0>]}
2022-01-05 16:42:12.370502 (Thread-25): sending response (<Response 19184 bytes [200 OK]>) to 10.0.32.67
2022-01-05 16:45:55.591816 (Thread-26): handling status request
2022-01-05 16:45:55.593518 (Thread-26): 16:45:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45be6a0>]}
2022-01-05 16:45:55.594475 (Thread-26): sending response (<Response 15820 bytes [200 OK]>) to 10.0.26.162
2022-01-05 16:45:56.024551 (Thread-27): handling run_sql request
2022-01-05 16:45:56.024960 (Thread-27): 16:45:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45befa0>]}
2022-01-05 16:45:58.156122 (Thread-27): sending response (<Response 138 bytes [200 OK]>) to 10.0.10.137
2022-01-05 16:45:58.181584 (MainThread): 16:45:58  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ba7393da-844d-4c5b-b182-0a0f9652e91c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ecd0001f0>]}
2022-01-05 16:45:58.182121 (MainThread): 16:45:58  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:45:58.182733 (Thread-1): 16:45:58  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:45:58.182865 (Thread-1): 16:45:58  Began compiling node rpc.my_new_project.request
2022-01-05 16:45:58.182953 (Thread-1): 16:45:58  Compiling rpc.my_new_project.request
2022-01-05 16:45:58.184088 (Thread-1): 16:45:58  finished collecting timing info
2022-01-05 16:45:58.184214 (Thread-1): 16:45:58  Began executing node rpc.my_new_project.request
2022-01-05 16:45:58.184312 (Thread-1): 16:45:58  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:45:58.184395 (Thread-1): 16:45:58  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:45:58.184475 (Thread-1): 16:45:58  Opening a new connection, currently in state init
2022-01-05 16:45:58.184557 (Thread-1): 16:45:58  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:45:58.212360 (Thread-1): 16:45:58  Postgres adapter: Postgres error: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^

2022-01-05 16:45:58.212560 (Thread-1): 16:45:58  finished collecting timing info
2022-01-05 16:45:58.212704 (Thread-1): 16:45:58  On rpc.my_new_project.request: Close
2022-01-05 16:45:58.212904 (Thread-1): Got an exception: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "raw"
LINE 8:     from raw.jaffle_shop.customers
                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  syntax error at or near "raw"
  LINE 8:     from raw.jaffle_shop.customers
                   ^
2022-01-05 16:45:58.214091 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  syntax error at or near "raw"\n  LINE 8:     from raw.jaffle_shop.customers\n                   ^', 'raw_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': 'with customers as (\n\n    select\n        id as customer_id,\n        first_name,\n        last_name\n\n    from raw.jaffle_shop.customers\n\n),\n\norders as (\n\n    select\n        id as order_id,\n        user_id as customer_id,\n        order_date,\n        status\n\n    from raw.jaffle_shop.orders\n\n),\n\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-05 16:45:58.558893 (Thread-28): handling poll request
2022-01-05 16:45:58.559396 (Thread-28): 16:45:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45eed00>]}
2022-01-05 16:45:58.560262 (Thread-28): sending response (<Response 15951 bytes [200 OK]>) to 10.0.38.111
2022-01-05 16:46:45.865147 (Thread-29): handling status request
2022-01-05 16:46:45.865585 (Thread-29): 16:46:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae41525b0>]}
2022-01-05 16:46:45.866555 (Thread-29): sending response (<Response 15820 bytes [200 OK]>) to 10.0.6.188
2022-01-05 16:46:46.311105 (Thread-30): handling run_sql request
2022-01-05 16:46:46.311512 (Thread-30): 16:46:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae45ee400>]}
2022-01-05 16:46:48.377682 (Thread-30): sending response (<Response 138 bytes [200 OK]>) to 10.0.19.216
2022-01-05 16:46:48.401169 (MainThread): 16:46:48  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dd52ea4c-3fa5-4ce4-a507-e05bdb90f89a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d75e3a1c0>]}
2022-01-05 16:46:48.401730 (MainThread): 16:46:48  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:46:48.402302 (Thread-1): 16:46:48  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:46:48.402431 (Thread-1): 16:46:48  Began compiling node rpc.my_new_project.request
2022-01-05 16:46:48.402522 (Thread-1): 16:46:48  Compiling rpc.my_new_project.request
2022-01-05 16:46:48.403672 (Thread-1): 16:46:48  finished collecting timing info
2022-01-05 16:46:48.403801 (Thread-1): 16:46:48  Began executing node rpc.my_new_project.request
2022-01-05 16:46:48.403904 (Thread-1): 16:46:48  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:46:48.403982 (Thread-1): 16:46:48  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from dev.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from dev.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:46:48.404061 (Thread-1): 16:46:48  Opening a new connection, currently in state init
2022-01-05 16:46:48.404143 (Thread-1): 16:46:48  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:46:48.710458 (Thread-1): 16:46:48  SQL status: SELECT in 0.31 seconds
2022-01-05 16:46:48.711577 (Thread-1): 16:46:48  finished collecting timing info
2022-01-05 16:46:48.711747 (Thread-1): 16:46:48  On rpc.my_new_project.request: Close
2022-01-05 16:46:48.771036 (Thread-31): handling poll request
2022-01-05 16:46:48.771480 (Thread-31): 16:46:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4191850>]}
2022-01-05 16:46:48.772345 (Thread-31): sending response (<Response 5941 bytes [200 OK]>) to 10.0.12.39
2022-01-05 16:46:50.210348 (Thread-32): handling poll request
2022-01-05 16:46:50.210730 (Thread-32): 16:46:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4191910>]}
2022-01-05 16:46:50.211890 (Thread-32): sending response (<Response 6204 bytes [200 OK]>) to 10.0.10.137
2022-01-05 16:47:06.349240 (Thread-33): handling status request
2022-01-05 16:47:06.349704 (Thread-33): 16:47:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4191a30>]}
2022-01-05 16:47:06.350656 (Thread-33): sending response (<Response 15820 bytes [200 OK]>) to 10.0.30.3
2022-01-05 16:47:06.795521 (Thread-34): handling run_sql request
2022-01-05 16:47:06.795892 (Thread-34): 16:47:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae414d3d0>]}
2022-01-05 16:47:08.863842 (Thread-34): sending response (<Response 138 bytes [200 OK]>) to 10.0.32.67
2022-01-05 16:47:08.890748 (MainThread): 16:47:08  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cc0580c8-00ce-45ae-b957-d7d4dc307db9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7848df8280>]}
2022-01-05 16:47:08.891308 (MainThread): 16:47:08  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:47:08.891883 (Thread-1): 16:47:08  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:47:08.892013 (Thread-1): 16:47:08  Began compiling node rpc.my_new_project.request
2022-01-05 16:47:08.892101 (Thread-1): 16:47:08  Compiling rpc.my_new_project.request
2022-01-05 16:47:08.893311 (Thread-1): 16:47:08  finished collecting timing info
2022-01-05 16:47:08.893513 (Thread-1): 16:47:08  Began executing node rpc.my_new_project.request
2022-01-05 16:47:08.893652 (Thread-1): 16:47:08  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:47:08.893739 (Thread-1): 16:47:08  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from dev.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from dev.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:47:08.893848 (Thread-1): 16:47:08  Opening a new connection, currently in state init
2022-01-05 16:47:08.893941 (Thread-1): 16:47:08  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:47:08.916921 (Thread-1): 16:47:08  SQL status: SELECT in 0.02 seconds
2022-01-05 16:47:08.917927 (Thread-1): 16:47:08  finished collecting timing info
2022-01-05 16:47:08.918066 (Thread-1): 16:47:08  On rpc.my_new_project.request: Close
2022-01-05 16:47:09.255197 (Thread-35): handling poll request
2022-01-05 16:47:09.255629 (Thread-35): 16:47:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae415abb0>]}
2022-01-05 16:47:09.256752 (Thread-35): sending response (<Response 11760 bytes [200 OK]>) to 10.0.17.156
2022-01-05 16:52:53.345938 (Thread-36): handling status request
2022-01-05 16:52:53.347350 (Thread-36): 16:52:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae415a700>]}
2022-01-05 16:52:53.348294 (Thread-36): sending response (<Response 15820 bytes [200 OK]>) to 10.0.26.162
2022-01-05 16:52:54.265808 (Thread-37): handling run_sql request
2022-01-05 16:52:54.266188 (Thread-37): 16:52:54  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae415a4c0>]}
2022-01-05 16:52:56.353889 (Thread-37): sending response (<Response 138 bytes [200 OK]>) to 10.0.42.85
2022-01-05 16:52:56.380688 (MainThread): 16:52:56  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2788a387-77ee-4871-8262-f407dcbea91b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a0f8b220>]}
2022-01-05 16:52:56.381259 (MainThread): 16:52:56  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:52:56.381889 (Thread-1): 16:52:56  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:52:56.382020 (Thread-1): 16:52:56  Began compiling node rpc.my_new_project.request
2022-01-05 16:52:56.382119 (Thread-1): 16:52:56  Compiling rpc.my_new_project.request
2022-01-05 16:52:56.383264 (Thread-1): 16:52:56  finished collecting timing info
2022-01-05 16:52:56.383389 (Thread-1): 16:52:56  Began executing node rpc.my_new_project.request
2022-01-05 16:52:56.383487 (Thread-1): 16:52:56  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:52:56.383564 (Thread-1): 16:52:56  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:52:56.383643 (Thread-1): 16:52:56  Opening a new connection, currently in state init
2022-01-05 16:52:56.383727 (Thread-1): 16:52:56  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:52:56.406748 (Thread-1): 16:52:56  SQL status: SELECT in 0.02 seconds
2022-01-05 16:52:56.407735 (Thread-1): 16:52:56  finished collecting timing info
2022-01-05 16:52:56.407872 (Thread-1): 16:52:56  On rpc.my_new_project.request: Close
2022-01-05 16:52:56.807903 (Thread-38): handling poll request
2022-01-05 16:52:56.808340 (Thread-38): 16:52:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4125cd0>]}
2022-01-05 16:52:56.809566 (Thread-38): sending response (<Response 11720 bytes [200 OK]>) to 10.0.42.119
2022-01-05 16:53:05.020856 (Thread-39): handling ps request
2022-01-05 16:53:05.021235 (Thread-39): 16:53:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4125e80>]}
2022-01-05 16:53:05.024387 (Thread-40): handling status request
2022-01-05 16:53:05.024659 (Thread-40): 16:53:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4191100>]}
2022-01-05 16:53:05.033217 (Thread-41): handling status request
2022-01-05 16:53:05.033542 (Thread-41): 16:53:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4135520>]}
2022-01-05 16:53:05.052842 (Thread-39): sending response (<Response 3642 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:53:05.054062 (Thread-40): sending response (<Response 15820 bytes [200 OK]>) to 10.0.26.162
2022-01-05 16:53:05.055097 (Thread-41): sending response (<Response 15820 bytes [200 OK]>) to 10.0.18.253
2022-01-05 16:53:05.131998 (Thread-42): handling status request
2022-01-05 16:53:05.132357 (Thread-42): 16:53:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4125a30>]}
2022-01-05 16:53:05.133225 (Thread-42): sending response (<Response 15820 bytes [200 OK]>) to 10.0.5.1
2022-01-05 16:56:14.676625 (Thread-43): handling status request
2022-01-05 16:56:14.677878 (Thread-43): 16:56:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae412d7f0>]}
2022-01-05 16:56:14.678718 (Thread-43): sending response (<Response 15820 bytes [200 OK]>) to 10.0.10.137
2022-01-05 16:56:15.022745 (Thread-44): handling run_sql request
2022-01-05 16:56:15.023120 (Thread-44): 16:56:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae412db50>]}
2022-01-05 16:56:17.110459 (Thread-44): sending response (<Response 138 bytes [200 OK]>) to 10.0.17.156
2022-01-05 16:56:17.128067 (MainThread): 16:56:17  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '33eee4ca-108c-4402-9729-865713de7d25', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7ece0e2b0>]}
2022-01-05 16:56:17.128648 (MainThread): 16:56:17  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 16:56:17.129292 (Thread-1): 16:56:17  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 16:56:17.129455 (Thread-1): 16:56:17  Began compiling node rpc.my_new_project.request
2022-01-05 16:56:17.129557 (Thread-1): 16:56:17  Compiling rpc.my_new_project.request
2022-01-05 16:56:17.130838 (Thread-1): 16:56:17  finished collecting timing info
2022-01-05 16:56:17.130966 (Thread-1): 16:56:17  Began executing node rpc.my_new_project.request
2022-01-05 16:56:17.131072 (Thread-1): 16:56:17  Using redshift connection "rpc.my_new_project.request"
2022-01-05 16:56:17.131155 (Thread-1): 16:56:17  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 16:56:17.131236 (Thread-1): 16:56:17  Opening a new connection, currently in state init
2022-01-05 16:56:17.131323 (Thread-1): 16:56:17  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 16:56:17.191739 (Thread-1): 16:56:17  SQL status: SELECT in 0.06 seconds
2022-01-05 16:56:17.194886 (Thread-1): 16:56:17  finished collecting timing info
2022-01-05 16:56:17.195066 (Thread-1): 16:56:17  On rpc.my_new_project.request: Close
2022-01-05 16:56:17.526557 (Thread-45): handling poll request
2022-01-05 16:56:17.526992 (Thread-45): 16:56:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae4135fd0>]}
2022-01-05 16:56:17.528603 (Thread-45): sending response (<Response 16788 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:57:13.672284 (Thread-46): 16:57:13  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 16:57:13.672516 (Thread-46): 16:57:13  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 16:57:13.678234 (Thread-46): 16:57:13  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac03b8a90>]}
2022-01-05 16:57:14.178227 (Thread-47): handling status request
2022-01-05 16:57:14.178600 (Thread-47): 16:57:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40b55b0>]}
2022-01-05 16:57:14.179127 (Thread-47): sending response (<Response 1241 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:57:14.245483 (Thread-48): handling status request
2022-01-05 16:57:14.245856 (Thread-48): 16:57:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40b51f0>]}
2022-01-05 16:57:14.246318 (Thread-48): sending response (<Response 1241 bytes [200 OK]>) to 10.0.42.85
2022-01-05 16:57:31.730616 (Thread-49): 16:57:31  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 16:57:31.730823 (Thread-49): 16:57:31  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 16:57:31.735672 (Thread-49): 16:57:31  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac034b970>]}
2022-01-05 16:57:32.334140 (Thread-50): handling status request
2022-01-05 16:57:32.334509 (Thread-50): 16:57:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae41913a0>]}
2022-01-05 16:57:32.334979 (Thread-50): sending response (<Response 1241 bytes [200 OK]>) to 10.0.9.25
2022-01-05 16:57:32.348009 (Thread-51): handling status request
2022-01-05 16:57:32.348379 (Thread-51): 16:57:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40d5310>]}
2022-01-05 16:57:32.348838 (Thread-51): sending response (<Response 1241 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:20:28.712209 (Thread-52): handling status request
2022-01-05 17:20:28.713633 (Thread-52): 17:20:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0376130>]}
2022-01-05 17:20:28.714135 (Thread-52): sending response (<Response 1241 bytes [200 OK]>) to 10.0.46.191
2022-01-05 17:20:28.789091 (Thread-53): handling status request
2022-01-05 17:20:28.789391 (Thread-53): 17:20:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0345cd0>]}
2022-01-05 17:20:28.789864 (Thread-53): sending response (<Response 1241 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:20:29.253632 (Thread-54): handling cli_args request
2022-01-05 17:20:29.253946 (Thread-54): 17:20:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0345c10>]}
2022-01-05 17:20:31.285207 (Thread-54): sending response (<Response 138 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:20:31.368158 (MainThread): 17:20:31  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 17:20:31.368548 (MainThread): 17:20:31  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 17:20:31.374483 (MainThread): 17:20:31  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3b071c71-0f21-4aec-a155-15949817d20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffaca2fdeb0>]}
2022-01-05 17:20:31.405575 (MainThread): 17:20:31  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3b071c71-0f21-4aec-a155-15949817d20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffaca4134c0>]}
2022-01-05 17:20:31.405805 (MainThread): 17:20:31  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:20:31.406772 (MainThread): 17:20:31  
2022-01-05 17:20:31.407040 (MainThread): 17:20:31  Acquiring new redshift connection "master"
2022-01-05 17:20:31.407820 (ThreadPoolExecutor-0_0): 17:20:31  Acquiring new redshift connection "list_dev"
2022-01-05 17:20:31.417518 (ThreadPoolExecutor-0_0): 17:20:31  Using redshift connection "list_dev"
2022-01-05 17:20:31.417619 (ThreadPoolExecutor-0_0): 17:20:31  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-05 17:20:31.417701 (ThreadPoolExecutor-0_0): 17:20:31  Opening a new connection, currently in state init
2022-01-05 17:20:31.417784 (ThreadPoolExecutor-0_0): 17:20:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:31.439471 (ThreadPoolExecutor-0_0): 17:20:31  SQL status: SELECT in 0.02 seconds
2022-01-05 17:20:31.440494 (ThreadPoolExecutor-0_0): 17:20:31  On list_dev: Close
2022-01-05 17:20:31.441532 (ThreadPoolExecutor-1_0): 17:20:31  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:20:31.447487 (ThreadPoolExecutor-1_0): 17:20:31  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:20:31.447585 (ThreadPoolExecutor-1_0): 17:20:31  On list_dev_dbt_nobodozie: BEGIN
2022-01-05 17:20:31.447666 (ThreadPoolExecutor-1_0): 17:20:31  Opening a new connection, currently in state closed
2022-01-05 17:20:31.447740 (ThreadPoolExecutor-1_0): 17:20:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:31.471806 (ThreadPoolExecutor-1_0): 17:20:31  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:20:31.471917 (ThreadPoolExecutor-1_0): 17:20:31  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:20:31.471991 (ThreadPoolExecutor-1_0): 17:20:31  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-05 17:20:31.488612 (ThreadPoolExecutor-1_0): 17:20:31  SQL status: SELECT in 0.02 seconds
2022-01-05 17:20:31.489727 (ThreadPoolExecutor-1_0): 17:20:31  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-05 17:20:31.492228 (ThreadPoolExecutor-1_0): 17:20:31  On list_dev_dbt_nobodozie: Close
2022-01-05 17:20:31.496455 (MainThread): 17:20:31  Using redshift connection "master"
2022-01-05 17:20:31.496567 (MainThread): 17:20:31  On master: BEGIN
2022-01-05 17:20:31.496649 (MainThread): 17:20:31  Opening a new connection, currently in state init
2022-01-05 17:20:31.496726 (MainThread): 17:20:31  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:31.649291 (Thread-55): handling poll request
2022-01-05 17:20:31.649733 (Thread-55): 17:20:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae412dc40>]}
2022-01-05 17:20:31.650759 (Thread-55): sending response (<Response 9949 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:20:32.186409 (MainThread): 17:20:32  SQL status: BEGIN in 0.69 seconds
2022-01-05 17:20:32.186572 (MainThread): 17:20:32  Using redshift connection "master"
2022-01-05 17:20:32.186655 (MainThread): 17:20:32  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-05 17:20:32.215191 (MainThread): 17:20:32  SQL status: SELECT in 0.03 seconds
2022-01-05 17:20:32.216314 (MainThread): 17:20:32  On master: ROLLBACK
2022-01-05 17:20:32.218517 (MainThread): 17:20:32  Using redshift connection "master"
2022-01-05 17:20:32.218629 (MainThread): 17:20:32  On master: BEGIN
2022-01-05 17:20:32.222972 (MainThread): 17:20:32  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:20:32.223083 (MainThread): 17:20:32  On master: COMMIT
2022-01-05 17:20:32.223154 (MainThread): 17:20:32  Using redshift connection "master"
2022-01-05 17:20:32.223222 (MainThread): 17:20:32  On master: COMMIT
2022-01-05 17:20:32.225162 (MainThread): 17:20:32  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:20:32.225270 (MainThread): 17:20:32  On master: Close
2022-01-05 17:20:32.225755 (MainThread): 17:20:32  Concurrency: 4 threads (target='default')
2022-01-05 17:20:32.225872 (MainThread): 17:20:32  
2022-01-05 17:20:32.227999 (Thread-1): 17:20:32  Began running node model.my_new_project.my_first_dbt_model
2022-01-05 17:20:32.228471 (Thread-1): 17:20:32  1 of 2 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-05 17:20:32.228760 (Thread-1): 17:20:32  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.228861 (Thread-1): 17:20:32  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-05 17:20:32.228955 (Thread-1): 17:20:32  Compiling model.my_new_project.my_first_dbt_model
2022-01-05 17:20:32.231288 (Thread-1): 17:20:32  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.249528 (Thread-1): 17:20:32  finished collecting timing info
2022-01-05 17:20:32.249671 (Thread-1): 17:20:32  Began executing node model.my_new_project.my_first_dbt_model
2022-01-05 17:20:32.280773 (Thread-1): 17:20:32  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.298262 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.298371 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:20:32.298454 (Thread-1): 17:20:32  Opening a new connection, currently in state closed
2022-01-05 17:20:32.298536 (Thread-1): 17:20:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:32.318595 (Thread-1): 17:20:32  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:20:32.318714 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.318810 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-05 17:20:32.365613 (Thread-1): 17:20:32  SQL status: SELECT in 0.05 seconds
2022-01-05 17:20:32.370908 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.371008 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-05 17:20:32.373565 (Thread-1): 17:20:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:20:32.375258 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.375353 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-05 17:20:32.377893 (Thread-1): 17:20:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:20:32.387953 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:20:32.388052 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.388125 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:20:32.428113 (Thread-1): 17:20:32  SQL status: COMMIT in 0.04 seconds
2022-01-05 17:20:32.428310 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.428388 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:20:32.430521 (Thread-1): 17:20:32  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:20:32.434356 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.434455 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-05 17:20:32.439373 (Thread-1): 17:20:32  SQL status: DROP TABLE in 0.0 seconds
2022-01-05 17:20:32.440326 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:20:32.440469 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.440591 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:20:32.470350 (Thread-1): 17:20:32  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:20:32.470467 (Thread-1): 17:20:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:20:32.470543 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:20:32.472715 (Thread-1): 17:20:32  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:20:32.473097 (Thread-1): 17:20:32  finished collecting timing info
2022-01-05 17:20:32.473222 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-05 17:20:32.475059 (Thread-1): 17:20:32  On model.my_new_project.my_first_dbt_model: Close
2022-01-05 17:20:32.475486 (Thread-1): 17:20:32  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b071c71-0f21-4aec-a155-15949817d20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffac9ac1dc0>]}
2022-01-05 17:20:32.475800 (Thread-1): 17:20:32  1 of 2 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.25s]
2022-01-05 17:20:32.475912 (Thread-1): 17:20:32  Finished running node model.my_new_project.my_first_dbt_model
2022-01-05 17:20:32.476696 (Thread-3): 17:20:32  Began running node model.my_new_project.my_second_dbt_model
2022-01-05 17:20:32.476960 (Thread-3): 17:20:32  2 of 2 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-05 17:20:32.477221 (Thread-3): 17:20:32  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.477326 (Thread-3): 17:20:32  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-05 17:20:32.477439 (Thread-3): 17:20:32  Compiling model.my_new_project.my_second_dbt_model
2022-01-05 17:20:32.479411 (Thread-3): 17:20:32  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.500240 (Thread-3): 17:20:32  finished collecting timing info
2022-01-05 17:20:32.500380 (Thread-3): 17:20:32  Began executing node model.my_new_project.my_second_dbt_model
2022-01-05 17:20:32.516039 (Thread-3): 17:20:32  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.529333 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.529467 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:20:32.529556 (Thread-3): 17:20:32  Opening a new connection, currently in state init
2022-01-05 17:20:32.529638 (Thread-3): 17:20:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:32.548735 (Thread-3): 17:20:32  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:20:32.548852 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.548934 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-05 17:20:32.553734 (Thread-3): 17:20:32  SQL status: CREATE VIEW in 0.0 seconds
2022-01-05 17:20:32.555485 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.555584 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-05 17:20:32.557800 (Thread-3): 17:20:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:20:32.558745 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:20:32.558844 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.558920 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:20:32.587529 (Thread-3): 17:20:32  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:20:32.587743 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.587826 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:20:32.590380 (Thread-3): 17:20:32  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:20:32.591557 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.591654 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-05 17:20:32.593649 (Thread-3): 17:20:32  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 17:20:32.594260 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:20:32.594354 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.594429 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:20:32.618770 (Thread-3): 17:20:32  SQL status: COMMIT in 0.02 seconds
2022-01-05 17:20:32.618888 (Thread-3): 17:20:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:20:32.618963 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:20:32.621265 (Thread-3): 17:20:32  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:20:32.621658 (Thread-3): 17:20:32  finished collecting timing info
2022-01-05 17:20:32.621785 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-05 17:20:32.623930 (Thread-3): 17:20:32  On model.my_new_project.my_second_dbt_model: Close
2022-01-05 17:20:32.624352 (Thread-3): 17:20:32  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b071c71-0f21-4aec-a155-15949817d20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffac81fd280>]}
2022-01-05 17:20:32.624653 (Thread-3): 17:20:32  2 of 2 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.15s]
2022-01-05 17:20:32.624762 (Thread-3): 17:20:32  Finished running node model.my_new_project.my_second_dbt_model
2022-01-05 17:20:32.626130 (MainThread): 17:20:32  Acquiring new redshift connection "master"
2022-01-05 17:20:32.626270 (MainThread): 17:20:32  Using redshift connection "master"
2022-01-05 17:20:32.626347 (MainThread): 17:20:32  On master: BEGIN
2022-01-05 17:20:32.626423 (MainThread): 17:20:32  Opening a new connection, currently in state closed
2022-01-05 17:20:32.626498 (MainThread): 17:20:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:20:32.649292 (MainThread): 17:20:32  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:20:32.649433 (MainThread): 17:20:32  On master: COMMIT
2022-01-05 17:20:32.649517 (MainThread): 17:20:32  Using redshift connection "master"
2022-01-05 17:20:32.649588 (MainThread): 17:20:32  On master: COMMIT
2022-01-05 17:20:32.651287 (MainThread): 17:20:32  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:20:32.651393 (MainThread): 17:20:32  On master: Close
2022-01-05 17:20:32.651758 (MainThread): 17:20:32  
2022-01-05 17:20:32.651867 (MainThread): 17:20:32  Finished running 1 table model, 1 view model in 1.24s.
2022-01-05 17:20:32.651946 (MainThread): 17:20:32  Connection 'master' was properly closed.
2022-01-05 17:20:32.652010 (MainThread): 17:20:32  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-05 17:20:32.652070 (MainThread): 17:20:32  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-05 17:20:32.722715 (MainThread): 17:20:32  
2022-01-05 17:20:32.722924 (MainThread): 17:20:32  Completed successfully
2022-01-05 17:20:32.723064 (MainThread): 17:20:32  
2022-01-05 17:20:32.723186 (MainThread): 17:20:32  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2022-01-05 17:20:33.191965 (Thread-56): handling poll request
2022-01-05 17:20:33.192318 (Thread-56): 17:20:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40e4c70>]}
2022-01-05 17:20:33.194331 (Thread-56): sending response (<Response 54422 bytes [200 OK]>) to 10.0.38.111
2022-01-05 17:20:33.906276 (Thread-57): handling status request
2022-01-05 17:20:33.906641 (Thread-57): 17:20:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40b5f40>]}
2022-01-05 17:20:33.907131 (Thread-57): sending response (<Response 1241 bytes [200 OK]>) to 10.0.9.25
2022-01-05 17:20:33.935630 (Thread-58): handling status request
2022-01-05 17:20:33.935882 (Thread-58): 17:20:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac034c670>]}
2022-01-05 17:20:33.936254 (Thread-58): sending response (<Response 1241 bytes [200 OK]>) to 10.0.12.39
2022-01-05 17:21:08.517276 (Thread-59): 17:21:08  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-05 17:21:08.517725 (Thread-59): 17:21:08  Partial parsing: updated file: my_new_project://models/dim_customers.sql
2022-01-05 17:21:08.522572 (Thread-59): 17:21:08  1699: static parser successfully parsed dim_customers.sql
2022-01-05 17:21:08.580279 (Thread-59): 17:21:08  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02cfdf0>]}
2022-01-05 17:21:09.322528 (Thread-60): handling status request
2022-01-05 17:21:09.322934 (Thread-60): 17:21:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40f6550>]}
2022-01-05 17:21:09.323407 (Thread-60): sending response (<Response 1552 bytes [200 OK]>) to 10.0.9.25
2022-01-05 17:21:09.397491 (Thread-61): handling status request
2022-01-05 17:21:09.397810 (Thread-61): 17:21:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac031d820>]}
2022-01-05 17:21:09.398263 (Thread-61): sending response (<Response 1552 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:21:12.432246 (Thread-62): handling status request
2022-01-05 17:21:12.432612 (Thread-62): 17:21:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40b5fa0>]}
2022-01-05 17:21:12.433097 (Thread-62): sending response (<Response 1552 bytes [200 OK]>) to 10.0.6.188
2022-01-05 17:21:12.667933 (Thread-63): handling status request
2022-01-05 17:21:12.668245 (Thread-63): 17:21:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40d57f0>]}
2022-01-05 17:21:12.668718 (Thread-63): sending response (<Response 1552 bytes [200 OK]>) to 10.0.17.156
2022-01-05 17:21:12.810381 (Thread-64): handling cli_args request
2022-01-05 17:21:12.810674 (Thread-64): 17:21:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae40d5130>]}
2022-01-05 17:21:14.836598 (Thread-64): sending response (<Response 138 bytes [200 OK]>) to 10.0.5.1
2022-01-05 17:21:14.907400 (MainThread): 17:21:14  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 17:21:14.907770 (MainThread): 17:21:14  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 17:21:14.913252 (MainThread): 17:21:14  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '16de0e09-5bb9-4497-9935-603c3bf9fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1274c1df40>]}
2022-01-05 17:21:14.955618 (MainThread): 17:21:14  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '16de0e09-5bb9-4497-9935-603c3bf9fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1274c9af70>]}
2022-01-05 17:21:14.955872 (MainThread): 17:21:14  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:21:14.956878 (MainThread): 17:21:14  
2022-01-05 17:21:14.957142 (MainThread): 17:21:14  Acquiring new redshift connection "master"
2022-01-05 17:21:14.957973 (ThreadPoolExecutor-0_0): 17:21:14  Acquiring new redshift connection "list_dev"
2022-01-05 17:21:14.967709 (ThreadPoolExecutor-0_0): 17:21:14  Using redshift connection "list_dev"
2022-01-05 17:21:14.967805 (ThreadPoolExecutor-0_0): 17:21:14  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-05 17:21:14.967886 (ThreadPoolExecutor-0_0): 17:21:14  Opening a new connection, currently in state init
2022-01-05 17:21:14.968121 (ThreadPoolExecutor-0_0): 17:21:14  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:14.993579 (ThreadPoolExecutor-0_0): 17:21:14  SQL status: SELECT in 0.03 seconds
2022-01-05 17:21:14.994574 (ThreadPoolExecutor-0_0): 17:21:14  On list_dev: Close
2022-01-05 17:21:14.995625 (ThreadPoolExecutor-1_0): 17:21:14  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:21:15.001679 (ThreadPoolExecutor-1_0): 17:21:15  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:21:15.001775 (ThreadPoolExecutor-1_0): 17:21:15  On list_dev_dbt_nobodozie: BEGIN
2022-01-05 17:21:15.001850 (ThreadPoolExecutor-1_0): 17:21:15  Opening a new connection, currently in state closed
2022-01-05 17:21:15.001925 (ThreadPoolExecutor-1_0): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.031186 (ThreadPoolExecutor-1_0): 17:21:15  SQL status: BEGIN in 0.03 seconds
2022-01-05 17:21:15.031293 (ThreadPoolExecutor-1_0): 17:21:15  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:21:15.031365 (ThreadPoolExecutor-1_0): 17:21:15  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-05 17:21:15.042641 (ThreadPoolExecutor-1_0): 17:21:15  SQL status: SELECT in 0.01 seconds
2022-01-05 17:21:15.043583 (ThreadPoolExecutor-1_0): 17:21:15  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-05 17:21:15.045371 (ThreadPoolExecutor-1_0): 17:21:15  On list_dev_dbt_nobodozie: Close
2022-01-05 17:21:15.049242 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.049367 (MainThread): 17:21:15  On master: BEGIN
2022-01-05 17:21:15.049473 (MainThread): 17:21:15  Opening a new connection, currently in state init
2022-01-05 17:21:15.049553 (MainThread): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.073686 (MainThread): 17:21:15  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:21:15.073793 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.073867 (MainThread): 17:21:15  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-05 17:21:15.102599 (MainThread): 17:21:15  SQL status: SELECT in 0.03 seconds
2022-01-05 17:21:15.103507 (MainThread): 17:21:15  On master: ROLLBACK
2022-01-05 17:21:15.105431 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.105526 (MainThread): 17:21:15  On master: BEGIN
2022-01-05 17:21:15.109090 (MainThread): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.109193 (MainThread): 17:21:15  On master: COMMIT
2022-01-05 17:21:15.109264 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.109331 (MainThread): 17:21:15  On master: COMMIT
2022-01-05 17:21:15.111104 (MainThread): 17:21:15  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:21:15.111214 (MainThread): 17:21:15  On master: Close
2022-01-05 17:21:15.111559 (MainThread): 17:21:15  Concurrency: 4 threads (target='default')
2022-01-05 17:21:15.111668 (MainThread): 17:21:15  
2022-01-05 17:21:15.113807 (Thread-1): 17:21:15  Began running node model.my_new_project.dim_customers
2022-01-05 17:21:15.114049 (Thread-1): 17:21:15  1 of 3 START view model dbt_nobodozie.dim_customers............................. [RUN]
2022-01-05 17:21:15.114268 (Thread-1): 17:21:15  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.114355 (Thread-1): 17:21:15  Began compiling node model.my_new_project.dim_customers
2022-01-05 17:21:15.114440 (Thread-1): 17:21:15  Compiling model.my_new_project.dim_customers
2022-01-05 17:21:15.115450 (Thread-1): 17:21:15  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-05 17:21:15.115782 (Thread-2): 17:21:15  Began running node model.my_new_project.my_first_dbt_model
2022-01-05 17:21:15.116001 (Thread-2): 17:21:15  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-05 17:21:15.116228 (Thread-2): 17:21:15  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.116310 (Thread-2): 17:21:15  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-05 17:21:15.116387 (Thread-2): 17:21:15  Compiling model.my_new_project.my_first_dbt_model
2022-01-05 17:21:15.118220 (Thread-2): 17:21:15  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.127341 (Thread-1): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.127477 (Thread-1): 17:21:15  Began executing node model.my_new_project.dim_customers
2022-01-05 17:21:15.132653 (Thread-2): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.132777 (Thread-2): 17:21:15  Began executing node model.my_new_project.my_first_dbt_model
2022-01-05 17:21:15.164712 (Thread-1): 17:21:15  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-05 17:21:15.175278 (Thread-2): 17:21:15  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.180254 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.180361 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:21:15.180437 (Thread-1): 17:21:15  Opening a new connection, currently in state closed
2022-01-05 17:21:15.180511 (Thread-1): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.188069 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.188170 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:21:15.188244 (Thread-2): 17:21:15  Opening a new connection, currently in state init
2022-01-05 17:21:15.188316 (Thread-2): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.198488 (Thread-65): handling poll request
2022-01-05 17:21:15.198873 (Thread-65): 17:21:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02cbb80>]}
2022-01-05 17:21:15.200311 (Thread-65): sending response (<Response 26535 bytes [200 OK]>) to 10.0.42.119
2022-01-05 17:21:15.453858 (Thread-2): 17:21:15  SQL status: BEGIN in 0.27 seconds
2022-01-05 17:21:15.454013 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.454094 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-05 17:21:15.454468 (Thread-1): 17:21:15  SQL status: BEGIN in 0.27 seconds
2022-01-05 17:21:15.454593 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.454666 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create view "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  ) ;

2022-01-05 17:21:15.466507 (Thread-1): 17:21:15  SQL status: CREATE VIEW in 0.01 seconds
2022-01-05 17:21:15.471982 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.472081 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-05 17:21:15.475492 (Thread-1): 17:21:15  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:21:15.482025 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:21:15.482129 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.482201 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:21:15.515913 (Thread-2): 17:21:15  SQL status: SELECT in 0.06 seconds
2022-01-05 17:21:15.517827 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.517918 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-05 17:21:15.520834 (Thread-2): 17:21:15  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:21:15.522576 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.522667 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-05 17:21:15.525960 (Thread-2): 17:21:15  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:21:15.530338 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:21:15.530433 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.530503 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:21:15.530730 (Thread-1): 17:21:15  SQL status: COMMIT in 0.05 seconds
2022-01-05 17:21:15.530940 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.531016 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:21:15.533666 (Thread-1): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.537485 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.537579 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop view if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-05 17:21:15.541588 (Thread-1): 17:21:15  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 17:21:15.542182 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:21:15.542271 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.542341 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:21:15.590726 (Thread-2): 17:21:15  SQL status: COMMIT in 0.06 seconds
2022-01-05 17:21:15.591076 (Thread-1): 17:21:15  SQL status: COMMIT in 0.05 seconds
2022-01-05 17:21:15.591194 (Thread-1): 17:21:15  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:21:15.591265 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:21:15.593510 (Thread-1): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.593931 (Thread-1): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.594058 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: ROLLBACK
2022-01-05 17:21:15.594268 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.594364 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:21:15.595971 (Thread-1): 17:21:15  On model.my_new_project.dim_customers: Close
2022-01-05 17:21:15.596416 (Thread-1): 17:21:15  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16de0e09-5bb9-4497-9935-603c3bf9fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12743f73d0>]}
2022-01-05 17:21:15.596734 (Thread-1): 17:21:15  1 of 3 OK created view model dbt_nobodozie.dim_customers........................ [CREATE VIEW in 0.48s]
2022-01-05 17:21:15.596880 (Thread-1): 17:21:15  Finished running node model.my_new_project.dim_customers
2022-01-05 17:21:15.597173 (Thread-2): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.598412 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.598503 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-05 17:21:15.604548 (Thread-2): 17:21:15  SQL status: DROP TABLE in 0.01 seconds
2022-01-05 17:21:15.605187 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:21:15.605278 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.605348 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:21:15.637193 (Thread-2): 17:21:15  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:21:15.637298 (Thread-2): 17:21:15  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:21:15.637366 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:21:15.639689 (Thread-2): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.640075 (Thread-2): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.640205 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-05 17:21:15.642097 (Thread-2): 17:21:15  On model.my_new_project.my_first_dbt_model: Close
2022-01-05 17:21:15.642485 (Thread-2): 17:21:15  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16de0e09-5bb9-4497-9935-603c3bf9fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1274341730>]}
2022-01-05 17:21:15.642768 (Thread-2): 17:21:15  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.53s]
2022-01-05 17:21:15.642869 (Thread-2): 17:21:15  Finished running node model.my_new_project.my_first_dbt_model
2022-01-05 17:21:15.643640 (Thread-4): 17:21:15  Began running node model.my_new_project.my_second_dbt_model
2022-01-05 17:21:15.643873 (Thread-4): 17:21:15  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-05 17:21:15.644118 (Thread-4): 17:21:15  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.644200 (Thread-4): 17:21:15  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-05 17:21:15.644282 (Thread-4): 17:21:15  Compiling model.my_new_project.my_second_dbt_model
2022-01-05 17:21:15.647097 (Thread-4): 17:21:15  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.661218 (Thread-4): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.661345 (Thread-4): 17:21:15  Began executing node model.my_new_project.my_second_dbt_model
2022-01-05 17:21:15.663136 (Thread-4): 17:21:15  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.677988 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.678094 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:21:15.678175 (Thread-4): 17:21:15  Opening a new connection, currently in state init
2022-01-05 17:21:15.678254 (Thread-4): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.700850 (Thread-4): 17:21:15  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:21:15.700959 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.701032 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-05 17:21:15.705749 (Thread-4): 17:21:15  SQL status: CREATE VIEW in 0.0 seconds
2022-01-05 17:21:15.707442 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.707535 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-05 17:21:15.709641 (Thread-4): 17:21:15  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:21:15.710585 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:21:15.710676 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.710745 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:21:15.740617 (Thread-4): 17:21:15  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:21:15.740830 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.741071 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:21:15.743080 (Thread-4): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.744153 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.744248 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-05 17:21:15.746149 (Thread-4): 17:21:15  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 17:21:15.746749 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:21:15.746839 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.746910 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:21:15.772685 (Thread-4): 17:21:15  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:21:15.772799 (Thread-4): 17:21:15  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:21:15.772870 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:21:15.774836 (Thread-4): 17:21:15  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:21:15.775204 (Thread-4): 17:21:15  finished collecting timing info
2022-01-05 17:21:15.775327 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-05 17:21:15.776977 (Thread-4): 17:21:15  On model.my_new_project.my_second_dbt_model: Close
2022-01-05 17:21:15.777381 (Thread-4): 17:21:15  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16de0e09-5bb9-4497-9935-603c3bf9fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12742ad820>]}
2022-01-05 17:21:15.777728 (Thread-4): 17:21:15  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.13s]
2022-01-05 17:21:15.777840 (Thread-4): 17:21:15  Finished running node model.my_new_project.my_second_dbt_model
2022-01-05 17:21:15.779138 (MainThread): 17:21:15  Acquiring new redshift connection "master"
2022-01-05 17:21:15.779276 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.779351 (MainThread): 17:21:15  On master: BEGIN
2022-01-05 17:21:15.779426 (MainThread): 17:21:15  Opening a new connection, currently in state closed
2022-01-05 17:21:15.779503 (MainThread): 17:21:15  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:21:15.804313 (MainThread): 17:21:15  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:21:15.804426 (MainThread): 17:21:15  On master: COMMIT
2022-01-05 17:21:15.804497 (MainThread): 17:21:15  Using redshift connection "master"
2022-01-05 17:21:15.804564 (MainThread): 17:21:15  On master: COMMIT
2022-01-05 17:21:15.806395 (MainThread): 17:21:15  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:21:15.806500 (MainThread): 17:21:15  On master: Close
2022-01-05 17:21:15.806886 (MainThread): 17:21:15  
2022-01-05 17:21:15.807008 (MainThread): 17:21:15  Finished running 2 view models, 1 table model in 0.85s.
2022-01-05 17:21:15.807090 (MainThread): 17:21:15  Connection 'master' was properly closed.
2022-01-05 17:21:15.807155 (MainThread): 17:21:15  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-05 17:21:15.807215 (MainThread): 17:21:15  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-05 17:21:15.807272 (MainThread): 17:21:15  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-05 17:21:15.870751 (MainThread): 17:21:15  
2022-01-05 17:21:15.870896 (MainThread): 17:21:15  Completed successfully
2022-01-05 17:21:15.870988 (MainThread): 17:21:15  
2022-01-05 17:21:15.871070 (MainThread): 17:21:15  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-05 17:21:16.602203 (Thread-66): handling poll request
2022-01-05 17:21:16.602577 (Thread-66): 17:21:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02ebee0>]}
2022-01-05 17:21:16.604615 (Thread-66): sending response (<Response 59270 bytes [200 OK]>) to 10.0.17.156
2022-01-05 17:21:17.208435 (Thread-67): handling status request
2022-01-05 17:21:17.208840 (Thread-67): 17:21:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02730d0>]}
2022-01-05 17:21:17.209350 (Thread-67): sending response (<Response 1552 bytes [200 OK]>) to 10.0.19.216
2022-01-05 17:21:17.264120 (Thread-68): handling status request
2022-01-05 17:21:17.264387 (Thread-68): 17:21:17  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02734c0>]}
2022-01-05 17:21:17.264801 (Thread-68): sending response (<Response 1552 bytes [200 OK]>) to 10.0.30.3
2022-01-05 17:24:05.359963 (Thread-69): handling status request
2022-01-05 17:24:05.361452 (Thread-69): 17:24:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0273700>]}
2022-01-05 17:24:05.389785 (Thread-69): sending response (<Response 1552 bytes [200 OK]>) to 10.0.20.28
2022-01-05 17:24:05.727924 (Thread-70): handling run_sql request
2022-01-05 17:24:05.728282 (Thread-70): 17:24:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02739a0>]}
2022-01-05 17:24:07.785613 (Thread-70): sending response (<Response 138 bytes [200 OK]>) to 10.0.42.119
2022-01-05 17:24:07.811994 (MainThread): 17:24:07  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '61ff180e-508c-425b-a6f6-868e8f8d5663', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81257eb100>]}
2022-01-05 17:24:07.812516 (MainThread): 17:24:07  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:24:07.813063 (Thread-1): 17:24:07  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 17:24:07.813187 (Thread-1): 17:24:07  Began compiling node rpc.my_new_project.request
2022-01-05 17:24:07.813274 (Thread-1): 17:24:07  Compiling rpc.my_new_project.request
2022-01-05 17:24:07.814403 (Thread-1): 17:24:07  finished collecting timing info
2022-01-05 17:24:07.814527 (Thread-1): 17:24:07  Began executing node rpc.my_new_project.request
2022-01-05 17:24:07.814632 (Thread-1): 17:24:07  Using redshift connection "rpc.my_new_project.request"
2022-01-05 17:24:07.814709 (Thread-1): 17:24:07  On rpc.my_new_project.request: SELECT *
FROM dev.dbt_nobodozie.my_second_dbt_model
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 17:24:07.814782 (Thread-1): 17:24:07  Opening a new connection, currently in state init
2022-01-05 17:24:07.814862 (Thread-1): 17:24:07  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:24:07.981462 (Thread-1): 17:24:07  SQL status: SELECT in 0.17 seconds
2022-01-05 17:24:07.982469 (Thread-1): 17:24:07  finished collecting timing info
2022-01-05 17:24:07.982625 (Thread-1): 17:24:07  On rpc.my_new_project.request: Close
2022-01-05 17:24:08.233339 (Thread-71): handling poll request
2022-01-05 17:24:08.233787 (Thread-71): 17:24:08  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac027a250>]}
2022-01-05 17:24:08.234931 (Thread-71): sending response (<Response 7182 bytes [200 OK]>) to 10.0.42.85
2022-01-05 17:24:33.494206 (Thread-72): handling status request
2022-01-05 17:24:33.494587 (Thread-72): 17:24:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac027a700>]}
2022-01-05 17:24:33.495097 (Thread-72): sending response (<Response 1552 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:24:33.931156 (Thread-73): handling run_sql request
2022-01-05 17:24:33.931520 (Thread-73): 17:24:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac027ab50>]}
2022-01-05 17:24:35.973403 (Thread-73): sending response (<Response 138 bytes [200 OK]>) to 10.0.5.1
2022-01-05 17:24:35.996999 (MainThread): 17:24:35  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '81b316fc-66b7-49fb-9cc8-45d7869fba76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd8fd3b280>]}
2022-01-05 17:24:35.997535 (MainThread): 17:24:35  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:24:35.998112 (Thread-1): 17:24:35  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 17:24:35.998245 (Thread-1): 17:24:35  Began compiling node rpc.my_new_project.request
2022-01-05 17:24:35.998337 (Thread-1): 17:24:35  Compiling rpc.my_new_project.request
2022-01-05 17:24:35.999529 (Thread-1): 17:24:35  finished collecting timing info
2022-01-05 17:24:35.999658 (Thread-1): 17:24:35  Began executing node rpc.my_new_project.request
2022-01-05 17:24:35.999761 (Thread-1): 17:24:35  Using redshift connection "rpc.my_new_project.request"
2022-01-05 17:24:35.999841 (Thread-1): 17:24:35  On rpc.my_new_project.request: SELECT *
FROM dev.dbt_nobodozie.dim_customers
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 17:24:35.999928 (Thread-1): 17:24:35  Opening a new connection, currently in state init
2022-01-05 17:24:36.000017 (Thread-1): 17:24:35  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:24:36.061063 (Thread-1): 17:24:36  SQL status: SELECT in 0.06 seconds
2022-01-05 17:24:36.064123 (Thread-1): 17:24:36  finished collecting timing info
2022-01-05 17:24:36.064287 (Thread-1): 17:24:36  On rpc.my_new_project.request: Close
2022-01-05 17:24:36.397917 (Thread-74): handling poll request
2022-01-05 17:24:36.398401 (Thread-74): 17:24:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac031dd00>]}
2022-01-05 17:24:36.400027 (Thread-74): sending response (<Response 12318 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:26:20.628671 (Thread-75): handling status request
2022-01-05 17:26:20.630305 (Thread-75): 17:26:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0275f40>]}
2022-01-05 17:26:20.630809 (Thread-75): sending response (<Response 1552 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:26:20.970191 (Thread-76): handling run_sql request
2022-01-05 17:26:20.970562 (Thread-76): 17:26:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02754c0>]}
2022-01-05 17:26:23.079128 (Thread-76): sending response (<Response 138 bytes [200 OK]>) to 10.0.46.191
2022-01-05 17:26:23.106146 (MainThread): 17:26:23  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '005825a7-53c0-4d65-ae4a-e7e45b153d38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0da7e48610>]}
2022-01-05 17:26:23.106687 (MainThread): 17:26:23  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:26:23.107244 (Thread-1): 17:26:23  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-05 17:26:23.107373 (Thread-1): 17:26:23  Began compiling node rpc.my_new_project.request
2022-01-05 17:26:23.107463 (Thread-1): 17:26:23  Compiling rpc.my_new_project.request
2022-01-05 17:26:23.109528 (Thread-1): 17:26:23  finished collecting timing info
2022-01-05 17:26:23.109661 (Thread-1): 17:26:23  Began executing node rpc.my_new_project.request
2022-01-05 17:26:23.109759 (Thread-1): 17:26:23  Using redshift connection "rpc.my_new_project.request"
2022-01-05 17:26:23.109845 (Thread-1): 17:26:23  On rpc.my_new_project.request: 

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-05 17:26:23.109919 (Thread-1): 17:26:23  Opening a new connection, currently in state init
2022-01-05 17:26:23.109995 (Thread-1): 17:26:23  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:23.143521 (Thread-1): 17:26:23  SQL status: SELECT in 0.03 seconds
2022-01-05 17:26:23.146588 (Thread-1): 17:26:23  finished collecting timing info
2022-01-05 17:26:23.146736 (Thread-1): 17:26:23  On rpc.my_new_project.request: Close
2022-01-05 17:26:23.530944 (Thread-77): handling poll request
2022-01-05 17:26:23.531383 (Thread-77): 17:26:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02976a0>]}
2022-01-05 17:26:23.532941 (Thread-77): sending response (<Response 16918 bytes [200 OK]>) to 10.0.12.39
2022-01-05 17:26:29.593023 (Thread-78): 17:26:29  Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
2022-01-05 17:26:29.593451 (Thread-78): 17:26:29  Partial parsing: updated file: my_new_project://models/dim_customers.sql
2022-01-05 17:26:29.597400 (Thread-78): 17:26:29  1699: static parser successfully parsed dim_customers.sql
2022-01-05 17:26:29.641716 (Thread-78): 17:26:29  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01e9a60>]}
2022-01-05 17:26:30.116418 (Thread-79): handling status request
2022-01-05 17:26:30.116791 (Thread-79): 17:26:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01bd760>]}
2022-01-05 17:26:30.117299 (Thread-79): sending response (<Response 1552 bytes [200 OK]>) to 10.0.6.188
2022-01-05 17:26:30.153082 (Thread-80): handling status request
2022-01-05 17:26:30.153389 (Thread-80): 17:26:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01bd4f0>]}
2022-01-05 17:26:30.153866 (Thread-80): sending response (<Response 1552 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:26:31.142331 (Thread-81): handling status request
2022-01-05 17:26:31.142705 (Thread-81): 17:26:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01bd280>]}
2022-01-05 17:26:31.143178 (Thread-81): sending response (<Response 1552 bytes [200 OK]>) to 10.0.9.25
2022-01-05 17:26:31.294467 (Thread-82): handling status request
2022-01-05 17:26:31.294852 (Thread-82): 17:26:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01bd070>]}
2022-01-05 17:26:31.295341 (Thread-82): sending response (<Response 1552 bytes [200 OK]>) to 10.0.19.216
2022-01-05 17:26:31.473115 (Thread-83): handling cli_args request
2022-01-05 17:26:31.473536 (Thread-83): 17:26:31  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0275100>]}
2022-01-05 17:26:33.515373 (Thread-83): sending response (<Response 138 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:26:33.592844 (MainThread): 17:26:33  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 17:26:33.593259 (MainThread): 17:26:33  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 17:26:33.598950 (MainThread): 17:26:33  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7559c76e-442f-4452-bf2d-d52ec843e089', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9cfe84fa0>]}
2022-01-05 17:26:33.633174 (MainThread): 17:26:33  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7559c76e-442f-4452-bf2d-d52ec843e089', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9cfef3fd0>]}
2022-01-05 17:26:33.633462 (MainThread): 17:26:33  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 17:26:33.634555 (MainThread): 17:26:33  
2022-01-05 17:26:33.634847 (MainThread): 17:26:33  Acquiring new redshift connection "master"
2022-01-05 17:26:33.635761 (ThreadPoolExecutor-0_0): 17:26:33  Acquiring new redshift connection "list_dev"
2022-01-05 17:26:33.645827 (ThreadPoolExecutor-0_0): 17:26:33  Using redshift connection "list_dev"
2022-01-05 17:26:33.645934 (ThreadPoolExecutor-0_0): 17:26:33  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-05 17:26:33.646017 (ThreadPoolExecutor-0_0): 17:26:33  Opening a new connection, currently in state init
2022-01-05 17:26:33.646097 (ThreadPoolExecutor-0_0): 17:26:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:33.667123 (ThreadPoolExecutor-0_0): 17:26:33  SQL status: SELECT in 0.02 seconds
2022-01-05 17:26:33.668166 (ThreadPoolExecutor-0_0): 17:26:33  On list_dev: Close
2022-01-05 17:26:33.669383 (ThreadPoolExecutor-1_0): 17:26:33  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:26:33.675534 (ThreadPoolExecutor-1_0): 17:26:33  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:26:33.675633 (ThreadPoolExecutor-1_0): 17:26:33  On list_dev_dbt_nobodozie: BEGIN
2022-01-05 17:26:33.675711 (ThreadPoolExecutor-1_0): 17:26:33  Opening a new connection, currently in state closed
2022-01-05 17:26:33.675786 (ThreadPoolExecutor-1_0): 17:26:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:33.699517 (ThreadPoolExecutor-1_0): 17:26:33  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:33.699635 (ThreadPoolExecutor-1_0): 17:26:33  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-05 17:26:33.699713 (ThreadPoolExecutor-1_0): 17:26:33  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-05 17:26:33.710913 (ThreadPoolExecutor-1_0): 17:26:33  SQL status: SELECT in 0.01 seconds
2022-01-05 17:26:33.711973 (ThreadPoolExecutor-1_0): 17:26:33  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-05 17:26:33.713848 (ThreadPoolExecutor-1_0): 17:26:33  On list_dev_dbt_nobodozie: Close
2022-01-05 17:26:33.718202 (MainThread): 17:26:33  Using redshift connection "master"
2022-01-05 17:26:33.718314 (MainThread): 17:26:33  On master: BEGIN
2022-01-05 17:26:33.718395 (MainThread): 17:26:33  Opening a new connection, currently in state init
2022-01-05 17:26:33.718472 (MainThread): 17:26:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:33.742645 (MainThread): 17:26:33  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:33.742760 (MainThread): 17:26:33  Using redshift connection "master"
2022-01-05 17:26:33.742838 (MainThread): 17:26:33  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-05 17:26:33.771943 (MainThread): 17:26:33  SQL status: SELECT in 0.03 seconds
2022-01-05 17:26:33.773031 (MainThread): 17:26:33  On master: ROLLBACK
2022-01-05 17:26:33.774950 (MainThread): 17:26:33  Using redshift connection "master"
2022-01-05 17:26:33.775047 (MainThread): 17:26:33  On master: BEGIN
2022-01-05 17:26:33.778761 (MainThread): 17:26:33  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:33.778866 (MainThread): 17:26:33  On master: COMMIT
2022-01-05 17:26:33.778938 (MainThread): 17:26:33  Using redshift connection "master"
2022-01-05 17:26:33.779007 (MainThread): 17:26:33  On master: COMMIT
2022-01-05 17:26:33.780800 (MainThread): 17:26:33  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:26:33.780906 (MainThread): 17:26:33  On master: Close
2022-01-05 17:26:33.781331 (MainThread): 17:26:33  Concurrency: 4 threads (target='default')
2022-01-05 17:26:33.781468 (MainThread): 17:26:33  
2022-01-05 17:26:33.783834 (Thread-1): 17:26:33  Began running node model.my_new_project.dim_customers
2022-01-05 17:26:33.784105 (Thread-1): 17:26:33  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-05 17:26:33.784355 (Thread-1): 17:26:33  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:33.784449 (Thread-1): 17:26:33  Began compiling node model.my_new_project.dim_customers
2022-01-05 17:26:33.784536 (Thread-1): 17:26:33  Compiling model.my_new_project.dim_customers
2022-01-05 17:26:33.786746 (Thread-1): 17:26:33  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-05 17:26:33.786971 (Thread-2): 17:26:33  Began running node model.my_new_project.my_first_dbt_model
2022-01-05 17:26:33.787198 (Thread-2): 17:26:33  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-05 17:26:33.787442 (Thread-2): 17:26:33  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.787525 (Thread-2): 17:26:33  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-05 17:26:33.787603 (Thread-2): 17:26:33  Compiling model.my_new_project.my_first_dbt_model
2022-01-05 17:26:33.789730 (Thread-2): 17:26:33  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.804175 (Thread-2): 17:26:33  finished collecting timing info
2022-01-05 17:26:33.804315 (Thread-2): 17:26:33  Began executing node model.my_new_project.my_first_dbt_model
2022-01-05 17:26:33.809433 (Thread-1): 17:26:33  finished collecting timing info
2022-01-05 17:26:33.809579 (Thread-1): 17:26:33  Began executing node model.my_new_project.dim_customers
2022-01-05 17:26:33.858912 (Thread-1): 17:26:33  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-05 17:26:33.860586 (Thread-2): 17:26:33  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.874136 (Thread-1): 17:26:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:33.874250 (Thread-1): 17:26:33  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:26:33.874334 (Thread-1): 17:26:33  Opening a new connection, currently in state closed
2022-01-05 17:26:33.874415 (Thread-1): 17:26:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:33.874730 (Thread-2): 17:26:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.874829 (Thread-2): 17:26:33  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:26:33.874911 (Thread-2): 17:26:33  Opening a new connection, currently in state init
2022-01-05 17:26:33.874988 (Thread-2): 17:26:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:33.898822 (Thread-1): 17:26:33  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:33.898943 (Thread-1): 17:26:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:33.899024 (Thread-1): 17:26:33  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-05 17:26:33.899718 (Thread-2): 17:26:33  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:33.899834 (Thread-2): 17:26:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.899921 (Thread-2): 17:26:33  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-05 17:26:33.958504 (Thread-84): handling poll request
2022-01-05 17:26:33.958937 (Thread-84): 17:26:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01e7a60>]}
2022-01-05 17:26:33.960390 (Thread-84): sending response (<Response 30570 bytes [200 OK]>) to 10.0.42.85
2022-01-05 17:26:33.987004 (Thread-2): 17:26:33  SQL status: SELECT in 0.09 seconds
2022-01-05 17:26:33.992960 (Thread-2): 17:26:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.993077 (Thread-2): 17:26:33  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-05 17:26:33.997300 (Thread-2): 17:26:33  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:26:33.999115 (Thread-2): 17:26:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:33.999212 (Thread-2): 17:26:33  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-05 17:26:34.002063 (Thread-2): 17:26:34  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:26:34.012080 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:26:34.012179 (Thread-2): 17:26:34  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:34.012251 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:26:34.064143 (Thread-2): 17:26:34  SQL status: COMMIT in 0.05 seconds
2022-01-05 17:26:34.064368 (Thread-2): 17:26:34  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:34.064449 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:26:34.067215 (Thread-2): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.071247 (Thread-2): 17:26:34  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:34.071342 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-05 17:26:34.076423 (Thread-2): 17:26:34  SQL status: DROP TABLE in 0.0 seconds
2022-01-05 17:26:34.077048 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:26:34.077139 (Thread-2): 17:26:34  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:34.077211 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-05 17:26:34.114712 (Thread-2): 17:26:34  SQL status: COMMIT in 0.04 seconds
2022-01-05 17:26:34.114823 (Thread-2): 17:26:34  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-05 17:26:34.114896 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-05 17:26:34.119364 (Thread-2): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.119803 (Thread-2): 17:26:34  finished collecting timing info
2022-01-05 17:26:34.119945 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-05 17:26:34.122629 (Thread-2): 17:26:34  On model.my_new_project.my_first_dbt_model: Close
2022-01-05 17:26:34.123105 (Thread-2): 17:26:34  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7559c76e-442f-4452-bf2d-d52ec843e089', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9cf6412b0>]}
2022-01-05 17:26:34.123434 (Thread-2): 17:26:34  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.34s]
2022-01-05 17:26:34.123548 (Thread-2): 17:26:34  Finished running node model.my_new_project.my_first_dbt_model
2022-01-05 17:26:34.124103 (Thread-4): 17:26:34  Began running node model.my_new_project.my_second_dbt_model
2022-01-05 17:26:34.124340 (Thread-4): 17:26:34  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-05 17:26:34.124590 (Thread-4): 17:26:34  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.124678 (Thread-4): 17:26:34  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-05 17:26:34.124762 (Thread-4): 17:26:34  Compiling model.my_new_project.my_second_dbt_model
2022-01-05 17:26:34.127770 (Thread-4): 17:26:34  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.141733 (Thread-4): 17:26:34  finished collecting timing info
2022-01-05 17:26:34.141867 (Thread-4): 17:26:34  Began executing node model.my_new_project.my_second_dbt_model
2022-01-05 17:26:34.157163 (Thread-4): 17:26:34  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.174705 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.174813 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:26:34.174895 (Thread-4): 17:26:34  Opening a new connection, currently in state init
2022-01-05 17:26:34.174976 (Thread-4): 17:26:34  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:34.199508 (Thread-4): 17:26:34  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:34.199623 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.199701 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-05 17:26:34.206621 (Thread-4): 17:26:34  SQL status: CREATE VIEW in 0.01 seconds
2022-01-05 17:26:34.208961 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.209057 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-05 17:26:34.212263 (Thread-4): 17:26:34  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:26:34.213221 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:26:34.213314 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.213385 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:26:34.256152 (Thread-4): 17:26:34  SQL status: COMMIT in 0.04 seconds
2022-01-05 17:26:34.256383 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.256464 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:26:34.259599 (Thread-4): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.260936 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.261028 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-05 17:26:34.263961 (Thread-4): 17:26:34  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 17:26:34.264590 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:26:34.264678 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.264750 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-05 17:26:34.301626 (Thread-4): 17:26:34  SQL status: COMMIT in 0.04 seconds
2022-01-05 17:26:34.301747 (Thread-4): 17:26:34  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-05 17:26:34.301823 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-05 17:26:34.304859 (Thread-4): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.305280 (Thread-4): 17:26:34  finished collecting timing info
2022-01-05 17:26:34.305440 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-05 17:26:34.307905 (Thread-4): 17:26:34  On model.my_new_project.my_second_dbt_model: Close
2022-01-05 17:26:34.308362 (Thread-4): 17:26:34  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7559c76e-442f-4452-bf2d-d52ec843e089', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9cf65e4c0>]}
2022-01-05 17:26:34.308723 (Thread-4): 17:26:34  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.18s]
2022-01-05 17:26:34.308838 (Thread-4): 17:26:34  Finished running node model.my_new_project.my_second_dbt_model
2022-01-05 17:26:34.719046 (Thread-1): 17:26:34  SQL status: SELECT in 0.82 seconds
2022-01-05 17:26:34.721364 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.721530 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-05 17:26:34.724371 (Thread-1): 17:26:34  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:26:34.726361 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.726459 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-05 17:26:34.728985 (Thread-1): 17:26:34  SQL status: ALTER TABLE in 0.0 seconds
2022-01-05 17:26:34.730173 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:26:34.730268 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.730338 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:26:34.779927 (Thread-1): 17:26:34  SQL status: COMMIT in 0.05 seconds
2022-01-05 17:26:34.780171 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.780253 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:26:34.782426 (Thread-1): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.783733 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.783827 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop view if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-05 17:26:34.788113 (Thread-1): 17:26:34  SQL status: DROP VIEW in 0.0 seconds
2022-01-05 17:26:34.788839 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:26:34.788932 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.789006 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: COMMIT
2022-01-05 17:26:34.823722 (Thread-1): 17:26:34  SQL status: COMMIT in 0.03 seconds
2022-01-05 17:26:34.823850 (Thread-1): 17:26:34  Using redshift connection "model.my_new_project.dim_customers"
2022-01-05 17:26:34.823925 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: BEGIN
2022-01-05 17:26:34.826064 (Thread-1): 17:26:34  SQL status: BEGIN in 0.0 seconds
2022-01-05 17:26:34.826516 (Thread-1): 17:26:34  finished collecting timing info
2022-01-05 17:26:34.826649 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: ROLLBACK
2022-01-05 17:26:34.828564 (Thread-1): 17:26:34  On model.my_new_project.dim_customers: Close
2022-01-05 17:26:34.829147 (Thread-1): 17:26:34  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7559c76e-442f-4452-bf2d-d52ec843e089', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9cf65e070>]}
2022-01-05 17:26:34.829535 (Thread-1): 17:26:34  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 1.04s]
2022-01-05 17:26:34.829654 (Thread-1): 17:26:34  Finished running node model.my_new_project.dim_customers
2022-01-05 17:26:34.831057 (MainThread): 17:26:34  Acquiring new redshift connection "master"
2022-01-05 17:26:34.831201 (MainThread): 17:26:34  Using redshift connection "master"
2022-01-05 17:26:34.831276 (MainThread): 17:26:34  On master: BEGIN
2022-01-05 17:26:34.831352 (MainThread): 17:26:34  Opening a new connection, currently in state closed
2022-01-05 17:26:34.831432 (MainThread): 17:26:34  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-05 17:26:34.856096 (MainThread): 17:26:34  SQL status: BEGIN in 0.02 seconds
2022-01-05 17:26:34.856216 (MainThread): 17:26:34  On master: COMMIT
2022-01-05 17:26:34.856290 (MainThread): 17:26:34  Using redshift connection "master"
2022-01-05 17:26:34.856359 (MainThread): 17:26:34  On master: COMMIT
2022-01-05 17:26:34.858098 (MainThread): 17:26:34  SQL status: COMMIT in 0.0 seconds
2022-01-05 17:26:34.858206 (MainThread): 17:26:34  On master: Close
2022-01-05 17:26:34.858663 (MainThread): 17:26:34  
2022-01-05 17:26:34.858777 (MainThread): 17:26:34  Finished running 2 table models, 1 view model in 1.22s.
2022-01-05 17:26:34.858858 (MainThread): 17:26:34  Connection 'master' was properly closed.
2022-01-05 17:26:34.858924 (MainThread): 17:26:34  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-05 17:26:34.858985 (MainThread): 17:26:34  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-05 17:26:34.859046 (MainThread): 17:26:34  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-05 17:26:34.929737 (MainThread): 17:26:34  
2022-01-05 17:26:34.929944 (MainThread): 17:26:34  Completed successfully
2022-01-05 17:26:34.930039 (MainThread): 17:26:34  
2022-01-05 17:26:34.930123 (MainThread): 17:26:34  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-05 17:26:35.380716 (Thread-85): handling poll request
2022-01-05 17:26:35.381089 (Thread-85): 17:26:35  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02479d0>]}
2022-01-05 17:26:35.383114 (Thread-85): sending response (<Response 56622 bytes [200 OK]>) to 10.0.32.47
2022-01-05 17:26:36.089452 (Thread-86): handling status request
2022-01-05 17:26:36.089823 (Thread-86): 17:26:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0247220>]}
2022-01-05 17:26:36.090327 (Thread-86): sending response (<Response 1552 bytes [200 OK]>) to 10.0.46.191
2022-01-05 17:26:36.245259 (Thread-87): handling status request
2022-01-05 17:26:36.245677 (Thread-87): 17:26:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01bda30>]}
2022-01-05 17:26:36.246143 (Thread-87): sending response (<Response 1552 bytes [200 OK]>) to 10.0.1.250
2022-01-05 17:37:36.466305 (Thread-88): handling status request
2022-01-05 17:37:36.467732 (Thread-88): 17:37:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01e8340>]}
2022-01-05 17:37:36.468223 (Thread-88): sending response (<Response 1552 bytes [200 OK]>) to 10.0.30.3
2022-01-05 17:37:39.169785 (Thread-89): 17:37:39  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-05 17:37:39.170001 (Thread-89): 17:37:39  Partial parsing enabled, no changes found, skipping parsing
2022-01-05 17:37:39.175096 (Thread-89): 17:37:39  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0111730>]}
2022-01-05 17:37:39.713062 (Thread-90): handling status request
2022-01-05 17:37:39.713507 (Thread-90): 17:37:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0247220>]}
2022-01-05 17:37:39.714030 (Thread-90): sending response (<Response 1241 bytes [200 OK]>) to 10.0.46.191
2022-01-05 17:37:39.720706 (Thread-91): handling status request
2022-01-05 17:37:39.721034 (Thread-91): 17:37:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01cbee0>]}
2022-01-05 17:37:39.721533 (Thread-91): sending response (<Response 1241 bytes [200 OK]>) to 10.0.12.39
2022-01-05 18:27:44.299651 (Thread-92): handling status request
2022-01-05 18:27:44.300025 (Thread-92): 18:27:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01e8a30>]}
2022-01-05 18:27:44.300487 (Thread-92): sending response (<Response 1241 bytes [200 OK]>) to 10.0.9.25
2022-01-05 18:27:44.314525 (Thread-93): handling status request
2022-01-05 18:27:44.314788 (Thread-93): 18:27:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01e8b20>]}
2022-01-05 18:27:44.315150 (Thread-93): sending response (<Response 1241 bytes [200 OK]>) to 10.0.18.253
2022-01-05 18:27:44.343297 (Thread-94): handling ps request
2022-01-05 18:27:44.343558 (Thread-94): 18:27:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01e8760>]}
2022-01-05 18:27:44.344343 (Thread-94): sending response (<Response 6873 bytes [200 OK]>) to 10.0.5.1
2022-01-05 18:27:44.365562 (Thread-95): handling status request
2022-01-05 18:27:44.365825 (Thread-95): 18:27:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0111b20>]}
2022-01-05 18:27:44.366188 (Thread-95): sending response (<Response 1241 bytes [200 OK]>) to 10.0.30.3
2022-01-05 18:27:44.950490 (Thread-96): handling poll request
2022-01-05 18:27:44.950850 (Thread-96): 18:27:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0111e20>]}
2022-01-05 18:27:44.953665 (Thread-96): sending response (<Response 86908 bytes [200 OK]>) to 10.0.46.191
2022-01-05 18:27:45.250026 (Thread-97): handling status request
2022-01-05 18:27:45.250816 (Thread-98): handling status request
2022-01-05 18:27:45.256565 (Thread-97): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac02a6040>]}
2022-01-05 18:27:45.257084 (Thread-97): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:27:45.257303 (Thread-98): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0111f40>]}
2022-01-05 18:27:45.262654 (Thread-99): handling status request
2022-01-05 18:27:45.264728 (Thread-98): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:27:45.265124 (Thread-99): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0111fd0>]}
2022-01-05 18:27:45.271398 (Thread-100): handling list request
2022-01-05 18:27:45.273619 (Thread-101): handling list request
2022-01-05 18:27:45.273918 (Thread-100): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01c6100>]}
2022-01-05 18:27:45.282047 (Thread-101): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0113a60>]}
2022-01-05 18:27:45.291580 (Thread-99): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:27:45.336806 (Thread-102): sending response (<Response 214 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:27:45.645595 (Thread-103): handling status request
2022-01-05 18:27:45.645969 (Thread-103): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0113280>]}
2022-01-05 18:27:45.646442 (Thread-103): sending response (<Response 1241 bytes [200 OK]>) to 10.0.38.111
2022-01-05 18:27:45.692059 (Thread-104): handling status request
2022-01-05 18:27:45.692458 (Thread-104): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0113310>]}
2022-01-05 18:27:45.692946 (Thread-104): sending response (<Response 1241 bytes [200 OK]>) to 10.0.5.1
2022-01-05 18:27:45.739117 (Thread-105): handling status request
2022-01-05 18:27:45.739421 (Thread-105): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0122880>]}
2022-01-05 18:27:45.739856 (Thread-105): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:27:45.746041 (Thread-106): handling list request
2022-01-05 18:27:45.746290 (Thread-106): 18:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01228b0>]}
2022-01-05 18:27:45.779461 (Thread-106): 18:27:45  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac00be700>]}
2022-01-05 18:27:45.779755 (Thread-106): 18:27:45  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 18:27:45.782118 (Thread-106): sending response (<Response 1686 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:52:02.003069 (Thread-107): handling status request
2022-01-05 18:52:02.004380 (Thread-107): 18:52:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01cbb20>]}
2022-01-05 18:52:02.004839 (Thread-107): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:52:02.010570 (Thread-108): handling list request
2022-01-05 18:52:02.010821 (Thread-108): 18:52:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01cb670>]}
2022-01-05 18:52:02.045093 (Thread-108): 18:52:02  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac00c6700>]}
2022-01-05 18:52:02.045390 (Thread-108): 18:52:02  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 18:52:02.051369 (Thread-108): sending response (<Response 1686 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:54:16.274809 (Thread-109): handling status request
2022-01-05 18:54:16.277206 (Thread-109): 18:54:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac00cb550>]}
2022-01-05 18:54:16.277696 (Thread-109): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:54:16.287710 (Thread-110): handling list request
2022-01-05 18:54:16.287947 (Thread-110): 18:54:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac00cb7c0>]}
2022-01-05 18:54:16.322182 (Thread-110): 18:54:16  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac01134c0>]}
2022-01-05 18:54:16.322448 (Thread-110): 18:54:16  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 18:54:16.327571 (Thread-110): sending response (<Response 1686 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:55:34.190676 (Thread-111): handling status request
2022-01-05 18:55:34.192867 (Thread-111): 18:55:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac0122eb0>]}
2022-01-05 18:55:34.193330 (Thread-111): sending response (<Response 1219 bytes [200 OK]>) to 10.0.18.120
2022-01-05 18:55:34.199351 (Thread-112): handling list request
2022-01-05 18:55:34.199598 (Thread-112): 18:55:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac00bec70>]}
2022-01-05 18:55:34.229619 (Thread-112): 18:55:34  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '97c3c77a-0aec-4af9-b150-4a10123742b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac00d4970>]}
2022-01-05 18:55:34.229912 (Thread-112): 18:55:34  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-05 18:55:34.236528 (Thread-112): sending response (<Response 1686 bytes [200 OK]>) to 10.0.18.120
2022-01-06 14:08:10.690361 (MainThread): Running with dbt=1.0.1
2022-01-06 14:08:10.786543 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt_rpc.task.server.RPCServerTask'>, debug=None, defer=None, exclude=None, fail_fast=None, host='0.0.0.0', log_cache_events=False, log_format=None, models=None, partial_parse=True, port=8580, printer_width=None, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, send_anonymous_usage_stats=None, single_threaded=False, state=None, static_parser=None, target=None, threads=None, use_colors=None, use_experimental_parser=None, vars='{}', version_check=None, warn_error=None, which='rpc', write_json=None)
2022-01-06 14:08:10.792998 (MainThread): Tracking: tracking
2022-01-06 14:08:10.813238 (MainThread): 14:08:10  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effcca05b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb87434f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb87ea280>]}
2022-01-06 14:08:10.813622 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=21
2022-01-06 14:08:10.813933 (MainThread): Supported methods: ['build', 'cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'list', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'source-freshness', 'status', 'test']
2022-01-06 14:08:10.814144 (MainThread): Send requests to http://localhost:8580/jsonrpc
2022-01-06 14:08:10.861567 (Thread-12): 14:08:10  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:08:10.861795 (Thread-12): 14:08:10  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:08:10.867837 (Thread-12): 14:08:10  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86dc6d0>]}
2022-01-06 14:08:13.262573 (Thread-13): handling status request
2022-01-06 14:08:13.262957 (Thread-13): 14:08:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb87aa5e0>]}
2022-01-06 14:08:13.263522 (Thread-13): sending response (<Response 1241 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:08:13.284330 (Thread-14): handling status request
2022-01-06 14:08:13.284592 (Thread-14): 14:08:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb87aa2b0>]}
2022-01-06 14:08:13.284956 (Thread-14): sending response (<Response 1241 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:08:13.301138 (Thread-15): handling ps request
2022-01-06 14:08:13.301417 (Thread-15): 14:08:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86c9fd0>]}
2022-01-06 14:08:13.301768 (Thread-15): sending response (<Response 105 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:08:13.326480 (Thread-16): handling status request
2022-01-06 14:08:13.326723 (Thread-16): 14:08:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86c9eb0>]}
2022-01-06 14:08:13.327057 (Thread-16): sending response (<Response 1241 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:08:15.543591 (Thread-17): handling status request
2022-01-06 14:08:15.543977 (Thread-17): 14:08:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86c9a00>]}
2022-01-06 14:08:15.544445 (Thread-17): sending response (<Response 1219 bytes [200 OK]>) to 10.0.7.144
2022-01-06 14:08:15.548326 (Thread-18): handling status request
2022-01-06 14:08:15.548575 (Thread-18): 14:08:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86c9880>]}
2022-01-06 14:08:15.548926 (Thread-18): sending response (<Response 1219 bytes [200 OK]>) to 10.0.7.144
2022-01-06 14:08:15.549815 (Thread-19): handling list request
2022-01-06 14:08:15.550162 (Thread-19): 14:08:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb87eab80>]}
2022-01-06 14:08:15.590223 (Thread-22): sending response (<Response 214 bytes [200 OK]>) to 10.0.7.144
2022-01-06 14:08:16.812792 (Thread-23): handling status request
2022-01-06 14:08:16.813182 (Thread-23): 14:08:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86c9610>]}
2022-01-06 14:08:16.813686 (Thread-23): sending response (<Response 1219 bytes [200 OK]>) to 10.0.7.144
2022-01-06 14:08:16.819085 (Thread-24): handling list request
2022-01-06 14:08:16.819347 (Thread-24): 14:08:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86c9430>]}
2022-01-06 14:08:16.844556 (Thread-24): 14:08:16  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86a7df0>]}
2022-01-06 14:08:16.844819 (Thread-24): 14:08:16  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:08:16.847644 (Thread-24): sending response (<Response 1682 bytes [200 OK]>) to 10.0.7.144
2022-01-06 14:08:20.139460 (Thread-25): handling status request
2022-01-06 14:08:20.139840 (Thread-25): 14:08:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8633520>]}
2022-01-06 14:08:20.140327 (Thread-25): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:08:20.588708 (Thread-26): handling run_sql request
2022-01-06 14:08:20.589119 (Thread-26): 14:08:20  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8633eb0>]}
2022-01-06 14:08:22.654390 (Thread-26): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:08:22.678937 (MainThread): 14:08:22  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '73aa9c02-b013-4f21-a5a9-b5d486d8dbc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f5ae13a60>]}
2022-01-06 14:08:22.679505 (MainThread): 14:08:22  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:08:22.680091 (Thread-1): 14:08:22  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:08:22.680220 (Thread-1): 14:08:22  Began compiling node rpc.my_new_project.request
2022-01-06 14:08:22.680309 (Thread-1): 14:08:22  Compiling rpc.my_new_project.request
2022-01-06 14:08:22.682362 (Thread-1): 14:08:22  finished collecting timing info
2022-01-06 14:08:22.682493 (Thread-1): 14:08:22  Began executing node rpc.my_new_project.request
2022-01-06 14:08:22.682592 (Thread-1): 14:08:22  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:08:22.682667 (Thread-1): 14:08:22  On rpc.my_new_project.request: 

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:08:22.682744 (Thread-1): 14:08:22  Opening a new connection, currently in state init
2022-01-06 14:08:22.682820 (Thread-1): 14:08:22  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:08:22.706450 (Thread-1): 14:08:22  SQL status: SELECT in 0.02 seconds
2022-01-06 14:08:22.709782 (Thread-1): 14:08:22  finished collecting timing info
2022-01-06 14:08:22.709945 (Thread-1): 14:08:22  On rpc.my_new_project.request: Close
2022-01-06 14:08:23.081492 (Thread-27): handling poll request
2022-01-06 14:08:23.081943 (Thread-27): 14:08:23  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86a7fd0>]}
2022-01-06 14:08:23.083620 (Thread-27): sending response (<Response 16920 bytes [200 OK]>) to 10.0.21.176
2022-01-06 14:08:36.923297 (Thread-28): handling status request
2022-01-06 14:08:36.924825 (Thread-28): 14:08:36  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86a7d30>]}
2022-01-06 14:08:36.925345 (Thread-28): sending response (<Response 1241 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:08:37.131938 (Thread-29): handling status request
2022-01-06 14:08:37.132283 (Thread-29): 14:08:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8644c70>]}
2022-01-06 14:08:37.132724 (Thread-29): sending response (<Response 1241 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:08:37.239015 (Thread-30): handling docs.generate request
2022-01-06 14:08:37.239289 (Thread-30): 14:08:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8644eb0>]}
2022-01-06 14:08:39.309620 (Thread-30): sending response (<Response 138 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:08:39.337874 (MainThread): 14:08:39  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9ada3381-031b-4a9a-aad2-e7db08da0a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0302449d90>]}
2022-01-06 14:08:39.338162 (MainThread): 14:08:39  Found 3 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:08:39.339360 (MainThread): 14:08:39  
2022-01-06 14:08:39.339512 (MainThread): 14:08:39  Acquiring new redshift connection "master"
2022-01-06 14:08:39.340196 (ThreadPoolExecutor-0_0): 14:08:39  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:08:39.353267 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/catalog.sql
2022-01-06 14:08:39.366855 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters.sql
2022-01-06 14:08:39.394551 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/relations.sql
2022-01-06 14:08:39.395266 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 14:08:39.396210 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/catalog.sql
2022-01-06 14:08:39.398452 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters.sql
2022-01-06 14:08:39.419268 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/relations.sql
2022-01-06 14:08:39.420655 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/snapshot_merge.sql
2022-01-06 14:08:39.423555 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/get_custom_name/get_custom_alias.sql
2022-01-06 14:08:39.425134 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/get_custom_name/get_custom_database.sql
2022-01-06 14:08:39.426785 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/get_custom_name/get_custom_schema.sql
2022-01-06 14:08:39.429419 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/generic_test_sql/accepted_values.sql
2022-01-06 14:08:39.430851 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/generic_test_sql/not_null.sql
2022-01-06 14:08:39.431529 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/generic_test_sql/relationships.sql
2022-01-06 14:08:39.432506 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/generic_test_sql/unique.sql
2022-01-06 14:08:39.433363 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/configs.sql
2022-01-06 14:08:39.435693 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/hooks.sql
2022-01-06 14:08:39.439506 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/snapshots/strategies.sql
2022-01-06 14:08:39.456099 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/snapshots/snapshot_merge.sql
2022-01-06 14:08:39.457855 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/snapshots/snapshot.sql
2022-01-06 14:08:39.468799 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/snapshots/helpers.sql
2022-01-06 14:08:39.479420 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/seeds/seed.sql
2022-01-06 14:08:39.485264 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/seeds/helpers.sql
2022-01-06 14:08:39.500742 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/view/create_view_as.sql
2022-01-06 14:08:39.503127 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/view/view.sql
2022-01-06 14:08:39.510103 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/view/create_or_replace_view.sql
2022-01-06 14:08:39.512774 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/view/helpers.sql
2022-01-06 14:08:39.514204 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/table/table.sql
2022-01-06 14:08:39.521349 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/table/create_table_as.sql
2022-01-06 14:08:39.524259 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/incremental/merge.sql
2022-01-06 14:08:39.535196 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/incremental/on_schema_change.sql
2022-01-06 14:08:39.550080 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/incremental/column_helpers.sql
2022-01-06 14:08:39.554486 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/incremental/incremental.sql
2022-01-06 14:08:39.564258 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/models/incremental/is_incremental.sql
2022-01-06 14:08:39.565849 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/tests/test.sql
2022-01-06 14:08:39.570187 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/tests/where_subquery.sql
2022-01-06 14:08:39.572034 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/materializations/tests/helpers.sql
2022-01-06 14:08:39.573875 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/etc/statement.sql
2022-01-06 14:08:39.578201 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/etc/datetime.sql
2022-01-06 14:08:39.586275 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters/indexes.sql
2022-01-06 14:08:39.588999 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters/persist_docs.sql
2022-01-06 14:08:39.593471 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters/freshness.sql
2022-01-06 14:08:39.596389 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters/relation.sql
2022-01-06 14:08:39.605641 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters/metadata.sql
2022-01-06 14:08:39.612619 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters/columns.sql
2022-01-06 14:08:39.622240 (ThreadPoolExecutor-0_0): 14:08:39  Parsing macros/adapters/schema.sql
2022-01-06 14:08:39.634244 (ThreadPoolExecutor-0_0): 14:08:39  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:08:39.634362 (ThreadPoolExecutor-0_0): 14:08:39  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:08:39.634448 (ThreadPoolExecutor-0_0): 14:08:39  Opening a new connection, currently in state init
2022-01-06 14:08:39.634529 (ThreadPoolExecutor-0_0): 14:08:39  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:08:39.653795 (ThreadPoolExecutor-0_0): 14:08:39  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:08:39.653902 (ThreadPoolExecutor-0_0): 14:08:39  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:08:39.653974 (ThreadPoolExecutor-0_0): 14:08:39  On list_dev_dbt_nobodozie: select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:08:39.665091 (ThreadPoolExecutor-0_0): 14:08:39  SQL status: SELECT in 0.01 seconds
2022-01-06 14:08:39.666172 (ThreadPoolExecutor-0_0): 14:08:39  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:08:39.668073 (ThreadPoolExecutor-0_0): 14:08:39  On list_dev_dbt_nobodozie: Close
2022-01-06 14:08:39.673542 (MainThread): 14:08:39  Using redshift connection "master"
2022-01-06 14:08:39.673700 (MainThread): 14:08:39  On master: BEGIN
2022-01-06 14:08:39.673824 (MainThread): 14:08:39  Opening a new connection, currently in state init
2022-01-06 14:08:39.673944 (MainThread): 14:08:39  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:08:39.696735 (MainThread): 14:08:39  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:08:39.696889 (MainThread): 14:08:39  Using redshift connection "master"
2022-01-06 14:08:39.697006 (MainThread): 14:08:39  On master: with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:08:39.720595 (Thread-31): handling poll request
2022-01-06 14:08:39.720943 (Thread-31): 14:08:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8668070>]}
2022-01-06 14:08:39.722229 (Thread-31): sending response (<Response 23421 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:08:39.726020 (MainThread): 14:08:39  SQL status: SELECT in 0.03 seconds
2022-01-06 14:08:39.727648 (MainThread): 14:08:39  On master: ROLLBACK
2022-01-06 14:08:39.729594 (MainThread): 14:08:39  On master: Close
2022-01-06 14:08:39.730001 (MainThread): 14:08:39  Concurrency: 4 threads (target='default')
2022-01-06 14:08:39.730176 (MainThread): 14:08:39  
2022-01-06 14:08:39.733031 (Thread-1): 14:08:39  Began running node model.my_new_project.dim_customers
2022-01-06 14:08:39.733198 (Thread-1): 14:08:39  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:08:39.733332 (Thread-1): 14:08:39  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:08:39.733429 (Thread-1): 14:08:39  Compiling model.my_new_project.dim_customers
2022-01-06 14:08:39.735518 (Thread-1): 14:08:39  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:08:39.735745 (Thread-2): 14:08:39  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:08:39.735921 (Thread-2): 14:08:39  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:08:39.736001 (Thread-2): 14:08:39  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:08:39.736078 (Thread-2): 14:08:39  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:08:39.738718 (Thread-2): 14:08:39  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:08:39.751721 (Thread-2): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.751862 (Thread-2): 14:08:39  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:08:39.751962 (Thread-2): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.752104 (Thread-2): 14:08:39  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:08:39.752282 (Thread-1): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.752413 (Thread-1): 14:08:39  Began executing node model.my_new_project.dim_customers
2022-01-06 14:08:39.752503 (Thread-1): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.752634 (Thread-1): 14:08:39  Finished running node model.my_new_project.dim_customers
2022-01-06 14:08:39.753525 (Thread-4): 14:08:39  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:08:39.753687 (Thread-4): 14:08:39  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:08:39.753768 (Thread-4): 14:08:39  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:08:39.753843 (Thread-4): 14:08:39  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:08:39.755773 (Thread-4): 14:08:39  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:08:39.756042 (Thread-3): 14:08:39  Began running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 14:08:39.756371 (Thread-3): 14:08:39  Acquiring new redshift connection "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-06 14:08:39.756462 (Thread-3): 14:08:39  Began compiling node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 14:08:39.756536 (Thread-3): 14:08:39  Compiling test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 14:08:39.761160 (Thread-2): 14:08:39  Began running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 14:08:39.761380 (Thread-2): 14:08:39  Acquiring new redshift connection "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-06 14:08:39.761496 (Thread-2): 14:08:39  Began compiling node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 14:08:39.761603 (Thread-2): 14:08:39  Compiling test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 14:08:39.781498 (Thread-3): 14:08:39  Writing injected SQL for node "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-06 14:08:39.782932 (Thread-2): 14:08:39  Writing injected SQL for node "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-06 14:08:39.788529 (Thread-4): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.788728 (Thread-4): 14:08:39  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:08:39.788870 (Thread-4): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.789074 (Thread-4): 14:08:39  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:08:39.790004 (Thread-1): 14:08:39  Began running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 14:08:39.790186 (Thread-1): 14:08:39  Acquiring new redshift connection "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2022-01-06 14:08:39.790277 (Thread-1): 14:08:39  Began compiling node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 14:08:39.790356 (Thread-1): 14:08:39  Compiling test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 14:08:39.793530 (Thread-1): 14:08:39  Writing injected SQL for node "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2022-01-06 14:08:39.793726 (Thread-4): 14:08:39  Began running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 14:08:39.793875 (Thread-4): 14:08:39  Acquiring new redshift connection "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2022-01-06 14:08:39.793954 (Thread-4): 14:08:39  Began compiling node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 14:08:39.794028 (Thread-4): 14:08:39  Compiling test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 14:08:39.797009 (Thread-4): 14:08:39  Writing injected SQL for node "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2022-01-06 14:08:39.802562 (Thread-3): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.802695 (Thread-3): 14:08:39  Began executing node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 14:08:39.802788 (Thread-3): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.802926 (Thread-3): 14:08:39  Finished running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-06 14:08:39.803199 (Thread-2): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.803331 (Thread-2): 14:08:39  Began executing node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 14:08:39.803424 (Thread-2): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.803556 (Thread-2): 14:08:39  Finished running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2022-01-06 14:08:39.806250 (Thread-4): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.806364 (Thread-4): 14:08:39  Began executing node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 14:08:39.806449 (Thread-4): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.806569 (Thread-4): 14:08:39  Finished running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-06 14:08:39.811347 (Thread-1): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.811480 (Thread-1): 14:08:39  Began executing node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 14:08:39.811575 (Thread-1): 14:08:39  finished collecting timing info
2022-01-06 14:08:39.811718 (Thread-1): 14:08:39  Finished running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-06 14:08:39.812887 (MainThread): 14:08:39  Connection 'master' was properly closed.
2022-01-06 14:08:39.812997 (MainThread): 14:08:39  Connection 'test.my_new_project.not_null_my_second_dbt_model_id.151b76d778' was properly closed.
2022-01-06 14:08:39.813064 (MainThread): 14:08:39  Connection 'test.my_new_project.unique_my_first_dbt_model_id.16e066b321' was properly closed.
2022-01-06 14:08:39.813125 (MainThread): 14:08:39  Connection 'test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
2022-01-06 14:08:39.813183 (MainThread): 14:08:39  Connection 'test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
2022-01-06 14:08:39.875972 (MainThread): 14:08:39  Done.
2022-01-06 14:08:39.916937 (MainThread): 14:08:39  Acquiring new redshift connection "generate_catalog"
2022-01-06 14:08:39.917060 (MainThread): 14:08:39  Building catalog
2022-01-06 14:08:39.918139 (ThreadPoolExecutor-1_0): 14:08:39  Acquiring new redshift connection "dev.information_schema"
2022-01-06 14:08:39.928694 (ThreadPoolExecutor-1_0): 14:08:39  Using redshift connection "dev.information_schema"
2022-01-06 14:08:39.928801 (ThreadPoolExecutor-1_0): 14:08:39  On dev.information_schema: BEGIN
2022-01-06 14:08:39.928885 (ThreadPoolExecutor-1_0): 14:08:39  Opening a new connection, currently in state init
2022-01-06 14:08:39.928964 (ThreadPoolExecutor-1_0): 14:08:39  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:08:40.512788 (ThreadPoolExecutor-1_0): 14:08:40  SQL status: BEGIN in 0.58 seconds
2022-01-06 14:08:40.512950 (ThreadPoolExecutor-1_0): 14:08:40  Using redshift connection "dev.information_schema"
2022-01-06 14:08:40.513029 (ThreadPoolExecutor-1_0): 14:08:40  On dev.information_schema: 
    

    with late_binding as (
      select
        'dev'::varchar as table_database,
        table_schema,
        table_name,
        'LATE BINDING VIEW'::varchar as table_type,
        null::text as table_comment,

        column_name,
        column_index,
        column_type,
        null::text as column_comment
      from pg_get_late_binding_view_cols()
        cols(table_schema name, table_name name, column_name name,
             column_type varchar,
             column_index int)
        order by "column_index"
    ),

    early_binding as (
        select
            'dev'::varchar as table_database,
            sch.nspname as table_schema,
            tbl.relname as table_name,
            case tbl.relkind
                when 'v' then 'VIEW'
                else 'BASE TABLE'
            end as table_type,
            tbl_desc.description as table_comment,
            col.attname as column_name,
            col.attnum as column_index,
            pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
            col_desc.description as column_comment

        from pg_catalog.pg_namespace sch
        join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
        join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
        left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
        left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
        where (upper(sch.nspname) = upper('dbt_nobodozie'))
            and tbl.relkind in ('r', 'v', 'f', 'p')
            and col.attnum > 0
            and not col.attisdropped
    ),

    table_owners as (

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            tablename as table_name,
            tableowner as table_owner

        from pg_tables

        union all

        select
            'dev'::varchar as table_database,
            schemaname as table_schema,
            viewname as table_name,
            viewowner as table_owner

        from pg_views

    ),

    unioned as (

        select *
        from early_binding

        union all

        select *
        from late_binding

    )

    select *,
        table_database || '.' || table_schema || '.' || table_name as table_id

    from unioned
    join table_owners using (table_database, table_schema, table_name)

    where (upper(table_schema) = upper('dbt_nobodozie'))

    order by "column_index"
2022-01-06 14:08:40.570610 (ThreadPoolExecutor-1_0): 14:08:40  SQL status: SELECT in 0.06 seconds
2022-01-06 14:08:40.574446 (ThreadPoolExecutor-1_0): 14:08:40  Using redshift connection "dev.information_schema"
2022-01-06 14:08:40.574561 (ThreadPoolExecutor-1_0): 14:08:40  On dev.information_schema: select has_table_privilege(current_user, 'svv_table_info', 'SELECT') as can_select
2022-01-06 14:08:40.577254 (ThreadPoolExecutor-1_0): 14:08:40  SQL status: SELECT in 0.0 seconds
2022-01-06 14:08:40.581051 (ThreadPoolExecutor-1_0): 14:08:40  Using redshift connection "dev.information_schema"
2022-01-06 14:08:40.581146 (ThreadPoolExecutor-1_0): 14:08:40  On dev.information_schema: select
        "database" || '.' || "schema" || '.' || "table" as table_id,

        'Encoded'::text as "stats:encoded:label",
        encoded as "stats:encoded:value",
        'Indicates whether any column in the table has compression encoding defined.'::text as "stats:encoded:description",
        true as "stats:encoded:include",

        'Dist Style' as "stats:diststyle:label",
        diststyle as "stats:diststyle:value",
        'Distribution style or distribution key column, if key distribution is defined.'::text as "stats:diststyle:description",
        true as "stats:diststyle:include",

        'Sort Key 1' as "stats:sortkey1:label",
        -- handle 0xFF byte in response for interleaved sort styles
        case
            when sortkey1 like 'INTERLEAVED%' then 'INTERLEAVED'::text
            else sortkey1
        end as "stats:sortkey1:value",
        'First column in the sort key.'::text as "stats:sortkey1:description",
        (sortkey1 is not null) as "stats:sortkey1:include",

        'Max Varchar' as "stats:max_varchar:label",
        max_varchar as "stats:max_varchar:value",
        'Size of the largest column that uses a VARCHAR data type.'::text as "stats:max_varchar:description",
        true as "stats:max_varchar:include",

        -- exclude this, as the data is strangely returned with null-byte characters
        'Sort Key 1 Encoding' as "stats:sortkey1_enc:label",
        sortkey1_enc as "stats:sortkey1_enc:value",
        'Compression encoding of the first column in the sort key.' as "stats:sortkey1_enc:description",
        false as "stats:sortkey1_enc:include",

        '# Sort Keys' as "stats:sortkey_num:label",
        sortkey_num as "stats:sortkey_num:value",
        'Number of columns defined as sort keys.' as "stats:sortkey_num:description",
        (sortkey_num > 0) as "stats:sortkey_num:include",

        'Approximate Size' as "stats:size:label",
        size * 1000000 as "stats:size:value",
        'Approximate size of the table, calculated from a count of 1MB blocks'::text as "stats:size:description",
        true as "stats:size:include",

        'Disk Utilization' as "stats:pct_used:label",
        pct_used / 100.0 as "stats:pct_used:value",
        'Percent of available space that is used by the table.'::text as "stats:pct_used:description",
        true as "stats:pct_used:include",

        'Unsorted %' as "stats:unsorted:label",
        unsorted / 100.0 as "stats:unsorted:value",
        'Percent of unsorted rows in the table.'::text as "stats:unsorted:description",
        (unsorted is not null) as "stats:unsorted:include",

        'Stats Off' as "stats:stats_off:label",
        stats_off as "stats:stats_off:value",
        'Number that indicates how stale the table statistics are; 0 is current, 100 is out of date.'::text as "stats:stats_off:description",
        true as "stats:stats_off:include",

        'Approximate Row Count' as "stats:rows:label",
        tbl_rows as "stats:rows:value",
        'Approximate number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed.'::text as "stats:rows:description",
        true as "stats:rows:include",

        'Sort Key Skew' as "stats:skew_sortkey1:label",
        skew_sortkey1 as "stats:skew_sortkey1:value",
        'Ratio of the size of the largest non-sort key column to the size of the first column of the sort key.'::text as "stats:skew_sortkey1:description",
        (skew_sortkey1 is not null) as "stats:skew_sortkey1:include",

        'Skew Rows' as "stats:skew_rows:label",
        skew_rows as "stats:skew_rows:value",
        'Ratio of the number of rows in the slice with the most rows to the number of rows in the slice with the fewest rows.'::text as "stats:skew_rows:description",
        (skew_rows is not null) as "stats:skew_rows:include"

    from svv_table_info
    where (upper(schema) = upper('dbt_nobodozie'))
2022-01-06 14:08:41.072551 (Thread-32): handling poll request
2022-01-06 14:08:41.072918 (Thread-32): 14:08:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb85f6700>]}
2022-01-06 14:08:41.074295 (Thread-32): sending response (<Response 43713 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:08:42.519789 (Thread-33): handling poll request
2022-01-06 14:08:42.520139 (Thread-33): 14:08:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb85f68b0>]}
2022-01-06 14:08:42.520610 (Thread-33): sending response (<Response 296 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:08:43.897904 (ThreadPoolExecutor-1_0): 14:08:43  SQL status: SELECT in 3.32 seconds
2022-01-06 14:08:43.907055 (ThreadPoolExecutor-1_0): 14:08:43  On dev.information_schema: ROLLBACK
2022-01-06 14:08:43.909307 (ThreadPoolExecutor-1_0): 14:08:43  On dev.information_schema: Close
2022-01-06 14:08:43.929920 (Thread-34): handling poll request
2022-01-06 14:08:43.930215 (Thread-34): 14:08:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb85f6d00>]}
2022-01-06 14:08:43.930696 (Thread-34): sending response (<Response 1163 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:08:43.966087 (MainThread): 14:08:43  Catalog written to /usr/src/develop/user-52374/environment-57794/repository-46678/target/catalog.json
2022-01-06 14:08:45.297770 (Thread-35): handling poll request
2022-01-06 14:08:45.298137 (Thread-35): 14:08:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb86a7910>]}
2022-01-06 14:08:45.298851 (Thread-35): sending response (<Response 5346 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:08:45.958940 (Thread-36): handling status request
2022-01-06 14:08:45.959559 (Thread-36): 14:08:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb860e100>]}
2022-01-06 14:08:45.960057 (Thread-37): handling status request
2022-01-06 14:08:45.962575 (Thread-37): 14:08:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb860ea00>]}
2022-01-06 14:08:45.986051 (Thread-36): sending response (<Response 1241 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:08:45.986452 (Thread-37): sending response (<Response 1241 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:08:46.018314 (Thread-38): handling status request
2022-01-06 14:08:46.018596 (Thread-38): 14:08:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb860e280>]}
2022-01-06 14:08:46.018972 (Thread-38): sending response (<Response 1241 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:25:04.380519 (Thread-39): 14:25:04  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-01-06 14:25:04.381862 (Thread-39): 14:25:04  Partial parsing: added file: my_new_project://models/stg_customers.sql
2022-01-06 14:25:04.393273 (Thread-39): 14:25:04  1699: static parser successfully parsed stg_customers.sql
2022-01-06 14:25:04.466532 (Thread-39): 14:25:04  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb855de20>]}
2022-01-06 14:25:04.971976 (Thread-40): handling status request
2022-01-06 14:25:04.972438 (Thread-40): 14:25:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8612a30>]}
2022-01-06 14:25:04.972957 (Thread-40): sending response (<Response 1550 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:25:05.045057 (Thread-41): handling status request
2022-01-06 14:25:05.045445 (Thread-41): 14:25:05  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb85359a0>]}
2022-01-06 14:25:05.045937 (Thread-41): sending response (<Response 1550 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:26:15.862281 (Thread-42): handling status request
2022-01-06 14:26:15.863663 (Thread-42): 14:26:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8535a60>]}
2022-01-06 14:26:15.864130 (Thread-42): sending response (<Response 1550 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:26:16.305254 (Thread-43): handling run_sql request
2022-01-06 14:26:16.305674 (Thread-43): 14:26:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8535220>]}
2022-01-06 14:26:18.405311 (Thread-43): sending response (<Response 138 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:26:18.431130 (MainThread): 14:26:18  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '49716b01-59dd-49cd-a94f-81af900c41a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f73d9aaf4c0>]}
2022-01-06 14:26:18.431648 (MainThread): 14:26:18  Found 4 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:26:18.432227 (Thread-1): 14:26:18  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:26:18.432357 (Thread-1): 14:26:18  Began compiling node rpc.my_new_project.request
2022-01-06 14:26:18.432447 (Thread-1): 14:26:18  Compiling rpc.my_new_project.request
2022-01-06 14:26:18.433592 (Thread-1): 14:26:18  finished collecting timing info
2022-01-06 14:26:18.433715 (Thread-1): 14:26:18  Began executing node rpc.my_new_project.request
2022-01-06 14:26:18.433812 (Thread-1): 14:26:18  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:26:18.433891 (Thread-1): 14:26:18  On rpc.my_new_project.request: with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

)
select * from customers
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:26:18.433972 (Thread-1): 14:26:18  Opening a new connection, currently in state init
2022-01-06 14:26:18.434055 (Thread-1): 14:26:18  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:26:18.606758 (Thread-1): 14:26:18  SQL status: SELECT in 0.17 seconds
2022-01-06 14:26:18.608682 (Thread-1): 14:26:18  finished collecting timing info
2022-01-06 14:26:18.608834 (Thread-1): 14:26:18  On rpc.my_new_project.request: Close
2022-01-06 14:26:18.756528 (Thread-44): handling poll request
2022-01-06 14:26:18.756951 (Thread-44): 14:26:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8539e50>]}
2022-01-06 14:26:18.758302 (Thread-44): sending response (<Response 10140 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:27:00.217999 (Thread-45): 14:27:00  Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
2022-01-06 14:27:00.218315 (Thread-45): 14:27:00  Partial parsing: added file: my_new_project://models/stg_orders.sql
2022-01-06 14:27:00.222647 (Thread-45): 14:27:00  1699: static parser successfully parsed stg_orders.sql
2022-01-06 14:27:00.264448 (Thread-45): 14:27:00  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb80a1ca0>]}
2022-01-06 14:27:00.799471 (Thread-46): handling status request
2022-01-06 14:27:00.799831 (Thread-46): 14:27:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb808aa60>]}
2022-01-06 14:27:00.800366 (Thread-46): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:27:00.828613 (Thread-47): handling status request
2022-01-06 14:27:00.828904 (Thread-47): 14:27:00  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb808a490>]}
2022-01-06 14:27:00.829349 (Thread-47): sending response (<Response 1544 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:27:45.472646 (Thread-48): handling status request
2022-01-06 14:27:45.473018 (Thread-48): 14:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb85f67f0>]}
2022-01-06 14:27:45.473532 (Thread-48): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:27:45.530679 (Thread-49): handling status request
2022-01-06 14:27:45.530960 (Thread-49): 14:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb808a670>]}
2022-01-06 14:27:45.531372 (Thread-49): sending response (<Response 1544 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:27:45.821883 (Thread-50): handling run_sql request
2022-01-06 14:27:45.822205 (Thread-50): 14:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb808a430>]}
2022-01-06 14:27:45.844831 (Thread-51): handling run_sql request
2022-01-06 14:27:45.845531 (Thread-51): 14:27:45  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb85438b0>]}
2022-01-06 14:27:47.899314 (Thread-50): sending response (<Response 138 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:27:47.923434 (Thread-51): sending response (<Response 138 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:27:47.923262 (MainThread): 14:27:47  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a081489e-a681-48b6-882c-ba9bd64d4ba3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9634875790>]}
2022-01-06 14:27:47.923785 (MainThread): 14:27:47  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:27:47.924360 (Thread-1): 14:27:47  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:27:47.924484 (Thread-1): 14:27:47  Began compiling node rpc.my_new_project.request
2022-01-06 14:27:47.924574 (Thread-1): 14:27:47  Compiling rpc.my_new_project.request
2022-01-06 14:27:47.925747 (Thread-1): 14:27:47  finished collecting timing info
2022-01-06 14:27:47.925872 (Thread-1): 14:27:47  Began executing node rpc.my_new_project.request
2022-01-06 14:27:47.925976 (Thread-1): 14:27:47  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:27:47.926058 (Thread-1): 14:27:47  On rpc.my_new_project.request: with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from dev.jaffle_shop.orders

)
select * from orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:27:47.926136 (Thread-1): 14:27:47  Opening a new connection, currently in state init
2022-01-06 14:27:47.926220 (Thread-1): 14:27:47  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:27:47.948106 (MainThread): 14:27:47  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '63b5c5f5-1b75-4484-aed7-7be18326b73a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12f309f820>]}
2022-01-06 14:27:47.948785 (MainThread): 14:27:47  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:27:47.949366 (Thread-1): 14:27:47  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:27:47.949519 (Thread-1): 14:27:47  Began compiling node rpc.my_new_project.request
2022-01-06 14:27:47.949619 (Thread-1): 14:27:47  Compiling rpc.my_new_project.request
2022-01-06 14:27:47.950738 (Thread-1): 14:27:47  finished collecting timing info
2022-01-06 14:27:47.950864 (Thread-1): 14:27:47  Began executing node rpc.my_new_project.request
2022-01-06 14:27:47.950964 (Thread-1): 14:27:47  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:27:47.951046 (Thread-1): 14:27:47  On rpc.my_new_project.request: with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from dev.jaffle_shop.orders

)
select * from orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:27:47.951122 (Thread-1): 14:27:47  Opening a new connection, currently in state init
2022-01-06 14:27:47.951204 (Thread-1): 14:27:47  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:27:48.159683 (Thread-1): 14:27:48  SQL status: SELECT in 0.23 seconds
2022-01-06 14:27:48.162275 (Thread-1): 14:27:48  finished collecting timing info
2022-01-06 14:27:48.162423 (Thread-1): 14:27:48  On rpc.my_new_project.request: Close
2022-01-06 14:27:48.162636 (Thread-1): 14:27:48  SQL status: SELECT in 0.21 seconds
2022-01-06 14:27:48.165279 (Thread-1): 14:27:48  finished collecting timing info
2022-01-06 14:27:48.165428 (Thread-1): 14:27:48  On rpc.my_new_project.request: Close
2022-01-06 14:27:48.240692 (Thread-52): handling poll request
2022-01-06 14:27:48.241662 (Thread-52): 14:27:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb80f56a0>]}
2022-01-06 14:27:48.242582 (Thread-52): sending response (<Response 5174 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:27:48.256600 (Thread-53): handling poll request
2022-01-06 14:27:48.256948 (Thread-53): 14:27:48  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb808aac0>]}
2022-01-06 14:27:48.257582 (Thread-53): sending response (<Response 5174 bytes [200 OK]>) to 10.0.40.39
2022-01-06 14:27:49.618632 (Thread-54): handling poll request
2022-01-06 14:27:49.619024 (Thread-54): 14:27:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb808ac40>]}
2022-01-06 14:27:49.620160 (Thread-54): sending response (<Response 7067 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:27:49.703208 (Thread-55): handling poll request
2022-01-06 14:27:49.703451 (Thread-55): 14:27:49  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb808ab50>]}
2022-01-06 14:27:49.704325 (Thread-55): sending response (<Response 7067 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:31:06.601343 (Thread-56): handling status request
2022-01-06 14:31:06.602790 (Thread-56): 14:31:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb80a1d90>]}
2022-01-06 14:31:06.603308 (Thread-56): sending response (<Response 1544 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:31:06.962276 (Thread-57): handling compile_sql request
2022-01-06 14:31:06.962649 (Thread-57): 14:31:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb809a400>]}
2022-01-06 14:31:09.024135 (Thread-57): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:31:09.051054 (MainThread): 14:31:09  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5ba18145-4c56-4f22-a659-a92a9fba1110', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6482876970>]}
2022-01-06 14:31:09.051555 (MainThread): 14:31:09  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:31:09.052113 (Thread-1): 14:31:09  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:31:09.052242 (Thread-1): 14:31:09  Began compiling node rpc.my_new_project.request
2022-01-06 14:31:09.052331 (Thread-1): 14:31:09  Compiling rpc.my_new_project.request
2022-01-06 14:31:09.054803 (Thread-1): 14:31:09  finished collecting timing info
2022-01-06 14:31:09.054926 (Thread-1): 14:31:09  Began executing node rpc.my_new_project.request
2022-01-06 14:31:09.055020 (Thread-1): 14:31:09  finished collecting timing info
2022-01-06 14:31:09.923670 (Thread-58): handling poll request
2022-01-06 14:31:09.924108 (Thread-58): 14:31:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8024820>]}
2022-01-06 14:31:09.925197 (Thread-58): sending response (<Response 8440 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:32:02.022239 (Thread-59): handling status request
2022-01-06 14:32:02.022591 (Thread-59): 14:32:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb80249a0>]}
2022-01-06 14:32:02.023100 (Thread-59): sending response (<Response 1544 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:32:02.184417 (Thread-60): handling status request
2022-01-06 14:32:02.184777 (Thread-60): 14:32:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8024dc0>]}
2022-01-06 14:32:02.185261 (Thread-60): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:32:02.365414 (Thread-61): handling cli_args request
2022-01-06 14:32:02.365782 (Thread-61): 14:32:02  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8024fd0>]}
2022-01-06 14:32:04.459650 (Thread-61): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:32:04.547590 (MainThread): 14:32:04  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:32:04.547965 (MainThread): 14:32:04  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:32:04.553572 (MainThread): 14:32:04  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b78f090a-48bd-4bcd-800b-82f3bb015fa5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ccbba6be0>]}
2022-01-06 14:32:04.580650 (MainThread): 14:32:04  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b78f090a-48bd-4bcd-800b-82f3bb015fa5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ccbc1ab80>]}
2022-01-06 14:32:04.580905 (MainThread): 14:32:04  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:32:04.582052 (MainThread): 14:32:04  
2022-01-06 14:32:04.582321 (MainThread): 14:32:04  Acquiring new redshift connection "master"
2022-01-06 14:32:04.583263 (ThreadPoolExecutor-0_0): 14:32:04  Acquiring new redshift connection "list_dev"
2022-01-06 14:32:04.593355 (ThreadPoolExecutor-0_0): 14:32:04  Using redshift connection "list_dev"
2022-01-06 14:32:04.593477 (ThreadPoolExecutor-0_0): 14:32:04  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:32:04.593565 (ThreadPoolExecutor-0_0): 14:32:04  Opening a new connection, currently in state init
2022-01-06 14:32:04.593650 (ThreadPoolExecutor-0_0): 14:32:04  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:04.613956 (ThreadPoolExecutor-0_0): 14:32:04  SQL status: SELECT in 0.02 seconds
2022-01-06 14:32:04.614989 (ThreadPoolExecutor-0_0): 14:32:04  On list_dev: Close
2022-01-06 14:32:04.616179 (ThreadPoolExecutor-1_0): 14:32:04  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:04.622669 (ThreadPoolExecutor-1_0): 14:32:04  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:04.622769 (ThreadPoolExecutor-1_0): 14:32:04  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:32:04.622849 (ThreadPoolExecutor-1_0): 14:32:04  Opening a new connection, currently in state closed
2022-01-06 14:32:04.622929 (ThreadPoolExecutor-1_0): 14:32:04  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:04.645528 (ThreadPoolExecutor-1_0): 14:32:04  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:04.645638 (ThreadPoolExecutor-1_0): 14:32:04  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:04.645713 (ThreadPoolExecutor-1_0): 14:32:04  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:32:04.656680 (ThreadPoolExecutor-1_0): 14:32:04  SQL status: SELECT in 0.01 seconds
2022-01-06 14:32:04.657707 (ThreadPoolExecutor-1_0): 14:32:04  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:32:04.659438 (ThreadPoolExecutor-1_0): 14:32:04  On list_dev_dbt_nobodozie: Close
2022-01-06 14:32:04.663174 (MainThread): 14:32:04  Using redshift connection "master"
2022-01-06 14:32:04.663284 (MainThread): 14:32:04  On master: BEGIN
2022-01-06 14:32:04.663363 (MainThread): 14:32:04  Opening a new connection, currently in state init
2022-01-06 14:32:04.663452 (MainThread): 14:32:04  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:04.686738 (MainThread): 14:32:04  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:04.686845 (MainThread): 14:32:04  Using redshift connection "master"
2022-01-06 14:32:04.686933 (MainThread): 14:32:04  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:32:04.715453 (MainThread): 14:32:04  SQL status: SELECT in 0.03 seconds
2022-01-06 14:32:04.716430 (MainThread): 14:32:04  On master: ROLLBACK
2022-01-06 14:32:04.718274 (MainThread): 14:32:04  Using redshift connection "master"
2022-01-06 14:32:04.718375 (MainThread): 14:32:04  On master: BEGIN
2022-01-06 14:32:04.721789 (MainThread): 14:32:04  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:04.721910 (MainThread): 14:32:04  On master: COMMIT
2022-01-06 14:32:04.721994 (MainThread): 14:32:04  Using redshift connection "master"
2022-01-06 14:32:04.722065 (MainThread): 14:32:04  On master: COMMIT
2022-01-06 14:32:04.723746 (MainThread): 14:32:04  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:32:04.723853 (MainThread): 14:32:04  On master: Close
2022-01-06 14:32:04.724242 (MainThread): 14:32:04  Concurrency: 4 threads (target='default')
2022-01-06 14:32:04.724357 (MainThread): 14:32:04  
2022-01-06 14:32:04.726532 (Thread-1): 14:32:04  Began running node model.my_new_project.dim_customers
2022-01-06 14:32:04.726771 (Thread-1): 14:32:04  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:32:04.727001 (Thread-1): 14:32:04  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:04.727093 (Thread-1): 14:32:04  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:32:04.727191 (Thread-1): 14:32:04  Compiling model.my_new_project.dim_customers
2022-01-06 14:32:04.729206 (Thread-1): 14:32:04  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:32:04.729466 (Thread-2): 14:32:04  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:04.729700 (Thread-2): 14:32:04  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:32:04.729939 (Thread-2): 14:32:04  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:04.730025 (Thread-2): 14:32:04  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:04.730106 (Thread-2): 14:32:04  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:32:04.732067 (Thread-2): 14:32:04  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:04.743563 (Thread-1): 14:32:04  finished collecting timing info
2022-01-06 14:32:04.743709 (Thread-1): 14:32:04  Began executing node model.my_new_project.dim_customers
2022-01-06 14:32:04.748963 (Thread-2): 14:32:04  finished collecting timing info
2022-01-06 14:32:04.749149 (Thread-2): 14:32:04  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:04.807346 (Thread-1): 14:32:04  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:32:04.810515 (Thread-2): 14:32:04  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:04.824757 (Thread-2): 14:32:04  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:04.824913 (Thread-2): 14:32:04  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:04.825040 (Thread-2): 14:32:04  Opening a new connection, currently in state init
2022-01-06 14:32:04.825161 (Thread-2): 14:32:04  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:04.825491 (Thread-1): 14:32:04  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:04.825590 (Thread-1): 14:32:04  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:04.825668 (Thread-1): 14:32:04  Opening a new connection, currently in state closed
2022-01-06 14:32:04.825743 (Thread-1): 14:32:04  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:04.852489 (Thread-1): 14:32:04  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:32:04.852605 (Thread-1): 14:32:04  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:04.852684 (Thread-1): 14:32:04  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:32:04.852843 (Thread-2): 14:32:04  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:32:04.852957 (Thread-2): 14:32:04  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:04.853035 (Thread-2): 14:32:04  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:32:04.940858 (Thread-2): 14:32:04  SQL status: SELECT in 0.09 seconds
2022-01-06 14:32:04.946554 (Thread-2): 14:32:04  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:04.946658 (Thread-2): 14:32:04  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:32:04.951832 (Thread-2): 14:32:04  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:32:04.953595 (Thread-2): 14:32:04  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:04.953693 (Thread-2): 14:32:04  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:32:04.956932 (Thread-2): 14:32:04  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:04.962231 (Thread-1): 14:32:04  SQL status: SELECT in 0.11 seconds
2022-01-06 14:32:04.964085 (Thread-1): 14:32:04  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:04.964182 (Thread-1): 14:32:04  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:32:04.969581 (Thread-1): 14:32:04  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:32:04.971242 (Thread-1): 14:32:04  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:04.971337 (Thread-1): 14:32:04  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:32:04.971451 (Thread-2): 14:32:04  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:04.971562 (Thread-2): 14:32:04  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:04.971638 (Thread-2): 14:32:04  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:04.974569 (Thread-1): 14:32:04  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:04.976645 (Thread-1): 14:32:04  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:04.976740 (Thread-1): 14:32:04  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:04.976812 (Thread-1): 14:32:04  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:04.989187 (Thread-62): handling poll request
2022-01-06 14:32:04.989585 (Thread-62): 14:32:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb803d1c0>]}
2022-01-06 14:32:04.991170 (Thread-62): sending response (<Response 38501 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:32:05.069345 (Thread-2): 14:32:05  SQL status: COMMIT in 0.1 seconds
2022-01-06 14:32:05.069567 (Thread-2): 14:32:05  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:05.069651 (Thread-2): 14:32:05  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:05.069899 (Thread-1): 14:32:05  SQL status: COMMIT in 0.09 seconds
2022-01-06 14:32:05.071777 (Thread-2): 14:32:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:05.075719 (Thread-2): 14:32:05  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:05.075815 (Thread-2): 14:32:05  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:32:05.080849 (Thread-2): 14:32:05  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:32:05.081505 (Thread-2): 14:32:05  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:05.081598 (Thread-2): 14:32:05  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:05.081672 (Thread-2): 14:32:05  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:05.112276 (Thread-2): 14:32:05  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:05.112384 (Thread-2): 14:32:05  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:05.112456 (Thread-2): 14:32:05  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:05.114532 (Thread-2): 14:32:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:05.114910 (Thread-2): 14:32:05  finished collecting timing info
2022-01-06 14:32:05.115037 (Thread-2): 14:32:05  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:32:05.115227 (Thread-1): 14:32:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:05.115334 (Thread-1): 14:32:05  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:05.117573 (Thread-1): 14:32:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:05.118682 (Thread-1): 14:32:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:05.118778 (Thread-1): 14:32:05  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:32:05.118952 (Thread-2): 14:32:05  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:32:05.119405 (Thread-2): 14:32:05  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b78f090a-48bd-4bcd-800b-82f3bb015fa5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cc82e1820>]}
2022-01-06 14:32:05.119718 (Thread-2): 14:32:05  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.39s]
2022-01-06 14:32:05.119830 (Thread-2): 14:32:05  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:05.120407 (Thread-4): 14:32:05  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:05.120644 (Thread-4): 14:32:05  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:32:05.120893 (Thread-4): 14:32:05  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.120981 (Thread-4): 14:32:05  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:05.121065 (Thread-4): 14:32:05  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:32:05.123077 (Thread-4): 14:32:05  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.124357 (Thread-1): 14:32:05  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 14:32:05.124979 (Thread-1): 14:32:05  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:05.125072 (Thread-1): 14:32:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:05.125145 (Thread-1): 14:32:05  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:05.135448 (Thread-4): 14:32:05  finished collecting timing info
2022-01-06 14:32:05.135587 (Thread-4): 14:32:05  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:05.151463 (Thread-4): 14:32:05  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.156629 (Thread-1): 14:32:05  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:05.156746 (Thread-1): 14:32:05  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:05.156821 (Thread-1): 14:32:05  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:05.158830 (Thread-1): 14:32:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:05.159195 (Thread-1): 14:32:05  finished collecting timing info
2022-01-06 14:32:05.159317 (Thread-1): 14:32:05  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:32:05.161023 (Thread-1): 14:32:05  On model.my_new_project.dim_customers: Close
2022-01-06 14:32:05.161475 (Thread-1): 14:32:05  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b78f090a-48bd-4bcd-800b-82f3bb015fa5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cc82b9fa0>]}
2022-01-06 14:32:05.161774 (Thread-1): 14:32:05  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.43s]
2022-01-06 14:32:05.161914 (Thread-1): 14:32:05  Finished running node model.my_new_project.dim_customers
2022-01-06 14:32:05.164065 (Thread-4): 14:32:05  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.164174 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:05.164258 (Thread-4): 14:32:05  Opening a new connection, currently in state init
2022-01-06 14:32:05.164339 (Thread-4): 14:32:05  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:05.186940 (Thread-4): 14:32:05  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:05.187051 (Thread-4): 14:32:05  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.187128 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:32:05.191974 (Thread-4): 14:32:05  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:32:05.193838 (Thread-4): 14:32:05  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.193933 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:32:05.196005 (Thread-4): 14:32:05  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:05.196912 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:05.197006 (Thread-4): 14:32:05  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.197079 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:05.225984 (Thread-4): 14:32:05  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:05.226201 (Thread-4): 14:32:05  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.226285 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:05.228878 (Thread-4): 14:32:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:05.230144 (Thread-4): 14:32:05  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.230240 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:32:05.232177 (Thread-4): 14:32:05  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:32:05.232845 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:05.232938 (Thread-4): 14:32:05  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.233011 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:05.258375 (Thread-4): 14:32:05  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:05.258488 (Thread-4): 14:32:05  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:05.258574 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:05.260592 (Thread-4): 14:32:05  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:05.260951 (Thread-4): 14:32:05  finished collecting timing info
2022-01-06 14:32:05.261071 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:32:05.262776 (Thread-4): 14:32:05  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:32:05.263153 (Thread-4): 14:32:05  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b78f090a-48bd-4bcd-800b-82f3bb015fa5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cc82aec40>]}
2022-01-06 14:32:05.263502 (Thread-4): 14:32:05  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.14s]
2022-01-06 14:32:05.263663 (Thread-4): 14:32:05  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:05.264928 (MainThread): 14:32:05  Acquiring new redshift connection "master"
2022-01-06 14:32:05.265073 (MainThread): 14:32:05  Using redshift connection "master"
2022-01-06 14:32:05.265151 (MainThread): 14:32:05  On master: BEGIN
2022-01-06 14:32:05.265259 (MainThread): 14:32:05  Opening a new connection, currently in state closed
2022-01-06 14:32:05.265342 (MainThread): 14:32:05  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:05.289073 (MainThread): 14:32:05  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:05.289188 (MainThread): 14:32:05  On master: COMMIT
2022-01-06 14:32:05.289285 (MainThread): 14:32:05  Using redshift connection "master"
2022-01-06 14:32:05.289356 (MainThread): 14:32:05  On master: COMMIT
2022-01-06 14:32:05.291037 (MainThread): 14:32:05  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:32:05.291139 (MainThread): 14:32:05  On master: Close
2022-01-06 14:32:05.291605 (MainThread): 14:32:05  
2022-01-06 14:32:05.291718 (MainThread): 14:32:05  Finished running 2 table models, 1 view model in 0.71s.
2022-01-06 14:32:05.291800 (MainThread): 14:32:05  Connection 'master' was properly closed.
2022-01-06 14:32:05.291895 (MainThread): 14:32:05  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:32:05.291959 (MainThread): 14:32:05  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:32:05.292019 (MainThread): 14:32:05  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:32:05.365730 (MainThread): 14:32:05  
2022-01-06 14:32:05.365890 (MainThread): 14:32:05  Completed successfully
2022-01-06 14:32:05.365986 (MainThread): 14:32:05  
2022-01-06 14:32:05.366072 (MainThread): 14:32:05  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:32:06.376356 (Thread-63): handling poll request
2022-01-06 14:32:06.376753 (Thread-63): 14:32:06  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff981da5b0>]}
2022-01-06 14:32:06.378778 (Thread-63): sending response (<Response 48689 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:32:07.017930 (Thread-64): handling status request
2022-01-06 14:32:07.018289 (Thread-64): 14:32:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff981da490>]}
2022-01-06 14:32:07.018819 (Thread-64): sending response (<Response 1544 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:32:07.067412 (Thread-65): handling status request
2022-01-06 14:32:07.067676 (Thread-65): 14:32:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff981da9a0>]}
2022-01-06 14:32:07.068092 (Thread-65): sending response (<Response 1544 bytes [200 OK]>) to 10.0.40.39
2022-01-06 14:32:13.930299 (Thread-66): handling status request
2022-01-06 14:32:13.930724 (Thread-66): 14:32:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff981cb550>]}
2022-01-06 14:32:13.956162 (Thread-66): sending response (<Response 1544 bytes [200 OK]>) to 10.0.5.191
2022-01-06 14:32:14.189197 (Thread-67): handling status request
2022-01-06 14:32:14.189570 (Thread-67): 14:32:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff981dacd0>]}
2022-01-06 14:32:14.190051 (Thread-67): sending response (<Response 1544 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:32:14.291153 (Thread-68): handling cli_args request
2022-01-06 14:32:14.291428 (Thread-68): 14:32:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff981f0190>]}
2022-01-06 14:32:16.412527 (Thread-68): sending response (<Response 138 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:32:16.490872 (MainThread): 14:32:16  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:32:16.491284 (MainThread): 14:32:16  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:32:16.497030 (MainThread): 14:32:16  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '89b90ef5-5a7b-4597-8c3e-6401a6831e24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a93b0c10>]}
2022-01-06 14:32:16.524455 (MainThread): 14:32:16  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '89b90ef5-5a7b-4597-8c3e-6401a6831e24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a9426c70>]}
2022-01-06 14:32:16.524718 (MainThread): 14:32:16  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:32:16.525863 (MainThread): 14:32:16  
2022-01-06 14:32:16.526156 (MainThread): 14:32:16  Acquiring new redshift connection "master"
2022-01-06 14:32:16.527207 (ThreadPoolExecutor-0_0): 14:32:16  Acquiring new redshift connection "list_dev"
2022-01-06 14:32:16.537629 (ThreadPoolExecutor-0_0): 14:32:16  Using redshift connection "list_dev"
2022-01-06 14:32:16.537732 (ThreadPoolExecutor-0_0): 14:32:16  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:32:16.537815 (ThreadPoolExecutor-0_0): 14:32:16  Opening a new connection, currently in state init
2022-01-06 14:32:16.537897 (ThreadPoolExecutor-0_0): 14:32:16  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:16.558147 (ThreadPoolExecutor-0_0): 14:32:16  SQL status: SELECT in 0.02 seconds
2022-01-06 14:32:16.559238 (ThreadPoolExecutor-0_0): 14:32:16  On list_dev: Close
2022-01-06 14:32:16.560595 (ThreadPoolExecutor-1_0): 14:32:16  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:16.567258 (ThreadPoolExecutor-1_0): 14:32:16  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:16.567354 (ThreadPoolExecutor-1_0): 14:32:16  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:32:16.567433 (ThreadPoolExecutor-1_0): 14:32:16  Opening a new connection, currently in state closed
2022-01-06 14:32:16.567510 (ThreadPoolExecutor-1_0): 14:32:16  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:16.589647 (ThreadPoolExecutor-1_0): 14:32:16  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:16.589805 (ThreadPoolExecutor-1_0): 14:32:16  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:16.589925 (ThreadPoolExecutor-1_0): 14:32:16  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:32:16.601244 (ThreadPoolExecutor-1_0): 14:32:16  SQL status: SELECT in 0.01 seconds
2022-01-06 14:32:16.602944 (ThreadPoolExecutor-1_0): 14:32:16  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:32:16.605035 (ThreadPoolExecutor-1_0): 14:32:16  On list_dev_dbt_nobodozie: Close
2022-01-06 14:32:16.609166 (MainThread): 14:32:16  Using redshift connection "master"
2022-01-06 14:32:16.609311 (MainThread): 14:32:16  On master: BEGIN
2022-01-06 14:32:16.609395 (MainThread): 14:32:16  Opening a new connection, currently in state init
2022-01-06 14:32:16.609472 (MainThread): 14:32:16  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:16.631307 (MainThread): 14:32:16  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:16.631420 (MainThread): 14:32:16  Using redshift connection "master"
2022-01-06 14:32:16.631498 (MainThread): 14:32:16  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:32:16.659795 (MainThread): 14:32:16  SQL status: SELECT in 0.03 seconds
2022-01-06 14:32:16.660862 (MainThread): 14:32:16  On master: ROLLBACK
2022-01-06 14:32:16.662749 (MainThread): 14:32:16  Using redshift connection "master"
2022-01-06 14:32:16.662849 (MainThread): 14:32:16  On master: BEGIN
2022-01-06 14:32:16.666642 (MainThread): 14:32:16  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:16.666745 (MainThread): 14:32:16  On master: COMMIT
2022-01-06 14:32:16.666816 (MainThread): 14:32:16  Using redshift connection "master"
2022-01-06 14:32:16.666884 (MainThread): 14:32:16  On master: COMMIT
2022-01-06 14:32:16.668657 (MainThread): 14:32:16  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:32:16.668762 (MainThread): 14:32:16  On master: Close
2022-01-06 14:32:16.669161 (MainThread): 14:32:16  Concurrency: 4 threads (target='default')
2022-01-06 14:32:16.669307 (MainThread): 14:32:16  
2022-01-06 14:32:16.671822 (Thread-1): 14:32:16  Began running node model.my_new_project.dim_customers
2022-01-06 14:32:16.672180 (Thread-1): 14:32:16  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:32:16.672453 (Thread-1): 14:32:16  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:16.672548 (Thread-1): 14:32:16  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:32:16.672666 (Thread-1): 14:32:16  Compiling model.my_new_project.dim_customers
2022-01-06 14:32:16.674940 (Thread-1): 14:32:16  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:32:16.675175 (Thread-2): 14:32:16  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:16.675400 (Thread-2): 14:32:16  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:32:16.675649 (Thread-2): 14:32:16  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.675734 (Thread-2): 14:32:16  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:16.675814 (Thread-2): 14:32:16  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:32:16.677872 (Thread-2): 14:32:16  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.690489 (Thread-1): 14:32:16  finished collecting timing info
2022-01-06 14:32:16.690627 (Thread-1): 14:32:16  Began executing node model.my_new_project.dim_customers
2022-01-06 14:32:16.695619 (Thread-2): 14:32:16  finished collecting timing info
2022-01-06 14:32:16.695747 (Thread-2): 14:32:16  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:16.747320 (Thread-1): 14:32:16  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:32:16.748218 (Thread-2): 14:32:16  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.761840 (Thread-1): 14:32:16  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:16.761959 (Thread-1): 14:32:16  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:16.762044 (Thread-1): 14:32:16  Opening a new connection, currently in state closed
2022-01-06 14:32:16.762126 (Thread-1): 14:32:16  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:16.762376 (Thread-2): 14:32:16  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.762478 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:16.762556 (Thread-2): 14:32:16  Opening a new connection, currently in state init
2022-01-06 14:32:16.762630 (Thread-2): 14:32:16  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:16.786592 (Thread-1): 14:32:16  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:16.786709 (Thread-1): 14:32:16  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:16.786787 (Thread-1): 14:32:16  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:32:16.788896 (Thread-2): 14:32:16  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:32:16.789012 (Thread-2): 14:32:16  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.789091 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:32:16.868220 (Thread-2): 14:32:16  SQL status: SELECT in 0.08 seconds
2022-01-06 14:32:16.874493 (Thread-2): 14:32:16  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.874608 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:32:16.878890 (Thread-2): 14:32:16  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:16.880629 (Thread-2): 14:32:16  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.880732 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:32:16.885816 (Thread-2): 14:32:16  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:16.896238 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:16.896352 (Thread-2): 14:32:16  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.896429 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:16.900778 (Thread-1): 14:32:16  SQL status: SELECT in 0.11 seconds
2022-01-06 14:32:16.903693 (Thread-1): 14:32:16  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:16.903792 (Thread-1): 14:32:16  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:32:16.907207 (Thread-1): 14:32:16  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:16.908935 (Thread-1): 14:32:16  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:16.909033 (Thread-1): 14:32:16  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:32:16.912335 (Thread-1): 14:32:16  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:16.913696 (Thread-1): 14:32:16  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:16.913796 (Thread-1): 14:32:16  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:16.913871 (Thread-1): 14:32:16  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:16.952978 (Thread-69): handling poll request
2022-01-06 14:32:16.953406 (Thread-69): 14:32:16  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff98193ee0>]}
2022-01-06 14:32:16.956855 (Thread-69): sending response (<Response 38499 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:32:16.968427 (Thread-2): 14:32:16  SQL status: COMMIT in 0.07 seconds
2022-01-06 14:32:16.968662 (Thread-2): 14:32:16  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.968749 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:16.969122 (Thread-1): 14:32:16  SQL status: COMMIT in 0.06 seconds
2022-01-06 14:32:16.970901 (Thread-2): 14:32:16  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:16.974810 (Thread-2): 14:32:16  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.974908 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:32:16.979784 (Thread-2): 14:32:16  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:32:16.980725 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:16.980856 (Thread-2): 14:32:16  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:16.980967 (Thread-2): 14:32:16  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:17.010406 (Thread-2): 14:32:17  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:17.010531 (Thread-2): 14:32:17  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:17.010610 (Thread-2): 14:32:17  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:17.013064 (Thread-2): 14:32:17  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:17.013516 (Thread-2): 14:32:17  finished collecting timing info
2022-01-06 14:32:17.013671 (Thread-2): 14:32:17  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:32:17.013949 (Thread-1): 14:32:17  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:17.014063 (Thread-1): 14:32:17  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:17.016261 (Thread-1): 14:32:17  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:17.017503 (Thread-1): 14:32:17  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:17.017603 (Thread-1): 14:32:17  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:32:17.017894 (Thread-2): 14:32:17  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:32:17.018464 (Thread-2): 14:32:17  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89b90ef5-5a7b-4597-8c3e-6401a6831e24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a82f4be0>]}
2022-01-06 14:32:17.018821 (Thread-2): 14:32:17  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.34s]
2022-01-06 14:32:17.018962 (Thread-2): 14:32:17  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:17.019674 (Thread-4): 14:32:17  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:17.019922 (Thread-4): 14:32:17  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:32:17.020176 (Thread-4): 14:32:17  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.020288 (Thread-4): 14:32:17  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:17.020387 (Thread-4): 14:32:17  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:32:17.022580 (Thread-4): 14:32:17  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.022829 (Thread-1): 14:32:17  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 14:32:17.023517 (Thread-1): 14:32:17  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:17.023613 (Thread-1): 14:32:17  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:17.023689 (Thread-1): 14:32:17  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:17.037027 (Thread-4): 14:32:17  finished collecting timing info
2022-01-06 14:32:17.037170 (Thread-4): 14:32:17  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:17.053178 (Thread-4): 14:32:17  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.058081 (Thread-1): 14:32:17  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:17.058211 (Thread-1): 14:32:17  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:17.058291 (Thread-1): 14:32:17  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:17.060405 (Thread-1): 14:32:17  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:17.060797 (Thread-1): 14:32:17  finished collecting timing info
2022-01-06 14:32:17.060923 (Thread-1): 14:32:17  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:32:17.062719 (Thread-1): 14:32:17  On model.my_new_project.dim_customers: Close
2022-01-06 14:32:17.063180 (Thread-1): 14:32:17  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89b90ef5-5a7b-4597-8c3e-6401a6831e24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a833a730>]}
2022-01-06 14:32:17.063525 (Thread-1): 14:32:17  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.39s]
2022-01-06 14:32:17.063693 (Thread-1): 14:32:17  Finished running node model.my_new_project.dim_customers
2022-01-06 14:32:17.064780 (Thread-4): 14:32:17  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.064897 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:17.064982 (Thread-4): 14:32:17  Opening a new connection, currently in state init
2022-01-06 14:32:17.065064 (Thread-4): 14:32:17  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:17.594466 (Thread-4): 14:32:17  SQL status: BEGIN in 0.53 seconds
2022-01-06 14:32:17.594652 (Thread-4): 14:32:17  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.594746 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:32:17.599576 (Thread-4): 14:32:17  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:32:17.602087 (Thread-4): 14:32:17  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.602204 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:32:17.604411 (Thread-4): 14:32:17  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:17.605550 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:17.605653 (Thread-4): 14:32:17  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.605729 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:17.635650 (Thread-4): 14:32:17  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:17.635999 (Thread-4): 14:32:17  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.636092 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:17.638334 (Thread-4): 14:32:17  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:17.639917 (Thread-4): 14:32:17  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.640026 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:32:17.641986 (Thread-4): 14:32:17  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:32:17.642802 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:17.642900 (Thread-4): 14:32:17  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.642977 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:17.668719 (Thread-4): 14:32:17  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:17.668868 (Thread-4): 14:32:17  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:17.668949 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:17.671039 (Thread-4): 14:32:17  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:17.671557 (Thread-4): 14:32:17  finished collecting timing info
2022-01-06 14:32:17.671701 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:32:17.673576 (Thread-4): 14:32:17  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:32:17.674083 (Thread-4): 14:32:17  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89b90ef5-5a7b-4597-8c3e-6401a6831e24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a82c8e20>]}
2022-01-06 14:32:17.674426 (Thread-4): 14:32:17  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.65s]
2022-01-06 14:32:17.674540 (Thread-4): 14:32:17  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:17.676038 (MainThread): 14:32:17  Acquiring new redshift connection "master"
2022-01-06 14:32:17.676189 (MainThread): 14:32:17  Using redshift connection "master"
2022-01-06 14:32:17.676269 (MainThread): 14:32:17  On master: BEGIN
2022-01-06 14:32:17.676348 (MainThread): 14:32:17  Opening a new connection, currently in state closed
2022-01-06 14:32:17.676428 (MainThread): 14:32:17  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:17.701102 (MainThread): 14:32:17  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:17.701280 (MainThread): 14:32:17  On master: COMMIT
2022-01-06 14:32:17.701371 (MainThread): 14:32:17  Using redshift connection "master"
2022-01-06 14:32:17.701457 (MainThread): 14:32:17  On master: COMMIT
2022-01-06 14:32:17.703336 (MainThread): 14:32:17  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:32:17.703461 (MainThread): 14:32:17  On master: Close
2022-01-06 14:32:17.703944 (MainThread): 14:32:17  
2022-01-06 14:32:17.704059 (MainThread): 14:32:17  Finished running 2 table models, 1 view model in 1.18s.
2022-01-06 14:32:17.704141 (MainThread): 14:32:17  Connection 'master' was properly closed.
2022-01-06 14:32:17.704216 (MainThread): 14:32:17  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:32:17.704279 (MainThread): 14:32:17  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:32:17.704339 (MainThread): 14:32:17  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:32:17.771881 (MainThread): 14:32:17  
2022-01-06 14:32:17.772138 (MainThread): 14:32:17  Completed successfully
2022-01-06 14:32:17.772296 (MainThread): 14:32:17  
2022-01-06 14:32:17.772438 (MainThread): 14:32:17  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:32:18.381335 (Thread-70): handling poll request
2022-01-06 14:32:18.381678 (Thread-70): 14:32:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8024a30>]}
2022-01-06 14:32:18.383529 (Thread-70): sending response (<Response 48693 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:32:18.996813 (Thread-71): handling status request
2022-01-06 14:32:18.997193 (Thread-71): 14:32:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8040f70>]}
2022-01-06 14:32:18.997736 (Thread-71): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:32:19.031127 (Thread-72): handling status request
2022-01-06 14:32:19.034493 (Thread-72): 14:32:19  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8040a90>]}
2022-01-06 14:32:19.034962 (Thread-72): sending response (<Response 1544 bytes [200 OK]>) to 10.0.21.176
2022-01-06 14:32:25.551964 (Thread-73): handling status request
2022-01-06 14:32:25.552351 (Thread-73): 14:32:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8040190>]}
2022-01-06 14:32:25.552882 (Thread-73): sending response (<Response 1544 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:32:25.743760 (Thread-74): handling status request
2022-01-06 14:32:25.744051 (Thread-74): 14:32:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb80403d0>]}
2022-01-06 14:32:25.744506 (Thread-74): sending response (<Response 1544 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:32:25.917242 (Thread-75): handling cli_args request
2022-01-06 14:32:25.917595 (Thread-75): 14:32:25  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8051100>]}
2022-01-06 14:32:27.945080 (Thread-75): sending response (<Response 138 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:32:28.019872 (MainThread): 14:32:28  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:32:28.020251 (MainThread): 14:32:28  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:32:28.025784 (MainThread): 14:32:28  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a4ad54c5-1880-4281-835a-3b6c72461a7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf44f50d60>]}
2022-01-06 14:32:28.050065 (MainThread): 14:32:28  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a4ad54c5-1880-4281-835a-3b6c72461a7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf44fc7dc0>]}
2022-01-06 14:32:28.050299 (MainThread): 14:32:28  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:32:28.051347 (MainThread): 14:32:28  
2022-01-06 14:32:28.051612 (MainThread): 14:32:28  Acquiring new redshift connection "master"
2022-01-06 14:32:28.052526 (ThreadPoolExecutor-0_0): 14:32:28  Acquiring new redshift connection "list_dev"
2022-01-06 14:32:28.062207 (ThreadPoolExecutor-0_0): 14:32:28  Using redshift connection "list_dev"
2022-01-06 14:32:28.062310 (ThreadPoolExecutor-0_0): 14:32:28  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:32:28.062392 (ThreadPoolExecutor-0_0): 14:32:28  Opening a new connection, currently in state init
2022-01-06 14:32:28.062473 (ThreadPoolExecutor-0_0): 14:32:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:28.083825 (ThreadPoolExecutor-0_0): 14:32:28  SQL status: SELECT in 0.02 seconds
2022-01-06 14:32:28.084847 (ThreadPoolExecutor-0_0): 14:32:28  On list_dev: Close
2022-01-06 14:32:28.085992 (ThreadPoolExecutor-1_0): 14:32:28  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:28.092475 (ThreadPoolExecutor-1_0): 14:32:28  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:28.092575 (ThreadPoolExecutor-1_0): 14:32:28  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:32:28.092653 (ThreadPoolExecutor-1_0): 14:32:28  Opening a new connection, currently in state closed
2022-01-06 14:32:28.092725 (ThreadPoolExecutor-1_0): 14:32:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:28.115256 (ThreadPoolExecutor-1_0): 14:32:28  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:28.115366 (ThreadPoolExecutor-1_0): 14:32:28  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:32:28.115441 (ThreadPoolExecutor-1_0): 14:32:28  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:32:28.126737 (ThreadPoolExecutor-1_0): 14:32:28  SQL status: SELECT in 0.01 seconds
2022-01-06 14:32:28.127729 (ThreadPoolExecutor-1_0): 14:32:28  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:32:28.129552 (ThreadPoolExecutor-1_0): 14:32:28  On list_dev_dbt_nobodozie: Close
2022-01-06 14:32:28.133109 (MainThread): 14:32:28  Using redshift connection "master"
2022-01-06 14:32:28.133251 (MainThread): 14:32:28  On master: BEGIN
2022-01-06 14:32:28.133334 (MainThread): 14:32:28  Opening a new connection, currently in state init
2022-01-06 14:32:28.133409 (MainThread): 14:32:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:28.224963 (MainThread): 14:32:28  SQL status: BEGIN in 0.09 seconds
2022-01-06 14:32:28.225074 (MainThread): 14:32:28  Using redshift connection "master"
2022-01-06 14:32:28.225150 (MainThread): 14:32:28  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:32:28.253978 (MainThread): 14:32:28  SQL status: SELECT in 0.03 seconds
2022-01-06 14:32:28.254976 (MainThread): 14:32:28  On master: ROLLBACK
2022-01-06 14:32:28.257022 (MainThread): 14:32:28  Using redshift connection "master"
2022-01-06 14:32:28.257132 (MainThread): 14:32:28  On master: BEGIN
2022-01-06 14:32:28.260739 (MainThread): 14:32:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:28.260857 (MainThread): 14:32:28  On master: COMMIT
2022-01-06 14:32:28.260931 (MainThread): 14:32:28  Using redshift connection "master"
2022-01-06 14:32:28.261000 (MainThread): 14:32:28  On master: COMMIT
2022-01-06 14:32:28.262754 (MainThread): 14:32:28  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:32:28.262878 (MainThread): 14:32:28  On master: Close
2022-01-06 14:32:28.263373 (MainThread): 14:32:28  Concurrency: 4 threads (target='default')
2022-01-06 14:32:28.263497 (MainThread): 14:32:28  
2022-01-06 14:32:28.265857 (Thread-1): 14:32:28  Began running node model.my_new_project.dim_customers
2022-01-06 14:32:28.266108 (Thread-1): 14:32:28  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:32:28.266362 (Thread-1): 14:32:28  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.266456 (Thread-1): 14:32:28  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:32:28.266552 (Thread-1): 14:32:28  Compiling model.my_new_project.dim_customers
2022-01-06 14:32:28.268731 (Thread-1): 14:32:28  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:32:28.268961 (Thread-2): 14:32:28  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:28.269211 (Thread-2): 14:32:28  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:32:28.269474 (Thread-2): 14:32:28  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.269560 (Thread-2): 14:32:28  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:28.269642 (Thread-2): 14:32:28  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:32:28.271679 (Thread-2): 14:32:28  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.282940 (Thread-2): 14:32:28  finished collecting timing info
2022-01-06 14:32:28.283090 (Thread-2): 14:32:28  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:28.288306 (Thread-1): 14:32:28  finished collecting timing info
2022-01-06 14:32:28.288448 (Thread-1): 14:32:28  Began executing node model.my_new_project.dim_customers
2022-01-06 14:32:28.333846 (Thread-76): handling poll request
2022-01-06 14:32:28.331408 (Thread-2): 14:32:28  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.334419 (Thread-76): 14:32:28  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8040d60>]}
2022-01-06 14:32:28.333203 (Thread-1): 14:32:28  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:32:28.335937 (Thread-76): sending response (<Response 23716 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:32:28.345045 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.345152 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:28.345268 (Thread-1): 14:32:28  Opening a new connection, currently in state closed
2022-01-06 14:32:28.345350 (Thread-1): 14:32:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:28.345597 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.345697 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:28.345774 (Thread-2): 14:32:28  Opening a new connection, currently in state init
2022-01-06 14:32:28.345849 (Thread-2): 14:32:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:28.371992 (Thread-2): 14:32:28  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:32:28.372103 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.372180 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:32:28.372439 (Thread-1): 14:32:28  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:32:28.372549 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.372625 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:32:28.467929 (Thread-2): 14:32:28  SQL status: SELECT in 0.1 seconds
2022-01-06 14:32:28.473607 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.473712 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:32:28.482022 (Thread-2): 14:32:28  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:32:28.483906 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.484004 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:32:28.487005 (Thread-2): 14:32:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:28.497989 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:28.498113 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.498190 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:28.514722 (Thread-1): 14:32:28  SQL status: SELECT in 0.14 seconds
2022-01-06 14:32:28.516511 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.516607 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:32:28.520693 (Thread-1): 14:32:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:28.523362 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.523458 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:32:28.526549 (Thread-1): 14:32:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:28.527589 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:28.527684 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.527755 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:28.563779 (Thread-2): 14:32:28  SQL status: COMMIT in 0.07 seconds
2022-01-06 14:32:28.563998 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.564081 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:28.564305 (Thread-1): 14:32:28  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:32:28.566246 (Thread-2): 14:32:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:28.570189 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.570288 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:32:28.575251 (Thread-2): 14:32:28  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:32:28.575878 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:28.575974 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.576055 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:32:28.605341 (Thread-2): 14:32:28  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:28.605455 (Thread-2): 14:32:28  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:32:28.605529 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:32:28.607645 (Thread-2): 14:32:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:28.608021 (Thread-2): 14:32:28  finished collecting timing info
2022-01-06 14:32:28.608146 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:32:28.608356 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.608465 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:28.610849 (Thread-2): 14:32:28  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:32:28.611047 (Thread-1): 14:32:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:28.612136 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.612231 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:32:28.612654 (Thread-2): 14:32:28  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4ad54c5-1880-4281-835a-3b6c72461a7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf44679f70>]}
2022-01-06 14:32:28.612972 (Thread-2): 14:32:28  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.34s]
2022-01-06 14:32:28.613085 (Thread-2): 14:32:28  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:32:28.613824 (Thread-4): 14:32:28  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:28.614059 (Thread-4): 14:32:28  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:32:28.614480 (Thread-4): 14:32:28  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.614576 (Thread-4): 14:32:28  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:28.614662 (Thread-4): 14:32:28  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:32:28.616443 (Thread-4): 14:32:28  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.616992 (Thread-1): 14:32:28  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:32:28.617647 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:28.617742 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.617816 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:32:28.629283 (Thread-4): 14:32:28  finished collecting timing info
2022-01-06 14:32:28.629420 (Thread-4): 14:32:28  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:28.644806 (Thread-4): 14:32:28  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.650979 (Thread-1): 14:32:28  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:28.651098 (Thread-1): 14:32:28  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:32:28.651171 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:32:28.653518 (Thread-1): 14:32:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:28.653867 (Thread-1): 14:32:28  finished collecting timing info
2022-01-06 14:32:28.653986 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:32:28.655642 (Thread-1): 14:32:28  On model.my_new_project.dim_customers: Close
2022-01-06 14:32:28.656036 (Thread-1): 14:32:28  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4ad54c5-1880-4281-835a-3b6c72461a7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf4468c610>]}
2022-01-06 14:32:28.656325 (Thread-1): 14:32:28  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.39s]
2022-01-06 14:32:28.656432 (Thread-1): 14:32:28  Finished running node model.my_new_project.dim_customers
2022-01-06 14:32:28.657350 (Thread-4): 14:32:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.657465 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:28.657548 (Thread-4): 14:32:28  Opening a new connection, currently in state init
2022-01-06 14:32:28.657627 (Thread-4): 14:32:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:28.681740 (Thread-4): 14:32:28  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:28.681865 (Thread-4): 14:32:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.681943 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:32:28.686841 (Thread-4): 14:32:28  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:32:28.688599 (Thread-4): 14:32:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.688694 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:32:28.691147 (Thread-4): 14:32:28  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:32:28.692041 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:28.692134 (Thread-4): 14:32:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.692206 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:28.724094 (Thread-4): 14:32:28  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:32:28.724311 (Thread-4): 14:32:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.724395 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:28.726550 (Thread-4): 14:32:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:28.727759 (Thread-4): 14:32:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.727856 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:32:28.729816 (Thread-4): 14:32:28  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:32:28.730472 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:28.730566 (Thread-4): 14:32:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.730640 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:32:28.754835 (Thread-4): 14:32:28  SQL status: COMMIT in 0.02 seconds
2022-01-06 14:32:28.754945 (Thread-4): 14:32:28  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:32:28.755017 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:32:28.757200 (Thread-4): 14:32:28  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:32:28.757576 (Thread-4): 14:32:28  finished collecting timing info
2022-01-06 14:32:28.757694 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:32:28.759386 (Thread-4): 14:32:28  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:32:28.759755 (Thread-4): 14:32:28  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4ad54c5-1880-4281-835a-3b6c72461a7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf4470ccd0>]}
2022-01-06 14:32:28.760036 (Thread-4): 14:32:28  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.15s]
2022-01-06 14:32:28.760138 (Thread-4): 14:32:28  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:32:28.761536 (MainThread): 14:32:28  Acquiring new redshift connection "master"
2022-01-06 14:32:28.761677 (MainThread): 14:32:28  Using redshift connection "master"
2022-01-06 14:32:28.761755 (MainThread): 14:32:28  On master: BEGIN
2022-01-06 14:32:28.761831 (MainThread): 14:32:28  Opening a new connection, currently in state closed
2022-01-06 14:32:28.761925 (MainThread): 14:32:28  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:32:28.786573 (MainThread): 14:32:28  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:32:28.786690 (MainThread): 14:32:28  On master: COMMIT
2022-01-06 14:32:28.786764 (MainThread): 14:32:28  Using redshift connection "master"
2022-01-06 14:32:28.786833 (MainThread): 14:32:28  On master: COMMIT
2022-01-06 14:32:28.788579 (MainThread): 14:32:28  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:32:28.788692 (MainThread): 14:32:28  On master: Close
2022-01-06 14:32:28.789137 (MainThread): 14:32:28  
2022-01-06 14:32:28.789284 (MainThread): 14:32:28  Finished running 2 table models, 1 view model in 0.74s.
2022-01-06 14:32:28.789371 (MainThread): 14:32:28  Connection 'master' was properly closed.
2022-01-06 14:32:28.789457 (MainThread): 14:32:28  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:32:28.789566 (MainThread): 14:32:28  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:32:28.789676 (MainThread): 14:32:28  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:32:28.840604 (MainThread): 14:32:28  
2022-01-06 14:32:28.840796 (MainThread): 14:32:28  Completed successfully
2022-01-06 14:32:28.840904 (MainThread): 14:32:28  
2022-01-06 14:32:28.840994 (MainThread): 14:32:28  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:32:29.761072 (Thread-77): handling poll request
2022-01-06 14:32:29.761482 (Thread-77): 14:32:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9814f250>]}
2022-01-06 14:32:29.763725 (Thread-77): sending response (<Response 63477 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:32:30.419180 (Thread-78): handling status request
2022-01-06 14:32:30.419539 (Thread-78): 14:32:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9814f130>]}
2022-01-06 14:32:30.420038 (Thread-78): sending response (<Response 1544 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:32:30.729569 (Thread-79): handling status request
2022-01-06 14:32:30.729957 (Thread-79): 14:32:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9814f6a0>]}
2022-01-06 14:32:30.730443 (Thread-79): sending response (<Response 1544 bytes [200 OK]>) to 10.0.5.191
2022-01-06 14:33:29.790718 (Thread-80): handling status request
2022-01-06 14:33:29.791091 (Thread-80): 14:33:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9814f880>]}
2022-01-06 14:33:29.791562 (Thread-80): sending response (<Response 1544 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:33:30.016887 (Thread-81): handling status request
2022-01-06 14:33:30.017253 (Thread-81): 14:33:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9814fb50>]}
2022-01-06 14:33:30.017714 (Thread-81): sending response (<Response 1544 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:33:30.111158 (Thread-82): handling cli_args request
2022-01-06 14:33:30.111498 (Thread-82): 14:33:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9814fdc0>]}
2022-01-06 14:33:32.278189 (Thread-82): sending response (<Response 138 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:33:32.364809 (MainThread): 14:33:32  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:33:32.365251 (MainThread): 14:33:32  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:33:32.370902 (MainThread): 14:33:32  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '90bdc5b0-c565-4a2e-897d-16812ba900de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4279f9d60>]}
2022-01-06 14:33:32.395165 (MainThread): 14:33:32  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '90bdc5b0-c565-4a2e-897d-16812ba900de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe427a70dc0>]}
2022-01-06 14:33:32.395407 (MainThread): 14:33:32  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:33:32.396463 (MainThread): 14:33:32  
2022-01-06 14:33:32.396728 (MainThread): 14:33:32  Acquiring new redshift connection "master"
2022-01-06 14:33:32.397711 (ThreadPoolExecutor-0_0): 14:33:32  Acquiring new redshift connection "list_dev"
2022-01-06 14:33:32.407738 (ThreadPoolExecutor-0_0): 14:33:32  Using redshift connection "list_dev"
2022-01-06 14:33:32.407845 (ThreadPoolExecutor-0_0): 14:33:32  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:33:32.407945 (ThreadPoolExecutor-0_0): 14:33:32  Opening a new connection, currently in state init
2022-01-06 14:33:32.408047 (ThreadPoolExecutor-0_0): 14:33:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:33:32.428638 (ThreadPoolExecutor-0_0): 14:33:32  SQL status: SELECT in 0.02 seconds
2022-01-06 14:33:32.429711 (ThreadPoolExecutor-0_0): 14:33:32  On list_dev: Close
2022-01-06 14:33:32.430874 (ThreadPoolExecutor-1_0): 14:33:32  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:33:32.437246 (ThreadPoolExecutor-1_0): 14:33:32  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:33:32.437348 (ThreadPoolExecutor-1_0): 14:33:32  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:33:32.437429 (ThreadPoolExecutor-1_0): 14:33:32  Opening a new connection, currently in state closed
2022-01-06 14:33:32.437507 (ThreadPoolExecutor-1_0): 14:33:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:33:32.458378 (ThreadPoolExecutor-1_0): 14:33:32  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:33:32.458487 (ThreadPoolExecutor-1_0): 14:33:32  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:33:32.458574 (ThreadPoolExecutor-1_0): 14:33:32  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:33:32.469471 (ThreadPoolExecutor-1_0): 14:33:32  SQL status: SELECT in 0.01 seconds
2022-01-06 14:33:32.470452 (ThreadPoolExecutor-1_0): 14:33:32  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:33:32.472267 (ThreadPoolExecutor-1_0): 14:33:32  On list_dev_dbt_nobodozie: Close
2022-01-06 14:33:32.475865 (MainThread): 14:33:32  Using redshift connection "master"
2022-01-06 14:33:32.475977 (MainThread): 14:33:32  On master: BEGIN
2022-01-06 14:33:32.476059 (MainThread): 14:33:32  Opening a new connection, currently in state init
2022-01-06 14:33:32.476135 (MainThread): 14:33:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:33:32.499384 (MainThread): 14:33:32  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:33:32.499496 (MainThread): 14:33:32  Using redshift connection "master"
2022-01-06 14:33:32.499572 (MainThread): 14:33:32  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:33:32.528462 (MainThread): 14:33:32  SQL status: SELECT in 0.03 seconds
2022-01-06 14:33:32.529442 (MainThread): 14:33:32  On master: ROLLBACK
2022-01-06 14:33:32.531227 (MainThread): 14:33:32  Using redshift connection "master"
2022-01-06 14:33:32.531327 (MainThread): 14:33:32  On master: BEGIN
2022-01-06 14:33:32.534768 (MainThread): 14:33:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:33:32.534878 (MainThread): 14:33:32  On master: COMMIT
2022-01-06 14:33:32.534951 (MainThread): 14:33:32  Using redshift connection "master"
2022-01-06 14:33:32.535018 (MainThread): 14:33:32  On master: COMMIT
2022-01-06 14:33:32.536695 (MainThread): 14:33:32  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:33:32.536805 (MainThread): 14:33:32  On master: Close
2022-01-06 14:33:32.537172 (MainThread): 14:33:32  Concurrency: 4 threads (target='default')
2022-01-06 14:33:32.537317 (MainThread): 14:33:32  
2022-01-06 14:33:32.539520 (Thread-1): 14:33:32  Began running node model.my_new_project.dim_customers
2022-01-06 14:33:32.539752 (Thread-1): 14:33:32  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:33:32.539979 (Thread-1): 14:33:32  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.540071 (Thread-1): 14:33:32  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:33:32.540168 (Thread-1): 14:33:32  Compiling model.my_new_project.dim_customers
2022-01-06 14:33:32.542189 (Thread-1): 14:33:32  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:33:32.542421 (Thread-2): 14:33:32  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:33:32.542647 (Thread-2): 14:33:32  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:33:32.542892 (Thread-2): 14:33:32  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.542978 (Thread-2): 14:33:32  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:33:32.543060 (Thread-2): 14:33:32  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:33:32.545113 (Thread-2): 14:33:32  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.558539 (Thread-1): 14:33:32  finished collecting timing info
2022-01-06 14:33:32.558678 (Thread-1): 14:33:32  Began executing node model.my_new_project.dim_customers
2022-01-06 14:33:32.563729 (Thread-2): 14:33:32  finished collecting timing info
2022-01-06 14:33:32.563860 (Thread-2): 14:33:32  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:33:32.598411 (Thread-83): handling poll request
2022-01-06 14:33:32.598801 (Thread-83): 14:33:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff98171e50>]}
2022-01-06 14:33:32.599998 (Thread-83): sending response (<Response 22988 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:33:32.613876 (Thread-2): 14:33:32  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.616155 (Thread-1): 14:33:32  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:33:32.629384 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.629506 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:33:32.629594 (Thread-2): 14:33:32  Opening a new connection, currently in state init
2022-01-06 14:33:32.629678 (Thread-2): 14:33:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:33:32.629930 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.630034 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:33:32.630114 (Thread-1): 14:33:32  Opening a new connection, currently in state closed
2022-01-06 14:33:32.630192 (Thread-1): 14:33:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:33:32.656685 (Thread-1): 14:33:32  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:33:32.656854 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.656944 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:33:32.657129 (Thread-2): 14:33:32  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:33:32.657283 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.657364 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:33:32.739177 (Thread-2): 14:33:32  SQL status: SELECT in 0.08 seconds
2022-01-06 14:33:32.746637 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.746962 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:33:32.750848 (Thread-2): 14:33:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:33:32.752994 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.753112 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:33:32.756850 (Thread-2): 14:33:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:33:32.767235 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:33:32.767350 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.767427 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:33:32.770343 (Thread-1): 14:33:32  SQL status: SELECT in 0.11 seconds
2022-01-06 14:33:32.773268 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.773373 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:33:32.777410 (Thread-1): 14:33:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:33:32.779071 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.779167 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:33:32.784019 (Thread-1): 14:33:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:33:32.785094 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:33:32.785191 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.785305 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:33:32.828945 (Thread-2): 14:33:32  SQL status: COMMIT in 0.06 seconds
2022-01-06 14:33:32.829165 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.829275 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:33:32.829498 (Thread-1): 14:33:32  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:33:32.831371 (Thread-2): 14:33:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:33:32.835396 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.835495 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:33:32.840350 (Thread-2): 14:33:32  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:33:32.840977 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:33:32.841072 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.841146 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:33:32.871762 (Thread-2): 14:33:32  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:33:32.871879 (Thread-2): 14:33:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:33:32.871953 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:33:32.874017 (Thread-2): 14:33:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:33:32.874436 (Thread-2): 14:33:32  finished collecting timing info
2022-01-06 14:33:32.874567 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:33:32.874765 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.874871 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:33:32.877355 (Thread-2): 14:33:32  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:33:32.877496 (Thread-1): 14:33:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:33:32.878771 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.878866 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:33:32.879295 (Thread-2): 14:33:32  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90bdc5b0-c565-4a2e-897d-16812ba900de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe424134a90>]}
2022-01-06 14:33:32.879684 (Thread-2): 14:33:32  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.34s]
2022-01-06 14:33:32.879804 (Thread-2): 14:33:32  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:33:32.880529 (Thread-4): 14:33:32  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:33:32.880774 (Thread-4): 14:33:32  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:33:32.881035 (Thread-4): 14:33:32  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.881125 (Thread-4): 14:33:32  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:33:32.881241 (Thread-4): 14:33:32  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:33:32.883247 (Thread-4): 14:33:32  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.883805 (Thread-1): 14:33:32  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:33:32.884460 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:33:32.884556 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.884632 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:33:32.897349 (Thread-4): 14:33:32  finished collecting timing info
2022-01-06 14:33:32.897489 (Thread-4): 14:33:32  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:33:32.912985 (Thread-4): 14:33:32  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.916399 (Thread-1): 14:33:32  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:33:32.916522 (Thread-1): 14:33:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:33:32.916600 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:33:32.918626 (Thread-1): 14:33:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:33:32.918997 (Thread-1): 14:33:32  finished collecting timing info
2022-01-06 14:33:32.919121 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:33:32.920850 (Thread-1): 14:33:32  On model.my_new_project.dim_customers: Close
2022-01-06 14:33:32.921347 (Thread-1): 14:33:32  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90bdc5b0-c565-4a2e-897d-16812ba900de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe424134be0>]}
2022-01-06 14:33:32.921727 (Thread-1): 14:33:32  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.38s]
2022-01-06 14:33:32.921842 (Thread-1): 14:33:32  Finished running node model.my_new_project.dim_customers
2022-01-06 14:33:32.927308 (Thread-4): 14:33:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.927422 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:33:32.927508 (Thread-4): 14:33:32  Opening a new connection, currently in state init
2022-01-06 14:33:32.927591 (Thread-4): 14:33:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:33:32.948728 (Thread-4): 14:33:32  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:33:32.948844 (Thread-4): 14:33:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.948921 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:33:32.953657 (Thread-4): 14:33:32  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:33:32.955460 (Thread-4): 14:33:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.955553 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:33:32.957683 (Thread-4): 14:33:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:33:32.958617 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:33:32.958712 (Thread-4): 14:33:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.958787 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:33:32.989390 (Thread-4): 14:33:32  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:33:32.989609 (Thread-4): 14:33:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.989696 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:33:32.992516 (Thread-4): 14:33:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:33:32.993772 (Thread-4): 14:33:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.993868 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:33:32.996465 (Thread-4): 14:33:32  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:33:32.997150 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:33:32.997280 (Thread-4): 14:33:32  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:32.997360 (Thread-4): 14:33:32  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:33:33.030503 (Thread-4): 14:33:33  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:33:33.030625 (Thread-4): 14:33:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:33:33.030702 (Thread-4): 14:33:33  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:33:33.032839 (Thread-4): 14:33:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:33:33.033295 (Thread-4): 14:33:33  finished collecting timing info
2022-01-06 14:33:33.033433 (Thread-4): 14:33:33  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:33:33.035195 (Thread-4): 14:33:33  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:33:33.035672 (Thread-4): 14:33:33  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90bdc5b0-c565-4a2e-897d-16812ba900de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe42408cb80>]}
2022-01-06 14:33:33.035997 (Thread-4): 14:33:33  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.15s]
2022-01-06 14:33:33.036109 (Thread-4): 14:33:33  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:33:33.037602 (MainThread): 14:33:33  Acquiring new redshift connection "master"
2022-01-06 14:33:33.037745 (MainThread): 14:33:33  Using redshift connection "master"
2022-01-06 14:33:33.037824 (MainThread): 14:33:33  On master: BEGIN
2022-01-06 14:33:33.037903 (MainThread): 14:33:33  Opening a new connection, currently in state closed
2022-01-06 14:33:33.037984 (MainThread): 14:33:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:33:33.061178 (MainThread): 14:33:33  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:33:33.061353 (MainThread): 14:33:33  On master: COMMIT
2022-01-06 14:33:33.061435 (MainThread): 14:33:33  Using redshift connection "master"
2022-01-06 14:33:33.061506 (MainThread): 14:33:33  On master: COMMIT
2022-01-06 14:33:33.063236 (MainThread): 14:33:33  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:33:33.063347 (MainThread): 14:33:33  On master: Close
2022-01-06 14:33:33.063753 (MainThread): 14:33:33  
2022-01-06 14:33:33.063868 (MainThread): 14:33:33  Finished running 2 table models, 1 view model in 0.67s.
2022-01-06 14:33:33.063950 (MainThread): 14:33:33  Connection 'master' was properly closed.
2022-01-06 14:33:33.064018 (MainThread): 14:33:33  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:33:33.064081 (MainThread): 14:33:33  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:33:33.064142 (MainThread): 14:33:33  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:33:33.114237 (MainThread): 14:33:33  
2022-01-06 14:33:33.114391 (MainThread): 14:33:33  Completed successfully
2022-01-06 14:33:33.114488 (MainThread): 14:33:33  
2022-01-06 14:33:33.114574 (MainThread): 14:33:33  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:33:33.915781 (Thread-84): handling poll request
2022-01-06 14:33:33.916139 (Thread-84): 14:33:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9812a610>]}
2022-01-06 14:33:33.918534 (Thread-84): sending response (<Response 64203 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:33:34.555498 (Thread-85): handling status request
2022-01-06 14:33:34.555860 (Thread-85): 14:33:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9812a7c0>]}
2022-01-06 14:33:34.556361 (Thread-85): sending response (<Response 1544 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:33:34.622730 (Thread-86): handling status request
2022-01-06 14:33:34.623008 (Thread-86): 14:33:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9812abb0>]}
2022-01-06 14:33:34.623430 (Thread-86): sending response (<Response 1544 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:34:44.217137 (Thread-87): handling status request
2022-01-06 14:34:44.218722 (Thread-87): 14:34:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9812adf0>]}
2022-01-06 14:34:44.219202 (Thread-87): sending response (<Response 1544 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:34:44.548211 (Thread-88): handling run_sql request
2022-01-06 14:34:44.548547 (Thread-88): 14:34:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9811f5b0>]}
2022-01-06 14:34:46.649670 (Thread-88): sending response (<Response 138 bytes [200 OK]>) to 10.0.8.130
2022-01-06 14:34:46.676824 (MainThread): 14:34:46  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c364d61f-2d97-49fe-aa0f-c7d8a4c9300a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8441e7970>]}
2022-01-06 14:34:46.677367 (MainThread): 14:34:46  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:34:46.677924 (Thread-1): 14:34:46  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:34:46.678052 (Thread-1): 14:34:46  Began compiling node rpc.my_new_project.request
2022-01-06 14:34:46.678150 (Thread-1): 14:34:46  Compiling rpc.my_new_project.request
2022-01-06 14:34:46.680651 (Thread-1): 14:34:46  finished collecting timing info
2022-01-06 14:34:46.680778 (Thread-1): 14:34:46  Began executing node rpc.my_new_project.request
2022-01-06 14:34:46.680872 (Thread-1): 14:34:46  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:34:46.680946 (Thread-1): 14:34:46  On rpc.my_new_project.request: 

with customers as (
    select * from "dev"."dbt_nobodozie"."stg_customers"
),
orders as (
    select * from "dev"."dbt_nobodozie"."stg_orders"
),
customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:34:46.681022 (Thread-1): 14:34:46  Opening a new connection, currently in state init
2022-01-06 14:34:46.681101 (Thread-1): 14:34:46  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:34:46.706363 (Thread-1): 14:34:46  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 14:34:46.706592 (Thread-1): 14:34:46  finished collecting timing info
2022-01-06 14:34:46.706778 (Thread-1): 14:34:46  On rpc.my_new_project.request: Close
2022-01-06 14:34:46.707051 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 14:34:46.708427 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n    select * from {{ref(\'stg_customers\')}}\n),\norders as (\n    select * from {{ref(\'stg_orders\')}}\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\norders as (\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n    select * from {{ref(\'stg_customers\')}}\n),\norders as (\n    select * from {{ref(\'stg_orders\')}}\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\norders as (\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 14:34:47.084253 (Thread-89): handling poll request
2022-01-06 14:34:47.084686 (Thread-89): 14:34:47  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980be2e0>]}
2022-01-06 14:34:47.085534 (Thread-89): sending response (<Response 14613 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:35:12.141930 (Thread-90): handling status request
2022-01-06 14:35:12.142288 (Thread-90): 14:35:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980be7f0>]}
2022-01-06 14:35:12.142814 (Thread-90): sending response (<Response 1544 bytes [200 OK]>) to 10.0.40.39
2022-01-06 14:35:12.501932 (Thread-91): handling compile_sql request
2022-01-06 14:35:12.502234 (Thread-91): 14:35:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980beaf0>]}
2022-01-06 14:35:14.568667 (Thread-91): sending response (<Response 138 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:35:14.594087 (MainThread): 14:35:14  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '73df3c1b-9ba4-4c55-9e81-15667f4580cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa48cbcd9a0>]}
2022-01-06 14:35:14.594616 (MainThread): 14:35:14  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:35:14.595185 (Thread-1): 14:35:14  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:35:14.595315 (Thread-1): 14:35:14  Began compiling node rpc.my_new_project.request
2022-01-06 14:35:14.595406 (Thread-1): 14:35:14  Compiling rpc.my_new_project.request
2022-01-06 14:35:14.597885 (Thread-1): 14:35:14  finished collecting timing info
2022-01-06 14:35:14.598013 (Thread-1): 14:35:14  Began executing node rpc.my_new_project.request
2022-01-06 14:35:14.598111 (Thread-1): 14:35:14  finished collecting timing info
2022-01-06 14:35:14.906320 (Thread-92): handling poll request
2022-01-06 14:35:14.906757 (Thread-92): 14:35:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980c6370>]}
2022-01-06 14:35:14.907824 (Thread-92): sending response (<Response 8440 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:36:38.627614 (Thread-93): handling status request
2022-01-06 14:36:38.629123 (Thread-93): 14:36:38  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980c6520>]}
2022-01-06 14:36:38.629712 (Thread-93): sending response (<Response 1544 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:36:39.059130 (Thread-94): handling run_sql request
2022-01-06 14:36:39.059488 (Thread-94): 14:36:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980c6910>]}
2022-01-06 14:36:41.159494 (Thread-94): sending response (<Response 138 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:36:41.186758 (MainThread): 14:36:41  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '72cfb2cc-c81b-47b2-bb51-c59e6ff3733f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c2f8b6a60>]}
2022-01-06 14:36:41.187333 (MainThread): 14:36:41  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:36:41.188003 (Thread-1): 14:36:41  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:36:41.188137 (Thread-1): 14:36:41  Began compiling node rpc.my_new_project.request
2022-01-06 14:36:41.188237 (Thread-1): 14:36:41  Compiling rpc.my_new_project.request
2022-01-06 14:36:41.190799 (Thread-1): 14:36:41  finished collecting timing info
2022-01-06 14:36:41.190926 (Thread-1): 14:36:41  Began executing node rpc.my_new_project.request
2022-01-06 14:36:41.191021 (Thread-1): 14:36:41  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:36:41.191095 (Thread-1): 14:36:41  On rpc.my_new_project.request: 

with customers as (
    select * from "dev"."dbt_nobodozie"."stg_customers"
),
orders as (
    select * from "dev"."dbt_nobodozie"."stg_orders"
),
customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:36:41.191171 (Thread-1): 14:36:41  Opening a new connection, currently in state init
2022-01-06 14:36:41.191249 (Thread-1): 14:36:41  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:36:41.211581 (Thread-1): 14:36:41  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 14:36:41.211733 (Thread-1): 14:36:41  finished collecting timing info
2022-01-06 14:36:41.211845 (Thread-1): 14:36:41  On rpc.my_new_project.request: Close
2022-01-06 14:36:41.212110 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 14:36:41.213044 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n    select * from {{ref(\'stg_customers\')}}\n),\norders as (\n    select * from {{ref(\'stg_orders\')}}\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\norders as (\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n    select * from {{ref(\'stg_customers\')}}\n),\norders as (\n    select * from {{ref(\'stg_orders\')}}\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\norders as (\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 14:36:41.597461 (Thread-95): handling poll request
2022-01-06 14:36:41.597884 (Thread-95): 14:36:41  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980cbb20>]}
2022-01-06 14:36:41.598710 (Thread-95): sending response (<Response 14613 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:36:43.399729 (Thread-96): handling status request
2022-01-06 14:36:43.400102 (Thread-96): 14:36:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980d8070>]}
2022-01-06 14:36:43.423259 (Thread-96): sending response (<Response 1544 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:36:43.902536 (Thread-97): handling compile_sql request
2022-01-06 14:36:43.902922 (Thread-97): 14:36:43  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980d81f0>]}
2022-01-06 14:36:45.985960 (Thread-97): sending response (<Response 138 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:36:46.011269 (MainThread): 14:36:46  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dd7f2c92-d136-4d33-a0fa-924e024900aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f169a6cfa90>]}
2022-01-06 14:36:46.011773 (MainThread): 14:36:46  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:36:46.012336 (Thread-1): 14:36:46  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:36:46.012468 (Thread-1): 14:36:46  Began compiling node rpc.my_new_project.request
2022-01-06 14:36:46.012558 (Thread-1): 14:36:46  Compiling rpc.my_new_project.request
2022-01-06 14:36:46.015075 (Thread-1): 14:36:46  finished collecting timing info
2022-01-06 14:36:46.015202 (Thread-1): 14:36:46  Began executing node rpc.my_new_project.request
2022-01-06 14:36:46.015297 (Thread-1): 14:36:46  finished collecting timing info
2022-01-06 14:36:46.399857 (Thread-98): handling poll request
2022-01-06 14:36:46.400261 (Thread-98): 14:36:46  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980dd340>]}
2022-01-06 14:36:46.401364 (Thread-98): sending response (<Response 8440 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:36:50.104693 (Thread-99): handling status request
2022-01-06 14:36:50.105049 (Thread-99): 14:36:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980dd3d0>]}
2022-01-06 14:36:50.105647 (Thread-99): sending response (<Response 1544 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:36:50.424477 (Thread-100): handling run_sql request
2022-01-06 14:36:50.424844 (Thread-100): 14:36:50  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980dda60>]}
2022-01-06 14:36:52.461004 (Thread-100): sending response (<Response 138 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:36:52.486212 (MainThread): 14:36:52  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '468ab41c-cb3e-4ee2-9943-c3d5020ece6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2bcb8707c0>]}
2022-01-06 14:36:52.486718 (MainThread): 14:36:52  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:36:52.487267 (Thread-1): 14:36:52  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:36:52.487396 (Thread-1): 14:36:52  Began compiling node rpc.my_new_project.request
2022-01-06 14:36:52.487487 (Thread-1): 14:36:52  Compiling rpc.my_new_project.request
2022-01-06 14:36:52.490003 (Thread-1): 14:36:52  finished collecting timing info
2022-01-06 14:36:52.490127 (Thread-1): 14:36:52  Began executing node rpc.my_new_project.request
2022-01-06 14:36:52.490222 (Thread-1): 14:36:52  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:36:52.490296 (Thread-1): 14:36:52  On rpc.my_new_project.request: 

with customers as (
    select * from "dev"."dbt_nobodozie"."stg_customers"
),
orders as (
    select * from "dev"."dbt_nobodozie"."stg_orders"
),
customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:36:52.490370 (Thread-1): 14:36:52  Opening a new connection, currently in state init
2022-01-06 14:36:52.490445 (Thread-1): 14:36:52  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:36:52.510314 (Thread-1): 14:36:52  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 14:36:52.510463 (Thread-1): 14:36:52  finished collecting timing info
2022-01-06 14:36:52.510577 (Thread-1): 14:36:52  On rpc.my_new_project.request: Close
2022-01-06 14:36:52.510746 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 14:36:52.511763 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n    select * from {{ref(\'stg_customers\')}}\n),\norders as (\n    select * from {{ref(\'stg_orders\')}}\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\norders as (\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n    select * from {{ref(\'stg_customers\')}}\n),\norders as (\n    select * from {{ref(\'stg_orders\')}}\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\norders as (\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 14:36:52.785980 (Thread-101): handling poll request
2022-01-06 14:36:52.786408 (Thread-101): 14:36:52  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980e5b80>]}
2022-01-06 14:36:52.787219 (Thread-101): sending response (<Response 14613 bytes [200 OK]>) to 10.0.40.39
2022-01-06 14:37:09.981316 (Thread-102): handling status request
2022-01-06 14:37:09.981699 (Thread-102): 14:37:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980ef0d0>]}
2022-01-06 14:37:09.982233 (Thread-102): sending response (<Response 1544 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:37:10.180519 (Thread-103): handling status request
2022-01-06 14:37:10.180880 (Thread-103): 14:37:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980ef3d0>]}
2022-01-06 14:37:10.181395 (Thread-103): sending response (<Response 1544 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:37:10.349665 (Thread-104): handling cli_args request
2022-01-06 14:37:10.350096 (Thread-104): 14:37:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980ef640>]}
2022-01-06 14:37:12.424129 (Thread-104): sending response (<Response 138 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:37:12.513069 (MainThread): 14:37:12  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:37:12.513516 (MainThread): 14:37:12  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:37:12.519922 (MainThread): 14:37:12  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a6514d0f-3cb5-4a04-bba7-e84a22dbcc78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d51c8bca0>]}
2022-01-06 14:37:12.547370 (MainThread): 14:37:12  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a6514d0f-3cb5-4a04-bba7-e84a22dbcc78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d51d01d00>]}
2022-01-06 14:37:12.547636 (MainThread): 14:37:12  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:37:12.548732 (MainThread): 14:37:12  
2022-01-06 14:37:12.549020 (MainThread): 14:37:12  Acquiring new redshift connection "master"
2022-01-06 14:37:12.550088 (ThreadPoolExecutor-0_0): 14:37:12  Acquiring new redshift connection "list_dev"
2022-01-06 14:37:12.559843 (ThreadPoolExecutor-0_0): 14:37:12  Using redshift connection "list_dev"
2022-01-06 14:37:12.560108 (ThreadPoolExecutor-0_0): 14:37:12  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:37:12.560195 (ThreadPoolExecutor-0_0): 14:37:12  Opening a new connection, currently in state init
2022-01-06 14:37:12.560277 (ThreadPoolExecutor-0_0): 14:37:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:37:12.580532 (ThreadPoolExecutor-0_0): 14:37:12  SQL status: SELECT in 0.02 seconds
2022-01-06 14:37:12.581667 (ThreadPoolExecutor-0_0): 14:37:12  On list_dev: Close
2022-01-06 14:37:12.582838 (ThreadPoolExecutor-1_0): 14:37:12  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:37:12.589316 (ThreadPoolExecutor-1_0): 14:37:12  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:37:12.589416 (ThreadPoolExecutor-1_0): 14:37:12  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:37:12.589497 (ThreadPoolExecutor-1_0): 14:37:12  Opening a new connection, currently in state closed
2022-01-06 14:37:12.589575 (ThreadPoolExecutor-1_0): 14:37:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:37:12.611164 (ThreadPoolExecutor-1_0): 14:37:12  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:37:12.611279 (ThreadPoolExecutor-1_0): 14:37:12  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:37:12.611357 (ThreadPoolExecutor-1_0): 14:37:12  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:37:12.622029 (ThreadPoolExecutor-1_0): 14:37:12  SQL status: SELECT in 0.01 seconds
2022-01-06 14:37:12.623089 (ThreadPoolExecutor-1_0): 14:37:12  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:37:12.624856 (ThreadPoolExecutor-1_0): 14:37:12  On list_dev_dbt_nobodozie: Close
2022-01-06 14:37:12.628649 (MainThread): 14:37:12  Using redshift connection "master"
2022-01-06 14:37:12.628762 (MainThread): 14:37:12  On master: BEGIN
2022-01-06 14:37:12.628845 (MainThread): 14:37:12  Opening a new connection, currently in state init
2022-01-06 14:37:12.628923 (MainThread): 14:37:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:37:12.651063 (MainThread): 14:37:12  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:37:12.651180 (MainThread): 14:37:12  Using redshift connection "master"
2022-01-06 14:37:12.651257 (MainThread): 14:37:12  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:37:12.679082 (MainThread): 14:37:12  SQL status: SELECT in 0.03 seconds
2022-01-06 14:37:12.680258 (MainThread): 14:37:12  On master: ROLLBACK
2022-01-06 14:37:12.682111 (MainThread): 14:37:12  Using redshift connection "master"
2022-01-06 14:37:12.682229 (MainThread): 14:37:12  On master: BEGIN
2022-01-06 14:37:12.685713 (MainThread): 14:37:12  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:37:12.685816 (MainThread): 14:37:12  On master: COMMIT
2022-01-06 14:37:12.685888 (MainThread): 14:37:12  Using redshift connection "master"
2022-01-06 14:37:12.685956 (MainThread): 14:37:12  On master: COMMIT
2022-01-06 14:37:12.687621 (MainThread): 14:37:12  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:37:12.687802 (MainThread): 14:37:12  On master: Close
2022-01-06 14:37:12.688350 (MainThread): 14:37:12  Concurrency: 4 threads (target='default')
2022-01-06 14:37:12.688483 (MainThread): 14:37:12  
2022-01-06 14:37:12.690925 (Thread-1): 14:37:12  Began running node model.my_new_project.dim_customers
2022-01-06 14:37:12.691202 (Thread-1): 14:37:12  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:37:12.691482 (Thread-1): 14:37:12  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:12.691580 (Thread-1): 14:37:12  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:37:12.691678 (Thread-1): 14:37:12  Compiling model.my_new_project.dim_customers
2022-01-06 14:37:12.694064 (Thread-1): 14:37:12  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:37:12.694294 (Thread-2): 14:37:12  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:37:12.694525 (Thread-2): 14:37:12  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:37:12.694800 (Thread-2): 14:37:12  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.694887 (Thread-2): 14:37:12  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:37:12.694968 (Thread-2): 14:37:12  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:37:12.697058 (Thread-2): 14:37:12  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.708524 (Thread-1): 14:37:12  finished collecting timing info
2022-01-06 14:37:12.708672 (Thread-1): 14:37:12  Began executing node model.my_new_project.dim_customers
2022-01-06 14:37:12.713894 (Thread-2): 14:37:12  finished collecting timing info
2022-01-06 14:37:12.714028 (Thread-2): 14:37:12  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:37:12.771790 (Thread-2): 14:37:12  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.774168 (Thread-1): 14:37:12  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:37:12.793544 (Thread-1): 14:37:12  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:12.793766 (Thread-1): 14:37:12  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:37:12.793923 (Thread-1): 14:37:12  Opening a new connection, currently in state closed
2022-01-06 14:37:12.794067 (Thread-1): 14:37:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:37:12.794427 (Thread-2): 14:37:12  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.794540 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:37:12.794626 (Thread-2): 14:37:12  Opening a new connection, currently in state init
2022-01-06 14:37:12.794702 (Thread-2): 14:37:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:37:12.818654 (Thread-1): 14:37:12  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:37:12.818853 (Thread-1): 14:37:12  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:12.818991 (Thread-1): 14:37:12  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:37:12.819643 (Thread-2): 14:37:12  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:37:12.819769 (Thread-2): 14:37:12  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.819849 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:37:12.832586 (Thread-105): handling poll request
2022-01-06 14:37:12.832966 (Thread-105): 14:37:12  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980cb640>]}
2022-01-06 14:37:12.834388 (Thread-105): sending response (<Response 30570 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:37:12.897828 (Thread-2): 14:37:12  SQL status: SELECT in 0.08 seconds
2022-01-06 14:37:12.904027 (Thread-2): 14:37:12  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.904147 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:37:12.908433 (Thread-2): 14:37:12  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:37:12.910411 (Thread-2): 14:37:12  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.910518 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:37:12.914148 (Thread-2): 14:37:12  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:37:12.924450 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:37:12.924578 (Thread-2): 14:37:12  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.924656 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:37:12.926553 (Thread-1): 14:37:12  SQL status: SELECT in 0.11 seconds
2022-01-06 14:37:12.931377 (Thread-1): 14:37:12  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:12.931538 (Thread-1): 14:37:12  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:37:12.936852 (Thread-1): 14:37:12  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:37:12.939765 (Thread-1): 14:37:12  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:12.939918 (Thread-1): 14:37:12  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:37:12.943065 (Thread-1): 14:37:12  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:37:12.944858 (Thread-1): 14:37:12  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:37:12.945011 (Thread-1): 14:37:12  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:12.945141 (Thread-1): 14:37:12  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:37:12.986727 (Thread-2): 14:37:12  SQL status: COMMIT in 0.06 seconds
2022-01-06 14:37:12.986970 (Thread-2): 14:37:12  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.987055 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:37:12.987651 (Thread-1): 14:37:12  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:37:12.989260 (Thread-2): 14:37:12  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:37:12.993419 (Thread-2): 14:37:12  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.993518 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:37:12.998285 (Thread-2): 14:37:12  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:37:12.999017 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:37:12.999116 (Thread-2): 14:37:12  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:12.999190 (Thread-2): 14:37:12  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:37:13.029867 (Thread-2): 14:37:13  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:37:13.029996 (Thread-2): 14:37:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:37:13.030074 (Thread-2): 14:37:13  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:37:13.032179 (Thread-2): 14:37:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:37:13.032663 (Thread-2): 14:37:13  finished collecting timing info
2022-01-06 14:37:13.032798 (Thread-2): 14:37:13  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:37:13.033156 (Thread-1): 14:37:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:13.033384 (Thread-1): 14:37:13  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:37:13.035779 (Thread-1): 14:37:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:37:13.038143 (Thread-1): 14:37:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:13.038293 (Thread-1): 14:37:13  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:37:13.038478 (Thread-2): 14:37:13  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:37:13.038942 (Thread-2): 14:37:13  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6514d0f-3cb5-4a04-bba7-e84a22dbcc78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d503ccbb0>]}
2022-01-06 14:37:13.039347 (Thread-2): 14:37:13  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.34s]
2022-01-06 14:37:13.039476 (Thread-2): 14:37:13  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:37:13.040044 (Thread-4): 14:37:13  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:37:13.040281 (Thread-4): 14:37:13  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:37:13.040534 (Thread-4): 14:37:13  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.040622 (Thread-4): 14:37:13  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:37:13.040708 (Thread-4): 14:37:13  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:37:13.042854 (Thread-4): 14:37:13  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.043425 (Thread-1): 14:37:13  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 14:37:13.044135 (Thread-1): 14:37:13  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:37:13.044233 (Thread-1): 14:37:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:13.044308 (Thread-1): 14:37:13  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:37:13.055258 (Thread-4): 14:37:13  finished collecting timing info
2022-01-06 14:37:13.055478 (Thread-4): 14:37:13  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:37:13.074947 (Thread-4): 14:37:13  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.075819 (Thread-1): 14:37:13  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:37:13.075944 (Thread-1): 14:37:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:37:13.076020 (Thread-1): 14:37:13  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:37:13.078203 (Thread-1): 14:37:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:37:13.078620 (Thread-1): 14:37:13  finished collecting timing info
2022-01-06 14:37:13.078749 (Thread-1): 14:37:13  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:37:13.080549 (Thread-1): 14:37:13  On model.my_new_project.dim_customers: Close
2022-01-06 14:37:13.080995 (Thread-1): 14:37:13  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6514d0f-3cb5-4a04-bba7-e84a22dbcc78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d503ccf70>]}
2022-01-06 14:37:13.081353 (Thread-1): 14:37:13  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.39s]
2022-01-06 14:37:13.081471 (Thread-1): 14:37:13  Finished running node model.my_new_project.dim_customers
2022-01-06 14:37:13.086472 (Thread-4): 14:37:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.086580 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:37:13.086662 (Thread-4): 14:37:13  Opening a new connection, currently in state init
2022-01-06 14:37:13.086741 (Thread-4): 14:37:13  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:37:13.109167 (Thread-4): 14:37:13  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:37:13.109324 (Thread-4): 14:37:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.109416 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:37:13.114137 (Thread-4): 14:37:13  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:37:13.116127 (Thread-4): 14:37:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.116223 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:37:13.118421 (Thread-4): 14:37:13  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:37:13.119392 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:37:13.119488 (Thread-4): 14:37:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.119560 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:37:13.147986 (Thread-4): 14:37:13  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:37:13.148212 (Thread-4): 14:37:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.148296 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:37:13.150333 (Thread-4): 14:37:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:37:13.151605 (Thread-4): 14:37:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.151700 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:37:13.153676 (Thread-4): 14:37:13  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:37:13.154359 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:37:13.154455 (Thread-4): 14:37:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.154528 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:37:13.178439 (Thread-4): 14:37:13  SQL status: COMMIT in 0.02 seconds
2022-01-06 14:37:13.178549 (Thread-4): 14:37:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:37:13.178622 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:37:13.180632 (Thread-4): 14:37:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:37:13.181036 (Thread-4): 14:37:13  finished collecting timing info
2022-01-06 14:37:13.181162 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:37:13.182882 (Thread-4): 14:37:13  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:37:13.183310 (Thread-4): 14:37:13  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6514d0f-3cb5-4a04-bba7-e84a22dbcc78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d50390160>]}
2022-01-06 14:37:13.183624 (Thread-4): 14:37:13  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.14s]
2022-01-06 14:37:13.183736 (Thread-4): 14:37:13  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:37:13.185086 (MainThread): 14:37:13  Acquiring new redshift connection "master"
2022-01-06 14:37:13.185263 (MainThread): 14:37:13  Using redshift connection "master"
2022-01-06 14:37:13.185348 (MainThread): 14:37:13  On master: BEGIN
2022-01-06 14:37:13.185428 (MainThread): 14:37:13  Opening a new connection, currently in state closed
2022-01-06 14:37:13.185506 (MainThread): 14:37:13  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:37:13.208398 (MainThread): 14:37:13  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:37:13.208528 (MainThread): 14:37:13  On master: COMMIT
2022-01-06 14:37:13.208604 (MainThread): 14:37:13  Using redshift connection "master"
2022-01-06 14:37:13.208674 (MainThread): 14:37:13  On master: COMMIT
2022-01-06 14:37:13.210294 (MainThread): 14:37:13  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:37:13.210401 (MainThread): 14:37:13  On master: Close
2022-01-06 14:37:13.210809 (MainThread): 14:37:13  
2022-01-06 14:37:13.210919 (MainThread): 14:37:13  Finished running 2 table models, 1 view model in 0.66s.
2022-01-06 14:37:13.211037 (MainThread): 14:37:13  Connection 'master' was properly closed.
2022-01-06 14:37:13.211107 (MainThread): 14:37:13  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:37:13.211170 (MainThread): 14:37:13  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:37:13.211230 (MainThread): 14:37:13  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:37:13.262073 (MainThread): 14:37:13  
2022-01-06 14:37:13.262295 (MainThread): 14:37:13  Completed successfully
2022-01-06 14:37:13.262402 (MainThread): 14:37:13  
2022-01-06 14:37:13.262490 (MainThread): 14:37:13  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:37:14.175223 (Thread-106): handling poll request
2022-01-06 14:37:14.175577 (Thread-106): 14:37:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8092f70>]}
2022-01-06 14:37:14.177685 (Thread-106): sending response (<Response 56625 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:37:14.784188 (Thread-107): handling status request
2022-01-06 14:37:14.784598 (Thread-107): 14:37:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8092be0>]}
2022-01-06 14:37:14.785144 (Thread-107): sending response (<Response 1544 bytes [200 OK]>) to 10.0.14.136
2022-01-06 14:37:14.841722 (Thread-108): handling status request
2022-01-06 14:37:14.842046 (Thread-108): 14:37:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980dd4f0>]}
2022-01-06 14:37:14.842502 (Thread-108): sending response (<Response 1544 bytes [200 OK]>) to 10.0.40.39
2022-01-06 14:41:29.929643 (Thread-109): handling status request
2022-01-06 14:41:29.931057 (Thread-109): 14:41:29  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb854b130>]}
2022-01-06 14:41:29.931560 (Thread-109): sending response (<Response 1544 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:41:30.142734 (Thread-110): handling status request
2022-01-06 14:41:30.143042 (Thread-110): 14:41:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb854b610>]}
2022-01-06 14:41:30.143485 (Thread-110): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:41:30.261117 (Thread-111): handling cli_args request
2022-01-06 14:41:30.261398 (Thread-111): 14:41:30  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb854d640>]}
2022-01-06 14:41:32.309413 (Thread-111): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:41:32.405107 (MainThread): 14:41:32  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:41:32.405525 (MainThread): 14:41:32  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:41:32.411124 (MainThread): 14:41:32  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7ac5b96e-f7a0-4351-8399-5ff50478a7a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57cefc3d90>]}
2022-01-06 14:41:32.439624 (MainThread): 14:41:32  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7ac5b96e-f7a0-4351-8399-5ff50478a7a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57cf0605e0>]}
2022-01-06 14:41:32.439855 (MainThread): 14:41:32  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:41:32.440885 (MainThread): 14:41:32  
2022-01-06 14:41:32.441145 (MainThread): 14:41:32  Acquiring new redshift connection "master"
2022-01-06 14:41:32.442117 (ThreadPoolExecutor-0_0): 14:41:32  Acquiring new redshift connection "list_dev"
2022-01-06 14:41:32.451844 (ThreadPoolExecutor-0_0): 14:41:32  Using redshift connection "list_dev"
2022-01-06 14:41:32.452104 (ThreadPoolExecutor-0_0): 14:41:32  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:41:32.452198 (ThreadPoolExecutor-0_0): 14:41:32  Opening a new connection, currently in state init
2022-01-06 14:41:32.452284 (ThreadPoolExecutor-0_0): 14:41:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:32.474101 (ThreadPoolExecutor-0_0): 14:41:32  SQL status: SELECT in 0.02 seconds
2022-01-06 14:41:32.475140 (ThreadPoolExecutor-0_0): 14:41:32  On list_dev: Close
2022-01-06 14:41:32.476291 (ThreadPoolExecutor-1_0): 14:41:32  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:41:32.482791 (ThreadPoolExecutor-1_0): 14:41:32  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:41:32.482891 (ThreadPoolExecutor-1_0): 14:41:32  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:41:32.482975 (ThreadPoolExecutor-1_0): 14:41:32  Opening a new connection, currently in state closed
2022-01-06 14:41:32.483060 (ThreadPoolExecutor-1_0): 14:41:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:32.512965 (ThreadPoolExecutor-1_0): 14:41:32  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:41:32.513076 (ThreadPoolExecutor-1_0): 14:41:32  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:41:32.513152 (ThreadPoolExecutor-1_0): 14:41:32  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:41:32.528266 (ThreadPoolExecutor-1_0): 14:41:32  SQL status: SELECT in 0.02 seconds
2022-01-06 14:41:32.529328 (ThreadPoolExecutor-1_0): 14:41:32  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:41:32.531547 (ThreadPoolExecutor-1_0): 14:41:32  On list_dev_dbt_nobodozie: Close
2022-01-06 14:41:32.535112 (MainThread): 14:41:32  Using redshift connection "master"
2022-01-06 14:41:32.535222 (MainThread): 14:41:32  On master: BEGIN
2022-01-06 14:41:32.535302 (MainThread): 14:41:32  Opening a new connection, currently in state init
2022-01-06 14:41:32.535379 (MainThread): 14:41:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:32.561470 (MainThread): 14:41:32  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:41:32.561581 (MainThread): 14:41:32  Using redshift connection "master"
2022-01-06 14:41:32.561669 (MainThread): 14:41:32  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:41:32.593597 (MainThread): 14:41:32  SQL status: SELECT in 0.03 seconds
2022-01-06 14:41:32.594607 (MainThread): 14:41:32  On master: ROLLBACK
2022-01-06 14:41:32.596571 (MainThread): 14:41:32  Using redshift connection "master"
2022-01-06 14:41:32.596691 (MainThread): 14:41:32  On master: BEGIN
2022-01-06 14:41:32.600248 (MainThread): 14:41:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:32.600354 (MainThread): 14:41:32  On master: COMMIT
2022-01-06 14:41:32.600426 (MainThread): 14:41:32  Using redshift connection "master"
2022-01-06 14:41:32.600493 (MainThread): 14:41:32  On master: COMMIT
2022-01-06 14:41:32.602157 (MainThread): 14:41:32  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:41:32.602261 (MainThread): 14:41:32  On master: Close
2022-01-06 14:41:32.602623 (MainThread): 14:41:32  Concurrency: 4 threads (target='default')
2022-01-06 14:41:32.602734 (MainThread): 14:41:32  
2022-01-06 14:41:32.604922 (Thread-1): 14:41:32  Began running node model.my_new_project.dim_customers
2022-01-06 14:41:32.605185 (Thread-1): 14:41:32  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:41:32.605453 (Thread-1): 14:41:32  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:32.605547 (Thread-1): 14:41:32  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:41:32.605645 (Thread-1): 14:41:32  Compiling model.my_new_project.dim_customers
2022-01-06 14:41:32.607828 (Thread-1): 14:41:32  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:41:32.608054 (Thread-2): 14:41:32  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:41:32.608263 (Thread-2): 14:41:32  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:41:32.608569 (Thread-2): 14:41:32  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.608669 (Thread-2): 14:41:32  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:41:32.608751 (Thread-2): 14:41:32  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:41:32.610745 (Thread-2): 14:41:32  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.625473 (Thread-1): 14:41:32  finished collecting timing info
2022-01-06 14:41:32.625629 (Thread-1): 14:41:32  Began executing node model.my_new_project.dim_customers
2022-01-06 14:41:32.630823 (Thread-2): 14:41:32  finished collecting timing info
2022-01-06 14:41:32.656813 (Thread-112): handling poll request
2022-01-06 14:41:32.657159 (Thread-112): 14:41:32  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9808bfa0>]}
2022-01-06 14:41:32.658529 (Thread-112): sending response (<Response 22631 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:41:32.630952 (Thread-2): 14:41:32  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:41:32.681318 (Thread-2): 14:41:32  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.681904 (Thread-1): 14:41:32  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:41:32.696899 (Thread-1): 14:41:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:32.697019 (Thread-1): 14:41:32  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:41:32.697107 (Thread-1): 14:41:32  Opening a new connection, currently in state closed
2022-01-06 14:41:32.697191 (Thread-1): 14:41:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:32.697499 (Thread-2): 14:41:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.697600 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:41:32.697679 (Thread-2): 14:41:32  Opening a new connection, currently in state init
2022-01-06 14:41:32.697757 (Thread-2): 14:41:32  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:32.736497 (Thread-1): 14:41:32  SQL status: BEGIN in 0.04 seconds
2022-01-06 14:41:32.736614 (Thread-1): 14:41:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:32.736692 (Thread-1): 14:41:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:41:32.737487 (Thread-2): 14:41:32  SQL status: BEGIN in 0.04 seconds
2022-01-06 14:41:32.737610 (Thread-2): 14:41:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.737719 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:41:32.836556 (Thread-2): 14:41:32  SQL status: SELECT in 0.1 seconds
2022-01-06 14:41:32.842851 (Thread-2): 14:41:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.842966 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:41:32.856792 (Thread-2): 14:41:32  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:41:32.858760 (Thread-2): 14:41:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.858859 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:41:32.863108 (Thread-2): 14:41:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:41:32.873808 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:41:32.873923 (Thread-2): 14:41:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.873998 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:41:32.908487 (Thread-1): 14:41:32  SQL status: SELECT in 0.17 seconds
2022-01-06 14:41:32.911579 (Thread-1): 14:41:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:32.911679 (Thread-1): 14:41:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:41:32.915209 (Thread-1): 14:41:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:41:32.916884 (Thread-1): 14:41:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:32.916980 (Thread-1): 14:41:32  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:41:32.920420 (Thread-1): 14:41:32  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:41:32.921535 (Thread-1): 14:41:32  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:41:32.921633 (Thread-1): 14:41:32  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:32.921706 (Thread-1): 14:41:32  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:41:32.957869 (Thread-2): 14:41:32  SQL status: COMMIT in 0.08 seconds
2022-01-06 14:41:32.958079 (Thread-2): 14:41:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.958159 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:41:32.959342 (Thread-1): 14:41:32  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:41:32.960754 (Thread-2): 14:41:32  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:32.964790 (Thread-2): 14:41:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.964888 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:41:32.975558 (Thread-2): 14:41:32  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 14:41:32.976183 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:41:32.976277 (Thread-2): 14:41:32  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:32.976350 (Thread-2): 14:41:32  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:41:33.065024 (Thread-2): 14:41:33  SQL status: COMMIT in 0.09 seconds
2022-01-06 14:41:33.065144 (Thread-2): 14:41:33  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:33.065258 (Thread-2): 14:41:33  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:41:33.067933 (Thread-2): 14:41:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:33.068378 (Thread-2): 14:41:33  finished collecting timing info
2022-01-06 14:41:33.068515 (Thread-2): 14:41:33  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:41:33.068736 (Thread-1): 14:41:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:33.068856 (Thread-1): 14:41:33  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:41:33.070763 (Thread-2): 14:41:33  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:41:33.071260 (Thread-2): 14:41:33  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7ac5b96e-f7a0-4351-8399-5ff50478a7a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57cc709040>]}
2022-01-06 14:41:33.071592 (Thread-2): 14:41:33  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.46s]
2022-01-06 14:41:33.071709 (Thread-2): 14:41:33  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:41:33.072296 (Thread-4): 14:41:33  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:41:33.072541 (Thread-4): 14:41:33  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:41:33.072799 (Thread-4): 14:41:33  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.072891 (Thread-4): 14:41:33  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:41:33.072976 (Thread-4): 14:41:33  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:41:33.075042 (Thread-4): 14:41:33  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.075330 (Thread-1): 14:41:33  SQL status: BEGIN in 0.01 seconds
2022-01-06 14:41:33.076544 (Thread-1): 14:41:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:33.076640 (Thread-1): 14:41:33  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:41:33.081552 (Thread-1): 14:41:33  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:41:33.082183 (Thread-1): 14:41:33  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:41:33.082278 (Thread-1): 14:41:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:33.082351 (Thread-1): 14:41:33  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:41:33.089249 (Thread-4): 14:41:33  finished collecting timing info
2022-01-06 14:41:33.089393 (Thread-4): 14:41:33  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:41:33.104833 (Thread-4): 14:41:33  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.117990 (Thread-4): 14:41:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.118095 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:41:33.118177 (Thread-4): 14:41:33  Opening a new connection, currently in state init
2022-01-06 14:41:33.118262 (Thread-4): 14:41:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:33.118577 (Thread-1): 14:41:33  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:41:33.118682 (Thread-1): 14:41:33  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:33.118755 (Thread-1): 14:41:33  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:41:33.121519 (Thread-1): 14:41:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:33.121887 (Thread-1): 14:41:33  finished collecting timing info
2022-01-06 14:41:33.122007 (Thread-1): 14:41:33  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:41:33.127831 (Thread-1): 14:41:33  On model.my_new_project.dim_customers: Close
2022-01-06 14:41:33.128266 (Thread-1): 14:41:33  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7ac5b96e-f7a0-4351-8399-5ff50478a7a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57cc6e9fa0>]}
2022-01-06 14:41:33.128579 (Thread-1): 14:41:33  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.52s]
2022-01-06 14:41:33.128687 (Thread-1): 14:41:33  Finished running node model.my_new_project.dim_customers
2022-01-06 14:41:33.347367 (Thread-4): 14:41:33  SQL status: BEGIN in 0.23 seconds
2022-01-06 14:41:33.347487 (Thread-4): 14:41:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.347567 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:41:33.354370 (Thread-4): 14:41:33  SQL status: CREATE VIEW in 0.01 seconds
2022-01-06 14:41:33.356253 (Thread-4): 14:41:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.356349 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:41:33.359168 (Thread-4): 14:41:33  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:41:33.360111 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:41:33.360205 (Thread-4): 14:41:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.360277 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:41:33.397772 (Thread-4): 14:41:33  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:41:33.397981 (Thread-4): 14:41:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.398064 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:41:33.400960 (Thread-4): 14:41:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:33.402188 (Thread-4): 14:41:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.402282 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:41:33.404981 (Thread-4): 14:41:33  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:41:33.405673 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:41:33.405766 (Thread-4): 14:41:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.405838 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:41:33.442307 (Thread-4): 14:41:33  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:41:33.442417 (Thread-4): 14:41:33  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:33.442494 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:41:33.445235 (Thread-4): 14:41:33  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:33.445607 (Thread-4): 14:41:33  finished collecting timing info
2022-01-06 14:41:33.445728 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:41:33.448151 (Thread-4): 14:41:33  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:41:33.448566 (Thread-4): 14:41:33  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7ac5b96e-f7a0-4351-8399-5ff50478a7a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57cc6d3520>]}
2022-01-06 14:41:33.448855 (Thread-4): 14:41:33  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.38s]
2022-01-06 14:41:33.448976 (Thread-4): 14:41:33  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:41:33.450452 (MainThread): 14:41:33  Acquiring new redshift connection "master"
2022-01-06 14:41:33.450594 (MainThread): 14:41:33  Using redshift connection "master"
2022-01-06 14:41:33.450672 (MainThread): 14:41:33  On master: BEGIN
2022-01-06 14:41:33.450748 (MainThread): 14:41:33  Opening a new connection, currently in state closed
2022-01-06 14:41:33.450825 (MainThread): 14:41:33  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:33.725732 (MainThread): 14:41:33  SQL status: BEGIN in 0.27 seconds
2022-01-06 14:41:33.725860 (MainThread): 14:41:33  On master: COMMIT
2022-01-06 14:41:33.725937 (MainThread): 14:41:33  Using redshift connection "master"
2022-01-06 14:41:33.726009 (MainThread): 14:41:33  On master: COMMIT
2022-01-06 14:41:33.728125 (MainThread): 14:41:33  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:41:33.728234 (MainThread): 14:41:33  On master: Close
2022-01-06 14:41:33.728684 (MainThread): 14:41:33  
2022-01-06 14:41:33.728798 (MainThread): 14:41:33  Finished running 2 table models, 1 view model in 1.29s.
2022-01-06 14:41:33.728908 (MainThread): 14:41:33  Connection 'master' was properly closed.
2022-01-06 14:41:33.729025 (MainThread): 14:41:33  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:41:33.729094 (MainThread): 14:41:33  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:41:33.729155 (MainThread): 14:41:33  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:41:33.778807 (MainThread): 14:41:33  
2022-01-06 14:41:33.778971 (MainThread): 14:41:33  Completed successfully
2022-01-06 14:41:33.779068 (MainThread): 14:41:33  
2022-01-06 14:41:33.779154 (MainThread): 14:41:33  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:41:33.992211 (Thread-113): handling poll request
2022-01-06 14:41:33.992562 (Thread-113): 14:41:33  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9803e6d0>]}
2022-01-06 14:41:33.994865 (Thread-113): sending response (<Response 64564 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:41:34.609939 (Thread-114): handling status request
2022-01-06 14:41:34.610291 (Thread-114): 14:41:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9803e880>]}
2022-01-06 14:41:34.610796 (Thread-114): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:41:34.670665 (Thread-115): handling status request
2022-01-06 14:41:34.670924 (Thread-115): 14:41:34  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9803ec70>]}
2022-01-06 14:41:34.671309 (Thread-115): sending response (<Response 1544 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:41:39.956915 (Thread-116): handling status request
2022-01-06 14:41:39.957317 (Thread-116): 14:41:39  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9803eeb0>]}
2022-01-06 14:41:39.957816 (Thread-116): sending response (<Response 1544 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:41:40.332392 (Thread-117): handling status request
2022-01-06 14:41:40.332710 (Thread-117): 14:41:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980590d0>]}
2022-01-06 14:41:40.333155 (Thread-117): sending response (<Response 1544 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:41:40.351166 (Thread-118): handling cli_args request
2022-01-06 14:41:40.351405 (Thread-118): 14:41:40  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980593d0>]}
2022-01-06 14:41:42.446556 (Thread-118): sending response (<Response 138 bytes [200 OK]>) to 10.0.19.29
2022-01-06 14:41:42.523060 (MainThread): 14:41:42  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:41:42.523445 (MainThread): 14:41:42  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:41:42.529305 (MainThread): 14:41:42  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '37edf41f-893d-4448-9f4e-8d7c35770865', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98db832c70>]}
2022-01-06 14:41:42.563101 (MainThread): 14:41:42  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '37edf41f-893d-4448-9f4e-8d7c35770865', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98db8a8cd0>]}
2022-01-06 14:41:42.563354 (MainThread): 14:41:42  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:41:42.564400 (MainThread): 14:41:42  
2022-01-06 14:41:42.564690 (MainThread): 14:41:42  Acquiring new redshift connection "master"
2022-01-06 14:41:42.565701 (ThreadPoolExecutor-0_0): 14:41:42  Acquiring new redshift connection "list_dev"
2022-01-06 14:41:42.575579 (ThreadPoolExecutor-0_0): 14:41:42  Using redshift connection "list_dev"
2022-01-06 14:41:42.575681 (ThreadPoolExecutor-0_0): 14:41:42  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:41:42.575766 (ThreadPoolExecutor-0_0): 14:41:42  Opening a new connection, currently in state init
2022-01-06 14:41:42.575849 (ThreadPoolExecutor-0_0): 14:41:42  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:42.596528 (ThreadPoolExecutor-0_0): 14:41:42  SQL status: SELECT in 0.02 seconds
2022-01-06 14:41:42.597624 (ThreadPoolExecutor-0_0): 14:41:42  On list_dev: Close
2022-01-06 14:41:42.598877 (ThreadPoolExecutor-1_0): 14:41:42  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:41:42.605431 (ThreadPoolExecutor-1_0): 14:41:42  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:41:42.605531 (ThreadPoolExecutor-1_0): 14:41:42  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:41:42.605613 (ThreadPoolExecutor-1_0): 14:41:42  Opening a new connection, currently in state closed
2022-01-06 14:41:42.605691 (ThreadPoolExecutor-1_0): 14:41:42  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:42.627117 (ThreadPoolExecutor-1_0): 14:41:42  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:41:42.627227 (ThreadPoolExecutor-1_0): 14:41:42  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:41:42.627303 (ThreadPoolExecutor-1_0): 14:41:42  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:41:42.638291 (ThreadPoolExecutor-1_0): 14:41:42  SQL status: SELECT in 0.01 seconds
2022-01-06 14:41:42.639299 (ThreadPoolExecutor-1_0): 14:41:42  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:41:42.641020 (ThreadPoolExecutor-1_0): 14:41:42  On list_dev_dbt_nobodozie: Close
2022-01-06 14:41:42.644642 (MainThread): 14:41:42  Using redshift connection "master"
2022-01-06 14:41:42.644755 (MainThread): 14:41:42  On master: BEGIN
2022-01-06 14:41:42.644835 (MainThread): 14:41:42  Opening a new connection, currently in state init
2022-01-06 14:41:42.644909 (MainThread): 14:41:42  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:42.668933 (MainThread): 14:41:42  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:41:42.669057 (MainThread): 14:41:42  Using redshift connection "master"
2022-01-06 14:41:42.669136 (MainThread): 14:41:42  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:41:42.697857 (MainThread): 14:41:42  SQL status: SELECT in 0.03 seconds
2022-01-06 14:41:42.699145 (MainThread): 14:41:42  On master: ROLLBACK
2022-01-06 14:41:42.701068 (MainThread): 14:41:42  Using redshift connection "master"
2022-01-06 14:41:42.701175 (MainThread): 14:41:42  On master: BEGIN
2022-01-06 14:41:42.704792 (MainThread): 14:41:42  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:42.704897 (MainThread): 14:41:42  On master: COMMIT
2022-01-06 14:41:42.704971 (MainThread): 14:41:42  Using redshift connection "master"
2022-01-06 14:41:42.705045 (MainThread): 14:41:42  On master: COMMIT
2022-01-06 14:41:42.706742 (MainThread): 14:41:42  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:41:42.706853 (MainThread): 14:41:42  On master: Close
2022-01-06 14:41:42.707302 (MainThread): 14:41:42  Concurrency: 4 threads (target='default')
2022-01-06 14:41:42.707421 (MainThread): 14:41:42  
2022-01-06 14:41:42.738778 (Thread-1): 14:41:42  Began running node model.my_new_project.dim_customers
2022-01-06 14:41:42.739057 (Thread-1): 14:41:42  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:41:42.739360 (Thread-1): 14:41:42  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:42.739481 (Thread-1): 14:41:42  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:41:42.739593 (Thread-1): 14:41:42  Compiling model.my_new_project.dim_customers
2022-01-06 14:41:42.742136 (Thread-1): 14:41:42  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:41:42.742400 (Thread-2): 14:41:42  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:41:42.742644 (Thread-2): 14:41:42  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:41:42.742922 (Thread-2): 14:41:42  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.743022 (Thread-2): 14:41:42  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:41:42.743128 (Thread-2): 14:41:42  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:41:42.745436 (Thread-2): 14:41:42  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.758117 (Thread-2): 14:41:42  finished collecting timing info
2022-01-06 14:41:42.758274 (Thread-2): 14:41:42  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:41:42.763525 (Thread-1): 14:41:42  finished collecting timing info
2022-01-06 14:41:42.763665 (Thread-1): 14:41:42  Began executing node model.my_new_project.dim_customers
2022-01-06 14:41:42.815194 (Thread-2): 14:41:42  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.817576 (Thread-1): 14:41:42  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:41:42.829485 (Thread-2): 14:41:42  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.829606 (Thread-2): 14:41:42  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:41:42.829703 (Thread-2): 14:41:42  Opening a new connection, currently in state init
2022-01-06 14:41:42.829789 (Thread-2): 14:41:42  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:42.831583 (Thread-1): 14:41:42  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:42.831700 (Thread-1): 14:41:42  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:41:42.831784 (Thread-1): 14:41:42  Opening a new connection, currently in state closed
2022-01-06 14:41:42.831864 (Thread-1): 14:41:42  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:42.855706 (Thread-2): 14:41:42  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:41:42.855828 (Thread-2): 14:41:42  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.855905 (Thread-2): 14:41:42  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:41:42.856346 (Thread-1): 14:41:42  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:41:42.856473 (Thread-1): 14:41:42  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:42.856552 (Thread-1): 14:41:42  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:41:42.878653 (Thread-119): handling poll request
2022-01-06 14:41:42.879049 (Thread-119): 14:41:42  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff9805f0d0>]}
2022-01-06 14:41:42.880367 (Thread-119): sending response (<Response 30569 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:41:42.928206 (Thread-2): 14:41:42  SQL status: SELECT in 0.07 seconds
2022-01-06 14:41:42.934311 (Thread-2): 14:41:42  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.934421 (Thread-2): 14:41:42  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:41:42.938694 (Thread-2): 14:41:42  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:41:42.940478 (Thread-2): 14:41:42  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.940577 (Thread-2): 14:41:42  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:41:42.944399 (Thread-2): 14:41:42  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:41:42.954628 (Thread-2): 14:41:42  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:41:42.954780 (Thread-2): 14:41:42  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.954857 (Thread-2): 14:41:42  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:41:42.973714 (Thread-1): 14:41:42  SQL status: SELECT in 0.12 seconds
2022-01-06 14:41:42.976552 (Thread-1): 14:41:42  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:42.976649 (Thread-1): 14:41:42  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:41:42.979657 (Thread-1): 14:41:42  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:41:42.981338 (Thread-1): 14:41:42  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:42.981438 (Thread-1): 14:41:42  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:41:42.987929 (Thread-1): 14:41:42  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:41:42.989190 (Thread-1): 14:41:42  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:41:42.989320 (Thread-1): 14:41:42  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:42.989397 (Thread-1): 14:41:42  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:41:42.994784 (Thread-2): 14:41:42  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:41:42.995012 (Thread-2): 14:41:42  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:42.995095 (Thread-2): 14:41:42  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:41:42.997760 (Thread-2): 14:41:42  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:43.001455 (Thread-2): 14:41:43  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:43.001553 (Thread-2): 14:41:43  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:41:43.019871 (Thread-2): 14:41:43  SQL status: DROP TABLE in 0.02 seconds
2022-01-06 14:41:43.020618 (Thread-2): 14:41:43  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:41:43.020715 (Thread-2): 14:41:43  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:43.020790 (Thread-2): 14:41:43  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:41:43.024816 (Thread-1): 14:41:43  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:41:43.048880 (Thread-2): 14:41:43  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:41:43.048991 (Thread-2): 14:41:43  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:41:43.049063 (Thread-2): 14:41:43  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:41:43.051101 (Thread-2): 14:41:43  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:43.051486 (Thread-2): 14:41:43  finished collecting timing info
2022-01-06 14:41:43.051614 (Thread-2): 14:41:43  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:41:43.051812 (Thread-1): 14:41:43  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:43.051919 (Thread-1): 14:41:43  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:41:43.054291 (Thread-1): 14:41:43  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:43.055393 (Thread-1): 14:41:43  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:43.055488 (Thread-1): 14:41:43  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:41:43.055624 (Thread-2): 14:41:43  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:41:43.056131 (Thread-2): 14:41:43  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '37edf41f-893d-4448-9f4e-8d7c35770865', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98d874d040>]}
2022-01-06 14:41:43.056463 (Thread-2): 14:41:43  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.31s]
2022-01-06 14:41:43.056584 (Thread-2): 14:41:43  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:41:43.057173 (Thread-4): 14:41:43  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:41:43.057438 (Thread-4): 14:41:43  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:41:43.057693 (Thread-4): 14:41:43  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.057783 (Thread-4): 14:41:43  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:41:43.057871 (Thread-4): 14:41:43  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:41:43.059840 (Thread-4): 14:41:43  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.064173 (Thread-1): 14:41:43  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 14:41:43.064804 (Thread-1): 14:41:43  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:41:43.064900 (Thread-1): 14:41:43  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:43.064975 (Thread-1): 14:41:43  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:41:43.071155 (Thread-4): 14:41:43  finished collecting timing info
2022-01-06 14:41:43.071294 (Thread-4): 14:41:43  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:41:43.086663 (Thread-4): 14:41:43  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.096626 (Thread-1): 14:41:43  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:41:43.096749 (Thread-1): 14:41:43  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:41:43.096825 (Thread-1): 14:41:43  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:41:43.098921 (Thread-1): 14:41:43  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:43.099281 (Thread-1): 14:41:43  finished collecting timing info
2022-01-06 14:41:43.099415 (Thread-1): 14:41:43  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:41:43.101181 (Thread-1): 14:41:43  On model.my_new_project.dim_customers: Close
2022-01-06 14:41:43.101609 (Thread-1): 14:41:43  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '37edf41f-893d-4448-9f4e-8d7c35770865', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98d8769370>]}
2022-01-06 14:41:43.101898 (Thread-1): 14:41:43  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.36s]
2022-01-06 14:41:43.102005 (Thread-1): 14:41:43  Finished running node model.my_new_project.dim_customers
2022-01-06 14:41:43.103454 (Thread-4): 14:41:43  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.103571 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:41:43.103658 (Thread-4): 14:41:43  Opening a new connection, currently in state init
2022-01-06 14:41:43.103741 (Thread-4): 14:41:43  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:43.125958 (Thread-4): 14:41:43  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:41:43.126072 (Thread-4): 14:41:43  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.126149 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:41:43.130812 (Thread-4): 14:41:43  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:41:43.132593 (Thread-4): 14:41:43  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.132687 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:41:43.134780 (Thread-4): 14:41:43  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:41:43.135673 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:41:43.135770 (Thread-4): 14:41:43  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.135843 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:41:43.165387 (Thread-4): 14:41:43  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:41:43.165592 (Thread-4): 14:41:43  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.165673 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:41:43.167780 (Thread-4): 14:41:43  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:43.169010 (Thread-4): 14:41:43  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.169110 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:41:43.171022 (Thread-4): 14:41:43  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:41:43.171696 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:41:43.171789 (Thread-4): 14:41:43  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.171862 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:41:43.196297 (Thread-4): 14:41:43  SQL status: COMMIT in 0.02 seconds
2022-01-06 14:41:43.196402 (Thread-4): 14:41:43  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:41:43.196472 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:41:43.198465 (Thread-4): 14:41:43  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:41:43.198804 (Thread-4): 14:41:43  finished collecting timing info
2022-01-06 14:41:43.198921 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:41:43.200657 (Thread-4): 14:41:43  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:41:43.201022 (Thread-4): 14:41:43  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '37edf41f-893d-4448-9f4e-8d7c35770865', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98dafef190>]}
2022-01-06 14:41:43.201331 (Thread-4): 14:41:43  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.14s]
2022-01-06 14:41:43.201438 (Thread-4): 14:41:43  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:41:43.202737 (MainThread): 14:41:43  Acquiring new redshift connection "master"
2022-01-06 14:41:43.202873 (MainThread): 14:41:43  Using redshift connection "master"
2022-01-06 14:41:43.202948 (MainThread): 14:41:43  On master: BEGIN
2022-01-06 14:41:43.203026 (MainThread): 14:41:43  Opening a new connection, currently in state closed
2022-01-06 14:41:43.203101 (MainThread): 14:41:43  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:41:43.226549 (MainThread): 14:41:43  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:41:43.226667 (MainThread): 14:41:43  On master: COMMIT
2022-01-06 14:41:43.226743 (MainThread): 14:41:43  Using redshift connection "master"
2022-01-06 14:41:43.226812 (MainThread): 14:41:43  On master: COMMIT
2022-01-06 14:41:43.228636 (MainThread): 14:41:43  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:41:43.228738 (MainThread): 14:41:43  On master: Close
2022-01-06 14:41:43.229116 (MainThread): 14:41:43  
2022-01-06 14:41:43.229261 (MainThread): 14:41:43  Finished running 2 table models, 1 view model in 0.66s.
2022-01-06 14:41:43.229348 (MainThread): 14:41:43  Connection 'master' was properly closed.
2022-01-06 14:41:43.229415 (MainThread): 14:41:43  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:41:43.229479 (MainThread): 14:41:43  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:41:43.229539 (MainThread): 14:41:43  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:41:43.274478 (MainThread): 14:41:43  
2022-01-06 14:41:43.274627 (MainThread): 14:41:43  Completed successfully
2022-01-06 14:41:43.274722 (MainThread): 14:41:43  
2022-01-06 14:41:43.274808 (MainThread): 14:41:43  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:41:44.289370 (Thread-120): handling poll request
2022-01-06 14:41:44.289740 (Thread-120): 14:41:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff783deb80>]}
2022-01-06 14:41:44.291762 (Thread-120): sending response (<Response 56626 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:41:44.912347 (Thread-121): handling status request
2022-01-06 14:41:44.912705 (Thread-121): 14:41:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff783ded30>]}
2022-01-06 14:41:44.913245 (Thread-121): sending response (<Response 1544 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:41:44.935944 (Thread-122): handling status request
2022-01-06 14:41:44.936204 (Thread-122): 14:41:44  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff783e60a0>]}
2022-01-06 14:41:44.936576 (Thread-122): sending response (<Response 1544 bytes [200 OK]>) to 10.0.21.176
2022-01-06 14:41:58.692866 (Thread-123): handling status request
2022-01-06 14:41:58.693288 (Thread-123): 14:41:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff783e63a0>]}
2022-01-06 14:41:58.693836 (Thread-123): sending response (<Response 1544 bytes [200 OK]>) to 10.0.26.129
2022-01-06 14:41:58.825934 (Thread-124): handling status request
2022-01-06 14:41:58.826240 (Thread-124): 14:41:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff783e6610>]}
2022-01-06 14:41:58.826715 (Thread-124): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:41:59.039660 (Thread-125): handling cli_args request
2022-01-06 14:41:59.040007 (Thread-125): 14:41:59  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff783e6880>]}
2022-01-06 14:42:01.143006 (Thread-125): sending response (<Response 138 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:42:01.222302 (MainThread): 14:42:01  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:42:01.222699 (MainThread): 14:42:01  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:42:01.228403 (MainThread): 14:42:01  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '93e223e9-6153-4e75-9589-589c0a8168b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50dd052c70>]}
2022-01-06 14:42:01.255517 (MainThread): 14:42:01  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '93e223e9-6153-4e75-9589-589c0a8168b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50dd0c9cd0>]}
2022-01-06 14:42:01.255753 (MainThread): 14:42:01  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:42:01.256765 (MainThread): 14:42:01  
2022-01-06 14:42:01.257027 (MainThread): 14:42:01  Acquiring new redshift connection "master"
2022-01-06 14:42:01.258028 (ThreadPoolExecutor-0_0): 14:42:01  Acquiring new redshift connection "list_dev"
2022-01-06 14:42:01.267714 (ThreadPoolExecutor-0_0): 14:42:01  Using redshift connection "list_dev"
2022-01-06 14:42:01.267814 (ThreadPoolExecutor-0_0): 14:42:01  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:42:01.268055 (ThreadPoolExecutor-0_0): 14:42:01  Opening a new connection, currently in state init
2022-01-06 14:42:01.268142 (ThreadPoolExecutor-0_0): 14:42:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:01.289092 (ThreadPoolExecutor-0_0): 14:42:01  SQL status: SELECT in 0.02 seconds
2022-01-06 14:42:01.290148 (ThreadPoolExecutor-0_0): 14:42:01  On list_dev: Close
2022-01-06 14:42:01.291303 (ThreadPoolExecutor-1_0): 14:42:01  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:42:01.297743 (ThreadPoolExecutor-1_0): 14:42:01  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:42:01.297842 (ThreadPoolExecutor-1_0): 14:42:01  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:42:01.297920 (ThreadPoolExecutor-1_0): 14:42:01  Opening a new connection, currently in state closed
2022-01-06 14:42:01.297995 (ThreadPoolExecutor-1_0): 14:42:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:01.320366 (ThreadPoolExecutor-1_0): 14:42:01  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:01.320478 (ThreadPoolExecutor-1_0): 14:42:01  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:42:01.320555 (ThreadPoolExecutor-1_0): 14:42:01  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:42:01.331448 (ThreadPoolExecutor-1_0): 14:42:01  SQL status: SELECT in 0.01 seconds
2022-01-06 14:42:01.332420 (ThreadPoolExecutor-1_0): 14:42:01  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:42:01.334169 (ThreadPoolExecutor-1_0): 14:42:01  On list_dev_dbt_nobodozie: Close
2022-01-06 14:42:01.337754 (MainThread): 14:42:01  Using redshift connection "master"
2022-01-06 14:42:01.337866 (MainThread): 14:42:01  On master: BEGIN
2022-01-06 14:42:01.337945 (MainThread): 14:42:01  Opening a new connection, currently in state init
2022-01-06 14:42:01.338020 (MainThread): 14:42:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:01.361323 (MainThread): 14:42:01  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:01.361434 (MainThread): 14:42:01  Using redshift connection "master"
2022-01-06 14:42:01.361509 (MainThread): 14:42:01  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:42:01.389947 (MainThread): 14:42:01  SQL status: SELECT in 0.03 seconds
2022-01-06 14:42:01.391037 (MainThread): 14:42:01  On master: ROLLBACK
2022-01-06 14:42:01.392960 (MainThread): 14:42:01  Using redshift connection "master"
2022-01-06 14:42:01.393058 (MainThread): 14:42:01  On master: BEGIN
2022-01-06 14:42:01.396533 (MainThread): 14:42:01  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:01.396647 (MainThread): 14:42:01  On master: COMMIT
2022-01-06 14:42:01.396719 (MainThread): 14:42:01  Using redshift connection "master"
2022-01-06 14:42:01.396787 (MainThread): 14:42:01  On master: COMMIT
2022-01-06 14:42:01.398507 (MainThread): 14:42:01  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:42:01.398614 (MainThread): 14:42:01  On master: Close
2022-01-06 14:42:01.398979 (MainThread): 14:42:01  Concurrency: 4 threads (target='default')
2022-01-06 14:42:01.399089 (MainThread): 14:42:01  
2022-01-06 14:42:01.401355 (Thread-1): 14:42:01  Began running node model.my_new_project.dim_customers
2022-01-06 14:42:01.401587 (Thread-1): 14:42:01  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:42:01.401812 (Thread-1): 14:42:01  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.401901 (Thread-1): 14:42:01  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:42:01.401985 (Thread-1): 14:42:01  Compiling model.my_new_project.dim_customers
2022-01-06 14:42:01.403992 (Thread-1): 14:42:01  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:42:01.404218 (Thread-2): 14:42:01  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:42:01.404439 (Thread-2): 14:42:01  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:42:01.404678 (Thread-2): 14:42:01  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.404762 (Thread-2): 14:42:01  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:42:01.404841 (Thread-2): 14:42:01  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:42:01.406821 (Thread-2): 14:42:01  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.418338 (Thread-1): 14:42:01  finished collecting timing info
2022-01-06 14:42:01.418479 (Thread-1): 14:42:01  Began executing node model.my_new_project.dim_customers
2022-01-06 14:42:01.423671 (Thread-2): 14:42:01  finished collecting timing info
2022-01-06 14:42:01.423802 (Thread-2): 14:42:01  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:42:01.476715 (Thread-1): 14:42:01  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:42:01.477030 (Thread-2): 14:42:01  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.488457 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.488566 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:42:01.488645 (Thread-2): 14:42:01  Opening a new connection, currently in state init
2022-01-06 14:42:01.488720 (Thread-2): 14:42:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:01.489137 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.489274 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:42:01.489356 (Thread-1): 14:42:01  Opening a new connection, currently in state closed
2022-01-06 14:42:01.489430 (Thread-1): 14:42:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:01.513521 (Thread-2): 14:42:01  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:01.513635 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.513713 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:42:01.514859 (Thread-1): 14:42:01  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:42:01.514980 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.515057 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:42:01.591407 (Thread-2): 14:42:01  SQL status: SELECT in 0.08 seconds
2022-01-06 14:42:01.597494 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.597614 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:42:01.602447 (Thread-2): 14:42:01  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:42:01.604359 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.604461 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:42:01.607707 (Thread-2): 14:42:01  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:42:01.618087 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:42:01.619531 (Thread-126): handling poll request
2022-01-06 14:42:01.618211 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.620110 (Thread-126): 14:42:01  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7839f2e0>]}
2022-01-06 14:42:01.618289 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:42:01.673508 (Thread-1): 14:42:01  SQL status: SELECT in 0.16 seconds
2022-01-06 14:42:01.676771 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.676882 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:42:01.684808 (Thread-1): 14:42:01  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:42:01.686640 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.686737 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:42:01.691648 (Thread-2): 14:42:01  SQL status: COMMIT in 0.07 seconds
2022-01-06 14:42:01.691883 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.691967 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:42:01.692123 (Thread-1): 14:42:01  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:42:01.693298 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:42:01.693396 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.693469 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:42:01.694093 (Thread-2): 14:42:01  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:01.698214 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.698327 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:42:01.723746 (Thread-2): 14:42:01  SQL status: DROP TABLE in 0.03 seconds
2022-01-06 14:42:01.724358 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:42:01.724451 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.724524 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:42:01.726791 (Thread-1): 14:42:01  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:42:01.752909 (Thread-2): 14:42:01  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:42:01.753022 (Thread-2): 14:42:01  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:01.753095 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:42:01.755179 (Thread-2): 14:42:01  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:01.755580 (Thread-2): 14:42:01  finished collecting timing info
2022-01-06 14:42:01.755708 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:42:01.755912 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.756024 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:42:01.758236 (Thread-1): 14:42:01  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:01.759696 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.759807 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:42:01.759999 (Thread-2): 14:42:01  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:42:01.760467 (Thread-2): 14:42:01  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '93e223e9-6153-4e75-9589-589c0a8168b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50dc796b80>]}
2022-01-06 14:42:01.760799 (Thread-2): 14:42:01  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.36s]
2022-01-06 14:42:01.760914 (Thread-2): 14:42:01  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:42:01.761544 (Thread-4): 14:42:01  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:42:01.761788 (Thread-4): 14:42:01  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:42:01.762040 (Thread-4): 14:42:01  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.762126 (Thread-4): 14:42:01  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:42:01.762211 (Thread-4): 14:42:01  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:42:01.764223 (Thread-4): 14:42:01  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.764618 (Thread-1): 14:42:01  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:42:01.765290 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:42:01.765391 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.765468 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:42:01.780529 (Thread-4): 14:42:01  finished collecting timing info
2022-01-06 14:42:01.780668 (Thread-4): 14:42:01  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:42:01.796077 (Thread-4): 14:42:01  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.798730 (Thread-1): 14:42:01  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:42:01.798852 (Thread-1): 14:42:01  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:01.798928 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:42:01.801001 (Thread-1): 14:42:01  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:01.801397 (Thread-1): 14:42:01  finished collecting timing info
2022-01-06 14:42:01.801520 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:42:01.803249 (Thread-1): 14:42:01  On model.my_new_project.dim_customers: Close
2022-01-06 14:42:01.803689 (Thread-1): 14:42:01  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '93e223e9-6153-4e75-9589-589c0a8168b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50dc771100>]}
2022-01-06 14:42:01.803983 (Thread-1): 14:42:01  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.40s]
2022-01-06 14:42:01.804165 (Thread-1): 14:42:01  Finished running node model.my_new_project.dim_customers
2022-01-06 14:42:01.810413 (Thread-4): 14:42:01  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.810524 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:42:01.810609 (Thread-4): 14:42:01  Opening a new connection, currently in state init
2022-01-06 14:42:01.810687 (Thread-4): 14:42:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:01.830386 (Thread-126): sending response (<Response 58759 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:42:01.833371 (Thread-4): 14:42:01  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:01.833492 (Thread-4): 14:42:01  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.833570 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:42:01.838400 (Thread-4): 14:42:01  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:42:01.840391 (Thread-4): 14:42:01  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.840489 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:42:01.842614 (Thread-4): 14:42:01  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:42:01.843580 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:42:01.843675 (Thread-4): 14:42:01  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.843747 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:42:01.874605 (Thread-4): 14:42:01  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:42:01.874832 (Thread-4): 14:42:01  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.874913 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:42:01.877088 (Thread-4): 14:42:01  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:01.878463 (Thread-4): 14:42:01  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.878561 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:42:01.880618 (Thread-4): 14:42:01  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:42:01.881355 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:42:01.881450 (Thread-4): 14:42:01  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.881525 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:42:01.906618 (Thread-4): 14:42:01  SQL status: COMMIT in 0.02 seconds
2022-01-06 14:42:01.906732 (Thread-4): 14:42:01  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:01.906804 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:42:01.908922 (Thread-4): 14:42:01  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:01.909351 (Thread-4): 14:42:01  finished collecting timing info
2022-01-06 14:42:01.909480 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:42:01.911270 (Thread-4): 14:42:01  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:42:01.911713 (Thread-4): 14:42:01  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '93e223e9-6153-4e75-9589-589c0a8168b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50dc7621f0>]}
2022-01-06 14:42:01.912033 (Thread-4): 14:42:01  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.15s]
2022-01-06 14:42:01.912143 (Thread-4): 14:42:01  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:42:01.913538 (MainThread): 14:42:01  Acquiring new redshift connection "master"
2022-01-06 14:42:01.913683 (MainThread): 14:42:01  Using redshift connection "master"
2022-01-06 14:42:01.913760 (MainThread): 14:42:01  On master: BEGIN
2022-01-06 14:42:01.913836 (MainThread): 14:42:01  Opening a new connection, currently in state closed
2022-01-06 14:42:01.913914 (MainThread): 14:42:01  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:01.938191 (MainThread): 14:42:01  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:01.938323 (MainThread): 14:42:01  On master: COMMIT
2022-01-06 14:42:01.938400 (MainThread): 14:42:01  Using redshift connection "master"
2022-01-06 14:42:01.938471 (MainThread): 14:42:01  On master: COMMIT
2022-01-06 14:42:01.940199 (MainThread): 14:42:01  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:42:01.940302 (MainThread): 14:42:01  On master: Close
2022-01-06 14:42:01.940709 (MainThread): 14:42:01  
2022-01-06 14:42:01.940836 (MainThread): 14:42:01  Finished running 2 table models, 1 view model in 0.68s.
2022-01-06 14:42:01.940916 (MainThread): 14:42:01  Connection 'master' was properly closed.
2022-01-06 14:42:01.940982 (MainThread): 14:42:01  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:42:01.941043 (MainThread): 14:42:01  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:42:01.941101 (MainThread): 14:42:01  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:42:01.986607 (MainThread): 14:42:01  
2022-01-06 14:42:01.986786 (MainThread): 14:42:01  Completed successfully
2022-01-06 14:42:01.986883 (MainThread): 14:42:01  
2022-01-06 14:42:01.986966 (MainThread): 14:42:01  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:42:03.230299 (Thread-127): handling poll request
2022-01-06 14:42:03.230673 (Thread-127): 14:42:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7833e400>]}
2022-01-06 14:42:03.232024 (Thread-127): sending response (<Response 28436 bytes [200 OK]>) to 10.0.5.191
2022-01-06 14:42:03.878873 (Thread-128): handling status request
2022-01-06 14:42:03.879237 (Thread-128): 14:42:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7833e5b0>]}
2022-01-06 14:42:03.879741 (Thread-128): sending response (<Response 1544 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:42:03.947033 (Thread-129): handling status request
2022-01-06 14:42:03.947393 (Thread-129): 14:42:03  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7833e9a0>]}
2022-01-06 14:42:03.947936 (Thread-129): sending response (<Response 1544 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:42:10.235495 (Thread-130): handling status request
2022-01-06 14:42:10.235858 (Thread-130): 14:42:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7833ebe0>]}
2022-01-06 14:42:10.236327 (Thread-130): sending response (<Response 1544 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:42:10.484283 (Thread-131): handling status request
2022-01-06 14:42:10.484608 (Thread-131): 14:42:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7833ee50>]}
2022-01-06 14:42:10.485056 (Thread-131): sending response (<Response 1544 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:42:10.645366 (Thread-132): handling cli_args request
2022-01-06 14:42:10.645704 (Thread-132): 14:42:10  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78349100>]}
2022-01-06 14:42:12.686467 (Thread-132): sending response (<Response 138 bytes [200 OK]>) to 10.0.5.191
2022-01-06 14:42:12.760900 (MainThread): 14:42:12  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:42:12.761329 (MainThread): 14:42:12  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:42:12.767662 (MainThread): 14:42:12  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '112add87-861b-4fcf-a1fb-571d514a8d12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6450f88df0>]}
2022-01-06 14:42:12.793386 (MainThread): 14:42:12  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '112add87-861b-4fcf-a1fb-571d514a8d12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6450ffedc0>]}
2022-01-06 14:42:12.793626 (MainThread): 14:42:12  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:42:12.794658 (MainThread): 14:42:12  
2022-01-06 14:42:12.794927 (MainThread): 14:42:12  Acquiring new redshift connection "master"
2022-01-06 14:42:12.795874 (ThreadPoolExecutor-0_0): 14:42:12  Acquiring new redshift connection "list_dev"
2022-01-06 14:42:12.805577 (ThreadPoolExecutor-0_0): 14:42:12  Using redshift connection "list_dev"
2022-01-06 14:42:12.805678 (ThreadPoolExecutor-0_0): 14:42:12  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:42:12.805759 (ThreadPoolExecutor-0_0): 14:42:12  Opening a new connection, currently in state init
2022-01-06 14:42:12.805838 (ThreadPoolExecutor-0_0): 14:42:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:12.826438 (ThreadPoolExecutor-0_0): 14:42:12  SQL status: SELECT in 0.02 seconds
2022-01-06 14:42:12.827457 (ThreadPoolExecutor-0_0): 14:42:12  On list_dev: Close
2022-01-06 14:42:12.828676 (ThreadPoolExecutor-1_0): 14:42:12  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:42:12.835147 (ThreadPoolExecutor-1_0): 14:42:12  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:42:12.835246 (ThreadPoolExecutor-1_0): 14:42:12  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:42:12.835325 (ThreadPoolExecutor-1_0): 14:42:12  Opening a new connection, currently in state closed
2022-01-06 14:42:12.835403 (ThreadPoolExecutor-1_0): 14:42:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:12.857880 (ThreadPoolExecutor-1_0): 14:42:12  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:12.857990 (ThreadPoolExecutor-1_0): 14:42:12  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:42:12.858065 (ThreadPoolExecutor-1_0): 14:42:12  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:42:12.868392 (ThreadPoolExecutor-1_0): 14:42:12  SQL status: SELECT in 0.01 seconds
2022-01-06 14:42:12.869460 (ThreadPoolExecutor-1_0): 14:42:12  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:42:12.871216 (ThreadPoolExecutor-1_0): 14:42:12  On list_dev_dbt_nobodozie: Close
2022-01-06 14:42:12.874868 (MainThread): 14:42:12  Using redshift connection "master"
2022-01-06 14:42:12.874980 (MainThread): 14:42:12  On master: BEGIN
2022-01-06 14:42:12.875059 (MainThread): 14:42:12  Opening a new connection, currently in state init
2022-01-06 14:42:12.875134 (MainThread): 14:42:12  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:12.898508 (MainThread): 14:42:12  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:12.898619 (MainThread): 14:42:12  Using redshift connection "master"
2022-01-06 14:42:12.898696 (MainThread): 14:42:12  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:42:12.927255 (MainThread): 14:42:12  SQL status: SELECT in 0.03 seconds
2022-01-06 14:42:12.928214 (MainThread): 14:42:12  On master: ROLLBACK
2022-01-06 14:42:12.930023 (MainThread): 14:42:12  Using redshift connection "master"
2022-01-06 14:42:12.930123 (MainThread): 14:42:12  On master: BEGIN
2022-01-06 14:42:12.933568 (MainThread): 14:42:12  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:12.933680 (MainThread): 14:42:12  On master: COMMIT
2022-01-06 14:42:12.933751 (MainThread): 14:42:12  Using redshift connection "master"
2022-01-06 14:42:12.933818 (MainThread): 14:42:12  On master: COMMIT
2022-01-06 14:42:12.935516 (MainThread): 14:42:12  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:42:12.935618 (MainThread): 14:42:12  On master: Close
2022-01-06 14:42:12.935975 (MainThread): 14:42:12  Concurrency: 4 threads (target='default')
2022-01-06 14:42:12.936088 (MainThread): 14:42:12  
2022-01-06 14:42:12.938324 (Thread-1): 14:42:12  Began running node model.my_new_project.dim_customers
2022-01-06 14:42:12.938559 (Thread-1): 14:42:12  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:42:12.938783 (Thread-1): 14:42:12  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:12.938874 (Thread-1): 14:42:12  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:42:12.938973 (Thread-1): 14:42:12  Compiling model.my_new_project.dim_customers
2022-01-06 14:42:12.940958 (Thread-1): 14:42:12  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:42:12.941179 (Thread-2): 14:42:12  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:42:12.941418 (Thread-2): 14:42:12  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:42:12.941656 (Thread-2): 14:42:12  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:12.941742 (Thread-2): 14:42:12  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:42:12.941822 (Thread-2): 14:42:12  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:42:12.943756 (Thread-2): 14:42:12  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:12.955990 (Thread-2): 14:42:12  finished collecting timing info
2022-01-06 14:42:12.956126 (Thread-2): 14:42:12  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:42:12.967978 (Thread-1): 14:42:12  finished collecting timing info
2022-01-06 14:42:12.968104 (Thread-1): 14:42:12  Began executing node model.my_new_project.dim_customers
2022-01-06 14:42:13.009607 (Thread-2): 14:42:13  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.010479 (Thread-1): 14:42:13  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:42:13.023666 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.023779 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:42:13.023861 (Thread-2): 14:42:13  Opening a new connection, currently in state init
2022-01-06 14:42:13.023942 (Thread-2): 14:42:13  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:13.024184 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.024284 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:42:13.024362 (Thread-1): 14:42:13  Opening a new connection, currently in state closed
2022-01-06 14:42:13.024438 (Thread-1): 14:42:13  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:13.049561 (Thread-2): 14:42:13  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:42:13.049674 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.049752 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:42:13.049915 (Thread-1): 14:42:13  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:42:13.050025 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.050101 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:42:13.118096 (Thread-2): 14:42:13  SQL status: SELECT in 0.07 seconds
2022-01-06 14:42:13.123598 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.123823 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:42:13.132710 (Thread-2): 14:42:13  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:42:13.134542 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.134638 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:42:13.138166 (Thread-2): 14:42:13  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:42:13.148315 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:42:13.148496 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.148626 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:42:13.162983 (Thread-133): handling poll request
2022-01-06 14:42:13.163614 (Thread-133): 14:42:13  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78349700>]}
2022-01-06 14:42:13.165207 (Thread-133): sending response (<Response 34593 bytes [200 OK]>) to 10.0.35.184
2022-01-06 14:42:13.162451 (Thread-1): 14:42:13  SQL status: SELECT in 0.11 seconds
2022-01-06 14:42:13.165193 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.165350 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:42:13.168681 (Thread-1): 14:42:13  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:42:13.170318 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.170412 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:42:13.173761 (Thread-1): 14:42:13  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:42:13.174849 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:42:13.174944 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.175015 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:42:13.213323 (Thread-2): 14:42:13  SQL status: COMMIT in 0.06 seconds
2022-01-06 14:42:13.213534 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.213617 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:42:13.213833 (Thread-1): 14:42:13  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:42:13.216101 (Thread-2): 14:42:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:13.220013 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.220109 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:42:13.225638 (Thread-2): 14:42:13  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 14:42:13.226252 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:42:13.226345 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.226419 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:42:13.257945 (Thread-2): 14:42:13  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:42:13.258059 (Thread-2): 14:42:13  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:42:13.258134 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:42:13.260121 (Thread-2): 14:42:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:13.260513 (Thread-2): 14:42:13  finished collecting timing info
2022-01-06 14:42:13.260639 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:42:13.260836 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.260942 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:42:13.263688 (Thread-2): 14:42:13  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:42:13.263896 (Thread-1): 14:42:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:13.265853 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.265989 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:42:13.266649 (Thread-2): 14:42:13  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '112add87-861b-4fcf-a1fb-571d514a8d12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64506cb8b0>]}
2022-01-06 14:42:13.267025 (Thread-2): 14:42:13  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.33s]
2022-01-06 14:42:13.267143 (Thread-2): 14:42:13  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:42:13.267794 (Thread-4): 14:42:13  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:42:13.268023 (Thread-4): 14:42:13  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:42:13.268275 (Thread-4): 14:42:13  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.268381 (Thread-4): 14:42:13  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:42:13.268466 (Thread-4): 14:42:13  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:42:13.270451 (Thread-4): 14:42:13  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.272519 (Thread-1): 14:42:13  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 14:42:13.273150 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:42:13.273281 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.273361 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:42:13.282176 (Thread-4): 14:42:13  finished collecting timing info
2022-01-06 14:42:13.282320 (Thread-4): 14:42:13  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:42:13.297820 (Thread-4): 14:42:13  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.305403 (Thread-1): 14:42:13  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:42:13.305520 (Thread-1): 14:42:13  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:42:13.305593 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:42:13.307601 (Thread-1): 14:42:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:13.307957 (Thread-1): 14:42:13  finished collecting timing info
2022-01-06 14:42:13.308078 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:42:13.309889 (Thread-1): 14:42:13  On model.my_new_project.dim_customers: Close
2022-01-06 14:42:13.310305 (Thread-1): 14:42:13  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '112add87-861b-4fcf-a1fb-571d514a8d12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64506d3970>]}
2022-01-06 14:42:13.310601 (Thread-1): 14:42:13  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.37s]
2022-01-06 14:42:13.310708 (Thread-1): 14:42:13  Finished running node model.my_new_project.dim_customers
2022-01-06 14:42:13.310989 (Thread-4): 14:42:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.311097 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:42:13.311179 (Thread-4): 14:42:13  Opening a new connection, currently in state init
2022-01-06 14:42:13.311260 (Thread-4): 14:42:13  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:13.335647 (Thread-4): 14:42:13  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:13.335758 (Thread-4): 14:42:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.335835 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:42:13.340599 (Thread-4): 14:42:13  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:42:13.342449 (Thread-4): 14:42:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.342544 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:42:13.344742 (Thread-4): 14:42:13  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:42:13.345679 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:42:13.345774 (Thread-4): 14:42:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.345847 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:42:13.372991 (Thread-4): 14:42:13  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:42:13.373236 (Thread-4): 14:42:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.373324 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:42:13.375367 (Thread-4): 14:42:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:13.376662 (Thread-4): 14:42:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.376759 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:42:13.378621 (Thread-4): 14:42:13  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:42:13.379298 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:42:13.379393 (Thread-4): 14:42:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.379466 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:42:13.403722 (Thread-4): 14:42:13  SQL status: COMMIT in 0.02 seconds
2022-01-06 14:42:13.403848 (Thread-4): 14:42:13  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:42:13.403922 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:42:13.405907 (Thread-4): 14:42:13  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:42:13.406345 (Thread-4): 14:42:13  finished collecting timing info
2022-01-06 14:42:13.406477 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:42:13.408256 (Thread-4): 14:42:13  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:42:13.408727 (Thread-4): 14:42:13  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '112add87-861b-4fcf-a1fb-571d514a8d12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64507087c0>]}
2022-01-06 14:42:13.409064 (Thread-4): 14:42:13  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.14s]
2022-01-06 14:42:13.409176 (Thread-4): 14:42:13  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:42:13.410793 (MainThread): 14:42:13  Acquiring new redshift connection "master"
2022-01-06 14:42:13.410989 (MainThread): 14:42:13  Using redshift connection "master"
2022-01-06 14:42:13.411107 (MainThread): 14:42:13  On master: BEGIN
2022-01-06 14:42:13.411219 (MainThread): 14:42:13  Opening a new connection, currently in state closed
2022-01-06 14:42:13.411336 (MainThread): 14:42:13  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:13.434808 (MainThread): 14:42:13  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:42:13.435016 (MainThread): 14:42:13  On master: COMMIT
2022-01-06 14:42:13.435152 (MainThread): 14:42:13  Using redshift connection "master"
2022-01-06 14:42:13.435274 (MainThread): 14:42:13  On master: COMMIT
2022-01-06 14:42:13.437137 (MainThread): 14:42:13  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:42:13.437350 (MainThread): 14:42:13  On master: Close
2022-01-06 14:42:13.438056 (MainThread): 14:42:13  
2022-01-06 14:42:13.438238 (MainThread): 14:42:13  Finished running 2 table models, 1 view model in 0.64s.
2022-01-06 14:42:13.438401 (MainThread): 14:42:13  Connection 'master' was properly closed.
2022-01-06 14:42:13.438529 (MainThread): 14:42:13  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:42:13.438642 (MainThread): 14:42:13  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:42:13.438756 (MainThread): 14:42:13  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:42:13.484833 (MainThread): 14:42:13  
2022-01-06 14:42:13.485029 (MainThread): 14:42:13  Completed successfully
2022-01-06 14:42:13.485124 (MainThread): 14:42:13  
2022-01-06 14:42:13.485208 (MainThread): 14:42:13  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:42:14.655202 (Thread-134): handling poll request
2022-01-06 14:42:14.655582 (Thread-134): 14:42:14  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff980898e0>]}
2022-01-06 14:42:14.657634 (Thread-134): sending response (<Response 52595 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:42:15.416064 (Thread-135): handling status request
2022-01-06 14:42:15.416433 (Thread-135): 14:42:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff98089280>]}
2022-01-06 14:42:15.416957 (Thread-135): sending response (<Response 1544 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:42:15.494602 (Thread-136): handling status request
2022-01-06 14:42:15.494869 (Thread-136): 14:42:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8038f40>]}
2022-01-06 14:42:15.495261 (Thread-136): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:42:55.299432 (Thread-137): handling status request
2022-01-06 14:42:55.299798 (Thread-137): 14:42:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb803dbe0>]}
2022-01-06 14:42:55.300274 (Thread-137): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:42:55.620557 (Thread-138): handling run_sql request
2022-01-06 14:42:55.620868 (Thread-138): 14:42:55  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8546220>]}
2022-01-06 14:42:57.661375 (Thread-138): sending response (<Response 138 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:42:57.685069 (MainThread): 14:42:57  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7d49e94f-fee3-4846-8467-9d3e06eed911', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa29ef49820>]}
2022-01-06 14:42:57.685605 (MainThread): 14:42:57  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:42:57.686157 (Thread-1): 14:42:57  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:42:57.686284 (Thread-1): 14:42:57  Began compiling node rpc.my_new_project.request
2022-01-06 14:42:57.686374 (Thread-1): 14:42:57  Compiling rpc.my_new_project.request
2022-01-06 14:42:57.687511 (Thread-1): 14:42:57  finished collecting timing info
2022-01-06 14:42:57.687638 (Thread-1): 14:42:57  Began executing node rpc.my_new_project.request
2022-01-06 14:42:57.687732 (Thread-1): 14:42:57  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:42:57.687813 (Thread-1): 14:42:57  On rpc.my_new_project.request: with orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

)
select * from orders
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:42:57.687891 (Thread-1): 14:42:57  Opening a new connection, currently in state init
2022-01-06 14:42:57.687976 (Thread-1): 14:42:57  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:42:57.710055 (Thread-1): 14:42:57  SQL status: SELECT in 0.02 seconds
2022-01-06 14:42:57.712513 (Thread-1): 14:42:57  finished collecting timing info
2022-01-06 14:42:57.712645 (Thread-1): 14:42:57  On rpc.my_new_project.request: Close
2022-01-06 14:42:58.017277 (Thread-139): handling poll request
2022-01-06 14:42:58.017712 (Thread-139): 14:42:58  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78350640>]}
2022-01-06 14:42:58.019247 (Thread-139): sending response (<Response 11838 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:44:53.204225 (Thread-140): handling status request
2022-01-06 14:44:53.205531 (Thread-140): 14:44:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78350370>]}
2022-01-06 14:44:53.206058 (Thread-140): sending response (<Response 1544 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:44:53.747703 (Thread-141): handling compile_sql request
2022-01-06 14:44:53.748015 (Thread-141): 14:44:53  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78350e50>]}
2022-01-06 14:44:55.826213 (Thread-141): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:44:55.845928 (MainThread): 14:44:55  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4f8cc452-a25b-4ec4-b7ff-513c70e1544c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58b2564790>]}
2022-01-06 14:44:55.846467 (MainThread): 14:44:55  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:44:55.847041 (Thread-1): 14:44:55  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:44:55.847173 (Thread-1): 14:44:55  Began compiling node rpc.my_new_project.request
2022-01-06 14:44:55.847262 (Thread-1): 14:44:55  Compiling rpc.my_new_project.request
2022-01-06 14:44:55.848442 (Thread-1): 14:44:55  finished collecting timing info
2022-01-06 14:44:55.848570 (Thread-1): 14:44:55  Began executing node rpc.my_new_project.request
2022-01-06 14:44:55.848667 (Thread-1): 14:44:55  finished collecting timing info
2022-01-06 14:44:56.292707 (Thread-142): handling poll request
2022-01-06 14:44:56.293150 (Thread-142): 14:44:56  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782f2130>]}
2022-01-06 14:44:56.294600 (Thread-142): sending response (<Response 5736 bytes [200 OK]>) to 10.0.26.21
2022-01-06 14:45:04.243524 (Thread-143): handling status request
2022-01-06 14:45:04.243896 (Thread-143): 14:45:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78350bb0>]}
2022-01-06 14:45:04.244428 (Thread-143): sending response (<Response 1544 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:45:04.674547 (Thread-144): handling compile_sql request
2022-01-06 14:45:04.674912 (Thread-144): 14:45:04  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb8038cd0>]}
2022-01-06 14:45:06.720207 (Thread-144): sending response (<Response 138 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:45:06.745378 (MainThread): 14:45:06  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '173c2128-d304-4efc-b14d-40180975c81c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6979a4ac0>]}
2022-01-06 14:45:06.745872 (MainThread): 14:45:06  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:45:06.746410 (Thread-1): 14:45:06  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:45:06.746537 (Thread-1): 14:45:06  Began compiling node rpc.my_new_project.request
2022-01-06 14:45:06.746625 (Thread-1): 14:45:06  Compiling rpc.my_new_project.request
2022-01-06 14:45:06.749102 (Thread-1): 14:45:06  finished collecting timing info
2022-01-06 14:45:06.749257 (Thread-1): 14:45:06  Began executing node rpc.my_new_project.request
2022-01-06 14:45:06.749354 (Thread-1): 14:45:06  finished collecting timing info
2022-01-06 14:45:07.037852 (Thread-145): handling poll request
2022-01-06 14:45:07.038297 (Thread-145): 14:45:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782f2e50>]}
2022-01-06 14:45:07.039375 (Thread-145): sending response (<Response 8440 bytes [200 OK]>) to 10.0.1.95
2022-01-06 14:45:15.362791 (Thread-146): handling status request
2022-01-06 14:45:15.363159 (Thread-146): 14:45:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782fa100>]}
2022-01-06 14:45:15.363695 (Thread-146): sending response (<Response 1544 bytes [200 OK]>) to 10.0.35.75
2022-01-06 14:45:15.697554 (Thread-147): handling run_sql request
2022-01-06 14:45:15.697829 (Thread-147): 14:45:15  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782fa400>]}
2022-01-06 14:45:17.749128 (Thread-147): sending response (<Response 138 bytes [200 OK]>) to 10.0.2.195
2022-01-06 14:45:17.774342 (MainThread): 14:45:17  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd1af0cb1-dbf9-49ec-87fe-23143873e50c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0588d2820>]}
2022-01-06 14:45:17.774847 (MainThread): 14:45:17  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:45:17.775428 (Thread-1): 14:45:17  Acquiring new redshift connection "rpc.my_new_project.request"
2022-01-06 14:45:17.775557 (Thread-1): 14:45:17  Began compiling node rpc.my_new_project.request
2022-01-06 14:45:17.775647 (Thread-1): 14:45:17  Compiling rpc.my_new_project.request
2022-01-06 14:45:17.778165 (Thread-1): 14:45:17  finished collecting timing info
2022-01-06 14:45:17.778307 (Thread-1): 14:45:17  Began executing node rpc.my_new_project.request
2022-01-06 14:45:17.778405 (Thread-1): 14:45:17  Using redshift connection "rpc.my_new_project.request"
2022-01-06 14:45:17.778479 (Thread-1): 14:45:17  On rpc.my_new_project.request: 

with customers as (
    select * from "dev"."dbt_nobodozie"."stg_customers"
),
orders as (
    select * from "dev"."dbt_nobodozie"."stg_orders"
),
customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
limit 500
/* limit added automatically by dbt cloud */
2022-01-06 14:45:17.778556 (Thread-1): 14:45:17  Opening a new connection, currently in state init
2022-01-06 14:45:17.778633 (Thread-1): 14:45:17  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:45:17.799287 (Thread-1): 14:45:17  Postgres adapter: Postgres error: relation "dbt_nobodozie.stg_customers" does not exist

2022-01-06 14:45:17.799442 (Thread-1): 14:45:17  finished collecting timing info
2022-01-06 14:45:17.799560 (Thread-1): 14:45:17  On rpc.my_new_project.request: Close
2022-01-06 14:45:17.799757 (Thread-1): Got an exception: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 59, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "dbt_nobodozie.stg_customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 361, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 314, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 403, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 225, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 127, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/sql/connections.py", line 83, in add_query
    return connection, cursor
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/postgres/connections.py", line 70, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error
  relation "dbt_nobodozie.stg_customers" does not exist
2022-01-06 14:45:17.800830 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n    select * from {{ ref(\'stg_customers\')}}\n),\norders as (\n    select * from {{ ref(\'stg_orders\')}}\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\norders as (\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/task/sql_commands.py", line 147, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 377, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt_rpc/rpc/node_runners.py", line 56, in error_result
    raise error
dbt_rpc.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  relation "dbt_nobodozie.stg_customers" does not exist', 'raw_sql': '{{ config (\n    materialized="table"\n)}}\n\nwith customers as (\n    select * from {{ ref(\'stg_customers\')}}\n),\norders as (\n    select * from {{ ref(\'stg_orders\')}}\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\nwith customers as (\n    select * from "dev"."dbt_nobodozie"."stg_customers"\n),\norders as (\n    select * from "dev"."dbt_nobodozie"."stg_orders"\n),\ncustomer_orders as (\n\n    select\n        customer_id,\n\n        min(order_date) as first_order_date,\n        max(order_date) as most_recent_order_date,\n        count(order_id) as number_of_orders\n\n    from orders\n\n    group by 1\n\n),\n\n\nfinal as (\n\n    select\n        customers.customer_id,\n        customers.first_name,\n        customers.last_name,\n        customer_orders.first_order_date,\n        customer_orders.most_recent_order_date,\n        coalesce(customer_orders.number_of_orders, 0) as number_of_orders\n\n    from customers\n\n    left join customer_orders using (customer_id)\n\n)\n\nselect * from final\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2022-01-06 14:45:18.161630 (Thread-148): handling poll request
2022-01-06 14:45:18.162086 (Thread-148): 14:45:18  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78301640>]}
2022-01-06 14:45:18.162907 (Thread-148): sending response (<Response 14619 bytes [200 OK]>) to 10.0.16.124
2022-01-06 14:47:07.010943 (Thread-149): handling status request
2022-01-06 14:47:07.012365 (Thread-149): 14:47:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78301b50>]}
2022-01-06 14:47:07.012914 (Thread-149): sending response (<Response 1544 bytes [200 OK]>) to 10.0.5.191
2022-01-06 14:47:07.270683 (Thread-150): handling status request
2022-01-06 14:47:07.271110 (Thread-150): 14:47:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78301e20>]}
2022-01-06 14:47:07.271597 (Thread-150): sending response (<Response 1544 bytes [200 OK]>) to 10.0.40.203
2022-01-06 14:47:07.396335 (Thread-151): handling cli_args request
2022-01-06 14:47:07.396587 (Thread-151): 14:47:07  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff7830c070>]}
2022-01-06 14:47:09.462996 (Thread-151): sending response (<Response 138 bytes [200 OK]>) to 10.0.25.31
2022-01-06 14:47:09.551382 (MainThread): 14:47:09  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
2022-01-06 14:47:09.551782 (MainThread): 14:47:09  Partial parsing enabled, no changes found, skipping parsing
2022-01-06 14:47:09.557359 (MainThread): 14:47:09  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e198e5c9-e30f-4ddc-abeb-be8ec4a6af63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70a33f4d90>]}
2022-01-06 14:47:09.582250 (MainThread): 14:47:09  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e198e5c9-e30f-4ddc-abeb-be8ec4a6af63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70a34945e0>]}
2022-01-06 14:47:09.582486 (MainThread): 14:47:09  Found 5 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
2022-01-06 14:47:09.583502 (MainThread): 14:47:09  
2022-01-06 14:47:09.583769 (MainThread): 14:47:09  Acquiring new redshift connection "master"
2022-01-06 14:47:09.584763 (ThreadPoolExecutor-0_0): 14:47:09  Acquiring new redshift connection "list_dev"
2022-01-06 14:47:09.594905 (ThreadPoolExecutor-0_0): 14:47:09  Using redshift connection "list_dev"
2022-01-06 14:47:09.595009 (ThreadPoolExecutor-0_0): 14:47:09  On list_dev: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
  
2022-01-06 14:47:09.595093 (ThreadPoolExecutor-0_0): 14:47:09  Opening a new connection, currently in state init
2022-01-06 14:47:09.595175 (ThreadPoolExecutor-0_0): 14:47:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:47:09.615304 (ThreadPoolExecutor-0_0): 14:47:09  SQL status: SELECT in 0.02 seconds
2022-01-06 14:47:09.616348 (ThreadPoolExecutor-0_0): 14:47:09  On list_dev: Close
2022-01-06 14:47:09.617471 (ThreadPoolExecutor-1_0): 14:47:09  Acquiring new redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:47:09.623849 (ThreadPoolExecutor-1_0): 14:47:09  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:47:09.623950 (ThreadPoolExecutor-1_0): 14:47:09  On list_dev_dbt_nobodozie: BEGIN
2022-01-06 14:47:09.624032 (ThreadPoolExecutor-1_0): 14:47:09  Opening a new connection, currently in state closed
2022-01-06 14:47:09.624109 (ThreadPoolExecutor-1_0): 14:47:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:47:09.647075 (ThreadPoolExecutor-1_0): 14:47:09  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:47:09.647188 (ThreadPoolExecutor-1_0): 14:47:09  Using redshift connection "list_dev_dbt_nobodozie"
2022-01-06 14:47:09.647264 (ThreadPoolExecutor-1_0): 14:47:09  On list_dev_dbt_nobodozie: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "list_dev_dbt_nobodozie"} */
select
      'dev' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_nobodozie'
    union all
    select
      'dev' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_nobodozie'
  
2022-01-06 14:47:09.658688 (ThreadPoolExecutor-1_0): 14:47:09  SQL status: SELECT in 0.01 seconds
2022-01-06 14:47:09.659721 (ThreadPoolExecutor-1_0): 14:47:09  On list_dev_dbt_nobodozie: ROLLBACK
2022-01-06 14:47:09.661498 (ThreadPoolExecutor-1_0): 14:47:09  On list_dev_dbt_nobodozie: Close
2022-01-06 14:47:09.665112 (MainThread): 14:47:09  Using redshift connection "master"
2022-01-06 14:47:09.665251 (MainThread): 14:47:09  On master: BEGIN
2022-01-06 14:47:09.665334 (MainThread): 14:47:09  Opening a new connection, currently in state init
2022-01-06 14:47:09.665411 (MainThread): 14:47:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:47:09.689520 (MainThread): 14:47:09  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:47:09.689631 (MainThread): 14:47:09  Using redshift connection "master"
2022-01-06 14:47:09.689707 (MainThread): 14:47:09  On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-06 14:47:09.718670 (MainThread): 14:47:09  SQL status: SELECT in 0.03 seconds
2022-01-06 14:47:09.719665 (MainThread): 14:47:09  On master: ROLLBACK
2022-01-06 14:47:09.721567 (MainThread): 14:47:09  Using redshift connection "master"
2022-01-06 14:47:09.721672 (MainThread): 14:47:09  On master: BEGIN
2022-01-06 14:47:09.725186 (MainThread): 14:47:09  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:47:09.725333 (MainThread): 14:47:09  On master: COMMIT
2022-01-06 14:47:09.725410 (MainThread): 14:47:09  Using redshift connection "master"
2022-01-06 14:47:09.725493 (MainThread): 14:47:09  On master: COMMIT
2022-01-06 14:47:09.727209 (MainThread): 14:47:09  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:47:09.727315 (MainThread): 14:47:09  On master: Close
2022-01-06 14:47:09.727711 (MainThread): 14:47:09  Concurrency: 4 threads (target='default')
2022-01-06 14:47:09.727828 (MainThread): 14:47:09  
2022-01-06 14:47:09.730076 (Thread-1): 14:47:09  Began running node model.my_new_project.dim_customers
2022-01-06 14:47:09.730351 (Thread-1): 14:47:09  1 of 3 START table model dbt_nobodozie.dim_customers............................ [RUN]
2022-01-06 14:47:09.730595 (Thread-1): 14:47:09  Acquiring new redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:09.730690 (Thread-1): 14:47:09  Began compiling node model.my_new_project.dim_customers
2022-01-06 14:47:09.730790 (Thread-1): 14:47:09  Compiling model.my_new_project.dim_customers
2022-01-06 14:47:09.732984 (Thread-1): 14:47:09  Writing injected SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:47:09.733254 (Thread-2): 14:47:09  Began running node model.my_new_project.my_first_dbt_model
2022-01-06 14:47:09.733496 (Thread-2): 14:47:09  2 of 3 START table model dbt_nobodozie.my_first_dbt_model....................... [RUN]
2022-01-06 14:47:09.733755 (Thread-2): 14:47:09  Acquiring new redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:09.733846 (Thread-2): 14:47:09  Began compiling node model.my_new_project.my_first_dbt_model
2022-01-06 14:47:09.733930 (Thread-2): 14:47:09  Compiling model.my_new_project.my_first_dbt_model
2022-01-06 14:47:09.735984 (Thread-2): 14:47:09  Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:09.749039 (Thread-1): 14:47:09  finished collecting timing info
2022-01-06 14:47:09.749188 (Thread-1): 14:47:09  Began executing node model.my_new_project.dim_customers
2022-01-06 14:47:09.754162 (Thread-2): 14:47:09  finished collecting timing info
2022-01-06 14:47:09.754348 (Thread-2): 14:47:09  Began executing node model.my_new_project.my_first_dbt_model
2022-01-06 14:47:09.815886 (Thread-2): 14:47:09  Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:09.818680 (Thread-1): 14:47:09  Writing runtime SQL for node "model.my_new_project.dim_customers"
2022-01-06 14:47:09.833567 (Thread-2): 14:47:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:09.833708 (Thread-2): 14:47:09  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:47:09.833801 (Thread-2): 14:47:09  Opening a new connection, currently in state init
2022-01-06 14:47:09.833884 (Thread-2): 14:47:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:47:09.834296 (Thread-1): 14:47:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:09.834415 (Thread-1): 14:47:09  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:47:09.834499 (Thread-1): 14:47:09  Opening a new connection, currently in state closed
2022-01-06 14:47:09.834578 (Thread-1): 14:47:09  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:47:09.860592 (Thread-2): 14:47:09  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:47:09.860742 (Thread-2): 14:47:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:09.860824 (Thread-2): 14:47:09  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table
    "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp"
    
    
    
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-06 14:47:09.861249 (Thread-1): 14:47:09  SQL status: BEGIN in 0.03 seconds
2022-01-06 14:47:09.861401 (Thread-1): 14:47:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:09.861489 (Thread-1): 14:47:09  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */


  create  table
    "dev"."dbt_nobodozie"."dim_customers__dbt_tmp"
    
    
    
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-01-06 14:47:09.869755 (Thread-152): handling poll request
2022-01-06 14:47:09.870134 (Thread-152): 14:47:09  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff78312160>]}
2022-01-06 14:47:09.871522 (Thread-152): sending response (<Response 30570 bytes [200 OK]>) to 10.0.35.205
2022-01-06 14:47:09.958590 (Thread-2): 14:47:09  SQL status: SELECT in 0.1 seconds
2022-01-06 14:47:09.964709 (Thread-2): 14:47:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:09.964835 (Thread-2): 14:47:09  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-06 14:47:09.968226 (Thread-2): 14:47:09  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:47:09.970132 (Thread-2): 14:47:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:09.970235 (Thread-2): 14:47:09  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-06 14:47:09.975792 (Thread-2): 14:47:09  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:47:09.985805 (Thread-2): 14:47:09  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:47:09.985909 (Thread-2): 14:47:09  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:09.985985 (Thread-2): 14:47:09  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:47:09.988782 (Thread-1): 14:47:09  SQL status: SELECT in 0.13 seconds
2022-01-06 14:47:09.990721 (Thread-1): 14:47:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:09.990820 (Thread-1): 14:47:09  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers" rename to "dim_customers__dbt_backup"
2022-01-06 14:47:09.997990 (Thread-1): 14:47:09  SQL status: ALTER TABLE in 0.01 seconds
2022-01-06 14:47:10.000793 (Thread-1): 14:47:09  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:10.000907 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
alter table "dev"."dbt_nobodozie"."dim_customers__dbt_tmp" rename to "dim_customers"
2022-01-06 14:47:10.003841 (Thread-1): 14:47:10  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:47:10.005254 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:47:10.005378 (Thread-1): 14:47:10  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:10.005488 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:47:10.046537 (Thread-2): 14:47:10  SQL status: COMMIT in 0.06 seconds
2022-01-06 14:47:10.046753 (Thread-2): 14:47:10  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:10.046837 (Thread-2): 14:47:10  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:47:10.047082 (Thread-1): 14:47:10  SQL status: COMMIT in 0.04 seconds
2022-01-06 14:47:10.049123 (Thread-2): 14:47:10  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:47:10.053058 (Thread-2): 14:47:10  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:10.053156 (Thread-2): 14:47:10  On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "dev"."dbt_nobodozie"."my_first_dbt_model__dbt_backup" cascade
2022-01-06 14:47:10.058057 (Thread-2): 14:47:10  SQL status: DROP TABLE in 0.0 seconds
2022-01-06 14:47:10.058687 (Thread-2): 14:47:10  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:47:10.058781 (Thread-2): 14:47:10  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:10.058854 (Thread-2): 14:47:10  On model.my_new_project.my_first_dbt_model: COMMIT
2022-01-06 14:47:10.087982 (Thread-2): 14:47:10  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:47:10.088096 (Thread-2): 14:47:10  Using redshift connection "model.my_new_project.my_first_dbt_model"
2022-01-06 14:47:10.088181 (Thread-2): 14:47:10  On model.my_new_project.my_first_dbt_model: BEGIN
2022-01-06 14:47:10.090368 (Thread-2): 14:47:10  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:47:10.090765 (Thread-2): 14:47:10  finished collecting timing info
2022-01-06 14:47:10.090895 (Thread-2): 14:47:10  On model.my_new_project.my_first_dbt_model: ROLLBACK
2022-01-06 14:47:10.091110 (Thread-1): 14:47:10  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:10.091222 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:47:10.093376 (Thread-1): 14:47:10  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:47:10.094496 (Thread-1): 14:47:10  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:10.094592 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.dim_customers"} */
drop table if exists "dev"."dbt_nobodozie"."dim_customers__dbt_backup" cascade
2022-01-06 14:47:10.094879 (Thread-2): 14:47:10  On model.my_new_project.my_first_dbt_model: Close
2022-01-06 14:47:10.095351 (Thread-2): 14:47:10  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e198e5c9-e30f-4ddc-abeb-be8ec4a6af63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70a031bbb0>]}
2022-01-06 14:47:10.095678 (Thread-2): 14:47:10  2 of 3 OK created table model dbt_nobodozie.my_first_dbt_model.................. [SELECT in 0.36s]
2022-01-06 14:47:10.095809 (Thread-2): 14:47:10  Finished running node model.my_new_project.my_first_dbt_model
2022-01-06 14:47:10.096409 (Thread-4): 14:47:10  Began running node model.my_new_project.my_second_dbt_model
2022-01-06 14:47:10.096651 (Thread-4): 14:47:10  3 of 3 START view model dbt_nobodozie.my_second_dbt_model....................... [RUN]
2022-01-06 14:47:10.096908 (Thread-4): 14:47:10  Acquiring new redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.097000 (Thread-4): 14:47:10  Began compiling node model.my_new_project.my_second_dbt_model
2022-01-06 14:47:10.097088 (Thread-4): 14:47:10  Compiling model.my_new_project.my_second_dbt_model
2022-01-06 14:47:10.099103 (Thread-4): 14:47:10  Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.099945 (Thread-1): 14:47:10  SQL status: DROP TABLE in 0.01 seconds
2022-01-06 14:47:10.100579 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:47:10.100676 (Thread-1): 14:47:10  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:10.100751 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: COMMIT
2022-01-06 14:47:10.111690 (Thread-4): 14:47:10  finished collecting timing info
2022-01-06 14:47:10.111832 (Thread-4): 14:47:10  Began executing node model.my_new_project.my_second_dbt_model
2022-01-06 14:47:10.127361 (Thread-4): 14:47:10  Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.132285 (Thread-1): 14:47:10  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:47:10.132412 (Thread-1): 14:47:10  Using redshift connection "model.my_new_project.dim_customers"
2022-01-06 14:47:10.132490 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: BEGIN
2022-01-06 14:47:10.134531 (Thread-1): 14:47:10  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:47:10.134905 (Thread-1): 14:47:10  finished collecting timing info
2022-01-06 14:47:10.135027 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: ROLLBACK
2022-01-06 14:47:10.136836 (Thread-1): 14:47:10  On model.my_new_project.dim_customers: Close
2022-01-06 14:47:10.137304 (Thread-1): 14:47:10  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e198e5c9-e30f-4ddc-abeb-be8ec4a6af63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70a0319fa0>]}
2022-01-06 14:47:10.137623 (Thread-1): 14:47:10  1 of 3 OK created table model dbt_nobodozie.dim_customers....................... [SELECT in 0.41s]
2022-01-06 14:47:10.137760 (Thread-1): 14:47:10  Finished running node model.my_new_project.dim_customers
2022-01-06 14:47:10.139787 (Thread-4): 14:47:10  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.139902 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:47:10.139987 (Thread-4): 14:47:10  Opening a new connection, currently in state init
2022-01-06 14:47:10.140069 (Thread-4): 14:47:10  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:47:10.195298 (Thread-4): 14:47:10  SQL status: BEGIN in 0.06 seconds
2022-01-06 14:47:10.195414 (Thread-4): 14:47:10  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.195494 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create view "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "dev"."dbt_nobodozie"."my_first_dbt_model"
where id = 1
  ) ;

2022-01-06 14:47:10.200277 (Thread-4): 14:47:10  SQL status: CREATE VIEW in 0.0 seconds
2022-01-06 14:47:10.202200 (Thread-4): 14:47:10  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.202297 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-06 14:47:10.204582 (Thread-4): 14:47:10  SQL status: ALTER TABLE in 0.0 seconds
2022-01-06 14:47:10.205543 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:47:10.205640 (Thread-4): 14:47:10  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.205714 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:47:10.237188 (Thread-4): 14:47:10  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:47:10.237436 (Thread-4): 14:47:10  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.237521 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:47:10.239516 (Thread-4): 14:47:10  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:47:10.240764 (Thread-4): 14:47:10  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.240880 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "user", "target_name": "default", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "dev"."dbt_nobodozie"."my_second_dbt_model__dbt_backup" cascade
2022-01-06 14:47:10.242783 (Thread-4): 14:47:10  SQL status: DROP VIEW in 0.0 seconds
2022-01-06 14:47:10.243450 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:47:10.243545 (Thread-4): 14:47:10  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.243620 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: COMMIT
2022-01-06 14:47:10.269019 (Thread-4): 14:47:10  SQL status: COMMIT in 0.03 seconds
2022-01-06 14:47:10.269129 (Thread-4): 14:47:10  Using redshift connection "model.my_new_project.my_second_dbt_model"
2022-01-06 14:47:10.269203 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: BEGIN
2022-01-06 14:47:10.271228 (Thread-4): 14:47:10  SQL status: BEGIN in 0.0 seconds
2022-01-06 14:47:10.271586 (Thread-4): 14:47:10  finished collecting timing info
2022-01-06 14:47:10.271702 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: ROLLBACK
2022-01-06 14:47:10.273399 (Thread-4): 14:47:10  On model.my_new_project.my_second_dbt_model: Close
2022-01-06 14:47:10.273793 (Thread-4): 14:47:10  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e198e5c9-e30f-4ddc-abeb-be8ec4a6af63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70a2bab8e0>]}
2022-01-06 14:47:10.274088 (Thread-4): 14:47:10  3 of 3 OK created view model dbt_nobodozie.my_second_dbt_model.................. [CREATE VIEW in 0.18s]
2022-01-06 14:47:10.274193 (Thread-4): 14:47:10  Finished running node model.my_new_project.my_second_dbt_model
2022-01-06 14:47:10.275444 (MainThread): 14:47:10  Acquiring new redshift connection "master"
2022-01-06 14:47:10.275590 (MainThread): 14:47:10  Using redshift connection "master"
2022-01-06 14:47:10.275668 (MainThread): 14:47:10  On master: BEGIN
2022-01-06 14:47:10.275745 (MainThread): 14:47:10  Opening a new connection, currently in state closed
2022-01-06 14:47:10.275822 (MainThread): 14:47:10  Redshift adapter: Connecting to Redshift using 'database' credentials
2022-01-06 14:47:10.299555 (MainThread): 14:47:10  SQL status: BEGIN in 0.02 seconds
2022-01-06 14:47:10.299675 (MainThread): 14:47:10  On master: COMMIT
2022-01-06 14:47:10.299752 (MainThread): 14:47:10  Using redshift connection "master"
2022-01-06 14:47:10.299823 (MainThread): 14:47:10  On master: COMMIT
2022-01-06 14:47:10.301495 (MainThread): 14:47:10  SQL status: COMMIT in 0.0 seconds
2022-01-06 14:47:10.301601 (MainThread): 14:47:10  On master: Close
2022-01-06 14:47:10.302000 (MainThread): 14:47:10  
2022-01-06 14:47:10.302115 (MainThread): 14:47:10  Finished running 2 table models, 1 view model in 0.72s.
2022-01-06 14:47:10.302198 (MainThread): 14:47:10  Connection 'master' was properly closed.
2022-01-06 14:47:10.302265 (MainThread): 14:47:10  Connection 'model.my_new_project.dim_customers' was properly closed.
2022-01-06 14:47:10.302327 (MainThread): 14:47:10  Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-01-06 14:47:10.302388 (MainThread): 14:47:10  Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-01-06 14:47:10.348452 (MainThread): 14:47:10  
2022-01-06 14:47:10.348602 (MainThread): 14:47:10  Completed successfully
2022-01-06 14:47:10.348699 (MainThread): 14:47:10  
2022-01-06 14:47:10.348785 (MainThread): 14:47:10  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2022-01-06 14:47:11.206657 (Thread-153): handling poll request
2022-01-06 14:47:11.207052 (Thread-153): 14:47:11  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782d5490>]}
2022-01-06 14:47:11.209104 (Thread-153): sending response (<Response 56626 bytes [200 OK]>) to 10.0.38.111
2022-01-06 14:47:11.831333 (Thread-154): handling status request
2022-01-06 14:47:11.831708 (Thread-154): 14:47:11  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782d5640>]}
2022-01-06 14:47:11.837931 (Thread-154): sending response (<Response 1544 bytes [200 OK]>) to 10.0.21.176
2022-01-06 14:47:11.866090 (Thread-155): handling status request
2022-01-06 14:47:11.866365 (Thread-155): 14:47:11  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782d5a30>]}
2022-01-06 14:47:11.866790 (Thread-155): sending response (<Response 1544 bytes [200 OK]>) to 10.0.15.67
2022-01-06 14:48:37.334229 (Thread-156): handling status request
2022-01-06 14:48:37.335741 (Thread-156): 14:48:37  Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd833f8b5-04bb-4195-84e1-afbfb5ff5e86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7eff782d5c70>]}
2022-01-06 14:48:37.358981 (Thread-156): sending response (<Response 1544 bytes [200 OK]>) to 10.0.40.39
